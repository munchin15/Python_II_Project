title,company_name,location,via,description,job_highlights,related_links,thumbnail,extensions,detected_extensions,job_id
Senior Data Engineer (m/f/d),Sportradar,"  Vienna, Austria   ",via SmartRecruiters Job Search,"Company Description

We‚Äôre the world‚Äôs leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.

Job Description

Sportradar, a global leader in understanding and leveraging the power of sports data for hundreds of business customers around the world, seeks a talented and experienced Data Engineer to join our diverse, highly skilled, and super enthusiastic Automated Content Team and support the team with building quality datasets needed for training deep learning and computer vision models as well as scalable and powerful annotation infrastructure that the team is building for smooth R&D of these models.

Automated Content Team is on a mission to revolutionize and reinvent the way content is created for our products and services and for the various sports enthusiasts that consume... them. We create cutting-edge solutions that drive automated production of video and data. You will be part of the Annotation Domain of our team focused on building advanced Annotation Systems & Datasets.

About the role

The Annotations Systems Squad and Data Chapter play a critical role in Computer Vision (CV) and Deep Learning (DL) development at Sportradar. The team provides data and systems that power Computer Vision and Deep Learning models that are key to our automation strategy. The team partners closely with product leads from the rest of the Automated Content team and provides the human operational rigor required to develop some of the most advanced technology at Sportradar.

As a Data Engineer, you will be responsible and have the engineering skills to make vast data sets more useful and accessible for CV/DL Engineers as well as supporting and coordinating data labeling and annotation campaigns for one or more Squads within our Automated Content Team. Are you ready for this new challenge?

As a member of our team, you will importantly contribute to the ongoing development of revolutionary solutions.

Some of the ongoing projects you will be involved are:
‚Ä¢ Sourcing, transforming, and analyzing data from various systems and making it more useful and accessible for Computer Vision and Deep Learning Engineers.
‚Ä¢ Coordinating data labelling campaigns based on requirements and specifications set by Computer Vision and Deep Learning Engineers, ensuring the highest quality of the data sets needed for model development.
‚Ä¢ Participating in the designing and implementation of the infrastructure for labelling solutions and data management that enable us to create vast data sets in the field of sports.

WHO ARE WE LOOKING FOR?

You are a talented and experienced ‚ÄØdata engineer who enjoys working with data in every conceivable way. Data is your passion! You also like‚ÄØchallenges, strive for continuous improvement and are eager to learn a new thing every day.

On top of being great with data, you are also great at talking with stakeholders, collecting requirements and can coordinate small-size projects that involve internal and external stakeholders. You enjoy collaborating with a diverse group of people‚ÄØand are passionate about what you‚ÄØdo.‚ÄØBesides all of that you are not afraid to go out of your comfort zone.

What will some of your challenges be?
‚Ä¢ Analyze raw data, develop, and maintain datasets and improve data quality and efficiency ‚Äì doing that you will support our common mission to develop best-in-class Computer Vision and Deep Learning models
‚Ä¢ Data modeling for machine learning, analytics, and reporting use cases
‚Ä¢ Perform ad-hoc data analyses, support data scientists and analysts with their data requirements
‚Ä¢ Identify opportunities for data acquisition, combine raw information from different sources and continuously explore ways to enhance data quality and reliability
‚Ä¢ A vital position in coordinating and scoping out projects in a highly cross-functional environment with internal (e.g. ML/CV Engineers & POs) and external stakeholders (Data Labeling partner companies & individual annotators)
‚Ä¢ Independently plan new annotation campaigns from the ground up: assess requirements, define labeling rules, and make sure that proper documentation is at hand
‚Ä¢ Proactively propose strategies for robust data collection at scale, contributing to continuous improvement of the data labeling and annotation efforts
‚Ä¢ Maintain in-depth understanding of relevant data engineering best practices

What professional and personal skills are we looking for in you?
‚Ä¢ University degree in Computer Science, Data Science or related field
‚Ä¢ Strong analytical and problem-solving skills and the ability to combine data from different sources
‚Ä¢ At least 2 years of related professional experience
‚Ä¢ Experience in conducting statistical analysis
‚Ä¢ Proficiency with SQL (PostgreSQL) and Python (sqlalchemy) and you are also familiar with other programming languages in a data engineering context
‚Ä¢ Experience in PostgreSQL database management is a plus
‚Ä¢ Good understanding of data structures
‚Ä¢ Experience working in AWS environment (RDS, S3, Step Functions, EC2)
‚Ä¢ Basic understanding of machine learning methods
‚Ä¢ Detail-oriented and love working with big data sets
‚Ä¢ Autonomous, creative, and a team player
‚Ä¢ Fluent in English (written and spoken)

Your superpowers:
‚Ä¢ PhD or master‚Äôs degree in Computer Science, Data Science or related field
‚Ä¢ Some project management skills will be considered a plus (able to interface with stakeholders, maintain schedule, manage a workflow ...)
‚Ä¢ Hands-on experience in creating algorithms for data analysis
‚Ä¢ Experience in successful managing of data labelling campaigns in the context of machine learning

What do we offer?
‚Ä¢ Competitive salary and benefits
‚Ä¢ Opportunity to work and develop in a dynamic tech environment within an inspiring and fast-growing company
‚Ä¢ A collaborative‚ÄØenvironment of talented and passionate‚ÄØcolleagues from all over the world‚ÄØ(Engineering offices in Europe, Asia and US) delivering innovative products
‚Ä¢ A hybrid working model

Additional Information

Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences","[{'items': ['Company Description\n\nWe‚Äôre the world‚Äôs leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\n\nJob Description\n\nSportradar, a global leader in understanding and leveraging the power of sports data for hundreds of business customers around the world, seeks a talented and experienced Data Engineer to join our diverse, highly skilled, and super enthusiastic Automated Content Team and support the team with building quality datasets needed for training deep learning and computer vision models as well as scalable and powerful annotation infrastructure that the team is building for smooth R&D of these models.\n\nAutomated Content Team is on a mission to revolutionize and reinvent the way content is created for our products and services and for the various sports enthusiasts that consume... them. We create cutting-edge solutions that drive automated production of video and data. You will be part of the Annotation Domain of our team focused on building advanced Annotation Systems & Datasets.\n\nAbout the role\n\nThe Annotations Systems Squad and Data Chapter play a critical role in Computer Vision (CV) and Deep Learning (DL) development at Sportradar. The team provides data and systems that power Computer Vision and Deep Learning models that are key to our automation strategy. The team partners closely with product leads from the rest of the Automated Content team and provides the human operational rigor required to develop some of the most advanced technology at Sportradar.\n\nAs a Data Engineer, you will be responsible and have the engineering skills to make vast data sets more useful and accessible for CV/DL Engineers as well as supporting and coordinating data labeling and annotation campaigns for one or more Squads within our Automated Content Team. Are you ready for this new challenge?\n\nAs a member of our team, you will importantly contribute to the ongoing development of revolutionary solutions.\n\nSome of the ongoing projects you will be involved are:\n‚Ä¢ Sourcing, transforming, and analyzing data from various systems and making it more useful and accessible for Computer Vision and Deep Learning Engineers.\n‚Ä¢ Coordinating data labelling campaigns based on requirements and specifications set by Computer Vision and Deep Learning Engineers, ensuring the highest quality of the data sets needed for model development.\n‚Ä¢ Participating in the designing and implementation of the infrastructure for labelling solutions and data management that enable us to create vast data sets in the field of sports.\n\nWHO ARE WE LOOKING FOR?\n\nYou are a talented and experienced \u202fdata engineer who enjoys working with data in every conceivable way. Data is your passion! You also like\u202fchallenges, strive for continuous improvement and are eager to learn a new thing every day.\n\nOn top of being great with data, you are also great at talking with stakeholders, collecting requirements and can coordinate small-size projects that involve internal and external stakeholders. You enjoy collaborating with a diverse group of people\u202fand are passionate about what you\u202fdo.\u202fBesides all of that you are not afraid to go out of your comfort zone.\n\nWhat will some of your challenges be?\n‚Ä¢ Analyze raw data, develop, and maintain datasets and improve data quality and efficiency ‚Äì doing that you will support our common mission to develop best-in-class Computer Vision and Deep Learning models\n‚Ä¢ Data modeling for machine learning, analytics, and reporting use cases\n‚Ä¢ Perform ad-hoc data analyses, support data scientists and analysts with their data requirements\n‚Ä¢ Identify opportunities for data acquisition, combine raw information from different sources and continuously explore ways to enhance data quality and reliability\n‚Ä¢ A vital position in coordinating and scoping out projects in a highly cross-functional environment with internal (e.g. ML/CV Engineers & POs) and external stakeholders (Data Labeling partner companies & individual annotators)\n‚Ä¢ Independently plan new annotation campaigns from the ground up: assess requirements, define labeling rules, and make sure that proper documentation is at hand\n‚Ä¢ Proactively propose strategies for robust data collection at scale, contributing to continuous improvement of the data labeling and annotation efforts\n‚Ä¢ Maintain in-depth understanding of relevant data engineering best practices\n\nWhat professional and personal skills are we looking for in you?\n‚Ä¢ University degree in Computer Science, Data Science or related field\n‚Ä¢ Strong analytical and problem-solving skills and the ability to combine data from different sources\n‚Ä¢ At least 2 years of related professional experience\n‚Ä¢ Experience in conducting statistical analysis\n‚Ä¢ Proficiency with SQL (PostgreSQL) and Python (sqlalchemy) and you are also familiar with other programming languages in a data engineering context\n‚Ä¢ Experience in PostgreSQL database management is a plus\n‚Ä¢ Good understanding of data structures\n‚Ä¢ Experience working in AWS environment (RDS, S3, Step Functions, EC2)\n‚Ä¢ Basic understanding of machine learning methods\n‚Ä¢ Detail-oriented and love working with big data sets\n‚Ä¢ Autonomous, creative, and a team player\n‚Ä¢ Fluent in English (written and spoken)\n\nYour superpowers:\n‚Ä¢ PhD or master‚Äôs degree in Computer Science, Data Science or related field\n‚Ä¢ Some project management skills will be considered a plus (able to interface with stakeholders, maintain schedule, manage a workflow ...)\n‚Ä¢ Hands-on experience in creating algorithms for data analysis\n‚Ä¢ Experience in successful managing of data labelling campaigns in the context of machine learning\n\nWhat do we offer?\n‚Ä¢ Competitive salary and benefits\n‚Ä¢ Opportunity to work and develop in a dynamic tech environment within an inspiring and fast-growing company\n‚Ä¢ A collaborative\u202fenvironment of talented and passionate\u202fcolleagues from all over the world\u202f(Engineering offices in Europe, Asia and US) delivering innovative products\n‚Ä¢ A hybrid working model\n\nAdditional Information\n\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences']}]","[{'link': 'http://sportradar.com/', 'text': 'sportradar.com'}, {'link': 'https://www.google.com/search?hl=en&q=Sportradar&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCOEK', 'text': 'See web results for Sportradar'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS_UXJyALf-Ch_c6AgAYfbJLkAZqV6oiTeUUzRj&s=0,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAobS9mL2QpIiwiaHRpZG9jaWQiOiJlNGZTNmN1alhmb0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzU1VGelRFeEhPVEJ6ZEVSemVGSTJWSE15Ym1kNWNtOXRUR1ZZV0VaSE5XVldPVU5JZFVWaExXOXlVRW93YmxWTGQweFlYMU5NZUZaWVRWWjFhamd5WmpsWVQwVjJVelptWlhCYVoxTk5WREJhWjFwSVQzVkxhR050TW00eGJFRnBUblpNU1ZkeVNrcDVNMEZJWW5WT2VHeEJXamd4TVhoaGFGODJha3QyVVdoUFQyRnFWREpIYzB0MVYyRjFUMVJ6Vms5RFMxbHBjVVJ4ZDIxa2VFWlZiekEzWm05blRrcDZkMVZyVFU1U1RUbE5VUzEyT0VaT09YbFBObXhoVEhsRGRGSlphemd6RWhjM1lreElXa28yYms5bFlXMDFUbTlRTW1ZdGRtZEJOQm9pUVV4RlV6bDFUbk40VVZkd2EwVkVMWEZHYVZac1IwOXRSRTB4ZG1oT1JqZFRRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgb24gU21hcnRSZWNydWl0ZXJzIEpvYiBTZWFyY2giLCJsaW5rIjoiaHR0cHM6Ly9qb2JzLnNtYXJ0cmVjcnVpdGVycy5jb20vU3BvcnRyYWRhci83NDM5OTk5MTA2MTgyMjMtc2VuaW9yLWRhdGEtZW5naW5lZXItbS1mLWQtP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer (remote from EU),PriceHubble, Anywhere ,via Jobs By Workable,"About PriceHubble

PriceHubble is a PropTech company with over 200 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, and Tokyo. We have a startup environment, low bureaucracy, an international team and business, and are backed by world-class investors.

Your role

You will be part of the Data Products team, responsible for building the large scale data transformation infrastructure and engineering that delivers several of the team‚Äôs data products.

As a Data Engineer, you will have a key role in helping to design and deliver efficient and scalable data products. These products will directly integrate in our customer workflows... as well as support key functions of the applications we offer them, and you will have a direct hand in ensuring they are trustworthy, versatile, and deliver value to our customers.

You have the technical expertise to contribute to the product and maintain optimal delivery efficiency. You are curious to deeply understand the impact of the product in the organization and the value it delivers to PriceHubble clients and the real-estate industry.

You will strive at PriceHubble and in the Data practice if you have great empathy and team mindset, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems .

Your daily activities
‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble‚Äôs processes and the activities of PriceHubble‚Äôs customers
‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products
‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases
‚Ä¢ Leverage the cutting edge of the industry‚Äôs best practices and technology in data design and management to continuously improve the quality and efficiency of our data products
‚Ä¢ Participate in improving and expanding the teams‚Äô data and engineering standards, and support peers and more junior engineers on their application

Your mindset
‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.
‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.
‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.
‚Ä¢ BSc or MSc in computer science or related fields.
‚Ä¢ 3+ years practice of agile methodologies and devops methods.
‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.
‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).
‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).

Your abilities
‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.
‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.
‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.
‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.
‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.

Join an ambitious and hungry team and enjoy the following benefits:

üí∞ Competitive salary because we always want to attract the best talents.

üìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.

üè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.

üïì Flexible working hours and work life balance","[{'items': ['About PriceHubble\n\nPriceHubble is a PropTech company with over 200 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, and Tokyo. We have a startup environment, low bureaucracy, an international team and business, and are backed by world-class investors.\n\nYour role\n\nYou will be part of the Data Products team, responsible for building the large scale data transformation infrastructure and engineering that delivers several of the team‚Äôs data products.\n\nAs a Data Engineer, you will have a key role in helping to design and deliver efficient and scalable data products. These products will directly integrate in our customer workflows... as well as support key functions of the applications we offer them, and you will have a direct hand in ensuring they are trustworthy, versatile, and deliver value to our customers.\n\nYou have the technical expertise to contribute to the product and maintain optimal delivery efficiency. You are curious to deeply understand the impact of the product in the organization and the value it delivers to PriceHubble clients and the real-estate industry.\n\nYou will strive at PriceHubble and in the Data practice if you have great empathy and team mindset, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems .\n\nYour daily activities\n‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble‚Äôs processes and the activities of PriceHubble‚Äôs customers\n‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products\n‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases\n‚Ä¢ Leverage the cutting edge of the industry‚Äôs best practices and technology in data design and management to continuously improve the quality and efficiency of our data products\n‚Ä¢ Participate in improving and expanding the teams‚Äô data and engineering standards, and support peers and more junior engineers on their application\n\nYour mindset\n‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.\n‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.\n‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.\n‚Ä¢ BSc or MSc in computer science or related fields.\n‚Ä¢ 3+ years practice of agile methodologies and devops methods.\n‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.\n‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).\n‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).\n\nYour abilities\n‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.\n‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.\n‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.\n‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.\n‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.\n\nJoin an ambitious and hungry team and enjoy the following benefits:\n\nüí∞ Competitive salary because we always want to attract the best talents.\n\nüìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.\n\nüè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.\n\nüïì Flexible working hours and work life balance']}]","[{'link': 'http://pricehubble.com/', 'text': 'pricehubble.com'}, {'link': 'https://www.google.com/search?hl=en&q=PriceHubble&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCJQL', 'text': 'See web results for PriceHubble'}]",,"['12 days ago', 'Work from home', 'Full-time']","{'posted_at': '12 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAocmVtb3RlIGZyb20gRVUpIiwiaHRpZG9jaWQiOiIyZjNhTUNUM1dPQUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzUzNwU1QxcGlObTUwZWtKU1RGWXlNV2d0ZWtOTFZqaG5VV05LZFhoaWJtcFpWelZYUWpWcU1WQnRRVUZUV0c1dFpraEZNWE5DV1VadE1FUlNabFJtWjBGSGRrc3RSR3hOY1c5NWJrUnNSVzVOWmxsdlVFTm1kVWRQWmtwd1VuQm5kMDFXZGt3dE9HSk5XRkV0TkZwV2VFSk1SbXBHVUhORlZVOW9TRkpuVG1aT1RXRklOR2hFUzBwYWIwdGxlbGxFZVhoWGNqUm1iekppZG01R04wSjRaREJHUVRoUlpGTXlRMFZPZDNWWU1XbzJVMU15ZUhOWGIweHpWV1ZRVDFSNU1HVkRYMko2RWhjM1lreElXa28yYms5bFlXMDFUbTlRTW1ZdGRtZEJOQm9pUVV4RlV6bDFVRXc0VVVodVdsUlBVM2hFVEdocFozSndXREJqV0ZCUWFsWnhVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gSm9icyBCeSBXb3JrYWJsZSIsImxpbmsiOiJodHRwczovL2FwcGx5LndvcmthYmxlLmNvbS9wcmljZWh1YmJsZS9qLzVCOEU3NTlFQkYvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Job in Germany: Data Engineer (w/m/d),KBV Kassen√§rztliche Bundesvereinigung,"  Vienna, Austria   ",via Recruit.net,"Join us in shaping the future of healthcare The National Association of Statutory Health Insurance Physicians (KBV), as a leading public institution, ensures on a daily basis that the approximately 73 million people with statutory health insurance receive the same high-quality medical care throughout Germany. More than 100,000 practices work with IT designed, developed or certified by the Kassen√§rztliche Bundesvereinigung. For our largest department IT and digitization in the center of Berlin, we are looking for a senior consultant (m/f) for an unlimited period of time as soon as possible. Data Engineer (f/m/d) With your expertise, you will contribute to fail-safe software that saves lives in the event of an emergency in the smooth operation of practices for more than 73 million people with statutory health insurance. Your tasks: You will model and implement Business Intelligence (BI) solutions based on Qracle Exadata and Microstrategy. You plan and accompany updates, installations... and configurations of the BI software You drive controls to increase data quality / validity You support the planning and implementation of process optimizations in the area of data management You coordinate requirements in the context of data analysis with the departments and advise and accompany them professionally in the use of health data You will implement complex data analyses and drive the development of dashboards and automated feedback reports on your own responsibility You implement solutions designed by you up to the roll-out Your profile: You have a degree in computer science or comparable field of study Good understanding of DWH and BI architectures. Experience working with BI and database technologies and good SQL and Python skills. Knowledge of reporting and data visualization Good knowledge of data analysis, data modeling and data integration. Solution-oriented mindset, creativity and high analytical understanding. Distinct team orientation Experience in the health care sector is advantageous Language skills (CEFR level): English as well as German at least C1 We offer: Agile combination: You enjoy the advantages of a secure workplace and at the same time operate in an innovative IT environment of system house and service provider. Early riser or late riser? Your working hours you can flexibly through mobile working and our flexitime model arrange Compensation: We appreciate your work with an attractive payment Professional development: We promote you with suitable training in our in-house academy or with external providers Other benefits: company pension plan, canteen, sports facilities, a day care center in the house and subsidy for the company ticket are just a few examples KBV ensures the professional equality of women and men. Severely disabled people are given special consideration in case of equal suitability. The position is suitable for staffing with part-time employees in principle. Have we aroused your interest? Then send us your application documents summarized into a PDF document of max. 8 MB by 21.08.2023 via our online application form. More info at https://it-karriere.kbv.de. We look forward to receiving your application","[{'items': ['Join us in shaping the future of healthcare The National Association of Statutory Health Insurance Physicians (KBV), as a leading public institution, ensures on a daily basis that the approximately 73 million people with statutory health insurance receive the same high-quality medical care throughout Germany. More than 100,000 practices work with IT designed, developed or certified by the Kassen√§rztliche Bundesvereinigung. For our largest department IT and digitization in the center of Berlin, we are looking for a senior consultant (m/f) for an unlimited period of time as soon as possible. Data Engineer (f/m/d) With your expertise, you will contribute to fail-safe software that saves lives in the event of an emergency in the smooth operation of practices for more than 73 million people with statutory health insurance. Your tasks: You will model and implement Business Intelligence (BI) solutions based on Qracle Exadata and Microstrategy. You plan and accompany updates, installations... and configurations of the BI software You drive controls to increase data quality / validity You support the planning and implementation of process optimizations in the area of data management You coordinate requirements in the context of data analysis with the departments and advise and accompany them professionally in the use of health data You will implement complex data analyses and drive the development of dashboards and automated feedback reports on your own responsibility You implement solutions designed by you up to the roll-out Your profile: You have a degree in computer science or comparable field of study Good understanding of DWH and BI architectures. Experience working with BI and database technologies and good SQL and Python skills. Knowledge of reporting and data visualization Good knowledge of data analysis, data modeling and data integration. Solution-oriented mindset, creativity and high analytical understanding. Distinct team orientation Experience in the health care sector is advantageous Language skills (CEFR level): English as well as German at least C1 We offer: Agile combination: You enjoy the advantages of a secure workplace and at the same time operate in an innovative IT environment of system house and service provider. Early riser or late riser? Your working hours you can flexibly through mobile working and our flexitime model arrange Compensation: We appreciate your work with an attractive payment Professional development: We promote you with suitable training in our in-house academy or with external providers Other benefits: company pension plan, canteen, sports facilities, a day care center in the house and subsidy for the company ticket are just a few examples KBV ensures the professional equality of women and men. Severely disabled people are given special consideration in case of equal suitability. The position is suitable for staffing with part-time employees in principle. Have we aroused your interest? Then send us your application documents summarized into a PDF document of max. 8 MB by 21.08.2023 via our online application form. More info at https://it-karriere.kbv.de. We look forward to receiving your application']}]","[{'link': 'http://www.kbv.de/', 'text': 'kbv.de'}, {'link': 'https://www.google.com/search?hl=en&q=KBV+Kassen%C3%A4rztliche+Bundesvereinigung&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCMgL', 'text': 'See web results for KBV Kassen√§rztliche Bundesvereinigung'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJMMSM3JVIY8PKn3JqstTUcODytm3gCiug77YSW8Y&s,"['2 days ago', 'Part-time']","{'posted_at': '2 days ago', 'schedule_type': 'Part-time'}",eyJqb2JfdGl0bGUiOiJKb2IgaW4gR2VybWFueTogRGF0YSBFbmdpbmVlciAody9tL2QpIiwiaHRpZG9jaWQiOiIxTmFzNVpydEtoNEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcmNDQ3ZjQlFVMXJNbXhzU1RsR05uRnBNak4zTURoU1ZDMWFSazUxUTFKVmEyTjFXazFQYURkb2VuaFJaRVZCTVZsamVWcFlWa2t6ZVhOUmNHOHRhblJhUVhGZmJrWnBSekl0U0RZNFV5MHpjVUo2YzBGUlR6aHpkbnBpZFVsck9YUllhV0pCTFhsNmRIbHNNRk5IWjJGSlpIVkRSR0ZWU1hsV1MweG5TVGc0YmpkbWJVRXpRWFpsUTA1R056UmtZMmRFUjJzM1RXNVlaVE5LY0dkRGEwZGFlRVpKZDJoQ1YyOUNZVXhaWWw5RGMxTjRZVW8yUXpSV1JYWXhOR1pYWkU0MFNrSTBMV0ZPUW5NNVpIRlBjelZITTJOblF6SjRkSEo0VDNFd2NtWjBlbTh0TUZRelZWaExNa1ZCZFdKSWNIWkdkRk5HYmtWRmNUVm5SUklYTjJKTVNGcEtObTVQWldGdE5VNXZVREptTFhablFUUWFJa0ZNUlZNNWRWQjBZVWxWTlZKd1EwaDBjREZ1YWtKVGNVWlZOMXBYU0hSdFRVRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gUmVjcnVpdC5uZXQiLCJsaW5rIjoiaHR0cHM6Ly93d3cucmVjcnVpdC5uZXQvam9iL2RhdGEtZW5naW5lZXItam9icy81NzMwNTUwQTdFMTJENzFCP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (m/f/d),Eversports,"  Vienna, Austria   ",via Eversports-1643036192524.Freshteam.com,"Our hearts are burning for sport in all its facets and for the many opportunities that the digital world brings with it. We at Eversports are an international, dynamic team that works hard, has fun and shares a great vision: ""Make Sports Happen"".

For more insight into our history, incredible team and products, check out our ‚Äòabout us‚Äô page on our website!

OVERVIEW

As a Data Engineer (m/f/d), part of our Core Team in Vienna, you will build and maintain the data infrastructure to enhance the quality of decisions made based on business and customer information. You will have the vital role of educating the engineering team and allowing stakeholders from different departments to effectively use data to gather insights and improve the decision-making process, contributing towards Eversports success.

YOUR TASKS
‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using AWS technologies
‚Ä¢ Collaborate with... stakeholders to understand business objectives and translate them into technical solutions
‚Ä¢ Develop and maintain data models and schema designs that support our business needs
‚Ä¢ Implement data solutions that are scalable, reliable, and optimized for performance
‚Ä¢ Maintain data quality and ensure data consistency across multiple systems and platforms
‚Ä¢ Stay up-to-date with the latest technologies, trends, and best practices in data engineering and data management

YOUR PROFILE
‚Ä¢ Bachelor's or Master's degree in Computer Science, Data Science, or related field
‚Ä¢ 3+ years of experience in data engineering, data warehousing, and/or big data technologies
‚Ä¢ Strong experience with SQL, ETL/ELT, data modeling, and data integration
‚Ä¢ Experience with cloud-based data platforms such as AWS, GCP, or Azure
‚Ä¢ Proficient in one or more programming languages such as JavaScript/Typescript, Python, Java, or Scala
‚Ä¢ Experience with data visualization tools such as AWS QuickSight, Tableau or Looker is a plus
‚Ä¢ Strong analytical and problem-solving skills
‚Ä¢ Strong communication and collaboration skills in English

WHAT WE OFFER
‚Ä¢ Flexible hours and a high degree of personal responsibility
‚Ä¢ Hybrid work setup
‚Ä¢ 35 hour working week
‚Ä¢ Freedom and budget for traveling to meet our amazing team in Amsterdam
‚Ä¢ Freely available budget and extra vacation days for further trainings and self-improvement
‚Ä¢ Monthly budget for sports at Eversports
‚Ä¢ Apple or Windows laptop as well as additional hardware
‚Ä¢ Joint after-work activities and cross-national team events
‚Ä¢ Passionate, international, innovative and, of course, sporty team
‚Ä¢ A beautiful open office in the heart of the city that waits for you to bring out the best of it

And here's the fine print: For this position, we will offer an annual gross salary of min. ‚Ç¨ 55,000 (based on full-time 35h)

At Eversports we acknowledge and value the strength in diversity which is why we have 80 employees from 20 different countries. Alongside our strong value for diversity is our emphasis on respect towards others. Every employee has a voice and the opportunity to contribute towards developing our company. We look forward to receiving your application regardless of your gender, ethnicity, age, disability and sexual orientation.

We look forward to hearing from you","[{'items': ['Our hearts are burning for sport in all its facets and for the many opportunities that the digital world brings with it. We at Eversports are an international, dynamic team that works hard, has fun and shares a great vision: ""Make Sports Happen"".\n\nFor more insight into our history, incredible team and products, check out our ‚Äòabout us‚Äô page on our website!\n\nOVERVIEW\n\nAs a Data Engineer (m/f/d), part of our Core Team in Vienna, you will build and maintain the data infrastructure to enhance the quality of decisions made based on business and customer information. You will have the vital role of educating the engineering team and allowing stakeholders from different departments to effectively use data to gather insights and improve the decision-making process, contributing towards Eversports success.\n\nYOUR TASKS\n‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using AWS technologies\n‚Ä¢ Collaborate with... stakeholders to understand business objectives and translate them into technical solutions\n‚Ä¢ Develop and maintain data models and schema designs that support our business needs\n‚Ä¢ Implement data solutions that are scalable, reliable, and optimized for performance\n‚Ä¢ Maintain data quality and ensure data consistency across multiple systems and platforms\n‚Ä¢ Stay up-to-date with the latest technologies, trends, and best practices in data engineering and data management\n\nYOUR PROFILE\n‚Ä¢ Bachelor\'s or Master\'s degree in Computer Science, Data Science, or related field\n‚Ä¢ 3+ years of experience in data engineering, data warehousing, and/or big data technologies\n‚Ä¢ Strong experience with SQL, ETL/ELT, data modeling, and data integration\n‚Ä¢ Experience with cloud-based data platforms such as AWS, GCP, or Azure\n‚Ä¢ Proficient in one or more programming languages such as JavaScript/Typescript, Python, Java, or Scala\n‚Ä¢ Experience with data visualization tools such as AWS QuickSight, Tableau or Looker is a plus\n‚Ä¢ Strong analytical and problem-solving skills\n‚Ä¢ Strong communication and collaboration skills in English\n\nWHAT WE OFFER\n‚Ä¢ Flexible hours and a high degree of personal responsibility\n‚Ä¢ Hybrid work setup\n‚Ä¢ 35 hour working week\n‚Ä¢ Freedom and budget for traveling to meet our amazing team in Amsterdam\n‚Ä¢ Freely available budget and extra vacation days for further trainings and self-improvement\n‚Ä¢ Monthly budget for sports at Eversports\n‚Ä¢ Apple or Windows laptop as well as additional hardware\n‚Ä¢ Joint after-work activities and cross-national team events\n‚Ä¢ Passionate, international, innovative and, of course, sporty team\n‚Ä¢ A beautiful open office in the heart of the city that waits for you to bring out the best of it\n\nAnd here\'s the fine print: For this position, we will offer an annual gross salary of min. ‚Ç¨ 55,000 (based on full-time 35h)\n\nAt Eversports we acknowledge and value the strength in diversity which is why we have 80 employees from 20 different countries. Alongside our strong value for diversity is our emphasis on respect towards others. Every employee has a voice and the opportunity to contribute towards developing our company. We look forward to receiving your application regardless of your gender, ethnicity, age, disability and sexual orientation.\n\nWe look forward to hearing from you']}]","[{'link': 'http://www.eversport.at/', 'text': 'eversport.at'}, {'link': 'https://www.google.com/search?hl=en&q=Eversports&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCPsL', 'text': 'See web results for Eversports'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTeay1ynp_wSi8ZOO5KVPF_owmS-t6tVELh3O6V&s=0,"['3 days ago', 'Full-time']","{'posted_at': '3 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6ImhrV2xEUHhNNzJjQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTa1IwT1VWVFRGWXphMlZKT1ZaUlVuQXhUMncxTjJobVp6QlZObUZ1WVVaYVRWbEZjbVJXTFVzMFVEZFRPRzE0VjE5RFFtMDBaa0ZNZW5vMFRreGtibU5SZVUxTmVGcFViVzl4U2xSc1JVOUdWbWsyV1RVM2NVRkNNVTlYU25SWWNrNUdiR2hoU0Vwd2QwazVZM0IwZGxCR2FIUm1MVVY0U2tJMmVFZzRMVlJGYjNacmEyUmFMVlZqUjNCbGVtWkVUa3htVFV4SVJGZDZPV2N4TUVWbFUxOVNVRzlTV25sdVlUaExVMUZsUkZoQkVoYzNZa3hJV2tvMmJrOWxZVzAxVG05UU1tWXRkbWRCTkJvaVFVeEZVemwxVG5OSGNIb3paVzlRZFhOcVVtcEJiR1ZPVms5YWVYTndjVzFxVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY183IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEV2ZXJzcG9ydHMtMTY0MzAzNjE5MjUyNC5GcmVzaHRlYW0uY29tIiwibGluayI6Imh0dHBzOi8vZXZlcnNwb3J0cy0xNjQzMDM2MTkyNTI0LmZyZXNodGVhbS5jb20vam9icy9wY2ppZEV5LWU2bHgvRGF0YSUyMEVuZ2luZWVyJTIwKG0lMkZmJTJGZCk/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,Schrankerl GmbH,"  Vienna, Austria   ",via JOIN,"Are you a tech-savvy data enthusiast with a passion for revolutionizing the way people access and enjoy fresh food? Are you excited about leveraging data to improve demand forecasting and meal planning and help reduce food waste? If so, we have an incredible opportunity for you!

Join SCHRANKERL, Austria's most innovative B2B food solution. We provide daily fresh and healthy food to employees of 100+ companies in Vienna and Linz through our cutting-edge smart IoT fridges. Our advanced demand forecasting algorithm eliminates the need for pre-orders by accurately predicting what and how much our clients will eat.

As we continuously strive to enhance our algorithm, we are seeking a talented Data Engineer to take the lead and collaborate closely with a PhD student specializing in this area.

Tasks

As a Data Engineer at SCHRANKERL, your primary focus will be to improve our demand forecasting algorithm for meal planning. You will work alongside a PhD student who is conducting his research... with us, specifically on this topic. Your main responsibilities will include:
‚Ä¢ Enhancing our existing demand forecasting algorithm by leveraging cutting-edge techniques and data engineering practices.
‚Ä¢ Collaborating closely with the PhD student to understand and implement their research findings into our algorithm.
‚Ä¢ Building and maintaining robust data pipelines to support data ingestion, processing, and model training.
‚Ä¢ Working with cross-functional teams to gather data requirements and ensure data quality and integrity.
‚Ä¢ Optimizing data storage and retrieval systems for efficient access to datasets.
‚Ä¢ Continuously monitoring and evaluating the performance of the demand forecasting algorithm, implementing improvements as necessary.

Requirements

To excel in this role, you should have:
‚Ä¢ 2+ years of experience as a Data Engineer or in a similar role.
‚Ä¢ Strong expertise in demand forecasting, predictive modeling, and statistical analysis.
‚Ä¢ Proficiency in programming languages commonly used in data engineering.
‚Ä¢ Proficiency in Python.
‚Ä¢ Experience with big data technologies and cloud-based data platforms.
‚Ä¢ Solid understanding of data modeling, ETL processes, and data warehousing principles.
‚Ä¢ Knowledge of machine learning algorithms and techniques for time series forecasting.
‚Ä¢ Excellent problem-solving and analytical skills.
‚Ä¢ Strong communication skills to collaborate effectively with technical and non-technical stakeholders.
‚Ä¢ Motivation to take ownership of projects and drive them from conception to completion.

Benefits
‚Ä¢ The opportunity to work and grow in an inspiring and fast-growing startup.
‚Ä¢ Direct collaboration with our company founders, benefiting from their expertise and insights.
‚Ä¢ A flat organizational structure where your voice and ideas truly matter.
‚Ä¢ Flexible working arrangements, including the possibility of home office and part-time/flex-time options (e.g., 25-30 hours per week).
‚Ä¢ Competitive salary based on experience.
‚Ä¢ 24/7 access to delicious free food from our own Schrankerl when you're at the office.

If you are passionate about leveraging data to improve demand forecasting and meal planning and want to be at the forefront of innovation in the food industry, apply now! We are excited to meet talented Data Engineers like you","[{'items': [""Are you a tech-savvy data enthusiast with a passion for revolutionizing the way people access and enjoy fresh food? Are you excited about leveraging data to improve demand forecasting and meal planning and help reduce food waste? If so, we have an incredible opportunity for you!\n\nJoin SCHRANKERL, Austria's most innovative B2B food solution. We provide daily fresh and healthy food to employees of 100+ companies in Vienna and Linz through our cutting-edge smart IoT fridges. Our advanced demand forecasting algorithm eliminates the need for pre-orders by accurately predicting what and how much our clients will eat.\n\nAs we continuously strive to enhance our algorithm, we are seeking a talented Data Engineer to take the lead and collaborate closely with a PhD student specializing in this area.\n\nTasks\n\nAs a Data Engineer at SCHRANKERL, your primary focus will be to improve our demand forecasting algorithm for meal planning. You will work alongside a PhD student who is conducting his research... with us, specifically on this topic. Your main responsibilities will include:\n‚Ä¢ Enhancing our existing demand forecasting algorithm by leveraging cutting-edge techniques and data engineering practices.\n‚Ä¢ Collaborating closely with the PhD student to understand and implement their research findings into our algorithm.\n‚Ä¢ Building and maintaining robust data pipelines to support data ingestion, processing, and model training.\n‚Ä¢ Working with cross-functional teams to gather data requirements and ensure data quality and integrity.\n‚Ä¢ Optimizing data storage and retrieval systems for efficient access to datasets.\n‚Ä¢ Continuously monitoring and evaluating the performance of the demand forecasting algorithm, implementing improvements as necessary.\n\nRequirements\n\nTo excel in this role, you should have:\n‚Ä¢ 2+ years of experience as a Data Engineer or in a similar role.\n‚Ä¢ Strong expertise in demand forecasting, predictive modeling, and statistical analysis.\n‚Ä¢ Proficiency in programming languages commonly used in data engineering.\n‚Ä¢ Proficiency in Python.\n‚Ä¢ Experience with big data technologies and cloud-based data platforms.\n‚Ä¢ Solid understanding of data modeling, ETL processes, and data warehousing principles.\n‚Ä¢ Knowledge of machine learning algorithms and techniques for time series forecasting.\n‚Ä¢ Excellent problem-solving and analytical skills.\n‚Ä¢ Strong communication skills to collaborate effectively with technical and non-technical stakeholders.\n‚Ä¢ Motivation to take ownership of projects and drive them from conception to completion.\n\nBenefits\n‚Ä¢ The opportunity to work and grow in an inspiring and fast-growing startup.\n‚Ä¢ Direct collaboration with our company founders, benefiting from their expertise and insights.\n‚Ä¢ A flat organizational structure where your voice and ideas truly matter.\n‚Ä¢ Flexible working arrangements, including the possibility of home office and part-time/flex-time options (e.g., 25-30 hours per week).\n‚Ä¢ Competitive salary based on experience.\n‚Ä¢ 24/7 access to delicious free food from our own Schrankerl when you're at the office.\n\nIf you are passionate about leveraging data to improve demand forecasting and meal planning and want to be at the forefront of innovation in the food industry, apply now! We are excited to meet talented Data Engineers like you""]}]","[{'link': 'https://www.google.com/search?hl=en&q=Schrankerl+GmbH&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCKwM', 'text': 'See web results for Schrankerl GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQl3IdjuWEMSRw3yeNJHMO8syxgqblSiQkDJvDaZUI&s,"['‚Ç¨30K‚Äì‚Ç¨50K a year', 'Full-time']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJHdUVtZDdfeTlQTUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVMXJNbXhzU1dwVk5sTmlVM3BvUm5jMU5YRTBkM1JSWWtaWlJWTXRXalpKTUU5M2NuWk9UbWRaTm5nMGRTMWlhamx3ZFdkMmMwVlpUa000WjNaQ01VMTVabTl4ZGpRek5uQkJjRXBmZHpNNFYySjNZbkV3YVc0MmFEUkJUMlpyVGpoc01WSmhWR1E0ZUY5c1kwcFRPRXBxZURWRlkwYzJhbEZDUzFsMmVsZFNPSEZLU0hKRFVHbE9Na0ZOTFd4bFdqQmZNbVJYUkhoTVdrOHRhazVhYmpOUkVoYzNZa3hJV2tvMmJrOWxZVzAxVG05UU1tWXRkbWRCTkJvaVFVeEZVemwxVG1aSFZGVm5abkkxYmtObVRUZFBUUzFwWW1Sb1ZqZDVkMU5MWnciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY185IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIEpPSU4iLCJsaW5rIjoiaHR0cHM6Ly9qb2luLmNvbS9jb21wYW5pZXMvc2NocmFua2VybC84Nzc0MTI2LWRhdGEtZW5naW5lZXI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Azure Data Engineer (m/f/d),Strabag AG,"  Vienna, Austria   (+2 others)   ",via Stepstone.at,"Progress starts with us.
STRABAG employs around 79,000 people at 700 locations worldwide, working on progress. From building construction and structural engineering, road construction and civil engineering, bridge building and tunnelling, industrial sites and port infrastructure, to building management and project development ‚Äì we are thinking ahead, aiming to become the most innovative and sustainable construction technology group in Europe. Every single one of us plays an important part: together we and our partners complete projects successfully and grow to meet new challenges. Together we achieve great things.

The group unit STRABAG Innovation & Digitalisation acts as an enabler for digitalisation and development projects. In close cooperation with operational colleagues, more than 400 different innovation and digitalisation projects are driven forward.

Application Services & Data Science deals with the strategic (further) development of software products as well as the... future-oriented and targeted handling of data in all corporate areas. We rely on a variety of technical and strategic skills as well as diverse personalities in our teams.

Tasks
‚Ä¢ Design, development, deployment and maintenance of data pipelines for ingestion and processing of data from multiple data sources in the Group's central data lake in the Microsoft Azure Cloud
‚Ä¢ Collaborate extensively with data analysts and data scientists to create scalable solutions for data visualization, data analysis and machine learning tasks
‚Ä¢ Substantial contribution in the further development and operation of the central Microsoft Scale Analytics-based multi-environment cloud platform for Data Science projects at STRABAG
‚Ä¢ Active participation in a highly motivated, innovative SCRUM team of STRABAG Innovation and Digitalization in close coordination with the Data Product Managers, Cloud Engineers and Solution Architect

Requirements
‚Ä¢ Extensive experience with ETL / ELT tools in the cloud, preferably in Microsoft Azure (Synapse Analytics Workspace, Databricks experience an advantage)
‚Ä¢ Solid technical understanding and hands-on experience with modern concepts for data science applications in a cloud context
‚Ä¢ Knowledge of data modeling and proficiency in relevant technologies for data processing (e.g. SQL)
‚Ä¢ Team player, strong communication skills, analytical thinking and structured way of working
‚Ä¢ Very good written and spoken English

We offer
In addition to a secure job, we offer you innovative, technologically challenging projects in an international environment. Take advantage of the opportunity to develop personally and professionally within a friendly, competent team. We encourage flexible working (hours to suit you, choose home or office). The gross annual salary for this position in Austria is starting from EUR 50,000. In addition, we offer an overpayment in line with the market depending on qualifications and experience. In Germany, the payment is governed by Bundesrahmentarifvertrag f√ºr das Baugewerbe. Please upload your application documents (CV, certificates) in English or German. We look forward to hearing from you!

Contact
STRABAG AG
Lisa Rakowsky, Albstadtweg 10, 70567 Stuttgart, +49 711 7883 2690, www.strabag.com
F√ºr diese Position ist ein Pre-Employement Screening vorgesehen. N√§here Informationen dazu auf unserer Karrierewebsite","[{'items': [""Progress starts with us.\nSTRABAG employs around 79,000 people at 700 locations worldwide, working on progress. From building construction and structural engineering, road construction and civil engineering, bridge building and tunnelling, industrial sites and port infrastructure, to building management and project development ‚Äì we are thinking ahead, aiming to become the most innovative and sustainable construction technology group in Europe. Every single one of us plays an important part: together we and our partners complete projects successfully and grow to meet new challenges. Together we achieve great things.\n\nThe group unit STRABAG Innovation & Digitalisation acts as an enabler for digitalisation and development projects. In close cooperation with operational colleagues, more than 400 different innovation and digitalisation projects are driven forward.\n\nApplication Services & Data Science deals with the strategic (further) development of software products as well as the... future-oriented and targeted handling of data in all corporate areas. We rely on a variety of technical and strategic skills as well as diverse personalities in our teams.\n\nTasks\n‚Ä¢ Design, development, deployment and maintenance of data pipelines for ingestion and processing of data from multiple data sources in the Group's central data lake in the Microsoft Azure Cloud\n‚Ä¢ Collaborate extensively with data analysts and data scientists to create scalable solutions for data visualization, data analysis and machine learning tasks\n‚Ä¢ Substantial contribution in the further development and operation of the central Microsoft Scale Analytics-based multi-environment cloud platform for Data Science projects at STRABAG\n‚Ä¢ Active participation in a highly motivated, innovative SCRUM team of STRABAG Innovation and Digitalization in close coordination with the Data Product Managers, Cloud Engineers and Solution Architect\n\nRequirements\n‚Ä¢ Extensive experience with ETL / ELT tools in the cloud, preferably in Microsoft Azure (Synapse Analytics Workspace, Databricks experience an advantage)\n‚Ä¢ Solid technical understanding and hands-on experience with modern concepts for data science applications in a cloud context\n‚Ä¢ Knowledge of data modeling and proficiency in relevant technologies for data processing (e.g. SQL)\n‚Ä¢ Team player, strong communication skills, analytical thinking and structured way of working\n‚Ä¢ Very good written and spoken English\n\nWe offer\nIn addition to a secure job, we offer you innovative, technologically challenging projects in an international environment. Take advantage of the opportunity to develop personally and professionally within a friendly, competent team. We encourage flexible working (hours to suit you, choose home or office). The gross annual salary for this position in Austria is starting from EUR 50,000. In addition, we offer an overpayment in line with the market depending on qualifications and experience. In Germany, the payment is governed by Bundesrahmentarifvertrag f√ºr das Baugewerbe. Please upload your application documents (CV, certificates) in English or German. We look forward to hearing from you!\n\nContact\nSTRABAG AG\nLisa Rakowsky, Albstadtweg 10, 70567 Stuttgart, +49 711 7883 2690, www.strabag.com\nF√ºr diese Position ist ein Pre-Employement Screening vorgesehen. N√§here Informationen dazu auf unserer Karrierewebsite""]}]","[{'link': 'http://www.strabag.com/', 'text': 'strabag.com'}, {'link': 'https://www.google.com/search?hl=en&q=Strabag+AG&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCOAM', 'text': 'See web results for Strabag AG'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcROISjbsqkFl0MiB1EX8WMiYX0ndpZ0Fh5PilaGs0M&s,"['14 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '14 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJBenVyZSBEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6InJYbVlnWW9VMHBrQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTMXBEVG5jdGVWZDVWR2x6WkRkZlZUSkNWVGxJT1d0S1NHOVdRVk42U1V4RU5tNUJTa2s1WkhOYVpXaGZSWGN6TW1oYVVGOWhWamhPV1doZllteGtZelJQTFZsTFlWRlVObXRzZDE5SFNGZHdWbFl4WnpKWFExRnVWVVJ2V2toM2VWbG5lREpwV2t0ZmFsQm5SVlZSZFRsQ2VVMUhVR1ZrY0MxelVWTkphMnQ0U3psMWJWbDJkVXhyZG13eVIybHphamRzTlhaMk9XaEdSSGxEU1VsSWRGbHRibUpZZFhSNWR6QnVhbmhUZWs1c1FtRkVPR3MwYmpVd04yZGhlbTlIWkdKWFZuWk1FaGMzWWt4SVdrbzJiazlsWVcwMVRtOVFNbVl0ZG1kQk5Cb2lRVXhGVXpsMVRrbEpTVjgyTUZkd1ZrdEJiSE0zT1hJeFdYazFSa1U1VEZGUFFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTAiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gU3RlcHN0b25lLmF0IiwibGluayI6Imh0dHBzOi8vd3d3LnN0ZXBzdG9uZS5hdC9zdGVsbGVuYW5nZWJvdGUtLUF6dXJlLURhdGEtRW5naW5lZXItbS1mLWQtU3R1dHRnYXJ0LVZpZW5uYS1Db2xvZ25lLVN0cmFiYWctQUctLTc1NzYyMy1pbmxpbmUuaHRtbD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer (remote from EU),PriceHubble,"  Vienna, Austria   ",via FinTech Belgium Job Board,"About PriceHubble

PriceHubble is a PropTech company with over 200 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, and Tokyo. We have a startup environment, low bureaucracy, an international team and business, and are backed by world-class investors.

Your role

You will be part of the Data Products team, responsible for building the large scale data transformation infrastructure and engineering that delivers several of the team‚Äôs data products.

As a Data Engineer, you will have a key role in helping to design and deliver efficient and scalable data products. These products will directly integrate in our customer workflows... as well as support key functions of the applications we offer them, and you will have a direct hand in ensuring they are trustworthy, versatile, and deliver value to our customers.

You have the technical expertise to contribute to the product and maintain optimal delivery efficiency. You are curious to deeply understand the impact of the product in the organization and the value it delivers to PriceHubble clients and the real-estate industry.

You will strive at PriceHubble and in the Data practice if you have great empathy and team mindset, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems .

Your daily activities
‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble‚Äôs processes and the activities of PriceHubble‚Äôs customers
‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products
‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases
‚Ä¢ Leverage the cutting edge of the industry‚Äôs best practices and technology in data design and management to continuously improve the quality and efficiency of our data products
‚Ä¢ Participate in improving and expanding the teams‚Äô data and engineering standards, and support peers and more junior engineers on their application

Your mindset
‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.
‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.
‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.
‚Ä¢ BSc or MSc in computer science or related fields.
‚Ä¢ 3+ years practice of agile methodologies and devops methods.
‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.
‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).
‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).

Your abilities
‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.
‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.
‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.
‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.
‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.

Join an ambitious and hungry team and enjoy the following benefits:

üí∞ Competitive salary because we always want to attract the best talents.

üìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.

üè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.

üïì Flexible working hours and work life balance","[{'items': ['About PriceHubble\n\nPriceHubble is a PropTech company with over 200 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague, and Tokyo. We have a startup environment, low bureaucracy, an international team and business, and are backed by world-class investors.\n\nYour role\n\nYou will be part of the Data Products team, responsible for building the large scale data transformation infrastructure and engineering that delivers several of the team‚Äôs data products.\n\nAs a Data Engineer, you will have a key role in helping to design and deliver efficient and scalable data products. These products will directly integrate in our customer workflows... as well as support key functions of the applications we offer them, and you will have a direct hand in ensuring they are trustworthy, versatile, and deliver value to our customers.\n\nYou have the technical expertise to contribute to the product and maintain optimal delivery efficiency. You are curious to deeply understand the impact of the product in the organization and the value it delivers to PriceHubble clients and the real-estate industry.\n\nYou will strive at PriceHubble and in the Data practice if you have great empathy and team mindset, you value elegant and highly efficient engineering, and you derive great satisfaction from delivering very reliable and usable systems .\n\nYour daily activities\n‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble‚Äôs processes and the activities of PriceHubble‚Äôs customers\n‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products\n‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases\n‚Ä¢ Leverage the cutting edge of the industry‚Äôs best practices and technology in data design and management to continuously improve the quality and efficiency of our data products\n‚Ä¢ Participate in improving and expanding the teams‚Äô data and engineering standards, and support peers and more junior engineers on their application\n\nYour mindset\n‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.\n‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.\n‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.\n‚Ä¢ BSc or MSc in computer science or related fields.\n‚Ä¢ 3+ years practice of agile methodologies and devops methods.\n‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.\n‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).\n‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).\n\nYour abilities\n‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.\n‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.\n‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.\n‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.\n‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.\n\nJoin an ambitious and hungry team and enjoy the following benefits:\n\nüí∞ Competitive salary because we always want to attract the best talents.\n\nüìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.\n\nüè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.\n\nüïì Flexible working hours and work life balance']}]","[{'link': 'http://pricehubble.com/', 'text': 'pricehubble.com'}, {'link': 'https://www.google.com/search?hl=en&q=PriceHubble&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCJQN', 'text': 'See web results for PriceHubble'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRiPM_FrAxdRplCX4UTgi2WL6EIyBpDWVDZWrWOF0I&s,"['10 days ago', 'Full-time']","{'posted_at': '10 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAocmVtb3RlIGZyb20gRVUpIiwiaHRpZG9jaWQiOiJ5Vkd5ZEZLYVVrd0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzU2tKNFlYVmpSWGsyT1VGbU9FTnRhMkpFTUVscVZGVkRaRFpwVlU1VGMzVnlTazVFZEU5Tk5YUTFhMUJ6VEhNeGFUSlJjVVZsY2tsWVFXTjVUV1pSYm5sQmMzRjBRVjlNZFRKelRtTm9iVTE0U0c1ZllUUmlVV0pyTnpWc1R6bHliVm8xTlRCVFVVeEJYM2wxZDBGRVNEQkxRa2Q1VTJsclNrOHhWRXMzVmxZd0xXeHhYekk1WWt4V2VXRllOMkptTUVscldWbFhVbEJsYmpOaFRIZG1WbmRpT1dadFoxcHNPWGQxU0cxaFpXcFJTbmhPYUZFMU5rNXNZWEV6UzNwcExWaHhkM2h4RWhjM1lreElXa28yYms5bFlXMDFUbTlRTW1ZdGRtZEJOQm9pUVV4RlV6bDFUemhyWTNSc2FrcDVNRmg0VlhsZlFUbGhXRTl3Vmw5VE0wVjNkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEyIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEZpblRlY2ggQmVsZ2l1bSBKb2IgQm9hcmQiLCJsaW5rIjoiaHR0cHM6Ly9jYXJlZXJzLmZpbnRlY2hiZWxnaXVtLmJlL2NvbXBhbmllcy9wcmljZWh1YmJsZS9qb2JzLzI4MDEyOTM1LXNlbmlvci1kYXRhLWVuZ2luZWVyLXJlbW90ZS1mcm9tLWV1P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Job in Germany: Data Engineer / BI Analyst / Power BI Reporting...,HUK COBURG Versicherungsgruppe,"  Vienna, Austria   ",via Recruit.net,"Data Engineer / BI Analyst / Power BI Reporting Specialist:in Full-time, starting immediately in Coburg, temporary for 2 years. Experienced professionals and newcomers will find many attractive challenges with us, in addition to a great team of more than 10,000 nice colleagues and over 770 different job profiles that a modern insurance company faces: Will the car of the future cause fewer accidents? What will old-age provision look like when everyone lives to be 100? We deal with the questions of tomorrow - to provide needs-based coverage for our more than 12 million customers - at our headquarters in Coburg, Upper Franconia, and at our 38 field offices in both the office and the field. What you can look forward to Responsibility for the conception, creation and further development of dashboards for the presentation of relevant KPIs. Continuous optimization of the reporting structure to improve internal processes and control-relevant KPIs. Design u. Implementation of requirements from... the services as well as analysis and optimization of the corresponding ETL processes. Elaboration, further development and optimization of a transparent, highly automated performance monitoring. Cost analysis to control budget compliance and measure actual performance against business plan Measurement of efficiency and effectiveness and preparation of results for different hierarchical levels. Content support for overarching control processes with internal interfaces and contact:inside What you bring with you Completed studies in (business) computer science, economics or a comparable field. First professional experience as a ""Data Engineer"" or in a comparable position in an agile environment desirable Good experience with data visualization tools such as MS Power BI, Tableau, QlikView or similar. Practical knowledge of using ETL tools, such as SQL Server Integration Services (SSIS). Strong enthusiasm for numbers and IT as well as strong affinity for data analysis, modeling, visualization. Strong communication skills, strong ability to self-organize and enjoy working on your own initiative Quick response, decision-making and responsibility with a strong results-oriented approach to work. What we offer Flexible working: Flexible working for us means you adjust your working hours to your circumstances. There is no core or minimum working time with us. Instead, you perform your workload within a defined working time framework - adapted to local requirements if necessary. Thanks to mobile work under certain conditions even up to half of the monthly working time from home or on the road. Family-friendly working: We attach importance to an optimal compatibility of family and career. For us, this includes support for childcare and vacation care, as well as care for relatives, as well as the opportunity to take a management position part-time. Since 2007, the audit berufundfamilie distinguishes us as a family-friendly employer. Results-oriented remuneration: in addition to your twelve monthly salaries, you will receive two collectively agreed special payments each year. And so that performance is also worthwhile, you participate in a performance and results-based remuneration, with the chance to receive more than one additional monthly salary. Your many years of loyalty to the company will also pay off: you will receive an anniversary payment, graded according to your length of service. Lifelong learning: If you are working on the future, you must not remain in yesterday. So that you are always up to date, we promote your professional development measures - internally and externally. However, not only the acquisition of company- or job-specific qualifications is the focus of our training measures, but also the private promotion of individually desired skills - for example, language courses, driving safety training and much more. Healthy work: Keep fit and healthy. We support you with free sports offers in our company-owned sports facilities or a subsidy for your membership in a gym. Particularly active employees can participate in various HUK sports groups in their free time: e.g. running, biking or team sports such as soccer or basketball. Or learn how to integrate a healthy lifestyle into your everyday life, both professionally and privately, in lectures and seminars. And because health also concerns nutrition, enjoy healthy and handmade delicacies in our coffee bars or the company restaurant. Have we piqued your interest? Then apply now If you have any questions, please do not hesitate to contact Ms. Uta Orlam√ºnde under the telephone number 49 9561 96-13483, karrierehuk-coburg.de at your disposal","[{'items': ['Data Engineer / BI Analyst / Power BI Reporting Specialist:in Full-time, starting immediately in Coburg, temporary for 2 years. Experienced professionals and newcomers will find many attractive challenges with us, in addition to a great team of more than 10,000 nice colleagues and over 770 different job profiles that a modern insurance company faces: Will the car of the future cause fewer accidents? What will old-age provision look like when everyone lives to be 100? We deal with the questions of tomorrow - to provide needs-based coverage for our more than 12 million customers - at our headquarters in Coburg, Upper Franconia, and at our 38 field offices in both the office and the field. What you can look forward to Responsibility for the conception, creation and further development of dashboards for the presentation of relevant KPIs. Continuous optimization of the reporting structure to improve internal processes and control-relevant KPIs. Design u. Implementation of requirements from... the services as well as analysis and optimization of the corresponding ETL processes. Elaboration, further development and optimization of a transparent, highly automated performance monitoring. Cost analysis to control budget compliance and measure actual performance against business plan Measurement of efficiency and effectiveness and preparation of results for different hierarchical levels. Content support for overarching control processes with internal interfaces and contact:inside What you bring with you Completed studies in (business) computer science, economics or a comparable field. First professional experience as a ""Data Engineer"" or in a comparable position in an agile environment desirable Good experience with data visualization tools such as MS Power BI, Tableau, QlikView or similar. Practical knowledge of using ETL tools, such as SQL Server Integration Services (SSIS). Strong enthusiasm for numbers and IT as well as strong affinity for data analysis, modeling, visualization. Strong communication skills, strong ability to self-organize and enjoy working on your own initiative Quick response, decision-making and responsibility with a strong results-oriented approach to work. What we offer Flexible working: Flexible working for us means you adjust your working hours to your circumstances. There is no core or minimum working time with us. Instead, you perform your workload within a defined working time framework - adapted to local requirements if necessary. Thanks to mobile work under certain conditions even up to half of the monthly working time from home or on the road. Family-friendly working: We attach importance to an optimal compatibility of family and career. For us, this includes support for childcare and vacation care, as well as care for relatives, as well as the opportunity to take a management position part-time. Since 2007, the audit berufundfamilie distinguishes us as a family-friendly employer. Results-oriented remuneration: in addition to your twelve monthly salaries, you will receive two collectively agreed special payments each year. And so that performance is also worthwhile, you participate in a performance and results-based remuneration, with the chance to receive more than one additional monthly salary. Your many years of loyalty to the company will also pay off: you will receive an anniversary payment, graded according to your length of service. Lifelong learning: If you are working on the future, you must not remain in yesterday. So that you are always up to date, we promote your professional development measures - internally and externally. However, not only the acquisition of company- or job-specific qualifications is the focus of our training measures, but also the private promotion of individually desired skills - for example, language courses, driving safety training and much more. Healthy work: Keep fit and healthy. We support you with free sports offers in our company-owned sports facilities or a subsidy for your membership in a gym. Particularly active employees can participate in various HUK sports groups in their free time: e.g. running, biking or team sports such as soccer or basketball. Or learn how to integrate a healthy lifestyle into your everyday life, both professionally and privately, in lectures and seminars. And because health also concerns nutrition, enjoy healthy and handmade delicacies in our coffee bars or the company restaurant. Have we piqued your interest? Then apply now If you have any questions, please do not hesitate to contact Ms. Uta Orlam√ºnde under the telephone number 49 9561 96-13483, karrierehuk-coburg.de at your disposal']}]","[{'link': 'https://www.google.com/search?hl=en&q=HUK+COBURG+Versicherungsgruppe&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCMYN', 'text': 'See web results for HUK COBURG Versicherungsgruppe'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJMMSM3JVIY8PKn3JqstTUcODytm3gCiug77YSW8Y&s,"['2 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJKb2IgaW4gR2VybWFueTogRGF0YSBFbmdpbmVlciAvIEJJIEFuYWx5c3QgLyBQb3dlciBCSSBSZXBvcnRpbmcgU3BlemlhbGlzdDppbiIsImh0aWRvY2lkIjoiLW1LYlpuTUJ3V01BQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXVJQ0NxSUNRVTFyTW14c1NrbHlRbWwxVUU1M1ZVbzVNalpKYzBkb1NtRnpTVUZpY21GeGRFOXhjRXBmY0dnM09FdENkRXN0WlROM1VHaFZYMnRMWkd4ellqaEJVRGhZVUhab2NDMU9kVEpDY1U5bFkxWm1TMHRWU1hZdFNXSjNWakZpYVRsdk5ubEtOamxwUVhoTGNsbHhSVnB6VjJKWVdHODJVM2hNZDBGNlREVnZla2h3Vkd0c2MwTjJORFZHVnkxS1dVWnBjM1pVWkVOVVVEWjVjR054UTNCTVZXOVJSazlaVVhOM1dsUmFTbmxSY2pFMFdEUjFZamhQTVRsUFpVTnhNbGRaZGtKaE5YaFBiMGRDVlRoNFJrbG1hbUZRYm1ScVExTndZM1ZhUldWQkxUUlhZVkpwUjJ3dGFFRjFNMjF2UlVsUVgxSkxjMUEyZUV4TmNrMTBNMFk0UTIxSFYwbGtSWEZST0RJNFluUnhiRXBZVDJkNVowdEZOSEp5WHpSeFNsYzJaR2NTRnpkaVRFaGFTalp1VDJWaGJUVk9iMUF5WmkxMlowRTBHaUpCVEVWVE9YVlBjMDVwY201WmIwdDVUbFJ6TVdaT2VraDVlV04xT0dORmRUaEIiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBSZWNydWl0Lm5ldCIsImxpbmsiOiJodHRwczovL3d3dy5yZWNydWl0Lm5ldC9qb2IvZGF0YS1lbmdpbmVlci1qb2JzL0UzQzM1N0RGMkUwOTBGQjI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (m/f/x),IMMOFINANZ AG,"  Vienna, Austria   ",via Talent.com,"Data Engineer (m / f / x) IMMOFINANZ is an international real estate company. We offer you the structure of a large corporation, outstanding development opportunities within a modern working environment and a young and inspiring team.

Find out more about IMMOFINANZ and what it means to be part of an international, dynamic organization. See how we design the way towards a new era of real estate development.

Did we catch your eye- read more about the current job offer : YOUR PROFILE
‚Ä¢ Practical experience in the core areas : ETL development, data modeling, advanced SQL, and system integrations, both on premise and in cloud environments
‚Ä¢ Interest in working with MS Azure technologies like Data Lake, Databricks, Data Factory, Synapse, Analysis Services, Power BI and PurView
‚Ä¢ Working experience of DevOps is an advantage
‚Ä¢ Good communication skills and team spirit is highly appreciated
‚Ä¢ Having a service-oriented mindset
‚Ä¢ Very good English skills - German skills are an advantage YOUR... RESPONSIBILITIES
‚Ä¢ Working with Oracle DB, Oracle ODI, Oracle Integration Cloud, MS SQL, MS SSAS, Azure Data Lake, Azure Data Factory, Power BI, etc.
‚Ä¢ Development of concepts and solutions for ETL processes, data models, data integrations and reporting environment
‚Ä¢ Operation, maintenance and continuous improvement of the data warehouse and data integration platform
‚Ä¢ Working with Azure DevOps together with external partners within an agile mindset
‚Ä¢ Active participation in IT projects
‚Ä¢ Technical support for IT application managers and business departments
‚Ä¢ Creation of application documentation for support, operation, and maintenance For this position we offer a market-compliant salary of EUR 3.

850 gross per month. However, an overpay is possible according to qualification and experience. BENEFITS
‚Ä¢ Sixth week of vacation after 3 years in the company
‚Ä¢ Daily meal allowance of EUR 6.00
‚Ä¢ Flexible working hours
‚Ä¢ Free fruit and drinks
‚Ä¢ Free use of the MyClubs app (sports offer)
‚Ä¢ Annual ticket of Wiener Linien or possibility for a garage parking space in the MyHive Vienna Twin Tower
‚Ä¢ Internal and external training and further development opportunities
‚Ä¢ Occupational pension provision
‚Ä¢ Occupational health care
‚Ä¢ Annual health check-up We are looking forward to your application. Please send us your application via our online job portal.

Apply online Contact We are looking forward to your application. Nadine Falkensteiner Apply online Kununu","[{'items': ['Data Engineer (m / f / x) IMMOFINANZ is an international real estate company. We offer you the structure of a large corporation, outstanding development opportunities within a modern working environment and a young and inspiring team.\n\nFind out more about IMMOFINANZ and what it means to be part of an international, dynamic organization. See how we design the way towards a new era of real estate development.\n\nDid we catch your eye- read more about the current job offer : YOUR PROFILE\n‚Ä¢ Practical experience in the core areas : ETL development, data modeling, advanced SQL, and system integrations, both on premise and in cloud environments\n‚Ä¢ Interest in working with MS Azure technologies like Data Lake, Databricks, Data Factory, Synapse, Analysis Services, Power BI and PurView\n‚Ä¢ Working experience of DevOps is an advantage\n‚Ä¢ Good communication skills and team spirit is highly appreciated\n‚Ä¢ Having a service-oriented mindset\n‚Ä¢ Very good English skills - German skills are an advantage YOUR... RESPONSIBILITIES\n‚Ä¢ Working with Oracle DB, Oracle ODI, Oracle Integration Cloud, MS SQL, MS SSAS, Azure Data Lake, Azure Data Factory, Power BI, etc.\n‚Ä¢ Development of concepts and solutions for ETL processes, data models, data integrations and reporting environment\n‚Ä¢ Operation, maintenance and continuous improvement of the data warehouse and data integration platform\n‚Ä¢ Working with Azure DevOps together with external partners within an agile mindset\n‚Ä¢ Active participation in IT projects\n‚Ä¢ Technical support for IT application managers and business departments\n‚Ä¢ Creation of application documentation for support, operation, and maintenance For this position we offer a market-compliant salary of EUR 3.\n\n850 gross per month. However, an overpay is possible according to qualification and experience. BENEFITS\n‚Ä¢ Sixth week of vacation after 3 years in the company\n‚Ä¢ Daily meal allowance of EUR 6.00\n‚Ä¢ Flexible working hours\n‚Ä¢ Free fruit and drinks\n‚Ä¢ Free use of the MyClubs app (sports offer)\n‚Ä¢ Annual ticket of Wiener Linien or possibility for a garage parking space in the MyHive Vienna Twin Tower\n‚Ä¢ Internal and external training and further development opportunities\n‚Ä¢ Occupational pension provision\n‚Ä¢ Occupational health care\n‚Ä¢ Annual health check-up We are looking forward to your application. Please send us your application via our online job portal.\n\nApply online Contact We are looking forward to your application. Nadine Falkensteiner Apply online Kununu']}]","[{'link': 'http://www.immofinanz.com/', 'text': 'immofinanz.com'}, {'link': 'https://www.google.com/search?hl=en&q=IMMOFINANZ+AG&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCPsN', 'text': 'See web results for IMMOFINANZ AG'}]",,"['7 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YveCkiLCJodGlkb2NpZCI6InJIc09ubUNVZWxVQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTVzl1U25KMGIxaG5lVVJ0Tmt3dFRsaFVURlkzVVdac1JtRktZM2cyZDJoUlZ6ZHNPSEZWUzJkVVpEQk1TVFJCZEhCSWRVODVjR3BLYUZvMk0ybDZOSFUxV0Mxd1JYUlRZMGx6UVhOUFNtbG9MVEp6TkhrME1VRkJjWHBRZGsxWVp6WlVhbWQxUlZsQ01GbFZWRlF4ZW1OclEyUmlRekJyUkhCSWJIWjZNMUJoYnpVME1YRjZkVmh6YVdSb2VtZE9SVGhKVTBkSVV6RkxURFpLYjNCRU1XeGFRbFIzYnpWQ1JIVlBRMmwyU0hSM0VoYzNZa3hJV2tvMmJrOWxZVzAxVG05UU1tWXRkbWRCTkJvaVFVeEZVemwxVGtFelVWRmpTWGgyV2pKM2VXb3pOR28xY0ROalVFSkxhMUJIVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBUYWxlbnQuY29tIiwibGluayI6Imh0dHBzOi8vYXQudGFsZW50LmNvbS92aWV3P2lkPTk0MWUzMzVmNjJiZlx1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (gn*),TUEV Austria, Anywhere ,via Indeed,"3.000 People. 30 Countries. #LivingTheFuture.
The independent T√úV AUSTRIA Group operates worldwide with over 3,000 employees in more than 30 countries. We, the leading testing, inspection and certification company, offer sustainable and flexible solutions through technical safety. For the T√úV AUSTRIA Group we are looking for a

T√úV AUSTRIA Data Intelligence is a data science consulting company of the T√úV Austria Group. We develop customized data-driven

AI solutions and support our customers in digitization projects.

Our focus is on the process industry and energy industry.

You are interested in data-driven automation and want to further expand your technology stack in practical use cases?

We are looking for a motivated Data Engineer (gn*) to start as soon as possible. With us you can gain practical experience and actively participate in the development of AI solutions.

If you want to use your IT affinity to drive the digital transformation in European industry together with us... apply as Data Engieer:

Data Engineer (gn*) (Jn. 215489)

Vienna or Klagenfurt

Job Description:
‚Ä¢ In your future job you will strengthen the T√úV AUSTRIA Data Intelligence Team and work together with experienced Data Scientists and Data Engineers.
‚Ä¢ You provide technical consulting services to customers, designing and implementing data engineering solutions with a special focus on ETL processes, AI operations and monitoring.
‚Ä¢ You support TUV teams in their TIC business by automatically processing technical documentation to extract relevant data for the inspection business.
‚Ä¢ You build cloud and on premise platforms for data streaming and online asset condition, data and ML model performance monitoring.
‚Ä¢ You quickly adapt to changing requirements and new technologies in accordance with customer requirements.

Your qualifications:
‚Ä¢ We recruit from all levels of experience (Junior to Senior).
‚Ä¢ You bring relevant work experience or have completed training at university, technical college (or comparable in the relevant departments)
‚Ä¢ You have experience working with data storage solutions (SQL, NoSQL, Blob storages, etc.)
‚Ä¢ You have profound knowledge of Python and an understanding of programming paradigms and design patterns; experience with third party libraries/applications integration.
‚Ä¢ You have an agile, solution oriented mindset and are eager to adapt to new technologies.

Nice to have:
‚Ä¢ Ideally, you have worked with containerization (Docker) and cloud (Azure or AWS) solutions, DevOps solutions and Infrastructure as code.
‚Ä¢ Monitoring and resilient logging designs are part of our daily business.
‚Ä¢ Experience with data warehouse or data lake solutions.
‚Ä¢ Familiarity with the principles of secure software development, Continuous Integration/Continuous Deployment (CI/CD), comprehensive testing strategies, and version control systems (GIT).
‚Ä¢ You will work with Data Scientists and AI solution development teams. AI know-how is a welcome addition to your technical foundation.
‚Ä¢ We rely on JavaScript/TypeScript for frontend implementation and appreciate experience with those programming languages.
‚Ä¢ Experience with processing sensor data and experience with connection of hardware devices and sensors is a valuable bonus.
‚Ä¢ Experience with SAP and the ability to build interfaces for data ingestion is frequently necessary.

We offer:
‚Ä¢ The collective bargain for this position is between ‚Ç¨ 2.854,- and ‚Ç¨ 4.761,- depending on your qualification and experience. We offer a fair overpayment in line with the market.
‚Ä¢ Flexible working environment with free time management and home office
‚Ä¢ A strong focus on your individual further training
‚Ä¢ Challenging and, above all, varied activities in a young and dynamic team with a family environment

You are interested? We‚Äôre looking forward to your online application to Karin Schumeth.

online application

Back to career portal
‚Ä¢ The sign ""gn"" stands for gender neutral. We are open to all people and address all genders equally","[{'items': ['3.000 People. 30 Countries. #LivingTheFuture.\nThe independent T√úV AUSTRIA Group operates worldwide with over 3,000 employees in more than 30 countries. We, the leading testing, inspection and certification company, offer sustainable and flexible solutions through technical safety. For the T√úV AUSTRIA Group we are looking for a\n\nT√úV AUSTRIA Data Intelligence is a data science consulting company of the T√úV Austria Group. We develop customized data-driven\n\nAI solutions and support our customers in digitization projects.\n\nOur focus is on the process industry and energy industry.\n\nYou are interested in data-driven automation and want to further expand your technology stack in practical use cases?\n\nWe are looking for a motivated Data Engineer (gn*) to start as soon as possible. With us you can gain practical experience and actively participate in the development of AI solutions.\n\nIf you want to use your IT affinity to drive the digital transformation in European industry together with us... apply as Data Engieer:\n\nData Engineer (gn*) (Jn. 215489)\n\nVienna or Klagenfurt\n\nJob Description:\n‚Ä¢ In your future job you will strengthen the T√úV AUSTRIA Data Intelligence Team and work together with experienced Data Scientists and Data Engineers.\n‚Ä¢ You provide technical consulting services to customers, designing and implementing data engineering solutions with a special focus on ETL processes, AI operations and monitoring.\n‚Ä¢ You support TUV teams in their TIC business by automatically processing technical documentation to extract relevant data for the inspection business.\n‚Ä¢ You build cloud and on premise platforms for data streaming and online asset condition, data and ML model performance monitoring.\n‚Ä¢ You quickly adapt to changing requirements and new technologies in accordance with customer requirements.\n\nYour qualifications:\n‚Ä¢ We recruit from all levels of experience (Junior to Senior).\n‚Ä¢ You bring relevant work experience or have completed training at university, technical college (or comparable in the relevant departments)\n‚Ä¢ You have experience working with data storage solutions (SQL, NoSQL, Blob storages, etc.)\n‚Ä¢ You have profound knowledge of Python and an understanding of programming paradigms and design patterns; experience with third party libraries/applications integration.\n‚Ä¢ You have an agile, solution oriented mindset and are eager to adapt to new technologies.\n\nNice to have:\n‚Ä¢ Ideally, you have worked with containerization (Docker) and cloud (Azure or AWS) solutions, DevOps solutions and Infrastructure as code.\n‚Ä¢ Monitoring and resilient logging designs are part of our daily business.\n‚Ä¢ Experience with data warehouse or data lake solutions.\n‚Ä¢ Familiarity with the principles of secure software development, Continuous Integration/Continuous Deployment (CI/CD), comprehensive testing strategies, and version control systems (GIT).\n‚Ä¢ You will work with Data Scientists and AI solution development teams. AI know-how is a welcome addition to your technical foundation.\n‚Ä¢ We rely on JavaScript/TypeScript for frontend implementation and appreciate experience with those programming languages.\n‚Ä¢ Experience with processing sensor data and experience with connection of hardware devices and sensors is a valuable bonus.\n‚Ä¢ Experience with SAP and the ability to build interfaces for data ingestion is frequently necessary.\n\nWe offer:\n‚Ä¢ The collective bargain for this position is between ‚Ç¨ 2.854,- and ‚Ç¨ 4.761,- depending on your qualification and experience. We offer a fair overpayment in line with the market.\n‚Ä¢ Flexible working environment with free time management and home office\n‚Ä¢ A strong focus on your individual further training\n‚Ä¢ Challenging and, above all, varied activities in a young and dynamic team with a family environment\n\nYou are interested? We‚Äôre looking forward to your online application to Karin Schumeth.\n\nonline application\n\nBack to career portal\n‚Ä¢ The sign ""gn"" stands for gender neutral. We are open to all people and address all genders equally']}]","[{'link': 'http://www.tuv.at/', 'text': 'tuv.at'}, {'link': 'https://www.google.com/search?hl=en&q=TUEV+Austria&sa=X&ved=0ahUKEwje0fzPgrmAAxVmE1kFHdn_C-AQmJACCLEO', 'text': 'See web results for TUEV Austria'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQewRVCKInOl9aQUV8aJTIXRmEcR4ZZI7veqa2d&s=0,"['6 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChnbiopIiwiaHRpZG9jaWQiOiJYdlJsUF91Ym9tTUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVEVsbWVWQkdla2RuUjNRMWFEVkVkbEJYZFhjNGMybFliMjFEUjNOVk1IVk1NazVJY3pWc1JYQnpVMU10VkdsTWVXZzRkVTAxZURobk1GQk5aVjlaZFRkdWJsQm5OSFZFV0RsdFUzTkxWRkZNUkRsWWFYVjFUREZ6WTBSc1FubEZlVloyYzBSUlEzcEtMVGhWVFVsRmRGOU1iVGRhTTJZeVdIcHhaemxGUVZkaFExRkZTRWhxZFdvd0xUVm9YMHhKYVVKWVQwTjZTazEzZG1WeFRGbzFUVTlwUTJkbmNXNXNNVXREUmpCNVptcGpFaGMzWWt4SVdrbzJiazlsWVcwMVRtOVFNbVl0ZG1kQk5Cb2lRVXhGVXpsMVVGRm5kbEpDTlZwalZYWkhVVXRuUTJWUlpFSnRkR28wUmpReVFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTciLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSW5kZWVkIiwibGluayI6Imh0dHBzOi8vYXQuaW5kZWVkLmNvbS92aWV3am9iP2prPWNkYTFiNGFmOTZmZmMwOGNcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer (f/m/x),Raiffeisen Bank International AG,"  Vienna, Austria   ",via WeAreDevelopers,"Senior Data Engineer (f/m/x), (Senior)

Required skills
‚Ä¢ PostgreSQL
‚Ä¢ Structured Query Language (SQL)
‚Ä¢ Data analysis
‚Ä¢ Data Warehouse
‚Ä¢ Scripting (Bash/Python/Go/Ruby)

Requirements

Your core competencies
‚Ä¢ Several years of working experience with DWH-architecture and ETL-Tools (Pentaho Data Integrator or similar), preferable in Scrum
‚Ä¢ Working experience in Data Analysis and Data Modelling (various models), SQL and DBMS (PostgreSQL)
‚Ä¢ Experience with Reporting- and BI-Tools (Qlik, PowerBI or similar)
‚Ä¢ Knowledge in DevOps, CI/CD, TDD, Containers, VMs, Python
‚Ä¢ Good communication skills in English, German is appreciated

Tasks

Your mission
‚Ä¢ Ad-hoc data analysis and further development of data pipelines, ETL-processes, data warehouse, data-interfaces, reports, and bi-solutions (OLAP, Dashboards)
‚Ä¢ Manage data integration of multiple sources
‚Ä¢ Create Proof-of-concepts, prototypes, and spikes
‚Ä¢ Proactively take care of branching, CI/CD-pipelines, code quality and testing
‚Ä¢ Address... non-functional requirements
‚Ä¢ Coach Junior Developers and exchange and grow your knowledge with other Lead Developers in various areas of Software Development/Data Engineering

Benefits

What's in it for you
‚Ä¢ Work Life Balance: flexible working hours, extensive hybrid working options / work from home
‚Ä¢ Easy Moving: work permit support
‚Ä¢ Top-notch Equipment: modern tools & technologies
‚Ä¢ International Spirit: multi-cultural teams, English as company language, team building events
‚Ä¢ Learning & Agile Working: as part of our DNA & culture
‚Ä¢ Canteen: healthy, tasty, and heavily subsidized
‚Ä¢ Saving: with vouchers / discounts from our staffs' council (eg. supermarket)
‚Ä¢ Further Goodies: free public transport pass, salary account & credit card, gender-neutral parental leave, bilingual company kindergarten etc.
‚Ä¢ Salary: the offered gross yearly salary starts at 60.000 Euro (basis full-time) excluding overtime, depending on experience and qualifications

About Raiffeisen Bank International AG

Did you know that RBI is one of the most popular domestic employers?

Sure: it is also one of the leading banking groups in Austria and CEE. RBI not only shines on the outside, it also has inner values. The banking landscape is changing, as is RBI. Cross-functional teams, quick exchange of knowledge, independent work and creativity are very important. This is the only way for the bank to bring products and services onto the market in this fast-moving time that bring real added value and are therefore in demand. In short, at RBI we shape the future of banking.

We are searching for talented IT experts and enthusiasts to join our teams. We're not just any IT employer, we're the kind that helps you grow, learn, and reach your full potential.

Become part of the RBI family!

We are looking forward to hearing from you","[{'items': [""Senior Data Engineer (f/m/x), (Senior)\n\nRequired skills\n‚Ä¢ PostgreSQL\n‚Ä¢ Structured Query Language (SQL)\n‚Ä¢ Data analysis\n‚Ä¢ Data Warehouse\n‚Ä¢ Scripting (Bash/Python/Go/Ruby)\n\nRequirements\n\nYour core competencies\n‚Ä¢ Several years of working experience with DWH-architecture and ETL-Tools (Pentaho Data Integrator or similar), preferable in Scrum\n‚Ä¢ Working experience in Data Analysis and Data Modelling (various models), SQL and DBMS (PostgreSQL)\n‚Ä¢ Experience with Reporting- and BI-Tools (Qlik, PowerBI or similar)\n‚Ä¢ Knowledge in DevOps, CI/CD, TDD, Containers, VMs, Python\n‚Ä¢ Good communication skills in English, German is appreciated\n\nTasks\n\nYour mission\n‚Ä¢ Ad-hoc data analysis and further development of data pipelines, ETL-processes, data warehouse, data-interfaces, reports, and bi-solutions (OLAP, Dashboards)\n‚Ä¢ Manage data integration of multiple sources\n‚Ä¢ Create Proof-of-concepts, prototypes, and spikes\n‚Ä¢ Proactively take care of branching, CI/CD-pipelines, code quality and testing\n‚Ä¢ Address... non-functional requirements\n‚Ä¢ Coach Junior Developers and exchange and grow your knowledge with other Lead Developers in various areas of Software Development/Data Engineering\n\nBenefits\n\nWhat's in it for you\n‚Ä¢ Work Life Balance: flexible working hours, extensive hybrid working options / work from home\n‚Ä¢ Easy Moving: work permit support\n‚Ä¢ Top-notch Equipment: modern tools & technologies\n‚Ä¢ International Spirit: multi-cultural teams, English as company language, team building events\n‚Ä¢ Learning & Agile Working: as part of our DNA & culture\n‚Ä¢ Canteen: healthy, tasty, and heavily subsidized\n‚Ä¢ Saving: with vouchers / discounts from our staffs' council (eg. supermarket)\n‚Ä¢ Further Goodies: free public transport pass, salary account & credit card, gender-neutral parental leave, bilingual company kindergarten etc.\n‚Ä¢ Salary: the offered gross yearly salary starts at 60.000 Euro (basis full-time) excluding overtime, depending on experience and qualifications\n\nAbout Raiffeisen Bank International AG\n\nDid you know that RBI is one of the most popular domestic employers?\n\nSure: it is also one of the leading banking groups in Austria and CEE. RBI not only shines on the outside, it also has inner values. The banking landscape is changing, as is RBI. Cross-functional teams, quick exchange of knowledge, independent work and creativity are very important. This is the only way for the bank to bring products and services onto the market in this fast-moving time that bring real added value and are therefore in demand. In short, at RBI we shape the future of banking.\n\nWe are searching for talented IT experts and enthusiasts to join our teams. We're not just any IT employer, we're the kind that helps you grow, learn, and reach your full potential.\n\nBecome part of the RBI family!\n\nWe are looking forward to hearing from you""]}]","[{'link': 'http://www.rbinternational.com/', 'text': 'rbinternational.com'}, {'link': 'https://www.google.com/search?hl=en&q=Raiffeisen+Bank+International+AG&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAII4wo', 'text': 'See web results for Raiffeisen Bank International AG'}]",,"['27 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '27 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAoZi9tL3gpIiwiaHRpZG9jaWQiOiJnY1FYSlZXVkNRSUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzU25RNVdVZGZaVXQ1ZEVWQ016QlNORUpSVkRWUFREbG1OVzVuYVdjNFp6SlBUREZGWVRGeFRIWlNlVzUyVERScFltRnFVbkIwVGxsT1VGOTBZemd4U1RKYVNFOVpUVFo1VFVkbFREVnVaRUpEU0RSRmVVVm1UVkpsYzBkeU9XNUpPRzlxWlVGVWFsb3hSRGxyZFMxdFprMVROMGRRVnpSd1pVZHZUMlpaTlZwU1JuTlpjRlJFWkZoamJVSnhjSEpFVTJwaFpHaEtNRTlHTkVSMFNXTnJVbU5uZVRCaldrMXBkVFIyVkdSaFgzbHhURTFvYWxwMmRtdEpZMVpCTmtsdmN6ZzJiR1l5VnpCblRuQm1VMUpLVEVOTWRUVnNSRjluT1ZCNlp4SVhPRXhNU0ZwT2JVUk1Yek5LYTFCSlVHODBNbWd0UVRnYUlrRk1SVk01ZFZCclRHazVabTE1ZVZkZllXZHROekF5WVZJeGFXOHlSeTFsTjFFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiIubkZnMmVie2ZvbnQtd2VpZ2h0OjUwMH0uQmk2RGRje2ZvbnQtd2VpZ2h0OjUwMH1BcHBseSBvbiBXZUFyZURldmVsb3BlcnMiLCJsaW5rIjoiaHR0cHM6Ly93d3cud2VhcmVkZXZlbG9wZXJzLmNvbS9lbi9jb21wYW5pZXMvMjkzOC9yYWlmZmVpc2VuLWJhbmstaW50ZXJuYXRpb25hbC1hZy8zMTk3MC9zZW5pb3ItZGF0YS1lbmdpbmVlci1mLW0teC0/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Azure Data Engineer (m/f/d). Job in Wien My Valley Jobs Today,Strabag AG,"  Vienna, Austria   ",via My Valley Jobs Today,"STRABAG employs around 79,000 people at 700 locations worldwide, working on progress. From building construction and structural engineering, road construction and civil engineering, bridge building and tunnelling, industrial sites and port infrastructure, to building management and project development - we are thinking ahead, aiming to become the most innovative and sustainable construction technology group in Europe. Every single one of us plays an important part: together we and our partners complete projects successfully and grow to meet new challenges. Together we achieve great things.

The group unit STRABAG Innovation & Digitalisation acts as an enabler for digitalisation and development projects. In close cooperation with operational colleagues, more than 400 different innovation and digitalisation projects are driven forward.

Application Services & Data Science deals with the strategic (further) development of software products as well as the future-oriented and targeted... handling of data in all corporate areas. We rely on a variety of technical and strategic skills as well as diverse personalities in our teams.
Aufgaben
‚Ä¢ Design, development, deployment and maintenance of data pipelines for ingestion and processing of data from multiple data sources in the Group's central data lake in the Microsoft Azure Cloud
‚Ä¢ Collaborate extensively with data analysts and data scientists to create scalable solutions for data visualization, data analysis and machine learning tasks
‚Ä¢ Substantial contribution in the further development and operation of the central Microsoft Scale Analytics-based multi-environment cloud platform for Data Science projects at STRABAG
‚Ä¢ Active participation in a highly motivated, innovative SCRUM team of STRABAG Innovation and Digitalization in close coordination with the Data Product Managers, Cloud Engineers and Solution Architect

Profil
‚Ä¢ Extensive experience with ETL / ELT tools in the cloud, preferably in Microsoft Azure (Synapse Analytics Workspace, Databricks experience an advantage)
‚Ä¢ Solid technical understanding and hands-on experience with modern concepts for data science applications in a cloud context
‚Ä¢ Knowledge of data modeling and proficiency in relevant technologies for data processing (e.g. SQL)
‚Ä¢ Team player, strong communication skills, analytical thinking and structured way of working
‚Ä¢ Very good written and spoken English

Wir bieten In addition to a secure job, we offer you innovative, technologically challenging projects in an international environment. Take advantage of the opportunity to develop personally and professionally within a friendly, competent team. We encourage flexible working (hours to suit you, choose home or office). The gross annual salary for this position in Austria is starting from EUR 50,000. In addition, we offer an overpayment in line with the market depending on qualifications and experience. In Germany, the payment is governed by Bundesrahmentarifvertrag f√ºr das Baugewerbe. Please upload your application documents (CV, certificates) in English or German. We look forward to hearing from you","[{'items': [""STRABAG employs around 79,000 people at 700 locations worldwide, working on progress. From building construction and structural engineering, road construction and civil engineering, bridge building and tunnelling, industrial sites and port infrastructure, to building management and project development - we are thinking ahead, aiming to become the most innovative and sustainable construction technology group in Europe. Every single one of us plays an important part: together we and our partners complete projects successfully and grow to meet new challenges. Together we achieve great things.\n\nThe group unit STRABAG Innovation & Digitalisation acts as an enabler for digitalisation and development projects. In close cooperation with operational colleagues, more than 400 different innovation and digitalisation projects are driven forward.\n\nApplication Services & Data Science deals with the strategic (further) development of software products as well as the future-oriented and targeted... handling of data in all corporate areas. We rely on a variety of technical and strategic skills as well as diverse personalities in our teams.\nAufgaben\n‚Ä¢ Design, development, deployment and maintenance of data pipelines for ingestion and processing of data from multiple data sources in the Group's central data lake in the Microsoft Azure Cloud\n‚Ä¢ Collaborate extensively with data analysts and data scientists to create scalable solutions for data visualization, data analysis and machine learning tasks\n‚Ä¢ Substantial contribution in the further development and operation of the central Microsoft Scale Analytics-based multi-environment cloud platform for Data Science projects at STRABAG\n‚Ä¢ Active participation in a highly motivated, innovative SCRUM team of STRABAG Innovation and Digitalization in close coordination with the Data Product Managers, Cloud Engineers and Solution Architect\n\nProfil\n‚Ä¢ Extensive experience with ETL / ELT tools in the cloud, preferably in Microsoft Azure (Synapse Analytics Workspace, Databricks experience an advantage)\n‚Ä¢ Solid technical understanding and hands-on experience with modern concepts for data science applications in a cloud context\n‚Ä¢ Knowledge of data modeling and proficiency in relevant technologies for data processing (e.g. SQL)\n‚Ä¢ Team player, strong communication skills, analytical thinking and structured way of working\n‚Ä¢ Very good written and spoken English\n\nWir bieten In addition to a secure job, we offer you innovative, technologically challenging projects in an international environment. Take advantage of the opportunity to develop personally and professionally within a friendly, competent team. We encourage flexible working (hours to suit you, choose home or office). The gross annual salary for this position in Austria is starting from EUR 50,000. In addition, we offer an overpayment in line with the market depending on qualifications and experience. In Germany, the payment is governed by Bundesrahmentarifvertrag f√ºr das Baugewerbe. Please upload your application documents (CV, certificates) in English or German. We look forward to hearing from you""]}]","[{'link': 'http://www.strabag.com/', 'text': 'strabag.com'}, {'link': 'https://www.google.com/search?hl=en&q=Strabag+AG&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIImAs', 'text': 'See web results for Strabag AG'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRH0Kvkknb5QamPGhqfQCCnSERdCaMlDwhLJ58XYHQ&s,"['2 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJBenVyZSBEYXRhIEVuZ2luZWVyIChtL2YvZCkuIEpvYiBpbiBXaWVuIE15IFZhbGxleSBKb2JzIFRvZGF5IiwiaHRpZG9jaWQiOiItR1d4RWVocHhCOEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzU1hkaFYzRkxhbW96VWtNemJrdEpSMlZaVDJoQlpGQnZiV2R6YlVzM1VrbHhjRVpzWTJod2JFOXNNWGM0UkZGUVJIRTBiMU41VDJSU1JtSmhlbWhYYXkxclNVbDBSV0pzZVRaa1VGUlRWVVZ0V1d3dGF6VjFOM1ZLZG5ob1YzWnFVV3hXTmtvM04wOU1PRmR5Wlcxa2RrVnRTRFJRTTBWS2FFVnlNM2RHYTFscWJGVkZjM1ZMVkRadWJVWm1RVEJ5V0U5RWQxVTFiMkU0YVVGMkxUQm5lVkJTV1RoUGNUWmtNa2RXWlRsR1FqRnlTVGx0TVZoRk5VTTFZbFI0WVRJelJFWTBhMjFQTnpVeE5UaFFiWE40ZVdjeVYyUkdUbEUyUVdkaVFSSVhPRXhNU0ZwT2JVUk1Yek5LYTFCSlVHODBNbWd0UVRnYUlrRk1SVk01ZFZCVFNscGxlbmM0YUZWblRHSnpaMTkwZURka2FUUlViMGhmTjFFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBNeSBWYWxsZXkgSm9icyBUb2RheSIsImxpbmsiOiJodHRwczovL2pvYnMud2tibi5jb20vam9icy9henVyZS1kYXRhLWVuZ2luZWVyLW0tZi1kLXdpZW4vMTA3NjUzNTM0My0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (all genders),Accenture,"  Vienna, Austria   ",via Accenture,"Unterst√ºtzte unseren Kunden dabei, aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln

Deine Mission‚Äã

In unserem Data & AI Network kombinieren wir unser strategisches, digitales und technologisches Know-how, um Unternehmen auf ein neues Innovations- und Performance-Level zu heben.

Wir agieren industrie√ºbergreifend, sodass du t√§glich Neues dazulernst und deine Karriere ein ganzes St√ºck nach vorn bringen kannst. Werde nicht nur ein Teil der datenzentrierten Transformation sondern sei vorne mit dabei. Bei Accenture gestaltest du dir selbst das Umfeld, in dem du aufgehst ‚Äì mit Arbeitsweisen, die zu dir passen. Du bleibst flexibel. Und wirst Teil eines Teams voller einzigartiger Menschen, die gemeinsam etwas bewegen.

Das erwartet dich:
‚Ä¢ Sei Data Driven und kreativ
Setze deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr die datengetriebene Unternehmen zu schaffen
‚Ä¢ Kollaboriere im Team & nutze die... Synergien
Als Teil eines interdisziplin√§ren Teams fokussierst du dich, auf Datenquellen zu identifizieren, komplexe Datenmodele zu modellieren und produktive Datenpipelines sowohl in der Cloud als auch on-Premise zu entwickeln
‚Ä¢ Agiere als trusted Advisor
Dabei stehst du mit den Entscheidungstr√§gern auf Kundenseite im engen Kontakt und sorgst daf√ºr, dass die End-2-End Datenpipelines als wesentlicher Basis f√ºr die Industrialisierung von K√ºnstlicher Intelligenz erfolgreich implementiert werden","[{'items': ['Unterst√ºtzte unseren Kunden dabei, aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln\n\nDeine Mission\u200b\n\nIn unserem Data & AI Network kombinieren wir unser strategisches, digitales und technologisches Know-how, um Unternehmen auf ein neues Innovations- und Performance-Level zu heben.\n\nWir agieren industrie√ºbergreifend, sodass du t√§glich Neues dazulernst und deine Karriere ein ganzes St√ºck nach vorn bringen kannst. Werde nicht nur ein Teil der datenzentrierten Transformation sondern sei vorne mit dabei. Bei Accenture gestaltest du dir selbst das Umfeld, in dem du aufgehst ‚Äì mit Arbeitsweisen, die zu dir passen. Du bleibst flexibel. Und wirst Teil eines Teams voller einzigartiger Menschen, die gemeinsam etwas bewegen.\n\nDas erwartet dich:\n‚Ä¢ Sei Data Driven und kreativ\nSetze deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr die datengetriebene Unternehmen zu schaffen\n‚Ä¢ Kollaboriere im Team & nutze die... Synergien\nAls Teil eines interdisziplin√§ren Teams fokussierst du dich, auf Datenquellen zu identifizieren, komplexe Datenmodele zu modellieren und produktive Datenpipelines sowohl in der Cloud als auch on-Premise zu entwickeln\n‚Ä¢ Agiere als trusted Advisor\nDabei stehst du mit den Entscheidungstr√§gern auf Kundenseite im engen Kontakt und sorgst daf√ºr, dass die End-2-End Datenpipelines als wesentlicher Basis f√ºr die Industrialisierung von K√ºnstlicher Intelligenz erfolgreich implementiert werden']}]","[{'link': 'http://www.accenture.com/', 'text': 'accenture.com'}, {'link': 'https://www.google.com/search?hl=en&q=Accenture&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIIyws', 'text': 'See web results for Accenture'}]",,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChhbGwgZ2VuZGVycykiLCJodGlkb2NpZCI6IkxQQ3Z6VVZzQlRzQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTa3AyZDNGNE1rRmxWMUZsWm1VNVpHRTJhVk5OYm0xbGJuQnZhbTFWUTJkWWMzaDRiVGRpUXpWV2JHTk9OazlaUjJKMmJGRXhiRFkyZERsSlNVSjBXSGRMY0RGWU9HbFJXVGhhTFZOVlozWXpkVzVaZG1KVWVUZFVjWGRwY21FNFQyUjJZemhSWDJwaldYTnFPRWxQZVhsYVJrMXNjRmhJWkhONk5IWjJUelZaTWpBeWJIUXpOMlYzVlMxT2RGQTJjWGRHWjJKTWVHcFhjamR0Y0hCNlYyUnVTRVk1UkZsUVZWOTFhMnRPU2tkdkVoYzRURXhJV2s1dFJFeGZNMHByVUVsUWJ6UXlhQzFCT0JvaVFVeEZVemwxVUV0ME1YQk5kV3RuYjNKQmVUWlBibGd3TkVwVWJFUnlaVUpXVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEFjY2VudHVyZSIsImxpbmsiOiJodHRwczovL3d3dy5hY2NlbnR1cmUuY29tL2F0LWRlL2NhcmVlcnMvam9iZGV0YWlscz9pZD1SMDAxNTQ0MjJfZGVcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Software Development Lead Data Engineer,Raiffeisen Informatik GmbH,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ Drive the design, development and maintenance of software applications in the data area
‚Ä¢ Steer the work of software engineers to ensure best practices around software development
‚Ä¢ Ensure that the software engineering staff is suitably trained
‚Ä¢ Assist product owners and requirements engineers in breaking down requirements into user stories

Technologies and skills
‚Ä¢ Bash
‚Ä¢ Linux
‚Ä¢ Java
‚Ä¢ Python

Our expectations:

Qualifications
‚Ä¢ Expert in software engineering principles like pair programming, separation of concerns, incremental development, data-driven development, etc.
‚Ä¢ CI/CD pipeline knowledge
‚Ä¢ Knowledge in Python and Java
‚Ä¢ Knowledge in test-driven development

Experience
‚Ä¢ Professional experience in DWH (Data Models, ETL), ETL tools and BI solutions
‚Ä¢ Experience in Linux / Bash
‚Ä¢ 5+ years experience in software development
‚Ä¢ 2+ years experience in software development leadership

Benefits
‚Ä¢ Flexible Working Hours
‚Ä¢ Day Care for Kids
‚Ä¢ Company... Restaurant
‚Ä¢ * Company Doctor
‚Ä¢ Public Transport Allowance
‚Ä¢ Additional Insurance","[{'items': ['Your role in the team\n‚Ä¢ Drive the design, development and maintenance of software applications in the data area\n‚Ä¢ Steer the work of software engineers to ensure best practices around software development\n‚Ä¢ Ensure that the software engineering staff is suitably trained\n‚Ä¢ Assist product owners and requirements engineers in breaking down requirements into user stories\n\nTechnologies and skills\n‚Ä¢ Bash\n‚Ä¢ Linux\n‚Ä¢ Java\n‚Ä¢ Python\n\nOur expectations:\n\nQualifications\n‚Ä¢ Expert in software engineering principles like pair programming, separation of concerns, incremental development, data-driven development, etc.\n‚Ä¢ CI/CD pipeline knowledge\n‚Ä¢ Knowledge in Python and Java\n‚Ä¢ Knowledge in test-driven development\n\nExperience\n‚Ä¢ Professional experience in DWH (Data Models, ETL), ETL tools and BI solutions\n‚Ä¢ Experience in Linux / Bash\n‚Ä¢ 5+ years experience in software development\n‚Ä¢ 2+ years experience in software development leadership\n\nBenefits\n‚Ä¢ Flexible Working Hours\n‚Ä¢ Day Care for Kids\n‚Ä¢ Company... Restaurant\n‚Ä¢ * Company Doctor\n‚Ä¢ Public Transport Allowance\n‚Ä¢ Additional Insurance']}]","[{'link': 'http://www.raiffeiseninformatik.at/', 'text': 'raiffeiseninformatik.at'}, {'link': 'https://www.google.com/search?hl=en&q=Raiffeisen+Informatik+GmbH&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAII_ws', 'text': 'See web results for Raiffeisen Informatik GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ6LyPIQ2-ZptHJ1Gvd9a86Uz1Cp53134pVehZg-DLgPFEGhV_tXo59qw&s,"['6 days ago', '‚Ç¨65K a year', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTb2Z0d2FyZSBEZXZlbG9wbWVudCBMZWFkIERhdGEgRW5naW5lZXIiLCJodGlkb2NpZCI6IlpfMTVDc2dfc0lFQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVUxck1teHNTWGcxYkY5QldGTllZa05vY1d0UlpERnhXR2MyWkZsVVFqWk9NMUZrZFhwUGFXOXJWR1ZxTVd4eFRXbEhjbTVxZDB0c01FRjRPRWhFVTFwM1FqZFZTalJFUm1sRVYyeEZXRVZIV0hCaVgxVmZVa1ZPZERSUlprbHJVa2xtZERsNFlXbEZObXBuTUZoSVNUVlFka0pXVUVWclRtOW1VR3BIU0ZaVk9UQmhNM2c1WkRaeFVHRlJhbTFQWjA0d00wNU5SVWhtUVY5dkxXMXFWRkZLTVhSRE1XSjJXRWg1Ym00MlpYRjFWazVVU0ZaMVR6TlJUWEp1WDFwdlpIbEZOamN5T0haaFJIRmhTMmhpUWxJdGVFcFBSbXBxVjFCZlRqSnRUa0pJUVJJWE9FeE1TRnBPYlVSTVh6TkthMUJKVUc4ME1tZ3RRVGdhSWtGTVJWTTVkVTFRY0ZkbGVVSlBVMWhxZVdWMFpYSlBWa3RDZVV4QlUwWmxhMUUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY183IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIERFVmpvYnMuYXQiLCJsaW5rIjoiaHR0cHM6Ly9lbi5kZXZqb2JzLmF0L2pvYi80OTdmMzNiMTRlNjFlZTU3ZjhmYzRjNTFkNTNlMzRmOT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (m/f/d),Ribbon Biolabs GmbH,"  Vienna, Austria   ",via STEMJOBS.AT - STEM Jobs In √ñsterreich,"Ribbon Biolabs is a dynamic and growing biotech company active in the area of synthetic biology. With our proprietary synthetic DNA platform, we are approaching market entry to disrupt the field of synthetic biology and its applications, with initial customers in the biotech and pharmaceutical industries. With us, you can make a change towards a healthier society of the future.

To support our growth, market entry, and commercialization, we are seeking to hire an experienced DATA ENGINEER (m/f/d) with a background and proven track record in data architecture, data management and data integration. The Data Engineer will work together with our business, scientific, and production teams to support the setup and expansion of our DNA production platform and its tight coupling with our R&D activities.

You will be responsible for the design, programming and implementation of databases and data-flow infrastructure and integration, to support management, processing and standardisation of data... collection and organisation across different teams in administration, DNA production and R&D. You will be working closely with the Computational Biology and the Automation Teams to develop procedures and data pipelines to ensure correct algorithm deployment and data flow across Ribbon‚Äôs production lines.

Your Roles & Responsibilities at Ribbon Biolabs:

Cooperate with stakeholders in data-generating R&D and production processes

Coordinate with cross-functional teams to develop data models and data warehousing solutions

Drive in-house software development in support of data management for Production Line and R&D operations

Support ongoing integration of data flows, data validation and curation at interfaces with existing and future systems both internal and external.

Integrate custom in-house algorithms‚ÄØwith automation software for lab robotics to ensure working backend data infrastructure in alignment with stakeholder requirements

Help ensure data safety and integrity, including data backup routines

Liaise with QC / quality management team to automate GDocP compliance

Support development and setup of processes and SOPs towards ISO9001:2015 and ISO 27001:2013 certification

Your background, experience & skills:

Masters (or higher) in computer science, software engineering or related fields

Experience and proven understanding of data management tools and methods, ideally in a laboratory context

Proven background in software development for data architecture and data modelling (e.g. development of APIs, enablement of interoperability)

Extensive experience working with database systems (SQL, or other), networked services (REST, microservices, containers), and cloud infrastructure (AWS, Azure, or similar).

Additional strengths considered a plus:

Experience with database server infrastructure and management

Strong background in working with cloud computing workflows

Familiarity with DNA sequence data, biological ontologies, and biological databases

Knowledge of requirements associated with FDA 21 CFR Part 11 regulations on electronic records, GDocP, eQMS and GLP compliance

Comfortable with cross-platform infrastructure, groupware, and teams (MacOS/Windows/Linux)

Our Offer:

Full health and social benefits according to Austrian law

Opportunity to contribute to a young company in the new, evolving synthetic biology field

Join a highly motivated and agile team

Flexible working hours and remote working possibilities

Company-supported professional development through trainings, workshops and conference attendance, including team activities

Support in German classes if required

The opportunity to grow with the company and to live and work in or near the city of Vienna, which is consistently ranked as the most livable city in the world.

Relocation support if necessary

Ticket for shuttle bus between Vienna and Klosteneuburg if required

Coffee, tea and snacks in the office

By Austrian law we are obliged to specify‚ÄØthe‚ÄØminimum salary‚ÄØlevel‚ÄØby collective agreement, which is Euro 47.000,- to 56.000,- ‚ÄØgross‚ÄØper‚ÄØyear.‚ÄØHowever, we offer‚ÄØa‚ÄØhigher salary adjusted to your experience and qualifications.

‚ÄØ‚ÄØ

Job type:‚ÄØFull time (40 h per week).‚ÄØ‚ÄØ

Location:‚ÄØThis role is for our Klosteneuburg and Vienna offices.‚ÄØ‚ÄØ

Availability:‚ÄØWe expect to fill the position‚ÄØas soon as possible.‚ÄØ‚ÄØ

‚ÄØ

How to apply:‚ÄØ‚ÄØ‚ÄØ‚ÄØ Applicants should provide a cover letter explaining the motivation behind the application, curriculum vitae, and a list of three references to‚ÄØhires@ribbonbiolabs.com.

Considerations of the applications will continue until the position is filled.‚ÄØ‚ÄØ

Your contact person:

Maryna Listratenko, MA

HCM of Ribbon Biolabs

‚ÄØ

Ribbon Biolabs takes data protection seriously. Unless you express‚ÄØotherwise, by submitting your CV you authorize Ribbon Biolabs to store your‚ÄØpersonal‚ÄØdata in its database‚ÄØfor the purpose of recruiting process or/and‚ÄØpossible future‚ÄØjob‚ÄØvacancies.‚ÄØIf you want your data to be deleted from our database, you simply need to‚ÄØinform our hiring manager. Ribbon Biolabs will not share your personal data with any other party without your consent.‚ÄØ‚ÄØ‚ÄØ

‚ÄØ

We are an Equal Employment Opportunity Employer. While focusing on the right set and mix of experience and skills, we value diversity and are highly committed to set up working environment with mutual respect to everyone regardless their race, nationality, religion, gender,‚ÄØage‚ÄØor other characteristics protected by applicable regulations and laws.‚ÄØTo keep the gender balance in our Company, we highly encourage women to apply.

The team at Ribbon Biolabs is looking forward to your application","[{'items': ['Ribbon Biolabs is a dynamic and growing biotech company active in the area of synthetic biology. With our proprietary synthetic DNA platform, we are approaching market entry to disrupt the field of synthetic biology and its applications, with initial customers in the biotech and pharmaceutical industries. With us, you can make a change towards a healthier society of the future.\n\nTo support our growth, market entry, and commercialization, we are seeking to hire an experienced DATA ENGINEER (m/f/d) with a background and proven track record in data architecture, data management and data integration. The Data Engineer will work together with our business, scientific, and production teams to support the setup and expansion of our DNA production platform and its tight coupling with our R&D activities.\n\nYou will be responsible for the design, programming and implementation of databases and data-flow infrastructure and integration, to support management, processing and standardisation of data... collection and organisation across different teams in administration, DNA production and R&D. You will be working closely with the Computational Biology and the Automation Teams to develop procedures and data pipelines to ensure correct algorithm deployment and data flow across Ribbon‚Äôs production lines.\n\nYour Roles & Responsibilities at Ribbon Biolabs:\n\nCooperate with stakeholders in data-generating R&D and production processes\n\nCoordinate with cross-functional teams to develop data models and data warehousing solutions\n\nDrive in-house software development in support of data management for Production Line and R&D operations\n\nSupport ongoing integration of data flows, data validation and curation at interfaces with existing and future systems both internal and external.\n\nIntegrate custom in-house algorithms\u202fwith automation software for lab robotics to ensure working backend data infrastructure in alignment with stakeholder requirements\n\nHelp ensure data safety and integrity, including data backup routines\n\nLiaise with QC / quality management team to automate GDocP compliance\n\nSupport development and setup of processes and SOPs towards ISO9001:2015 and ISO 27001:2013 certification\n\nYour background, experience & skills:\n\nMasters (or higher) in computer science, software engineering or related fields\n\nExperience and proven understanding of data management tools and methods, ideally in a laboratory context\n\nProven background in software development for data architecture and data modelling (e.g. development of APIs, enablement of interoperability)\n\nExtensive experience working with database systems (SQL, or other), networked services (REST, microservices, containers), and cloud infrastructure (AWS, Azure, or similar).\n\nAdditional strengths considered a plus:\n\nExperience with database server infrastructure and management\n\nStrong background in working with cloud computing workflows\n\nFamiliarity with DNA sequence data, biological ontologies, and biological databases\n\nKnowledge of requirements associated with FDA 21 CFR Part 11 regulations on electronic records, GDocP, eQMS and GLP compliance\n\nComfortable with cross-platform infrastructure, groupware, and teams (MacOS/Windows/Linux)\n\nOur Offer:\n\nFull health and social benefits according to Austrian law\n\nOpportunity to contribute to a young company in the new, evolving synthetic biology field\n\nJoin a highly motivated and agile team\n\nFlexible working hours and remote working possibilities\n\nCompany-supported professional development through trainings, workshops and conference attendance, including team activities\n\nSupport in German classes if required\n\nThe opportunity to grow with the company and to live and work in or near the city of Vienna, which is consistently ranked as the most livable city in the world.\n\nRelocation support if necessary\n\nTicket for shuttle bus between Vienna and Klosteneuburg if required\n\nCoffee, tea and snacks in the office\n\nBy Austrian law we are obliged to specify\u202fthe\u202fminimum salary\u202flevel\u202fby collective agreement, which is Euro 47.000,- to 56.000,- \u202fgross\u202fper\u202fyear.\u202fHowever, we offer\u202fa\u202fhigher salary adjusted to your experience and qualifications.\n\n\u202f\u202f\n\nJob type:\u202fFull time (40 h per week).\u202f\u202f\n\nLocation:\u202fThis role is for our Klosteneuburg and Vienna offices.\u202f\u202f\n\nAvailability:\u202fWe expect to fill the position\u202fas soon as possible.\u202f\u202f\n\n\u202f\n\nHow to apply:\u202f\u202f\u202f\u202f Applicants should provide a cover letter explaining the motivation behind the application, curriculum vitae, and a list of three references to\u202fhires@ribbonbiolabs.com.\n\nConsiderations of the applications will continue until the position is filled.\u202f\u202f\n\nYour contact person:\n\nMaryna Listratenko, MA\n\nHCM of Ribbon Biolabs\n\n\u202f\n\nRibbon Biolabs takes data protection seriously. Unless you express\u202fotherwise, by submitting your CV you authorize Ribbon Biolabs to store your\u202fpersonal\u202fdata in its database\u202ffor the purpose of recruiting process or/and\u202fpossible future\u202fjob\u202fvacancies.\u202fIf you want your data to be deleted from our database, you simply need to\u202finform our hiring manager. Ribbon Biolabs will not share your personal data with any other party without your consent.\u202f\u202f\u202f\n\n\u202f\n\nWe are an Equal Employment Opportunity Employer. While focusing on the right set and mix of experience and skills, we value diversity and are highly committed to set up working environment with mutual respect to everyone regardless their race, nationality, religion, gender,\u202fage\u202for other characteristics protected by applicable regulations and laws.\u202fTo keep the gender balance in our Company, we highly encourage women to apply.\n\nThe team at Ribbon Biolabs is looking forward to your application']}]","[{'link': 'http://www.ribbonbiolabs.com/', 'text': 'ribbonbiolabs.com'}, {'link': 'https://www.google.com/search?hl=en&q=Ribbon+Biolabs+GmbH&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIItAw', 'text': 'See web results for Ribbon Biolabs GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSQe2olNyqYRRCQ_vuIPBNrqH_1rJoC445CuNzvTXs&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6IlliOHplYVd4elY4QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNURTFEV0VwYWRXWlhlbkI1UXpCR1dGQmpZVmxJVTJaVVpYbDBOa0owYkRGR2MzaDJjV0Z3Y2xSVVVYY3lNMmhXWDB3eE5ISm5ObU0yY0VKUlEyMHhWVXhLT1ZVeldHRkZZVEZLUlZOR1ozVnJjRmhyWmtObFl6SjFVSGRKTWxObGFWbEdYMGwxWm1wS2EwcDZSR1ozTWpaMmREWlpjMHh2VjBWS1RFSjZPVnBpZGxOalZsSm5Wa2MzY1VkWlQwcHdZWGxMVDFOa1VYWnhZMWt4VmpWRlRYTnpSMUZTTjBGUWEzRmFlRFZSYjNkc05EZEZVMnR6Y3paRVJuZDZaalF5VDFOcmRHdFJFaGM0VEV4SVdrNXRSRXhmTTBwclVFbFFielF5YUMxQk9Cb2lRVXhGVXpsMVQzUm5ia3BtYzJjeVVHTlVSVTlzVkY5Nk56bFpYMll4U1dsRlp3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTVEVNSk9CUy5BVCAtIFNURU0gSm9icyBJbiDDlnN0ZXJyZWljaCIsImxpbmsiOiJodHRwczovL3d3dy5zdGVtam9icy5hdC81MzAzNS8wL0RhdGEtRW5naW5lZXItKG0tZi1kKT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer (m/f/d),voestalpine High Performance Metals GmbH,"  Vienna, Austria   ",via Voestalpine ‚Äì Jobs,"Job description
‚Ä¢ Lead the DataOps efforts to develop and extend our shared data platform to support sustainable, self-service, and high-quality data applications
‚Ä¢ Work with an agile mindset in cross-functional teams
‚Ä¢ Design, develop, deploy, and maintain batch & streaming data pipelines for ingestion and distributed processing of data from multiple sources, such as relational databases, REST APIs, SAP, and Kafka
‚Ä¢ Work closely with Data Scientists, Data Engineers, and Full Stack Developers to create scalable data architectures for data visualization, data analysis, and machine learning tasks
‚Ä¢ Develop a solid understanding of our production processes and our value chains, and pro-actively engage with domain experts to understand their needs
‚Ä¢ Stay on top of latest technology developments and continuously contribute to the transfer of data engineering and DevOps practices across several globally located data teams

Qualifications
‚Ä¢ Strong software engineering/programming skills in... Python with a University degree in a related technical field and/or years of professional experience
‚Ä¢ Solid experience with agile methods, DevOps, and DataOps practices (git, CI/CD, containerization and orchestration using OpenShift/K8s, monitoring, Unix/Linux, shell scripting)
‚Ä¢ Extensive knowledge of big data architectures and distributed computing (Hadoop, Spark, Hive, Kafka), orchestration (Apache Airflow), and SQL/NoSQL databases
‚Ä¢ Basic understanding of Data Science (statistics, data visualization, machine learning) and knowledge of related Python libraries (pandas, scikit-learn) is beneficial
‚Ä¢ Fluently written and spoken English/German, and willingness to travel nationally
‚Ä¢ Experience in an industrial setting (especially in the process industry, e.g. metals, paper, etc.) is beneficial

What we offer

Salary Package and Benefits: The collective minimum salary agreement for this position is ‚Ç¨ 4.222,78 gross (14 x per year). The actual payment depends on the particular qualification and experience.

voestalpine offers its workforce an attractive and appreciative working environment: We support with an extensive initial introduction phase, regular on ‚Äì the ‚Äì job trainings, flexible working hours and annual appraisal interviews. We enable certain perquisites and benefits for different commercial partners and with a good course of business all employees will be paid an additional annual bonus. Employee participation is of particular importance for us; currently employees of voestalpine hold 14% of the shares.

The fact that voestalpine is a globally leading steel and technology group today is primarily thanks to its approximately 50,200 employees. We are constantly working to create a modern working environment that values diversity, equal opportunities and the joy of innovation.

We are looking forward to receive your application.

More information about our application process can be found on the first page of our application form and in the ‚ÄúFAQs to apply‚Äù.
Please be aware that benefits may vary depending on location.

If we have sparked your interest, please use our online application form. Our CV - parsing tool makes your application even faster.

Introduction

Are you an experienced Data Engineer and keen to:
‚Ä¢ Realize projects and develop data products in an industrial setting?
‚Ä¢ Contribute to the further development of our data science platform?
‚Ä¢ Join a highly motivated, innovative, and multi-disciplinary team?

We look for a self-motivated and goal-oriented team player with a hands-on mentality and strong problem-solving skills to join our Data Science & AI Team at DIGITAL SOLUTIONS. We are an ambitious team of open-minded people and play a lead role in the digital transformation of our division‚Äôs global company network.

We are excited to appoint a Senior Data Engineer (m/f/d) in Kapfenberg or Vienna. The position offers a unique opportunity to play a key role in implementing data-driven products & services that secure the future operational excellence of our enterprise.

The primarily desired job site is Kapfenberg, Austria, with a certain share of remote work. Vienna is also possible as place of employment but requires regular travel to Kapfenberg.

voestalpine High Performance Metals DIGITAL SOLUTIONS GmbH is the innovative partner of the High Performance Metals Division within the voestalpine Group. We provide scalable products and solutions in the areas of Data Science & AI, Industrial IoT, Automation & Robotics, and Sensors.

Please find further information on our website: https://www.voestalpine.com/highperformancemetals/en/digitalsolutions","[{'items': ['Job description\n‚Ä¢ Lead the DataOps efforts to develop and extend our shared data platform to support sustainable, self-service, and high-quality data applications\n‚Ä¢ Work with an agile mindset in cross-functional teams\n‚Ä¢ Design, develop, deploy, and maintain batch & streaming data pipelines for ingestion and distributed processing of data from multiple sources, such as relational databases, REST APIs, SAP, and Kafka\n‚Ä¢ Work closely with Data Scientists, Data Engineers, and Full Stack Developers to create scalable data architectures for data visualization, data analysis, and machine learning tasks\n‚Ä¢ Develop a solid understanding of our production processes and our value chains, and pro-actively engage with domain experts to understand their needs\n‚Ä¢ Stay on top of latest technology developments and continuously contribute to the transfer of data engineering and DevOps practices across several globally located data teams\n\nQualifications\n‚Ä¢ Strong software engineering/programming skills in... Python with a University degree in a related technical field and/or years of professional experience\n‚Ä¢ Solid experience with agile methods, DevOps, and DataOps practices (git, CI/CD, containerization and orchestration using OpenShift/K8s, monitoring, Unix/Linux, shell scripting)\n‚Ä¢ Extensive knowledge of big data architectures and distributed computing (Hadoop, Spark, Hive, Kafka), orchestration (Apache Airflow), and SQL/NoSQL databases\n‚Ä¢ Basic understanding of Data Science (statistics, data visualization, machine learning) and knowledge of related Python libraries (pandas, scikit-learn) is beneficial\n‚Ä¢ Fluently written and spoken English/German, and willingness to travel nationally\n‚Ä¢ Experience in an industrial setting (especially in the process industry, e.g. metals, paper, etc.) is beneficial\n\nWhat we offer\n\nSalary Package and Benefits: The collective minimum salary agreement for this position is ‚Ç¨ 4.222,78 gross (14 x per year). The actual payment depends on the particular qualification and experience.\n\nvoestalpine offers its workforce an attractive and appreciative working environment: We support with an extensive initial introduction phase, regular on ‚Äì the ‚Äì job trainings, flexible working hours and annual appraisal interviews. We enable certain perquisites and benefits for different commercial partners and with a good course of business all employees will be paid an additional annual bonus. Employee participation is of particular importance for us; currently employees of voestalpine hold 14% of the shares.\n\nThe fact that voestalpine is a globally leading steel and technology group today is primarily thanks to its approximately 50,200 employees. We are constantly working to create a modern working environment that values diversity, equal opportunities and the joy of innovation.\n\nWe are looking forward to receive your application.\n\nMore information about our application process can be found on the first page of our application form and in the ‚ÄúFAQs to apply‚Äù.\nPlease be aware that benefits may vary depending on location.\n\nIf we have sparked your interest, please use our online application form. Our CV - parsing tool makes your application even faster.\n\nIntroduction\n\nAre you an experienced Data Engineer and keen to:\n‚Ä¢ Realize projects and develop data products in an industrial setting?\n‚Ä¢ Contribute to the further development of our data science platform?\n‚Ä¢ Join a highly motivated, innovative, and multi-disciplinary team?\n\nWe look for a self-motivated and goal-oriented team player with a hands-on mentality and strong problem-solving skills to join our Data Science & AI Team at DIGITAL SOLUTIONS. We are an ambitious team of open-minded people and play a lead role in the digital transformation of our division‚Äôs global company network.\n\nWe are excited to appoint a Senior Data Engineer (m/f/d) in Kapfenberg or Vienna. The position offers a unique opportunity to play a key role in implementing data-driven products & services that secure the future operational excellence of our enterprise.\n\nThe primarily desired job site is Kapfenberg, Austria, with a certain share of remote work. Vienna is also possible as place of employment but requires regular travel to Kapfenberg.\n\nvoestalpine High Performance Metals DIGITAL SOLUTIONS GmbH is the innovative partner of the High Performance Metals Division within the voestalpine Group. We provide scalable products and solutions in the areas of Data Science & AI, Industrial IoT, Automation & Robotics, and Sensors.\n\nPlease find further information on our website: https://www.voestalpine.com/highperformancemetals/en/digitalsolutions']}]","[{'link': 'http://www.voestalpine.com/highperformancemetals/en/', 'text': 'voestalpine.com/highperformancemetals/en'}, {'link': 'https://www.google.com/search?hl=en&q=voestalpine+High+Performance+Metals+GmbH&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAII5gw', 'text': 'See web results for voestalpine High Performance Metals GmbH'}]",,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAobS9mL2QpIiwiaHRpZG9jaWQiOiJDTTc4aENDX0czVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcmNDQ3ZjQlFVMXJNbXhzU25jd2RtWjNaVU5FVUhGMGVXdHBhSEZPZEZsbmJWWkpkekZ6UnpabmFUbHhlSGRVYTNZdFRXcHRRVmhvYm1wRE1YUlljSEpNTldoVFRXYzBhbmR5UjFCQkxUWjBNR1puTVdKc1prNDJXV3h0VkdoNVNsTmxhV3hzTTFkU05YUk5TRmhVVW1GR1RUVndORVJrZUVSTkxUbGpWRFU0ZVY5YWJXZFpkMlkyZDFSemEwMXRNbWxaYzFaQk1UazBNSGhYT0hSbWJsSmhOVzB0TTFsdVVtUmZSbnBWUkZCRFYxOUtjRU5JTTJkMVJraDRNblJ0WW5FdGVWUkxUak5yV0RadWVYQnNaR1ZNUzBoeFNsTkVNRUpJU1dZd09YQmFSelZOYWtaMlYwMXVTME5RYTI1UFFXRlBiVEpHV2pCd2JubEtieElYT0V4TVNGcE9iVVJNWHpOS2ExQkpVRzgwTW1ndFFUZ2FJa0ZNUlZNNWRWQTBNMGwxYTFGdlRrWXlTVTlzUldORloyVjRSMGR2Um1aWVMzYyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzExIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIFZvZXN0YWxwaW5lIOKAkyBKb2JzIiwibGluayI6Imh0dHBzOi8vam9icy52b2VzdGFscGluZS5jb20vaW5kZXgucGhwP2FjPWpvYmFkXHUwMDI2aWQ9MTIzMDZcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior DataOps Engineer (kafka),Bitpanda,"  Vienna, Austria   ",via Greenhouse,"Your Mission:

The dataops team in Bitpanda is responsible for building and supporting all data sources. If you are passionate about kafka, databases and infrastructure then this is a role for you. You will ensure delivery of solutions based on the backbone of good architecture, best data engineering practices around operational efficiencies, security, robustness, performance and reliability.

Our tech stack:
‚Ä¢ Kafka, Kafka connectors/streams
‚Ä¢ HashiCorp Terraform (Infrastructure as Code)
‚Ä¢ AWS (EKS, EC2, RDS, S3, SQS etc.)
‚Ä¢ Postgresql, Mysql, Mongodb, Dynamodb, Redis as datastores
‚Ä¢ Docker, Kubernetes, Gitlab CI/CD

What you'll do:
‚Ä¢ Assist devops team with all data related activities, mainly on MSK Kafka and RDS clusters.
‚Ä¢ Play a key role in technical design and ongoing development of custom data solutions; understanding and contributing from design to implementation
‚Ä¢ Support application engineers with datasource related implementations, support AI teams with machine learning... efforts
‚Ä¢ Develop and deploy systems to ensure quality, reliability, and efficiency of data systems
‚Ä¢ Build and maintain data tools/products to suit the specific needs of all our stakeholders

Who you are:
‚Ä¢ University degree in Computer Science or Software Engineering
‚Ä¢ Experience building highly scalable event driven environments with Kafka and relational databases
‚Ä¢ Familiarity with distributed computing using a cloud based tech stack on platforms such as AWS or GCP managed by Terraform
‚Ä¢ Familiarity in the development of software using a wide variety of object oriented languages to manage big data, relational DBs (SQL, MySQL, etc.) and working with REST APIs","[{'items': [""Your Mission:\n\nThe dataops team in Bitpanda is responsible for building and supporting all data sources. If you are passionate about kafka, databases and infrastructure then this is a role for you. You will ensure delivery of solutions based on the backbone of good architecture, best data engineering practices around operational efficiencies, security, robustness, performance and reliability.\n\nOur tech stack:\n‚Ä¢ Kafka, Kafka connectors/streams\n‚Ä¢ HashiCorp Terraform (Infrastructure as Code)\n‚Ä¢ AWS (EKS, EC2, RDS, S3, SQS etc.)\n‚Ä¢ Postgresql, Mysql, Mongodb, Dynamodb, Redis as datastores\n‚Ä¢ Docker, Kubernetes, Gitlab CI/CD\n\nWhat you'll do:\n‚Ä¢ Assist devops team with all data related activities, mainly on MSK Kafka and RDS clusters.\n‚Ä¢ Play a key role in technical design and ongoing development of custom data solutions; understanding and contributing from design to implementation\n‚Ä¢ Support application engineers with datasource related implementations, support AI teams with machine learning... efforts\n‚Ä¢ Develop and deploy systems to ensure quality, reliability, and efficiency of data systems\n‚Ä¢ Build and maintain data tools/products to suit the specific needs of all our stakeholders\n\nWho you are:\n‚Ä¢ University degree in Computer Science or Software Engineering\n‚Ä¢ Experience building highly scalable event driven environments with Kafka and relational databases\n‚Ä¢ Familiarity with distributed computing using a cloud based tech stack on platforms such as AWS or GCP managed by Terraform\n‚Ä¢ Familiarity in the development of software using a wide variety of object oriented languages to manage big data, relational DBs (SQL, MySQL, etc.) and working with REST APIs""]}]","[{'link': 'http://www.bitpanda.com/', 'text': 'bitpanda.com'}, {'link': 'https://www.google.com/search?hl=en&q=Bitpanda&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIIlw0', 'text': 'See web results for Bitpanda'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTrCzAaKT0w8sQmhbNIspdr5aPv28Qf2Umgn4xvVSfTjZPdwQm2PyMN&s,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YU9wcyBFbmdpbmVlciAoa2Fma2EpIiwiaHRpZG9jaWQiOiJ1VHh1YlM3RHBKOEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzVERaMWEwSTFlbmhZTm1oT09HSkpaamxtYm1SaGVqbHlkR3MzVjA5SGIzY3phR0pPY2pSb1pqUnNSM3BZYzNCVmEwZDZkbFJvWDFKVFEyMU9RM00zVFRCT2NGVlllRjkyUWpGUVJrRkdRbWhsVURkcmN6SnNaV1ZWUkVGQmJGUnVTbmcyWVVaZkxXNVBiRlo1YkhCYVNVZFZaR3BWWDNkcE5WaGhUVGgxTjNoV1JFeFhhV2d4V1d0dGVsbFhZMDlUZEhrd2NYaEtXRVE1YjFFelNubExhbDlCVGxoSGN6ZzNWSEpvZEZaaFVXWXRWRFozZG00MVoxWnVTbmRoZUhZMWIwdFpZemRLRWhjNFRFeElXazV0UkV4Zk0wcHJVRWxRYnpReWFDMUJPQm9pUVV4RlV6bDFUWEZNVVdJNVprWkZiMlZLTFdoSFZVaHNSM0YwWm1abFkwazNVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEzIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEdyZWVuaG91c2UiLCJsaW5rIjoiaHR0cHM6Ly9ib2FyZHMuZXUuZ3JlZW5ob3VzZS5pby9iaXRwYW5kYS9qb2JzLzQxMzc2MjYxMDE/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Senior MLOps Engineer (m/f/x) - Kaleido AI,Canva,"  Vienna, Austria   ",via Ai-Jobs.net,"Join the team redefining how the world experiences design.Hey, g'day, mabuhay, kia ora,‰Ω†Â•Ω, hallo, v√≠tejte!Thanks for stopping by. We know job hunting can be a little time consuming and you're probably keen to find out what's on offer, so we'll get straight to the point. Where and how you can workOur flagship campus is in Sydney, Australia but Austria is home to part of our European operations. And with that you will have choice in how you work. That means if you want to do your thing in the office (if you're nearby), at home or a bit of both, it's up to you. Fun fact - our Austrian team actually started out as Kaleido before being acquired by us in 2021. Kaleido's product team develops visual AI products, that make complex things simple for users. Now, together we deliver visual AI features within Canva to help reimagine how artificial intelligence can be used in design. We think it's a perfect match. What you‚Äôd be doing in this roleAs Canva scales change continues to be part of our... DNA. But we like to think that's all part of the fun. So this will give you the flavour of the type of things you'll be working on when you start, but this will likely evolve. At the moment, this role is focused on: You'll get the opportunity to lead large-scale experiments in the cloud, working closely with our skilled platform team to craft efficient tooling solutions.You'll play a strategic role in pushing highly parallelized workloads in the cloud, enhancing both the efficiency and effectiveness of our operations.Drive the adoption of best practices in MLOps, including version control, testing, continuous integration, and deployment.Keep abreast of the latest advancements in machine learning and MLOps technologies, and be proactive in suggesting improvements and new techniques that can enhance the team's capabilities. You're probably a match if You have several years of practical experience working with modern data platforms (both cloud and on-premise), with experience delivering data-centric solutions.You have knowledge in Python, Pytorch, Docker, Kubernetes, AWS, databases, etc. You have a strong sense of ownership and are eager to find and develop novel solutions to challenging problems proactively.You are a strong communicator and a team player and are eager to work together with your colleagues to brainstorm ideas.As Senior MLOps Engineer, you play a crucial role in driving Canva's mission to empower the world to design. Our team is at the forefront of developing cutting-edge machine-learning solutions that have a significant impact on Canvas products and services. We collaborate closely with talented machine learning engineers, and product teams to build and deploy scalable, efficient, and reliable machine learning pipelines. Together, we strive to push the boundaries of what's possible, constantly innovating and improving our processes to deliver exceptional user experiences. By joining our team, you will not only contribute to Canvas success but also help shape the future of design and technology.What's in it for you?Achieving our crazy big goals motivates us to work hard - and we do - but you'll experience lots of moments of magic, connectivity and fun woven throughout life at Canva, too. We also offer a stack of benefits to set you up for every success in and outside of work.Here's a taste of what's on offer: ‚Ä¢ Equity packages - we want our success to be yours too ‚Ä¢ Inclusive parental leave policy that supports all parents & carers ‚Ä¢ An annual Vibe & Thrive allowance to support your wellbeing, social connection, office setup & more ‚Ä¢ Flexible leave options that empower you to be a force for good, take time to recharge and supports you personally Check out lifeatcanva.com for more info. Other stuff to knowWe make hiring decisions based on your experience, skills and passion, as well as how you can enhance Canva and our culture. When you apply, please tell us the pronouns you use and any reasonable adjustments you may need during the interview process. Please note that interviews are conducted virtually","[{'items': [""Join the team redefining how the world experiences design.Hey, g'day, mabuhay, kia ora,‰Ω†Â•Ω, hallo, v√≠tejte!Thanks for stopping by. We know job hunting can be a little time consuming and you're probably keen to find out what's on offer, so we'll get straight to the point. Where and how you can workOur flagship campus is in Sydney, Australia but Austria is home to part of our European operations. And with that you will have choice in how you work. That means if you want to do your thing in the office (if you're nearby), at home or a bit of both, it's up to you. Fun fact - our Austrian team actually started out as Kaleido before being acquired by us in 2021. Kaleido's product team develops visual AI products, that make complex things simple for users. Now, together we deliver visual AI features within Canva to help reimagine how artificial intelligence can be used in design. We think it's a perfect match. What you‚Äôd be doing in this roleAs Canva scales change continues to be part of our... DNA. But we like to think that's all part of the fun. So this will give you the flavour of the type of things you'll be working on when you start, but this will likely evolve. At the moment, this role is focused on: You'll get the opportunity to lead large-scale experiments in the cloud, working closely with our skilled platform team to craft efficient tooling solutions.You'll play a strategic role in pushing highly parallelized workloads in the cloud, enhancing both the efficiency and effectiveness of our operations.Drive the adoption of best practices in MLOps, including version control, testing, continuous integration, and deployment.Keep abreast of the latest advancements in machine learning and MLOps technologies, and be proactive in suggesting improvements and new techniques that can enhance the team's capabilities. You're probably a match if You have several years of practical experience working with modern data platforms (both cloud and on-premise), with experience delivering data-centric solutions.You have knowledge in Python, Pytorch, Docker, Kubernetes, AWS, databases, etc. You have a strong sense of ownership and are eager to find and develop novel solutions to challenging problems proactively.You are a strong communicator and a team player and are eager to work together with your colleagues to brainstorm ideas.As Senior MLOps Engineer, you play a crucial role in driving Canva's mission to empower the world to design. Our team is at the forefront of developing cutting-edge machine-learning solutions that have a significant impact on Canvas products and services. We collaborate closely with talented machine learning engineers, and product teams to build and deploy scalable, efficient, and reliable machine learning pipelines. Together, we strive to push the boundaries of what's possible, constantly innovating and improving our processes to deliver exceptional user experiences. By joining our team, you will not only contribute to Canvas success but also help shape the future of design and technology.What's in it for you?Achieving our crazy big goals motivates us to work hard - and we do - but you'll experience lots of moments of magic, connectivity and fun woven throughout life at Canva, too. We also offer a stack of benefits to set you up for every success in and outside of work.Here's a taste of what's on offer: ‚Ä¢ Equity packages - we want our success to be yours too ‚Ä¢ Inclusive parental leave policy that supports all parents & carers ‚Ä¢ An annual Vibe & Thrive allowance to support your wellbeing, social connection, office setup & more ‚Ä¢ Flexible leave options that empower you to be a force for good, take time to recharge and supports you personally Check out lifeatcanva.com for more info. Other stuff to knowWe make hiring decisions based on your experience, skills and passion, as well as how you can enhance Canva and our culture. When you apply, please tell us the pronouns you use and any reasonable adjustments you may need during the interview process. Please note that interviews are conducted virtually""]}]","[{'link': 'http://www.canva.com/', 'text': 'canva.com'}, {'link': 'https://www.google.com/search?hl=en&q=Canva&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIIyg0', 'text': 'See web results for Canva'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsZBLXC9j0_AhFeeNliyir32E0kNsoTcbNRJ7Q&s=0,"['14 days ago', '62,370‚Äì115,830 a year', 'Full-time']","{'posted_at': '14 days ago', 'schedule_type': 'Full-time', 'salary': '62,370‚Äì115,830 a year'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgTUxPcHMgRW5naW5lZXIgKG0vZi94KSAtIEthbGVpZG8gQUkiLCJodGlkb2NpZCI6Ikg2bEVsRnBIal84QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTa1ZxT1VsdFdERTBWVVZGY0hoWVIybzVkSGhmTkY5clpYcHlRbXhFVmxvNVZrNVVTVXBzWDA5eGRXMDFWMUpsYm5KNmJFZzNhR2t6VTBWTldTMW1WVXB2U2pka2EwNUxhbFJxYUdoVk5Gb3lNR2xwVERGZmVqQnRlVFZUT1hneGVVeEJZMjE1WkVKdFZHTklPRE5RVFhOdVZXbGZXRjlzZVZOcWEyY3dhbXRsVm1KcExVVkVRVzFyTVZSdE5UbEZabTFRYUVVM2NXVjFla3N3ZUVweFRVcHhWRTloZWpWSU0zZFRTa2M1TWtSM2RsQjFVRGR1YlU5VFVVTk9PR3g2TW1jM1FYTkZFaGM0VEV4SVdrNXRSRXhmTTBwclVFbFFielF5YUMxQk9Cb2lRVXhGVXpsMVVHaG1SVTlyYzBkTGRtNHlkbUoxU0dKd05qUnBURTl2UkdaQlp3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQWktSm9icy5uZXQiLCJsaW5rIjoiaHR0cHM6Ly9haS1qb2JzLm5ldC9qb2IvNTkwNTktc2VuaW9yLW1sb3BzLWVuZ2luZWVyLW1meC1rYWxlaWRvLWFpLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer (m/w/d),Hays √ñsterreich Working for your tomorrow,"  Vienna, Austria   ",via WJHL Jobs,"Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.

Mein Arbeitgeber

Unser Auftraggeber stellt die Software und den Systembetrieb f√ºr √ºber 25.000 NutzerInnen in der Dienstleistungsbranche.
Aufgaben
‚Ä¢ Ziel ist es, eine einheitliche Datenbasis als Data Analytics-Plattform f√ºr interne Dashboards, Data Driven Analytics / Self-Service Business Intelligence, Advanced Analytics Szenarios und als Datenfeed f√ºr Apps und Web Applikationen zu schaffen
‚Ä¢ Die Time to Market Data driven Architecture-Technologie erm√∂glicht den Fachbereichen der Versicherungsunternehmen, selbstst√§ndig Zusammenh√§nge und Antworten √ºber Kunden- bzw. Vertriebspartner-Verhalten zu finden und daraus Ma√ünahmen abzuleiten
‚Ä¢ Fokus liegt auf Single Point of Truth bzw. qualitativ hochwertige Daten, saubere und transparente Anreicherung der Daten und eine performante Abfragem√∂glichkeit

Profil
‚Ä¢ Fundierte praktische Erfahrung im Umgang mit relationalen DWH Datenbanken basierend auf Microsoft SQL Server
‚Ä¢ Erfahrung in der ETL Programmierung, vor allem hands-on Erfahrung mit SSIS
‚Ä¢ Erfahrung mit C#/.NET ist von Vorteil
‚Ä¢ Du hast Datenmodelierungs-Know-how
‚Ä¢ SQL Performance Optimierung ist mitunter dein Hobby
‚Ä¢ Du bist es gewohnt, deinen Quellcode in GIT oder anderen Versionierungstools f√ºr deine Teamkollegen nachvollziehbar abzulegen
‚Ä¢ Du arbeitest gewissenhaft und dir ist eine analytische und strukturierte Arbeitsweise zu eigen

Wir bieten
‚Ä¢ Modernstes Arbeitsumfeld mit flachen Hierarchien
‚Ä¢ Keine All-In-Vertr√§ge
‚Ä¢ Weiterbildungsm√∂glichkeiten
‚Ä¢ Mindestens 50% Home Office m√∂glich
‚Ä¢ Sichere Deutsch- und Englischkenntnisse
Gehaltsinformationen
‚Ä¢ Das j√§hrliche Bruttogehalt (Vollzeit) f√ºr die Position betr√§gt mindestens ‚Ç¨ 70.000,-. Du bringst bereits viel Erfahrung und Know-how mit? Dann ist man selbstverst√§ndlich bereit, dies mit einer √úberzahlung zu w√ºrdigen","[{'items': ['Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.\n\nMein Arbeitgeber\n\nUnser Auftraggeber stellt die Software und den Systembetrieb f√ºr √ºber 25.000 NutzerInnen in der Dienstleistungsbranche.\nAufgaben\n‚Ä¢ Ziel ist es, eine einheitliche Datenbasis als Data Analytics-Plattform f√ºr interne Dashboards, Data Driven Analytics / Self-Service Business Intelligence, Advanced Analytics Szenarios und als Datenfeed f√ºr Apps und Web Applikationen zu schaffen\n‚Ä¢ Die Time to Market Data driven Architecture-Technologie erm√∂glicht den Fachbereichen der Versicherungsunternehmen, selbstst√§ndig Zusammenh√§nge und Antworten √ºber Kunden- bzw. Vertriebspartner-Verhalten zu finden und daraus Ma√ünahmen abzuleiten\n‚Ä¢ Fokus liegt auf Single Point of Truth bzw. qualitativ hochwertige Daten, saubere und transparente Anreicherung der Daten und eine performante Abfragem√∂glichkeit\n\nProfil\n‚Ä¢ Fundierte praktische Erfahrung im Umgang mit relationalen DWH Datenbanken basierend auf Microsoft SQL Server\n‚Ä¢ Erfahrung in der ETL Programmierung, vor allem hands-on Erfahrung mit SSIS\n‚Ä¢ Erfahrung mit C#/.NET ist von Vorteil\n‚Ä¢ Du hast Datenmodelierungs-Know-how\n‚Ä¢ SQL Performance Optimierung ist mitunter dein Hobby\n‚Ä¢ Du bist es gewohnt, deinen Quellcode in GIT oder anderen Versionierungstools f√ºr deine Teamkollegen nachvollziehbar abzulegen\n‚Ä¢ Du arbeitest gewissenhaft und dir ist eine analytische und strukturierte Arbeitsweise zu eigen\n\nWir bieten\n‚Ä¢ Modernstes Arbeitsumfeld mit flachen Hierarchien\n‚Ä¢ Keine All-In-Vertr√§ge\n‚Ä¢ Weiterbildungsm√∂glichkeiten\n‚Ä¢ Mindestens 50% Home Office m√∂glich\n‚Ä¢ Sichere Deutsch- und Englischkenntnisse\nGehaltsinformationen\n‚Ä¢ Das j√§hrliche Bruttogehalt (Vollzeit) f√ºr die Position betr√§gt mindestens ‚Ç¨ 70.000,-. Du bringst bereits viel Erfahrung und Know-how mit? Dann ist man selbstverst√§ndlich bereit, dies mit einer √úberzahlung zu w√ºrdigen']}]","[{'link': 'https://www.google.com/search?hl=en&q=Hays+%C3%96sterreich+Working+for+your+tomorrow&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAII_Q0', 'text': 'See web results for Hays √ñsterreich Working for your tomorrow'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvIbD0b-JZO9EOSPvXcS2sFRhxy1ho8zUBNqnmr3Px4NRccJpy_8gR&s,"['6 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAobS93L2QpIiwiaHRpZG9jaWQiOiJnWGdVS0RNSGxVNEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzU1hScFUxbG5TMDFoVWpCek5IZElaemhDUWxaSGExbDJSemxIVjFadVkycEhTV1pSTjNCeFRHWXRlRTB6TjA1dlIxVkVabEZuTjNoWGVVSjBhRzB0WTFKb1JrUjNWRlJzVUY5cU5qZDRSVlZMTUU5VlVWaHNSRWc0TFc0MlVXVkhUMmxTYTB3NVpFZDJWRXBKWkVSQ1VrNXNZMk5QZUdScVRVMVRia2xUY0RsV1gwbHJXR05hU1VwTlVYZExSRUpHZFhsMVEyTkJZVU5CYW1wNVIxSmlkRFIxZEV0aVRGaEdVVEIzY2pZM0xXRlJWV2xKYjFsUlJWQkpjRkJTVVRoVFZIaEdhMnRPVnpCcFkwWXphbW8xY1c5MWJWTjZabmRrTUU5S1p4SVhPRXhNU0ZwT2JVUk1Yek5LYTFCSlVHODBNbWd0UVRnYUlrRk1SVk01ZFU5bGRUVndVVXhoUkZsVlNscFJiWHBQZG1WcWFFVmZSRWQwTVZFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTciLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gV0pITCBKb2JzIiwibGluayI6Imh0dHBzOi8vam9icy53amhsLmNvbS9qb2JzL3Nlbmlvci1kYXRhLWVuZ2luZWVyLW0tdy1kLXdpZW4vMTA3MzE4NTM4Mi0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
(Senior) Data Engineer,Payla, Anywhere ,via Wellfound,"The mission of Payla is to build the next generation Buy Now Pay Later platform for European Payment Providers and Financial Institutions, allowing our customers to offer invoice and installment plans to meet the demand for fast & frictionless payments.

Along the way, we solve exciting challenges in risk management, payment type processing, and accounts receivable management, all while delivering a superior customer experience.

So, if you're passionate about being in the center of something new and exciting, and love to work collaboratively on the Payla vision with us, don‚Äôt look any further; you can do so as our (Senior) Data Engineer (all genders)!

This position is ‚Äì in the spirit of Payla ‚Äì Europe-based and remote first.

What you will do:
‚Ä¢ You will create, own, maintain, and develop our Data Warehouse from the scratch, ensuring its robustness, scalability, and extensibility
‚Ä¢ You will act as an important link between our DevOps, Data Science, Analysts, and software engineers
‚Ä¢... Your ETL processes will make sure that reliable data is available to our data consumers, such as Risk Analysts, Data Scientists, and other departments, as quickly and efficiently as possible
‚Ä¢ You will build the foundations for our Data Scientists to bring our Machine Learning models to the next level
‚Ä¢ You will enjoy making your code as efficient and readable as possible
‚Ä¢ You will take ownership of the quality of data being processed
‚Ä¢ You will contribute your own ideas to make the flow of our data even better

What you will bring to the team:
‚Ä¢ You have a bachelor‚Äôs degree in computer science or a related field (or good arguments, why this was a waste of time)
‚Ä¢ You have at least two years of experience as a Data engineer or in a similar role
‚Ä¢ You are comfortable working with Python, Containers, and CI infrastructure
‚Ä¢ You have working experience with scheduling tools such as Apache Airflow or Dagster
‚Ä¢ You have experience with data modeling, ETLs, data warehousing and SQL
‚Ä¢ You have already crafted data solutions and deployed data pipelines in production
‚Ä¢ Experience with building reports and using reporting tools (e.g. Apache Superset, Looker, Tableau) is a plus
‚Ä¢ Having knowledge in AWS, Kubernetes, and DevOps principles is a plus
‚Ä¢ You are fluent in both written and spoken English, German is a plus
‚Ä¢ You are a team player with a caring personality
‚Ä¢ It's Day 1, so for us it is most important that you bring in the right engineering mindset and that you are curious on tackling upcoming architectural challenges while being able to solve the details on your own or in consultation with our Software Engineers

What Payla offers:
‚Ä¢ Team: An encouraging, passionate and supportive team environment
‚Ä¢ Flexibility: We will create a professional work environment for you at your remote location
‚Ä¢ Freedom: Select your hardware and operating system
‚Ä¢ Vacation: 30 days paid per year
‚Ä¢ Start-up Spirit: Exciting challenges from Day 1 with focus on results, less on hierarchy or ""bingo meetings""

Payla focuses on Europe. Their company has offices in Hamburg. They have a small team that's between 11-50 employees.

You can view their website at https://payla.de","[{'items': ['The mission of Payla is to build the next generation Buy Now Pay Later platform for European Payment Providers and Financial Institutions, allowing our customers to offer invoice and installment plans to meet the demand for fast & frictionless payments.\n\nAlong the way, we solve exciting challenges in risk management, payment type processing, and accounts receivable management, all while delivering a superior customer experience.\n\nSo, if you\'re passionate about being in the center of something new and exciting, and love to work collaboratively on the Payla vision with us, don‚Äôt look any further; you can do so as our (Senior) Data Engineer (all genders)!\n\nThis position is ‚Äì in the spirit of Payla ‚Äì Europe-based and remote first.\n\nWhat you will do:\n‚Ä¢ You will create, own, maintain, and develop our Data Warehouse from the scratch, ensuring its robustness, scalability, and extensibility\n‚Ä¢ You will act as an important link between our DevOps, Data Science, Analysts, and software engineers\n‚Ä¢... Your ETL processes will make sure that reliable data is available to our data consumers, such as Risk Analysts, Data Scientists, and other departments, as quickly and efficiently as possible\n‚Ä¢ You will build the foundations for our Data Scientists to bring our Machine Learning models to the next level\n‚Ä¢ You will enjoy making your code as efficient and readable as possible\n‚Ä¢ You will take ownership of the quality of data being processed\n‚Ä¢ You will contribute your own ideas to make the flow of our data even better\n\nWhat you will bring to the team:\n‚Ä¢ You have a bachelor‚Äôs degree in computer science or a related field (or good arguments, why this was a waste of time)\n‚Ä¢ You have at least two years of experience as a Data engineer or in a similar role\n‚Ä¢ You are comfortable working with Python, Containers, and CI infrastructure\n‚Ä¢ You have working experience with scheduling tools such as Apache Airflow or Dagster\n‚Ä¢ You have experience with data modeling, ETLs, data warehousing and SQL\n‚Ä¢ You have already crafted data solutions and deployed data pipelines in production\n‚Ä¢ Experience with building reports and using reporting tools (e.g. Apache Superset, Looker, Tableau) is a plus\n‚Ä¢ Having knowledge in AWS, Kubernetes, and DevOps principles is a plus\n‚Ä¢ You are fluent in both written and spoken English, German is a plus\n‚Ä¢ You are a team player with a caring personality\n‚Ä¢ It\'s Day 1, so for us it is most important that you bring in the right engineering mindset and that you are curious on tackling upcoming architectural challenges while being able to solve the details on your own or in consultation with our Software Engineers\n\nWhat Payla offers:\n‚Ä¢ Team: An encouraging, passionate and supportive team environment\n‚Ä¢ Flexibility: We will create a professional work environment for you at your remote location\n‚Ä¢ Freedom: Select your hardware and operating system\n‚Ä¢ Vacation: 30 days paid per year\n‚Ä¢ Start-up Spirit: Exciting challenges from Day 1 with focus on results, less on hierarchy or ""bingo meetings""\n\nPayla focuses on Europe. Their company has offices in Hamburg. They have a small team that\'s between 11-50 employees.\n\nYou can view their website at https://payla.de']}]","[{'link': 'https://www.google.com/search?hl=en&q=Payla&sa=X&ved=0ahUKEwjZu6nRgrmAAxX9JEQIHaNGCP84ChCYkAIIrw4', 'text': 'See web results for Payla'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSYRCB_YymHLD14mkmnvbFgWX_-87bueuVMzHT254I&s,"['Work from home', 'Full-time']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiIoU2VuaW9yKSBEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJXTDhZVUhiVHFKVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVMXJNbXhzU25adVJIcDNWMmhzWlRWbVpsZHBlRFJRVW1KTlRHTXlTRkpqU0ZCQ1p6bG5lVWhzVVdNeFRFTlNTMnBJVFZCYVdVdE9XR2hyUWtjMVFpMHRPVTVLVVVGR2RqaGpWRU5DUTBwcWFYRTRNV2d4Tm5adVJIWkZlV2xwVUdGRGFYbG1XbVpNZDA1MFdUSlhkME5CV2pCWlRrNTJORlo2VTJKMlUzZHdRbUY0VkdOVFMxVXliWE5LVDI4NU1VbFRWRWszT1hkNWVXWTVhMjVHY1Y5QkVoYzRURXhJV2s1dFJFeGZNMHByVUVsUWJ6UXlhQzFCT0JvaVFVeEZVemwxVUZsVFRUaHNjV05UTkdwWVdIQnhRbTVOTldoR1RWVklTMGd3ZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xOCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBXZWxsZm91bmQiLCJsaW5rIjoiaHR0cHM6Ly93ZWxsZm91bmQuY29tL2NvbXBhbnkvcGF5LWxhL2pvYnMvMTcyNDA3NC1zZW5pb3ItZGF0YS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer (m/w/d),Hays √ñsterreich Working for your tomorrow,"  Vienna, Austria   ",via WJHL Jobs,"Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.

Mein Arbeitgeber

Unser Auftraggeber stellt die Software und den Systembetrieb f√ºr √ºber 25.000 NutzerInnen in der Dienstleistungsbranche.
Aufgaben
‚Ä¢ Ziel ist es, eine einheitliche Datenbasis als Data Analytics-Plattform f√ºr interne Dashboards, Data Driven Analytics / Self-Service Business Intelligence, Advanced Analytics Szenarios und als Datenfeed f√ºr Apps und Web Applikationen zu schaffen
‚Ä¢ Die Time to Market Data driven Architecture-Technologie erm√∂glicht den Fachbereichen der Versicherungsunternehmen, selbstst√§ndig Zusammenh√§nge und Antworten √ºber Kunden- bzw. Vertriebspartner-Verhalten zu finden und daraus Ma√ünahmen abzuleiten
‚Ä¢ Fokus liegt auf Single Point of Truth bzw. qualitativ hochwertige Daten, saubere und transparente Anreicherung der Daten und eine performante Abfragem√∂glichkeit

Profil
‚Ä¢ Fundierte praktische Erfahrung im Umgang mit relationalen DWH Datenbanken basierend auf Microsoft SQL Server
‚Ä¢ Erfahrung in der ETL Programmierung, vor allem hands-on Erfahrung mit SSIS
‚Ä¢ Erfahrung mit C#/.NET ist von Vorteil
‚Ä¢ Du hast Datenmodelierungs-Know-how
‚Ä¢ SQL Performance Optimierung ist mitunter dein Hobby
‚Ä¢ Du bist es gewohnt, deinen Quellcode in GIT oder anderen Versionierungstools f√ºr deine Teamkollegen nachvollziehbar abzulegen
‚Ä¢ Du arbeitest gewissenhaft und dir ist eine analytische und strukturierte Arbeitsweise zu eigen

Wir bieten
‚Ä¢ Modernstes Arbeitsumfeld mit flachen Hierarchien
‚Ä¢ Keine All-In-Vertr√§ge
‚Ä¢ Weiterbildungsm√∂glichkeiten
‚Ä¢ Mindestens 50% Home Office m√∂glich
‚Ä¢ Sichere Deutsch- und Englischkenntnisse
Gehaltsinformationen
‚Ä¢ Das j√§hrliche Bruttogehalt (Vollzeit) f√ºr die Position betr√§gt mindestens ‚Ç¨ 70.000,-. Du bringst bereits viel Erfahrung und Know-how mit? Dann ist man selbstverst√§ndlich bereit, dies mit einer √úberzahlung zu w√ºrdigen","[{'items': ['Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.\n\nMein Arbeitgeber\n\nUnser Auftraggeber stellt die Software und den Systembetrieb f√ºr √ºber 25.000 NutzerInnen in der Dienstleistungsbranche.\nAufgaben\n‚Ä¢ Ziel ist es, eine einheitliche Datenbasis als Data Analytics-Plattform f√ºr interne Dashboards, Data Driven Analytics / Self-Service Business Intelligence, Advanced Analytics Szenarios und als Datenfeed f√ºr Apps und Web Applikationen zu schaffen\n‚Ä¢ Die Time to Market Data driven Architecture-Technologie erm√∂glicht den Fachbereichen der Versicherungsunternehmen, selbstst√§ndig Zusammenh√§nge und Antworten √ºber Kunden- bzw. Vertriebspartner-Verhalten zu finden und daraus Ma√ünahmen abzuleiten\n‚Ä¢ Fokus liegt auf Single Point of Truth bzw. qualitativ hochwertige Daten, saubere und transparente Anreicherung der Daten und eine performante Abfragem√∂glichkeit\n\nProfil\n‚Ä¢ Fundierte praktische Erfahrung im Umgang mit relationalen DWH Datenbanken basierend auf Microsoft SQL Server\n‚Ä¢ Erfahrung in der ETL Programmierung, vor allem hands-on Erfahrung mit SSIS\n‚Ä¢ Erfahrung mit C#/.NET ist von Vorteil\n‚Ä¢ Du hast Datenmodelierungs-Know-how\n‚Ä¢ SQL Performance Optimierung ist mitunter dein Hobby\n‚Ä¢ Du bist es gewohnt, deinen Quellcode in GIT oder anderen Versionierungstools f√ºr deine Teamkollegen nachvollziehbar abzulegen\n‚Ä¢ Du arbeitest gewissenhaft und dir ist eine analytische und strukturierte Arbeitsweise zu eigen\n\nWir bieten\n‚Ä¢ Modernstes Arbeitsumfeld mit flachen Hierarchien\n‚Ä¢ Keine All-In-Vertr√§ge\n‚Ä¢ Weiterbildungsm√∂glichkeiten\n‚Ä¢ Mindestens 50% Home Office m√∂glich\n‚Ä¢ Sichere Deutsch- und Englischkenntnisse\nGehaltsinformationen\n‚Ä¢ Das j√§hrliche Bruttogehalt (Vollzeit) f√ºr die Position betr√§gt mindestens ‚Ç¨ 70.000,-. Du bringst bereits viel Erfahrung und Know-how mit? Dann ist man selbstverst√§ndlich bereit, dies mit einer √úberzahlung zu w√ºrdigen']}]","[{'link': 'https://www.google.com/search?hl=en&q=Hays+%C3%96sterreich+Working+for+your+tomorrow&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAII4Qo', 'text': 'See web results for Hays √ñsterreich Working for your tomorrow'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvIbD0b-JZO9EOSPvXcS2sFRhxy1ho8zUBNqnmr3Px4NRccJpy_8gR&s,"['6 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAobS93L2QpIiwiaHRpZG9jaWQiOiJnWGdVS0RNSGxVNEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzU1d0MFprNHRWMDVyYmxCUVZHUnlTak55Y2xObWEybGtXbkZRUTFvd1YxZDBVM05FVXpBMFFVbDJZM2xVTkdFdFpqSkZlVEZ5UW1Nd1JVNUlWMFpmVFZkQmVuZG9TVXMzUjI4MGNYQmtjbk5GZWt0dU1VTlFXbEF6ZUhkeWVFcExMVkUwVHpsTFVWQmpSMlZTVEdZeE5WaHVVMkpYUXpoTGNYa3lWRkpTU0ZZM2RVWlJkVkp2VkdrNWNFVlZiUzFrWDJ0b2EyTXpYMTlOVmxweU0yaHFUVE0zV1V0ME5HRktRMDVOZEhCTFZuUmFhSFI2UzBWTFRqWjZlbkk1VW5oRlpVeDRXSFI2TTNjeGVubEdjRWh1WTJKcGVWcGlOVGhWV0RKSVFSSVhPV0pNU0ZwUU4ybENZMkZ2TlU1dlVEbHljVEpuUVZVYUlrRk1SVk01ZFUwdFdWOWFZVUpUVTNFMlNEQnJhMlphV1RkSGVIVjNMVXAzY0hjIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiIubkZnMmVie2ZvbnQtd2VpZ2h0OjUwMH0uQmk2RGRje2ZvbnQtd2VpZ2h0OjUwMH1BcHBseSBvbiBXSkhMIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9qb2JzLndqaGwuY29tL2pvYnMvc2VuaW9yLWRhdGEtZW5naW5lZXItbS13LWQtd2llbi8xMDczMTg1MzgyLTIvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
(Senior) Data Engineer,Payla, Anywhere ,via Wellfound,"The mission of Payla is to build the next generation Buy Now Pay Later platform for European Payment Providers and Financial Institutions, allowing our customers to offer invoice and installment plans to meet the demand for fast & frictionless payments.

Along the way, we solve exciting challenges in risk management, payment type processing, and accounts receivable management, all while delivering a superior customer experience.

So, if you're passionate about being in the center of something new and exciting, and love to work collaboratively on the Payla vision with us, don‚Äôt look any further; you can do so as our (Senior) Data Engineer (all genders)!

This position is ‚Äì in the spirit of Payla ‚Äì Europe-based and remote first.

What you will do:
‚Ä¢ You will create, own, maintain, and develop our Data Warehouse from the scratch, ensuring its robustness, scalability, and extensibility
‚Ä¢ You will act as an important link between our DevOps, Data Science, Analysts, and software engineers
‚Ä¢... Your ETL processes will make sure that reliable data is available to our data consumers, such as Risk Analysts, Data Scientists, and other departments, as quickly and efficiently as possible
‚Ä¢ You will build the foundations for our Data Scientists to bring our Machine Learning models to the next level
‚Ä¢ You will enjoy making your code as efficient and readable as possible
‚Ä¢ You will take ownership of the quality of data being processed
‚Ä¢ You will contribute your own ideas to make the flow of our data even better

What you will bring to the team:
‚Ä¢ You have a bachelor‚Äôs degree in computer science or a related field (or good arguments, why this was a waste of time)
‚Ä¢ You have at least two years of experience as a Data engineer or in a similar role
‚Ä¢ You are comfortable working with Python, Containers, and CI infrastructure
‚Ä¢ You have working experience with scheduling tools such as Apache Airflow or Dagster
‚Ä¢ You have experience with data modeling, ETLs, data warehousing and SQL
‚Ä¢ You have already crafted data solutions and deployed data pipelines in production
‚Ä¢ Experience with building reports and using reporting tools (e.g. Apache Superset, Looker, Tableau) is a plus
‚Ä¢ Having knowledge in AWS, Kubernetes, and DevOps principles is a plus
‚Ä¢ You are fluent in both written and spoken English, German is a plus
‚Ä¢ You are a team player with a caring personality
‚Ä¢ It's Day 1, so for us it is most important that you bring in the right engineering mindset and that you are curious on tackling upcoming architectural challenges while being able to solve the details on your own or in consultation with our Software Engineers

What Payla offers:
‚Ä¢ Team: An encouraging, passionate and supportive team environment
‚Ä¢ Flexibility: We will create a professional work environment for you at your remote location
‚Ä¢ Freedom: Select your hardware and operating system
‚Ä¢ Vacation: 30 days paid per year
‚Ä¢ Start-up Spirit: Exciting challenges from Day 1 with focus on results, less on hierarchy or ""bingo meetings""

Payla focuses on Europe. Their company has offices in Hamburg. They have a small team that's between 11-50 employees.

You can view their website at https://payla.de","[{'items': ['The mission of Payla is to build the next generation Buy Now Pay Later platform for European Payment Providers and Financial Institutions, allowing our customers to offer invoice and installment plans to meet the demand for fast & frictionless payments.\n\nAlong the way, we solve exciting challenges in risk management, payment type processing, and accounts receivable management, all while delivering a superior customer experience.\n\nSo, if you\'re passionate about being in the center of something new and exciting, and love to work collaboratively on the Payla vision with us, don‚Äôt look any further; you can do so as our (Senior) Data Engineer (all genders)!\n\nThis position is ‚Äì in the spirit of Payla ‚Äì Europe-based and remote first.\n\nWhat you will do:\n‚Ä¢ You will create, own, maintain, and develop our Data Warehouse from the scratch, ensuring its robustness, scalability, and extensibility\n‚Ä¢ You will act as an important link between our DevOps, Data Science, Analysts, and software engineers\n‚Ä¢... Your ETL processes will make sure that reliable data is available to our data consumers, such as Risk Analysts, Data Scientists, and other departments, as quickly and efficiently as possible\n‚Ä¢ You will build the foundations for our Data Scientists to bring our Machine Learning models to the next level\n‚Ä¢ You will enjoy making your code as efficient and readable as possible\n‚Ä¢ You will take ownership of the quality of data being processed\n‚Ä¢ You will contribute your own ideas to make the flow of our data even better\n\nWhat you will bring to the team:\n‚Ä¢ You have a bachelor‚Äôs degree in computer science or a related field (or good arguments, why this was a waste of time)\n‚Ä¢ You have at least two years of experience as a Data engineer or in a similar role\n‚Ä¢ You are comfortable working with Python, Containers, and CI infrastructure\n‚Ä¢ You have working experience with scheduling tools such as Apache Airflow or Dagster\n‚Ä¢ You have experience with data modeling, ETLs, data warehousing and SQL\n‚Ä¢ You have already crafted data solutions and deployed data pipelines in production\n‚Ä¢ Experience with building reports and using reporting tools (e.g. Apache Superset, Looker, Tableau) is a plus\n‚Ä¢ Having knowledge in AWS, Kubernetes, and DevOps principles is a plus\n‚Ä¢ You are fluent in both written and spoken English, German is a plus\n‚Ä¢ You are a team player with a caring personality\n‚Ä¢ It\'s Day 1, so for us it is most important that you bring in the right engineering mindset and that you are curious on tackling upcoming architectural challenges while being able to solve the details on your own or in consultation with our Software Engineers\n\nWhat Payla offers:\n‚Ä¢ Team: An encouraging, passionate and supportive team environment\n‚Ä¢ Flexibility: We will create a professional work environment for you at your remote location\n‚Ä¢ Freedom: Select your hardware and operating system\n‚Ä¢ Vacation: 30 days paid per year\n‚Ä¢ Start-up Spirit: Exciting challenges from Day 1 with focus on results, less on hierarchy or ""bingo meetings""\n\nPayla focuses on Europe. Their company has offices in Hamburg. They have a small team that\'s between 11-50 employees.\n\nYou can view their website at https://payla.de']}]","[{'link': 'https://www.google.com/search?hl=en&q=Payla&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIkws', 'text': 'See web results for Payla'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSYRCB_YymHLD14mkmnvbFgWX_-87bueuVMzHT254I&s,"['Work from home', 'Full-time']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiIoU2VuaW9yKSBEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJXTDhZVUhiVHFKVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVMXJNbXhzUzNOWmNDMW1ORUpWVHpkUlozTm9aM0JtYjNacWNrMXZUbWh4V1hsUE0zbDFiRTEyWDNSV2NsZGtla2N6ZDNwbFdXdHhVV2hwWTNsRk1qbEZWSEZuT0ZSQ1RUWkxZalphU2sxMFQyTm1iMmxpTFhWMVJVODNVQzFhZG5ka1prcFpka0p0VFdwd2VtMVVjMHhaZUUxR1ozb3paV1o1YldkWWFrTllXbmRPT1d0c1FVcFpZWEYyWVVkS1JXeExZM1kwUnpKaVRUbDNZWEJwYzB0bkVoYzVZa3hJV2xBM2FVSmpZVzgxVG05UU9YSnhNbWRCVlJvaVFVeEZVemwxVUZGcWMzUXRSR1l0WTBwRmIyUnRiR1JZVm5KWlNFMUpVVWxOZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18yIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIFdlbGxmb3VuZCIsImxpbmsiOiJodHRwczovL3dlbGxmb3VuZC5jb20vY29tcGFueS9wYXktbGEvam9icy8xNzI0MDc0LXNlbmlvci1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer /m/f/x/ - Excellent Benefits Package,Immofinanz Ag,"  Vienna, Austria   ",via GrabJobs,"We are hiring a strategic Data Engineer (m/f/x) to join our all-star team at IMMOFINANZ AG in Wien.
Growing your career as a Full Time Data Engineer (m/f/x) is an outstanding opportunity to develop key skills.
If you are strong in communication, adaptability and have the right determination for the job, then apply for the position of Data Engineer (m/f/x) at IMMOFINANZ AG today!

Data Engineer (m/f/x)

IMMOFINANZ is an international real estate company. We offer you the structure of a large corporation, outstanding development opportunities within a modern working environment and a young and inspiring team. Find out more about IMMOFINANZ and what it means to be part of an international, dynamic organization. See how we design the way towards a new era of real estate development. Did we catch your eye- read more about the current job offer:

YOUR PROFILE
‚Ä¢ Practical experience in the core areas: ETL development, data modeling, advanced SQL, and system integrations, both on premise and... in cloud environments
‚Ä¢ Interest in working with MS Azure technologies like Data Lake, Databricks, Data Factory, Synapse, Analysis Services, Power BI and PurView
‚Ä¢ Working experience of DevOps is an advantage
‚Ä¢ Good communication skills and team spirit is highly appreciated
‚Ä¢ Having a service-oriented mindset
‚Ä¢ Very good English skills - German skills are an advantage

YOUR RESPONSIBILITIES
‚Ä¢ Working with Oracle DB, Oracle ODI, Oracle Integration Cloud, MS SQL, MS SSAS, Azure Data Lake, Azure Data Factory, Power BI, etc.
‚Ä¢ Development of concepts and solutions for ETL processes, data models, data integrations and reporting environment
‚Ä¢ Operation, maintenance and continuous improvement of the data warehouse and data integration platform
‚Ä¢ Working with Azure DevOps together with external partners within an agile mindset
‚Ä¢ Active participation in IT projects
‚Ä¢ Technical support for IT application managers and business departments
‚Ä¢ Creation of application documentation for support, operation, and maintenance

For this position we offer a market-compliant salary of EUR 3.850 gross per month. However, an overpay is possible according to qualification and experience.
BENEFITS
‚Ä¢ Sixth week of vacation after 3 years in the company
‚Ä¢ Daily meal allowance of EUR 6.00
‚Ä¢ Flexible working hours
‚Ä¢ Free fruit and drinks
‚Ä¢ Free use of the MyClubs app (sports offer)
‚Ä¢ Annual ticket of Wiener Linien or possibility for a garage parking space in the
MyHive Vienna Twin Tower
‚Ä¢ Internal and external training and further development opportunities
‚Ä¢ Occupational pension provision
‚Ä¢ Occupational health care
‚Ä¢ Annual health check-up

We are looking forward to your application.

Please send us your application via our online job portal.

Contact

We are looking forward to your application.

Nadine Falkensteiner

Benefits of working as a Data Engineer (m/f/x) in Wien:

‚óè Excellent Benefits Package
‚óè Professional Development Opportunities
‚óè Competitive salary","[{'items': ['We are hiring a strategic Data Engineer (m/f/x) to join our all-star team at IMMOFINANZ AG in Wien.\nGrowing your career as a Full Time Data Engineer (m/f/x) is an outstanding opportunity to develop key skills.\nIf you are strong in communication, adaptability and have the right determination for the job, then apply for the position of Data Engineer (m/f/x) at IMMOFINANZ AG today!\n\nData Engineer (m/f/x)\n\nIMMOFINANZ is an international real estate company. We offer you the structure of a large corporation, outstanding development opportunities within a modern working environment and a young and inspiring team. Find out more about IMMOFINANZ and what it means to be part of an international, dynamic organization. See how we design the way towards a new era of real estate development. Did we catch your eye- read more about the current job offer:\n\nYOUR PROFILE\n‚Ä¢ Practical experience in the core areas: ETL development, data modeling, advanced SQL, and system integrations, both on premise and... in cloud environments\n‚Ä¢ Interest in working with MS Azure technologies like Data Lake, Databricks, Data Factory, Synapse, Analysis Services, Power BI and PurView\n‚Ä¢ Working experience of DevOps is an advantage\n‚Ä¢ Good communication skills and team spirit is highly appreciated\n‚Ä¢ Having a service-oriented mindset\n‚Ä¢ Very good English skills - German skills are an advantage\n\nYOUR RESPONSIBILITIES\n‚Ä¢ Working with Oracle DB, Oracle ODI, Oracle Integration Cloud, MS SQL, MS SSAS, Azure Data Lake, Azure Data Factory, Power BI, etc.\n‚Ä¢ Development of concepts and solutions for ETL processes, data models, data integrations and reporting environment\n‚Ä¢ Operation, maintenance and continuous improvement of the data warehouse and data integration platform\n‚Ä¢ Working with Azure DevOps together with external partners within an agile mindset\n‚Ä¢ Active participation in IT projects\n‚Ä¢ Technical support for IT application managers and business departments\n‚Ä¢ Creation of application documentation for support, operation, and maintenance\n\nFor this position we offer a market-compliant salary of EUR 3.850 gross per month. However, an overpay is possible according to qualification and experience.\nBENEFITS\n‚Ä¢ Sixth week of vacation after 3 years in the company\n‚Ä¢ Daily meal allowance of EUR 6.00\n‚Ä¢ Flexible working hours\n‚Ä¢ Free fruit and drinks\n‚Ä¢ Free use of the MyClubs app (sports offer)\n‚Ä¢ Annual ticket of Wiener Linien or possibility for a garage parking space in the\nMyHive Vienna Twin Tower\n‚Ä¢ Internal and external training and further development opportunities\n‚Ä¢ Occupational pension provision\n‚Ä¢ Occupational health care\n‚Ä¢ Annual health check-up\n\nWe are looking forward to your application.\n\nPlease send us your application via our online job portal.\n\nContact\n\nWe are looking forward to your application.\n\nNadine Falkensteiner\n\nBenefits of working as a Data Engineer (m/f/x) in Wien:\n\n‚óè Excellent Benefits Package\n‚óè Professional Development Opportunities\n‚óè Competitive salary']}]","[{'link': 'http://www.immofinanz.com/', 'text': 'immofinanz.com'}, {'link': 'https://www.google.com/search?hl=en&q=Immofinanz+Ag&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIxws', 'text': 'See web results for Immofinanz Ag'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRbIp5G6VBZX4zF_PWtdUG9FA5m4G-6US-iIXVuJZ4&s,"['5 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '5 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIC9tL2YveC8gLSBFeGNlbGxlbnQgQmVuZWZpdHMgUGFja2FnZSIsImh0aWRvY2lkIjoiVjVNZk5weVc1N2tBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVTFyTW14c1NuUXpObFJsZVdGTGVWbFdVRWx1UWt4eFpYbHFaUzFSWm5ZMFpHNTJiR1Z6T0d4ZlRYZ3RPVmRXVkd0Q1MyWjJValJMYkVwc1pXdHNhV1ZrTjJsalJ6ZFhaMlZqWkU5QmFEaHZTa1JMZWs5T1drbEhSMFY0YW1weVQwNXBSMUoyWnpkS2NWRnRiRVZ3UWpKV1NraEhRa0ZSYWxaeVlVWjZiemc1YWsxWFVHdHdURXhQTkhBMVNsUmlhMmxRZEVGRlVUZzBZeTFFYUdsUmREVnVPR1JYVWt0TVRsOVVhek41WmpnelQxaFJSbVJzZWt0elZFcGFRbFJyYWxoa1FuTkZiWGR0Y1MxTk9ERnhibWM1TUU5M04wNHhUVlE0Wm5wdlEwZE1keElYT1dKTVNGcFFOMmxDWTJGdk5VNXZVRGx5Y1RKblFWVWFJa0ZNUlZNNWRVMDVTbXRwWTNKZlpVdFVjSGRMVFhOalMwdE5VSGQ0UjNkeFRYYyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gR3JhYkpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9ncmFiam9icy5jby9hdXN0cmlhL2pvYi9mdWxsLXRpbWUvbWFya2V0aW5nLW1lZGlhL2RhdGEtZW5naW5lZXItbWZ4LWV4Y2VsbGVudC1iZW5lZml0cy1wYWNrYWdlLTI0NTc4NTA4P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer,SO Digital Recruitment Ltd,"  Vienna, Austria   ",via GoHire,"We are partnered with a great company in Vienna who are seeking an experienced Data Engineer to join their team. This is a truly exciting place to work where you will be exposed to innovative projects and use modern technologies. There is a great team culture and a focus on learning and development.

WHAT TO EXPECT
‚Ä¢ Exciting projects with well-known customers
‚Ä¢ A focus on learning and development
‚Ä¢ Opportunity to use cutting-edge technologies
‚Ä¢ Flexi working

YOUR PROFILE
‚Ä¢ Proven work as a Data Engineer
‚Ä¢ Experience with Cloud-based data architecture (ideally Azure, others accepted)
‚Ä¢ SQL and NoSQL Databsae knowledge
‚Ä¢ Spark and Hadoop stack knowledge (Nice to have)
‚Ä¢ Knowledge of building data processing pipelines
‚Ä¢ German and/or English speakers","[{'items': ['We are partnered with a great company in Vienna who are seeking an experienced Data Engineer to join their team. This is a truly exciting place to work where you will be exposed to innovative projects and use modern technologies. There is a great team culture and a focus on learning and development.\n\nWHAT TO EXPECT\n‚Ä¢ Exciting projects with well-known customers\n‚Ä¢ A focus on learning and development\n‚Ä¢ Opportunity to use cutting-edge technologies\n‚Ä¢ Flexi working\n\nYOUR PROFILE\n‚Ä¢ Proven work as a Data Engineer\n‚Ä¢ Experience with Cloud-based data architecture (ideally Azure, others accepted)\n‚Ä¢ SQL and NoSQL Databsae knowledge\n‚Ä¢ Spark and Hadoop stack knowledge (Nice to have)\n‚Ä¢ Knowledge of building data processing pipelines\n‚Ä¢ German and/or English speakers']}]","[{'link': 'https://www.google.com/search?hl=en&q=SO+Digital+Recruitment+Ltd&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAII-As', 'text': 'See web results for SO Digital Recruitment Ltd'}]",,"['‚Ç¨65K‚Äì‚Ç¨85K a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiWTYtMkQ3QmtmUUVBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1NWOUVXa1JtU1haTFlVVjRMWGwxYlc4M2JESndabU56VUhaMmVrZEVhM2c0VFRoUFNrdDNhMk5HT1ZCNk0zSTNNVE14VGtaTVNUbHNaWHBEWjFWUldHVlVOMFZHYUZsSGJuTkRhRmxRYVdScFNFVk1YMEpZUTJKak5GTm5NMjV5TjBKNVQzVnhha0Z6V1ZRMWVtTkZUVFJWYmpoVU4xVmxZalUzU1hFelF6QjVOWEp5UjNOV1l6Snhka2d6UmxWWFJVbDFkWEk0UVU5SVFsQnhTalp0V0ZCTFIzUmhhbGhGVUhreFpWVjJOMGxqRWhjNVlreElXbEEzYVVKallXODFUbTlRT1hKeE1tZEJWUm9pUVV4RlV6bDFUbmhTVW1OaldsVXpRakJHZHpOU1VEaDRMVzVRZVdreWNqSm9RUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gR29IaXJlIiwibGluayI6Imh0dHBzOi8vam9icy5nb2hpcmUuaW8vc28tZGlnaXRhbC1yZWNydWl0bWVudC1sdGQtaWpwNWp2bnovc2VuaW9yLWRhdGEtZW5naW5lZXItMTEyMzA5Lz9zb3VyY2U9bW9uc3Rlclx1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Scientist ( Senior ),paiqo GmbH,"  Vienna, Austria   ",via Careers - Jobs - Paiqo GmbH,"We are a young consulting company with a team of talented data engineers, architects and data scientists specializing in building cloud-based data platforms and AI/ML solutions for our customers. Our customers, with which we have strong relationships and multi-year contracts, include well-known companies in the areas of energy providers & utilities, retail, financial services, and mobile apps. Our projects always involve applying cutting-edge cloud technologies to exciting real-world data. This is shown by our strong relationship with Microsoft where we have multiple Gold- and Advanced Certifications.

One extremely important aspect of the work at paiqo is our culture ‚Äì having fun working together, trusting each other, and combining independence with teamwork. There are no fixed working hours and no fixed reporting structure. We are looking for Data Engineers who we can trust to do great work on their projects because they are motivated by the challenging nature of the projects... themselves. We are also looking for people who we can learn from and who are willing to learn with us, to always stay on the cutting edge with our technical skills.

Your tasks in a project could be
‚Ä¢ Interacting with the customer and understanding his business needs and processes
‚Ä¢ Use case reflection together with the customer to find the best use case to apply Data Science / Machine Learning
‚Ä¢ Analyzing and understanding the provided data and connecting it to the business processes
‚Ä¢ Implementing a machine learning model (whichever model fits best; e.g. in python) which improves the business processes
‚Ä¢ Presentation of results and discussion of machine learning model internally and with the customer
‚Ä¢ Deployment of the found model in customer's business processes (on-Prem or in cloud)

What we offer
‚Ä¢ Challenging projects with well-known companies in various fields
‚Ä¢ Young and highly motivated team
‚Ä¢ Great emphasis on education and trainings with dedicated time on the job
‚Ä¢ Mentoring and guidance from senior colleagues
‚Ä¢ Opportunity to use the newest technologies around Data Science
‚Ä¢ Home office
‚Ä¢ Flexible working hours
‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand customers‚Äô technical ecosystems and data, as well as an ability to communicate complex technical problems and their solutions clearly
‚Ä¢ Experience in the Python and/or R Data Science ecosystems
‚Ä¢ Interest in working with visualization tools (PowerBI, etc.)
‚Ä¢ Interest in modern cloud-based data architecture and cloud services
‚Ä¢ Interest in working with Spark and the Hadoop stack
‚Ä¢ Readiness to travel
‚Ä¢ German and English fluently spoken and written
‚Ä¢ Deep understanding of the overall Data Science workflow including the most common algorithms
‚Ä¢ Experience in working with various databases (SQL and NoSQL)
‚Ä¢ 5+ years of experience in a similar role
‚Ä¢ Ability to handle the full data science lifecycle from conception to deployment","[{'items': [""We are a young consulting company with a team of talented data engineers, architects and data scientists specializing in building cloud-based data platforms and AI/ML solutions for our customers. Our customers, with which we have strong relationships and multi-year contracts, include well-known companies in the areas of energy providers & utilities, retail, financial services, and mobile apps. Our projects always involve applying cutting-edge cloud technologies to exciting real-world data. This is shown by our strong relationship with Microsoft where we have multiple Gold- and Advanced Certifications.\n\nOne extremely important aspect of the work at paiqo is our culture ‚Äì having fun working together, trusting each other, and combining independence with teamwork. There are no fixed working hours and no fixed reporting structure. We are looking for Data Engineers who we can trust to do great work on their projects because they are motivated by the challenging nature of the projects... themselves. We are also looking for people who we can learn from and who are willing to learn with us, to always stay on the cutting edge with our technical skills.\n\nYour tasks in a project could be\n‚Ä¢ Interacting with the customer and understanding his business needs and processes\n‚Ä¢ Use case reflection together with the customer to find the best use case to apply Data Science / Machine Learning\n‚Ä¢ Analyzing and understanding the provided data and connecting it to the business processes\n‚Ä¢ Implementing a machine learning model (whichever model fits best; e.g. in python) which improves the business processes\n‚Ä¢ Presentation of results and discussion of machine learning model internally and with the customer\n‚Ä¢ Deployment of the found model in customer's business processes (on-Prem or in cloud)\n\nWhat we offer\n‚Ä¢ Challenging projects with well-known companies in various fields\n‚Ä¢ Young and highly motivated team\n‚Ä¢ Great emphasis on education and trainings with dedicated time on the job\n‚Ä¢ Mentoring and guidance from senior colleagues\n‚Ä¢ Opportunity to use the newest technologies around Data Science\n‚Ä¢ Home office\n‚Ä¢ Flexible working hours\n‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand customers‚Äô technical ecosystems and data, as well as an ability to communicate complex technical problems and their solutions clearly\n‚Ä¢ Experience in the Python and/or R Data Science ecosystems\n‚Ä¢ Interest in working with visualization tools (PowerBI, etc.)\n‚Ä¢ Interest in modern cloud-based data architecture and cloud services\n‚Ä¢ Interest in working with Spark and the Hadoop stack\n‚Ä¢ Readiness to travel\n‚Ä¢ German and English fluently spoken and written\n‚Ä¢ Deep understanding of the overall Data Science workflow including the most common algorithms\n‚Ä¢ Experience in working with various databases (SQL and NoSQL)\n‚Ä¢ 5+ years of experience in a similar role\n‚Ä¢ Ability to handle the full data science lifecycle from conception to deployment""]}]","[{'link': 'https://www.google.com/search?hl=en&q=paiqo+GmbH&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIqQw', 'text': 'See web results for paiqo GmbH'}]",,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCAoIFNlbmlvciApIiwiaHRpZG9jaWQiOiJyLTdPUkNtbVUzVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVEc1dFVtZENhMmRyZG5nNVJFOVdZVE5uTTBkWlVWSkdUM1ZSZVU1VmJXNUVabWhKZGxKcFdWVlRNbkZmVlV0cFpYVk1kV05EY25SRU1EWnpZMWsyWTNkcE5qUnpiMUU1TTJ0aE5YQkJTVWRTV1dkR01HcHpORTk1YUMxTU4wcG1SVVZUVERjd1pVbDBOVE53WkdsQ1YxSTBlVTVZYkZsTFRGRXpkR00zTFVSSVZXVk1SV3M1ZG5kSFVFSTRSVEpoY1ZKTWQwUjNWa1pmYkVoUWJVdzViWGN4WVVSSU16bDBOV2x3UzFaVVlsRnJFaGM1WWt4SVdsQTNhVUpqWVc4MVRtOVFPWEp4TW1kQlZSb2lRVXhGVXpsMVQycGFkSEI0WjBGd01qaFlSRmhzZDNWUVNDMUJNR3BrYm1aM1FRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBDYXJlZXJzIC0gSm9icyAtIFBhaXFvIEdtYkgiLCJsaW5rIjoiaHR0cHM6Ly9wYWlxby5yZWNydWl0ZWUuY29tL28vZGF0YS1zY2llbnRpc3Qtc2VuaW9yP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (m/f/d) (377750PA),Siemens,"  Vienna, Austria   ",via JobMonkey Jobs,"Would you like to shape the intelligent infrastructure of the future at one of the world's most innovative companies? As part of a company that uses smart digital solutions to contribute to the most responsible resource utilization, that ensures a secure supply of drinking water and that combats climate change?

Do your part for a better tomorrow - as a Da ta Engineer (m/f/d) in Vienna.

More on the Siemens Business you could be active for:
Siemens Smart Infrastructure .

The job
‚Ä¢ Define data requirements from IoT sources and other applications.
‚Ä¢ Negotiate interfaces between applications.
‚Ä¢ Design and deploy data pipelines and other data infrastructure.
‚Ä¢ Monitor, maintain, and update deployed pipelines.
‚Ä¢ Optimize data tools and help automate data science workflows.
‚Ä¢ Ability to travel globally for this position.
‚Ä¢ Lives and promotes Siemens Values.

Your profile
‚Ä¢ Bachelor's degree or master's degree in a technical field.
‚Ä¢ Minimum 3 years of hands-on experience in working with... data at scale.
‚Ä¢ Clear communication skills and ability to define technical requirements.
‚Ä¢ Comfortable with a distributed setup and collaboration with data scientists.
‚Ä¢ Programming in Python (other experience relevant).
‚Ä¢ V ery good knowledge of English and German is an advantage
‚Ä¢ Strong SQL Skills and general database knowledge.
‚Ä¢ API usage, definition, and implementation (REST, GraphQL).
‚Ä¢ Infrastructure as code on AWS.
‚Ä¢ A bonus would be experience with IoT data, sensor time series or building data.
‚Ä¢ Additional valued technical skills include ci/cd on gitlab, docker and spark.

Your benefits
‚Ä¢ Flexible working hours
‚Ä¢ Uncomplicated home office rules
‚Ä¢ On-site canteen
‚Ä¢ Comprehensive career development opportunities
‚Ä¢ Open and familial corporate structure
‚Ä¢ and more

Our offer
The annual gross salary in accordance with the collective agreement amounts to at least EUR 54.898,- for this function. Overpayment is possible, depending on qualification and experience.

Our application process
We hope to have sparked your interest for this position. Should this be the case, then we look forward to your comprehensive online application. The job opening is available effective immediately. Mr. Michael H√∂ttinger will gladly provide additional information under a ngelika.przybycien@siemens.com","[{'items': [""Would you like to shape the intelligent infrastructure of the future at one of the world's most innovative companies? As part of a company that uses smart digital solutions to contribute to the most responsible resource utilization, that ensures a secure supply of drinking water and that combats climate change?\n\nDo your part for a better tomorrow - as a Da ta Engineer (m/f/d) in Vienna.\n\nMore on the Siemens Business you could be active for:\nSiemens Smart Infrastructure .\n\nThe job\n‚Ä¢ Define data requirements from IoT sources and other applications.\n‚Ä¢ Negotiate interfaces between applications.\n‚Ä¢ Design and deploy data pipelines and other data infrastructure.\n‚Ä¢ Monitor, maintain, and update deployed pipelines.\n‚Ä¢ Optimize data tools and help automate data science workflows.\n‚Ä¢ Ability to travel globally for this position.\n‚Ä¢ Lives and promotes Siemens Values.\n\nYour profile\n‚Ä¢ Bachelor's degree or master's degree in a technical field.\n‚Ä¢ Minimum 3 years of hands-on experience in working with... data at scale.\n‚Ä¢ Clear communication skills and ability to define technical requirements.\n‚Ä¢ Comfortable with a distributed setup and collaboration with data scientists.\n‚Ä¢ Programming in Python (other experience relevant).\n‚Ä¢ V ery good knowledge of English and German is an advantage\n‚Ä¢ Strong SQL Skills and general database knowledge.\n‚Ä¢ API usage, definition, and implementation (REST, GraphQL).\n‚Ä¢ Infrastructure as code on AWS.\n‚Ä¢ A bonus would be experience with IoT data, sensor time series or building data.\n‚Ä¢ Additional valued technical skills include ci/cd on gitlab, docker and spark.\n\nYour benefits\n‚Ä¢ Flexible working hours\n‚Ä¢ Uncomplicated home office rules\n‚Ä¢ On-site canteen\n‚Ä¢ Comprehensive career development opportunities\n‚Ä¢ Open and familial corporate structure\n‚Ä¢ and more\n\nOur offer\nThe annual gross salary in accordance with the collective agreement amounts to at least EUR 54.898,- for this function. Overpayment is possible, depending on qualification and experience.\n\nOur application process\nWe hope to have sparked your interest for this position. Should this be the case, then we look forward to your comprehensive online application. The job opening is available effective immediately. Mr. Michael H√∂ttinger will gladly provide additional information under a ngelika.przybycien@siemens.com""]}]","[{'link': 'http://www.siemens.com/', 'text': 'siemens.com'}, {'link': 'https://www.google.com/search?hl=en&q=Siemens&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAII2ww', 'text': 'See web results for Siemens'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTTNyQijiv7pb6SxXLX8s48XeH8q5StX3KYVzUb&s=0,"['21 days ago', 'Full-time']","{'posted_at': '21 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkgKDM3Nzc1MFBBKSIsImh0aWRvY2lkIjoiMmJibHhYU1hqSDhBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RFbDJibFpZYUZWcGIzRlRUV050ZERSaFEyOVlWVkJoZG1GQ1NpMXhkMU0xTlVFNE5XTktlbk5QU0Y4eGNVaFRUbG94U3paQldtcEJNM1UwVVVNM2FWQjNibU5XVlVSU1VVdzRaV3cxUjFRdE5raG1SbGRhWlhnNU1FSnlUa3h3ZFROd1RrRTJOa1oxVTNCa2FsVlVUbkV5YlVGTU4wcEJOV0pNWjBFMVkwdExRekZUWm5GQmJFcHJPVW8wVURsUVlqTTFZVlpYVDFFMU1FVlBhMlpwWlZJMVRGSmFUbUkzYmtKYVZuQXhPVkZORWhjNVlreElXbEEzYVVKallXODFUbTlRT1hKeE1tZEJWUm9pUVV4RlV6bDFUMFJWU0hjeGJFcHphMDVqVFd0VU9HNDFTRWxWWDBsdGJWRkpVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzciLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9iTW9ua2V5IEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly93d3cuam9ibW9ua2V5am9icy5jb20vY2FyZWVyLzI0ODYzODAwL0RhdGEtRW5naW5lZXItTS1GLUQtMzc3NzUwcGEtQW55LVZpZW5uYS0xMzc1P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Machine Learning Engineer (m/f/d),Machine Learning Reply,"  Vienna, Austria   ",via JOIN,"Job Description

At

Machine Learning Reply Austria we strive to work on leading-edge data science projects with our clients for which we are seeking Cloud Engineer consultants with a strong technical background.

Machine Learning Reply, with its sister companies in Italy and Germany and over 8500 employees at Reply globally, is a fast-growing consultancy focused on solving problems with Data Science, Cloud technologies and the right organizational frameworks as their backbone. We are a tight knit, laid back, but seriously motivated unit that aims to be involved at conferences and in community of practice with our tech partners.

We offer tailor-made end-to-end cloud-based solutions in the Data Science area that cover the entire project life cycle - from initial strategy consulting to data architecture and infrastructure issues to data processing and deployment of production-ready algorithms.

We have a vast expertise in every step of the Data Science implementation spectrum in all... key industries of the German HDAX-companies. With focus on open source and cloud technologies we enable our customers to successfully introduce and implement new data-driven solutions and to optimize already existing processes and products while simultaneously adapting to cloud technologies.

Tasks

Use your cloud know-how and work closely with our customers to find out what the perfect (cloud) technology is for them!
‚Ä¢ Through your knowledge you are able to design innovative, technical approaches for cloud solution architectures
‚Ä¢ Your designed cloud architectures (based on AWS, Microsoft Azure or Google Cloud) will be implemented by you also always considering DevOps / MLOps
‚Ä¢ You will not be alone and will work closely with colleagues from Data Science or Data Engineering to jointly develop data-intensive applicationssuch as data warehouses, data lakes and/or data platforms
‚Ä¢ You enjoy brainstorming, conceptualization and final implementation. You therefore like to accompany the complete LifeCycle by creating specifications, code and presentations for your solutions.
‚Ä¢ As part of the Reply network, you join communities of practice, participate in hackathons and use all available learning resources

What we offer you:
‚Ä¢ We offer you for this position according to the collective agreement for employees in data processing and information technology a gross monthly salary of at least EUR 3215 (Consultant) or EUR 4286 (Senior Consultant) depending on your previous experience.
‚Ä¢ Access to work on projects across industries (large and mid-market companies in Banking, Insurance, Automotive, Retail, etc.)
‚Ä¢ Very active group social program - including conference funding, team building, group events, Reply Exchange
‚Ä¢ Recognition for Innovation to foster your personal development
‚Ä¢ Work in an open, flat environment, within a broad Reply knowledge sharing network (more than 90 autonomous Reply groups across 8 countries)
‚Ä¢ Office space in downtown Vienna with access to Stammstrecke
‚Ä¢ Training and certification encouraged
‚Ä¢ Home-office contracts
‚Ä¢ State of the art work equipment
‚Ä¢ Award winning office spaces for an excellent work experience
‚Ä¢ Public transport ticket within Vienna
‚Ä¢ Gym-membership subsidy for a gym of your choice
‚Ä¢ Flexible work environment between client, Reply office and remote work

Requirements

A university degree in (business) informatics, mathematics, statistics (or comparable) and at least 3 years of professional experience in industry or consulting
‚Ä¢ Experience in the development of data-intensive applications such as data warehouses, data lakes and / or data platforms
‚Ä¢ You have knowledge in code development using Java/Scala or Python
‚Ä¢ You are familiar with relational databases as well as ideally NoSQL databases (e.g. Oracle, Aurora, Mongodb, Cassandra)
‚Ä¢ Deep understanding in the development of Machine Learning applications as well as solutions based on Big Data technologies such as Hadoop or Spark or their cloud-based equivalents
‚Ä¢ Very good English and good German skills as well as willingness to travel nationally","[{'items': ['Job Description\n\nAt\n\nMachine Learning Reply Austria we strive to work on leading-edge data science projects with our clients for which we are seeking Cloud Engineer consultants with a strong technical background.\n\nMachine Learning Reply, with its sister companies in Italy and Germany and over 8500 employees at Reply globally, is a fast-growing consultancy focused on solving problems with Data Science, Cloud technologies and the right organizational frameworks as their backbone. We are a tight knit, laid back, but seriously motivated unit that aims to be involved at conferences and in community of practice with our tech partners.\n\nWe offer tailor-made end-to-end cloud-based solutions in the Data Science area that cover the entire project life cycle - from initial strategy consulting to data architecture and infrastructure issues to data processing and deployment of production-ready algorithms.\n\nWe have a vast expertise in every step of the Data Science implementation spectrum in all... key industries of the German HDAX-companies. With focus on open source and cloud technologies we enable our customers to successfully introduce and implement new data-driven solutions and to optimize already existing processes and products while simultaneously adapting to cloud technologies.\n\nTasks\n\nUse your cloud know-how and work closely with our customers to find out what the perfect (cloud) technology is for them!\n‚Ä¢ Through your knowledge you are able to design innovative, technical approaches for cloud solution architectures\n‚Ä¢ Your designed cloud architectures (based on AWS, Microsoft Azure or Google Cloud) will be implemented by you also always considering DevOps / MLOps\n‚Ä¢ You will not be alone and will work closely with colleagues from Data Science or Data Engineering to jointly develop data-intensive applicationssuch as data warehouses, data lakes and/or data platforms\n‚Ä¢ You enjoy brainstorming, conceptualization and final implementation. You therefore like to accompany the complete LifeCycle by creating specifications, code and presentations for your solutions.\n‚Ä¢ As part of the Reply network, you join communities of practice, participate in hackathons and use all available learning resources\n\nWhat we offer you:\n‚Ä¢ We offer you for this position according to the collective agreement for employees in data processing and information technology a gross monthly salary of at least EUR 3215 (Consultant) or EUR 4286 (Senior Consultant) depending on your previous experience.\n‚Ä¢ Access to work on projects across industries (large and mid-market companies in Banking, Insurance, Automotive, Retail, etc.)\n‚Ä¢ Very active group social program - including conference funding, team building, group events, Reply Exchange\n‚Ä¢ Recognition for Innovation to foster your personal development\n‚Ä¢ Work in an open, flat environment, within a broad Reply knowledge sharing network (more than 90 autonomous Reply groups across 8 countries)\n‚Ä¢ Office space in downtown Vienna with access to Stammstrecke\n‚Ä¢ Training and certification encouraged\n‚Ä¢ Home-office contracts\n‚Ä¢ State of the art work equipment\n‚Ä¢ Award winning office spaces for an excellent work experience\n‚Ä¢ Public transport ticket within Vienna\n‚Ä¢ Gym-membership subsidy for a gym of your choice\n‚Ä¢ Flexible work environment between client, Reply office and remote work\n\nRequirements\n\nA university degree in (business) informatics, mathematics, statistics (or comparable) and at least 3 years of professional experience in industry or consulting\n‚Ä¢ Experience in the development of data-intensive applications such as data warehouses, data lakes and / or data platforms\n‚Ä¢ You have knowledge in code development using Java/Scala or Python\n‚Ä¢ You are familiar with relational databases as well as ideally NoSQL databases (e.g. Oracle, Aurora, Mongodb, Cassandra)\n‚Ä¢ Deep understanding in the development of Machine Learning applications as well as solutions based on Big Data technologies such as Hadoop or Spark or their cloud-based equivalents\n‚Ä¢ Very good English and good German skills as well as willingness to travel nationally']}]","[{'link': 'https://www.google.com/search?hl=en&q=Machine+Learning+Reply&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIjQ0', 'text': 'See web results for Machine Learning Reply'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQzhRs0n26KwGFfb_4KR8knAA2J6iHPzFxvm8N8hyY&s,"['4 days ago', 'Full-time']","{'posted_at': '4 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6Il9OUWdBb3JEakJVQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVUxck1teHNURmN0YWxaWmRVaE1VMGg1V0VrdGJWb3pka1JoUjJVeVVHUTBXa2xLV1V0SVJFTnBNRUkzTFVGTldHZEpXRGxwWWpsbFVFOXJkM0p1WW1zeU1FUm5NbFpSYmsxMUxXTXlSalprYzBONGFqTmpPREpRTjJJd1ZEWXpkMnRsUWxOTU1YSmlkSFJSV1dVelRWWmtXVUp1V0RKdmVqRldWVFJHYkRaS1dHdGpURGh0ZWsxUGMxZG9OMHh5VldZeGIyUkhiM28xTkdwUFRqazNXSFJEZEZkdFRXOW5WVE5NTVZoTFYxYzRRbEJ4UWtGT1JIazVkbUpKUTBSMmRVTXdWMmhYZG5CWWRVTXRSV3hDZGpoVWVUWmZjblExU1ZWMWMzTnBla1F4UVJJWE9XSk1TRnBRTjJsQ1kyRnZOVTV2VURseWNUSm5RVlVhSWtGTVJWTTVkVTAwVlRod2NHVmFjREJQYjIwM2FHdGFkRFJXVm5aRFNWSkVORkUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY185IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIEpPSU4iLCJsaW5rIjoiaHR0cHM6Ly9qb2luLmNvbS9jb21wYW5pZXMvbWxyZXBseS84NzUwMDU5LW1hY2hpbmUtbGVhcm5pbmctZW5naW5lZXItbS1mLWQ/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (all genders),OÃàsterreichische Lotterien,"  Vienna, Austria   ",via √ñsterreichische Lotterien,"Wien, Vollzeit

Die √ñsterreichischen Lotterien sind ein international anerkanntes Gl√ºcksspielunternehmen, das verantwortungsvoll, innovativ und partnerschaftlich agiert. Wir bieten spielinteressierten Erwachsenen eine breite Palette an Lotteriespielen in h√∂chster Qualit√§t. ‚ÄûGl√ºcksspiel mit Verantwortung‚Äú ist Grundlage unseres Handelns.

Zur weiteren Verst√§rkung unserer Data Competence Center Abteilung sind wir auf der Suche nach einem Data Engineer (all genders), der die Welt der Daten gemeinsam mit uns erleben, verbessern und gestalten will! Zusammen setzen wir spannende Projekte um und erm√∂glichen datengesteuerte Entscheidungsprozesse

Deine Rolle am Gl√ºck
‚Ä¢ Du arbeitest in interdisziplin√§ren Teams mit agilen Methoden hautnah bei spannenden Projekten mit, unterst√ºtzt bei der Evaluierung der Anforderungen unserer internen Stakeholder und setzt diese mittels unterschiedlicher Tech-Stacks um.
‚Ä¢ Mit hohem Qualit√§tsbewusstsein bist du f√ºr die Konzeption und Implementierung von... Datenpipelines zur Sicherstellung effizienter und effektiver Datenfl√ºsse zust√§ndig.
‚Ä¢ Deine Expertise bringst du bei technologischen Entscheidungen ein.
‚Ä¢ Du hast Spa√ü daran neue Technologien kennenzulernen und beim Aufbau eines neuen Data Warehouse zu unterst√ºtzen.

Dein Einsatz im Team
‚Ä¢ Abgeschlossene Ausbildung mit IT-Background (HTL/FH/Uni, etc.)
‚Ä¢ Mehrj√§hrige Berufserfahrung in den Bereichen Data Engineering sowie relationale Datenbanken und SQL (idealerweise Oracle)
‚Ä¢ Datenmodellierung, ETL-Prozesse, Data Pipelines, Python, Spark und Databricks sind f√ºr dich nicht nur Begriffe, sondern du hast sie auch schon produktiv eingesetzt
‚Ä¢ Interesse f√ºr Plattform-Technologien und -Services wie AWS oder Azure
‚Ä¢ Hohes Security-Bewusstsein, L√∂sungskompetenz sowie ausgepr√§gte Teamorientierung
‚Ä¢ Begeisterung f√ºr Neues und die Motivation zur kontinuierlichen Weiterbildung

Mit diesen Technologien arbeiten wir: Databricks, AWS Cloud, Python, Spark, SQL, dbt (Data Build Tool), GitLab CI/CD, Terraform, OpenMetadata, Lakehouse, JIRA

Dein Jackpot

modernes Arbeitsumfeld l gute √∂ffentliche Verkehrsanbindung, Cityn√§he l kollegiale Atmosph√§re im motivierten Team l flexible Arbeitszeiten und umfangreiche Home-Office-M√∂glichkeit

Lies hier, welche Vorteile Dich als Mitarbeiter:in bei uns erwarten.

Interesse? Mach den n√§chsten Schritt und bewirb Dich online mit Motivationsschreiben, Lebenslauf und Zeugnissen. Wir freuen uns auf Dich!

Wir stehen als Arbeitgeber f√ºr Chancengleichheit und Diversit√§t und freuen uns besonders √ºber Bewerbungen von Menschen mit Behinderungen. Bei Fragen zu individuellen Anforderungen wende Dich gerne an uns.

Wir arbeiten am Gl√ºck ‚Äì werde ein Teil davon!

√ñsterreichische Lotterien GmbH

Rennweg 44, 1038 Wien
Jetzt Bewerben!Drucken

Auf Facebook empfehlenAuf Twitter teilenPer E-Mail weiterleiten
Infobox
Jetzt Bewerben

Dienstort

Wien Zentrale

Eintritt

ab sofort

Besch√§ftigungsart

Vollzeit

Gehalt

Qualifikationsabh√§ngiges

Jahresbruttogehalt bei Vollzeit ab EUR 55.000,-

Kontakt

Martina Codemo

Tel.: +43 (1) 79070 - 34806","[{'items': ['Wien, Vollzeit\n\nDie √ñsterreichischen Lotterien sind ein international anerkanntes Gl√ºcksspielunternehmen, das verantwortungsvoll, innovativ und partnerschaftlich agiert. Wir bieten spielinteressierten Erwachsenen eine breite Palette an Lotteriespielen in h√∂chster Qualit√§t. ‚ÄûGl√ºcksspiel mit Verantwortung‚Äú ist Grundlage unseres Handelns.\n\nZur weiteren Verst√§rkung unserer Data Competence Center Abteilung sind wir auf der Suche nach einem Data Engineer (all genders), der die Welt der Daten gemeinsam mit uns erleben, verbessern und gestalten will! Zusammen setzen wir spannende Projekte um und erm√∂glichen datengesteuerte Entscheidungsprozesse\n\nDeine Rolle am Gl√ºck\n‚Ä¢ Du arbeitest in interdisziplin√§ren Teams mit agilen Methoden hautnah bei spannenden Projekten mit, unterst√ºtzt bei der Evaluierung der Anforderungen unserer internen Stakeholder und setzt diese mittels unterschiedlicher Tech-Stacks um.\n‚Ä¢ Mit hohem Qualit√§tsbewusstsein bist du f√ºr die Konzeption und Implementierung von... Datenpipelines zur Sicherstellung effizienter und effektiver Datenfl√ºsse zust√§ndig.\n‚Ä¢ Deine Expertise bringst du bei technologischen Entscheidungen ein.\n‚Ä¢ Du hast Spa√ü daran neue Technologien kennenzulernen und beim Aufbau eines neuen Data Warehouse zu unterst√ºtzen.\n\nDein Einsatz im Team\n‚Ä¢ Abgeschlossene Ausbildung mit IT-Background (HTL/FH/Uni, etc.)\n‚Ä¢ Mehrj√§hrige Berufserfahrung in den Bereichen Data Engineering sowie relationale Datenbanken und SQL (idealerweise Oracle)\n‚Ä¢ Datenmodellierung, ETL-Prozesse, Data Pipelines, Python, Spark und Databricks sind f√ºr dich nicht nur Begriffe, sondern du hast sie auch schon produktiv eingesetzt\n‚Ä¢ Interesse f√ºr Plattform-Technologien und -Services wie AWS oder Azure\n‚Ä¢ Hohes Security-Bewusstsein, L√∂sungskompetenz sowie ausgepr√§gte Teamorientierung\n‚Ä¢ Begeisterung f√ºr Neues und die Motivation zur kontinuierlichen Weiterbildung\n\nMit diesen Technologien arbeiten wir: Databricks, AWS Cloud, Python, Spark, SQL, dbt (Data Build Tool), GitLab CI/CD, Terraform, OpenMetadata, Lakehouse, JIRA\n\nDein Jackpot\n\nmodernes Arbeitsumfeld l gute √∂ffentliche Verkehrsanbindung, Cityn√§he l kollegiale Atmosph√§re im motivierten Team l flexible Arbeitszeiten und umfangreiche Home-Office-M√∂glichkeit\n\nLies hier, welche Vorteile Dich als Mitarbeiter:in bei uns erwarten.\n\nInteresse? Mach den n√§chsten Schritt und bewirb Dich online mit Motivationsschreiben, Lebenslauf und Zeugnissen. Wir freuen uns auf Dich!\n\nWir stehen als Arbeitgeber f√ºr Chancengleichheit und Diversit√§t und freuen uns besonders √ºber Bewerbungen von Menschen mit Behinderungen. Bei Fragen zu individuellen Anforderungen wende Dich gerne an uns.\n\nWir arbeiten am Gl√ºck ‚Äì werde ein Teil davon!\n\n√ñsterreichische Lotterien GmbH\n\nRennweg 44, 1038 Wien\nJetzt Bewerben!Drucken\n\nAuf Facebook empfehlenAuf Twitter teilenPer E-Mail weiterleiten\nInfobox\nJetzt Bewerben\n\nDienstort\n\nWien Zentrale\n\nEintritt\n\nab sofort\n\nBesch√§ftigungsart\n\nVollzeit\n\nGehalt\n\nQualifikationsabh√§ngiges\n\nJahresbruttogehalt bei Vollzeit ab EUR 55.000,-\n\nKontakt\n\nMartina Codemo\n\nTel.: +43 (1) 79070 - 34806']}]","[{'link': 'http://www.lotterien.at/', 'text': 'lotterien.at'}, {'link': 'https://www.google.com/search?hl=en&q=O%CC%88sterreichische+Lotterien&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIwA0', 'text': 'See web results for OÃàsterreichische Lotterien'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSA3vRJOD9Kh3L07cDHxs3o8hmdhuDhZnIGZrc5&s=0,"['‚Ç¨55K a year', 'Full-time']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChhbGwgZ2VuZGVycykiLCJodGlkb2NpZCI6InF1VnRpNXRBWldFQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVUxck1teHNTbDlvVVVjeWJWRm1RbFU1TlVrdFVGcFhTMDQwZG10ak9GWXlNRWhpUW1VemVUSmpVSFZHVWtOamFsZE9hakk1T0RaRVVHaG9ZVjk2VW1ScWEwczVabFpLYURCNlJrZGFUM0ZZTVZaS1NYUjBjRWRWZHpKVU9EUjFTV2xLWjJGSVMyMVRNRWN0YzB0dFdGQmlSMUZLVVVWd1VEZGZYMkprUkRaNVRVVkdabEpFYjBaRWNHRjFRbGxVTTJOTE4wMUJVRFJXTWtkdFltZERkMFZ0TVZFd01VbHlWRXRwVEhCMWNYcGhkMnRqYVVSUlRFRmFObXc1VEZFNE5XbFJSblY0WnpsSk1UZHZlRkZ4U3pWYVNITlJTRVo1UTBONE0wRnFhWFJGVVJJWE9XSk1TRnBRTjJsQ1kyRnZOVTV2VURseWNUSm5RVlVhSWtGTVJWTTVkVTlEUzFwVmRXOHdlVmhrVldkamRqZGhZbGRxUlRORFlWQmthMUUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiDDlnN0ZXJyZWljaGlzY2hlIExvdHRlcmllbiIsImxpbmsiOiJodHRwczovL3d3dy5sb3R0ZXJpZW4uYXQva2FycmllcmUvc3RlbGxlbmFuZ2Vib3RlL2RhdGEtZW5naW5lZXItYWxsLWdlbmRlcnM/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,Wiener Stadtwerke GmbH,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ Provision and management of environments for data engineering, on premise and in the cloud, in compliance with IT and data governance guidelines and the identification and elimination of systematic vulnerabilities
‚Ä¢ Support for and implementation of IT, digitization and optimization measures in the area of generation plants and in the power plant sector (renewable energies, electricity generation, waste incineration, combined heat and power generation, ...)
‚Ä¢ Ensuring, improving and expanding the existing technical (data) infrastructure and quality as well as the underlying organizational processes
‚Ä¢ Interface to IT demand management for requirements management for the responsible digitization topics
‚Ä¢ Positioning as a key player by building up know-how in all aspects of requirements management and supporting specialist knowledge holders in the department
‚Ä¢ Cooperation with IT portfolio management for reporting and environmental management

Technologies and... skills
‚Ä¢ SQL
‚Ä¢ Java
‚Ä¢ Apache Spark
‚Ä¢ Python

Our expectations:

Qualifications
‚Ä¢ A sense of responsibility and independent working methods, enjoyment of interdisciplinary cooperation as well as a high level of commitment and flexibility
‚Ä¢ Communicative person with the willingness to impart knowledge and to train and coach users

Experience
‚Ä¢ Several years of experience in programming e.g. Spark / Java / Python as well as experience with EventHubs
‚Ä¢ Experience in dealing with Big Data frameworks and in-depth knowledge of databases (SQL)
‚Ä¢ Experience managing configurations and implementing CI/CD pipelines for applications and infrastructure

Education
‚Ä¢ Successfully completed higher education (university, FH, HTL) in the field of computer science, software engineering, coding, data processing or similar

Benefits
‚Ä¢ Coffee, Tea, etc.
‚Ä¢ Fresh Fruit
‚Ä¢ * Company Restaurant
‚Ä¢ Educational Leave/Sabbatical
‚Ä¢ *
‚Ä¢ Flexible Working Hours
‚Ä¢ Health Care Benefits
‚Ä¢ Fitness Offers
‚Ä¢ Company Doctor
‚Ä¢ Public Transport Allowance
‚Ä¢ Company Phone for Private Use
‚Ä¢ Company Notebook for Private Use
‚Ä¢ Excellent Traffic Connections
‚Ä¢ Day Care for Kids","[{'items': ['Your role in the team\n‚Ä¢ Provision and management of environments for data engineering, on premise and in the cloud, in compliance with IT and data governance guidelines and the identification and elimination of systematic vulnerabilities\n‚Ä¢ Support for and implementation of IT, digitization and optimization measures in the area of generation plants and in the power plant sector (renewable energies, electricity generation, waste incineration, combined heat and power generation, ...)\n‚Ä¢ Ensuring, improving and expanding the existing technical (data) infrastructure and quality as well as the underlying organizational processes\n‚Ä¢ Interface to IT demand management for requirements management for the responsible digitization topics\n‚Ä¢ Positioning as a key player by building up know-how in all aspects of requirements management and supporting specialist knowledge holders in the department\n‚Ä¢ Cooperation with IT portfolio management for reporting and environmental management\n\nTechnologies and... skills\n‚Ä¢ SQL\n‚Ä¢ Java\n‚Ä¢ Apache Spark\n‚Ä¢ Python\n\nOur expectations:\n\nQualifications\n‚Ä¢ A sense of responsibility and independent working methods, enjoyment of interdisciplinary cooperation as well as a high level of commitment and flexibility\n‚Ä¢ Communicative person with the willingness to impart knowledge and to train and coach users\n\nExperience\n‚Ä¢ Several years of experience in programming e.g. Spark / Java / Python as well as experience with EventHubs\n‚Ä¢ Experience in dealing with Big Data frameworks and in-depth knowledge of databases (SQL)\n‚Ä¢ Experience managing configurations and implementing CI/CD pipelines for applications and infrastructure\n\nEducation\n‚Ä¢ Successfully completed higher education (university, FH, HTL) in the field of computer science, software engineering, coding, data processing or similar\n\nBenefits\n‚Ä¢ Coffee, Tea, etc.\n‚Ä¢ Fresh Fruit\n‚Ä¢ * Company Restaurant\n‚Ä¢ Educational Leave/Sabbatical\n‚Ä¢ *\n‚Ä¢ Flexible Working Hours\n‚Ä¢ Health Care Benefits\n‚Ä¢ Fitness Offers\n‚Ä¢ Company Doctor\n‚Ä¢ Public Transport Allowance\n‚Ä¢ Company Phone for Private Use\n‚Ä¢ Company Notebook for Private Use\n‚Ä¢ Excellent Traffic Connections\n‚Ä¢ Day Care for Kids']}]","[{'link': 'http://www.wienerstadtwerke.at/', 'text': 'wienerstadtwerke.at'}, {'link': 'https://www.google.com/search?hl=en&q=Wiener+Stadtwerke+GmbH&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAII9Q0', 'text': 'See web results for Wiener Stadtwerke GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRBQv96U7qPnktezi2TT4QNPYMQ4gpU0sgHLvbIQbc&s,"['27 days ago', '‚Ç¨55,525 a year', 'Full-time', 'No degree mentioned']","{'posted_at': '27 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJFV3h1aW96ZDR1Y0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzUzJ0WVpXd3hObEo1Y0d4RVR6WlZMVzl6VUU1TlpESXdOMUoxVEUxRlQwTnJZWFYzTjB0a1kwdFhSRE54WWpNd1RWcHdaR3hDUlhoR1MycEdVSEZQU1RsQ2VVdzVUa2RITFVSMVprcHRlRGxXWmpsSGVuZGlhbVptVG5sRmJWQjFZMk00ZEZZeU9HNXhaV2RJUTJKVmVsWlNlbkZJTFVGNlZWSjZiMFJrZG1VNWJrZFlTRkpLZVhKaGJGOUlVV0pIZUZSRlUyZFRlRVpvV0V0TWJuaDFSMUp0V2pSSVVXUkpUakp5UVZaQlVHUnJFaGM1WWt4SVdsQTNhVUpqWVc4MVRtOVFPWEp4TW1kQlZSb2lRVXhGVXpsMVVFeDBXWEZMU0dWWloxWkNhbkZ0TlcxQ1RHNUJUV2xvWVRGR2R3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iLzQ1NGQ2NGZmNWFiMjg1ZDVhNGFiN2ZhZjk4ODFmZjRmP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer,Bitpanda,"  Vienna, Austria   ",via Speedinvest Job Board,"Who we are

Bitpanda simplifies wealth creation. Founded in 2014 in Vienna, Austria by Eric Demuth, Paul Klanschek and Christian Trummer, Bitpanda exists to help people trust themselves enough to build financial freedom for their future. Our user-friendly, trade-everything platform empowers both first-time investors and seasoned experts to invest in the cryptocurrencies, crypto indices, stocks, precious metals and commodities they want ‚Äî all possible with any sized budget, 24/7. With more than 700 team members and more than 4 million customers, our company is one of Europe's most successful fintechs.

Headquartered in Austria but operating across all of Europe, our products are built by fast-moving, talented, ‚Äúroll-up-your-sleeves-and-make-it-happen‚Äù kind of people who represent more than 50 nationalities. If you‚Äôre someone who thinks big, moves fast and wants to make an impact right from day one, then get ready to join our industry-changing team. Let‚Äôs go!

Your mission

Do you want... to develop data pipelines and do innovative work on the data processing frameworks and architectures with the ability to scale intelligently? Then join Bitpanda Data Engineering team!

What you‚Äôll do
‚Ä¢ Opportunity to build and define the data initiatives for the company
‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using AWS technologies. Implement data pipelines and data integration solutions with Python and Java languages
‚Ä¢ Ensure accuracy and timeliness of data is maintained in the data layer. Clean and wrangle data into a usable state that are ready to be used by our Product and Engineering teams
‚Ä¢ Work with stakeholders to align solutions and data integration with business objectives
‚Ä¢ Debug, troubleshoot, and improve cloud-based applications and s2uggest improvements to current data architecture

Who you are
‚Ä¢ Strong skills in data integration and data gathering methodologies and APIs and experience working with a variety of APIs (e.g., REST API or SOAP API)
‚Ä¢ Experience with AWS services and Service-Oriented Architecture
‚Ä¢ Proficient in at least one of the following languages: Python, Java, Scala
‚Ä¢ Understanding of ETL/ELT infrastructures and Cloud architectures
‚Ä¢ Experience with event driven Architectures and tools such as Kafka and knowledge of version control systems such as GIT

What‚Äôs in it for you
‚Ä¢ Flexibility-first approach to work* including:
‚Ä¢ Unlimited fully-paid annual leave
‚Ä¢ Recharge Breaks
‚Ä¢ 20 weeks gender-neutral New Parent Leave
‚Ä¢ Hybrid Working*:
‚Ä¢ 50/50 home/office for office hub locations
‚Ä¢ 60 days Work From Anywhere* following the 80/20 Rule
‚Ä¢ ‚Ç¨500 Work from Home budget
‚Ä¢ An attractive individual stock option plan* in a high growth company, and a competitive salary
‚Ä¢ Exclusive premiums when trading on Bitpanda
‚Ä¢ Occasional company-wide and team events ‚Äî both in-person and virtually!
‚Ä¢ Learning & development opportunities
‚Ä¢ Top-notch ‚Äútech pack‚Äù ‚Äì your choice between PC or Mac
‚Ä¢ Bitpanda merch to keep you swagged out and living the Bitpanda brand
‚Ä¢ A global Bitpanda team of fast-moving, talented, ‚Äúroll-up-your-sleeves-and-make-it-happen‚Äù kind of people who are united (across cultures and time zones) by our unique way of working
‚Ä¢ These benefits do not apply for our internships and exceptions to our Hybrid Working policy apply to teams with shift schedules or for folks whose roles require them to be in office (think: Workplaces team or IT).

And, above all, the opportunity to learn & grow as part of Bitpanda‚Äôs incredible journey towards being Europe‚Äôs future #1 investment platform.

Bitpanda is committed to fostering a fair and equal environment based on trust and mutual respect. We believe that a diverse and inclusive workplace is paramount to our success and we are committed to building a team that represents a wide variety of backgrounds, perspectives, and skills","[{'items': [""Who we are\n\nBitpanda simplifies wealth creation. Founded in 2014 in Vienna, Austria by Eric Demuth, Paul Klanschek and Christian Trummer, Bitpanda exists to help people trust themselves enough to build financial freedom for their future. Our user-friendly, trade-everything platform empowers both first-time investors and seasoned experts to invest in the cryptocurrencies, crypto indices, stocks, precious metals and commodities they want ‚Äî all possible with any sized budget, 24/7. With more than 700 team members and more than 4 million customers, our company is one of Europe's most successful fintechs.\n\nHeadquartered in Austria but operating across all of Europe, our products are built by fast-moving, talented, ‚Äúroll-up-your-sleeves-and-make-it-happen‚Äù kind of people who represent more than 50 nationalities. If you‚Äôre someone who thinks big, moves fast and wants to make an impact right from day one, then get ready to join our industry-changing team. Let‚Äôs go!\n\nYour mission\n\nDo you want... to develop data pipelines and do innovative work on the data processing frameworks and architectures with the ability to scale intelligently? Then join Bitpanda Data Engineering team!\n\nWhat you‚Äôll do\n‚Ä¢ Opportunity to build and define the data initiatives for the company\n‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using AWS technologies. Implement data pipelines and data integration solutions with Python and Java languages\n‚Ä¢ Ensure accuracy and timeliness of data is maintained in the data layer. Clean and wrangle data into a usable state that are ready to be used by our Product and Engineering teams\n‚Ä¢ Work with stakeholders to align solutions and data integration with business objectives\n‚Ä¢ Debug, troubleshoot, and improve cloud-based applications and s2uggest improvements to current data architecture\n\nWho you are\n‚Ä¢ Strong skills in data integration and data gathering methodologies and APIs and experience working with a variety of APIs (e.g., REST API or SOAP API)\n‚Ä¢ Experience with AWS services and Service-Oriented Architecture\n‚Ä¢ Proficient in at least one of the following languages: Python, Java, Scala\n‚Ä¢ Understanding of ETL/ELT infrastructures and Cloud architectures\n‚Ä¢ Experience with event driven Architectures and tools such as Kafka and knowledge of version control systems such as GIT\n\nWhat‚Äôs in it for you\n‚Ä¢ Flexibility-first approach to work* including:\n‚Ä¢ Unlimited fully-paid annual leave\n‚Ä¢ Recharge Breaks\n‚Ä¢ 20 weeks gender-neutral New Parent Leave\n‚Ä¢ Hybrid Working*:\n‚Ä¢ 50/50 home/office for office hub locations\n‚Ä¢ 60 days Work From Anywhere* following the 80/20 Rule\n‚Ä¢ ‚Ç¨500 Work from Home budget\n‚Ä¢ An attractive individual stock option plan* in a high growth company, and a competitive salary\n‚Ä¢ Exclusive premiums when trading on Bitpanda\n‚Ä¢ Occasional company-wide and team events ‚Äî both in-person and virtually!\n‚Ä¢ Learning & development opportunities\n‚Ä¢ Top-notch ‚Äútech pack‚Äù ‚Äì your choice between PC or Mac\n‚Ä¢ Bitpanda merch to keep you swagged out and living the Bitpanda brand\n‚Ä¢ A global Bitpanda team of fast-moving, talented, ‚Äúroll-up-your-sleeves-and-make-it-happen‚Äù kind of people who are united (across cultures and time zones) by our unique way of working\n‚Ä¢ These benefits do not apply for our internships and exceptions to our Hybrid Working policy apply to teams with shift schedules or for folks whose roles require them to be in office (think: Workplaces team or IT).\n\nAnd, above all, the opportunity to learn & grow as part of Bitpanda‚Äôs incredible journey towards being Europe‚Äôs future #1 investment platform.\n\nBitpanda is committed to fostering a fair and equal environment based on trust and mutual respect. We believe that a diverse and inclusive workplace is paramount to our success and we are committed to building a team that represents a wide variety of backgrounds, perspectives, and skills""]}]","[{'link': 'http://www.bitpanda.com/', 'text': 'bitpanda.com'}, {'link': 'https://www.google.com/search?hl=en&q=Bitpanda&sa=X&ved=0ahUKEwi-sbHTgrmAAxVGFFkFHXadDVA4FBCYkAIIqQ4', 'text': 'See web results for Bitpanda'}]",,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoicGtkNkZ1NHdZSllBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RFWlhWRzlDY21SaGJITjVhSEZxTWxaVUxUaHhhVWx3Ym5kT1VEVjNURWxtZDJvelkyZFJkWFZmYXpaS2VrRmFVRlZpVWxOWVUxUmxlVWhTTWsxUE9EbERhalpMVGtKeFoxOTVlRlZOYjA1UFpHbGxWbGRDV1hGdlQyWmtaMEppYW1WSVUxRlJWbVJPYWtOR1JucGlabWwwUVVGek9IUkdaRzQyYmkxWGJuWjNUbTVmZFZSVFpYVkxhMGxNU0ZFM2RuUkRTbmRHWW1SV2Nrc3ROVkU0UzFGQ1oxaElNR3cwY0ZoM1ZqWjZWMGRORWhjNVlreElXbEEzYVVKallXODFUbTlRT1hKeE1tZEJWUm9pUVV4RlV6bDFUMVZSVG5wU01VaExaa3BSY0c1NkxVSkJiMFZFZGpaSWRVUmxadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzE1IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFNwZWVkaW52ZXN0IEpvYiBCb2FyZCIsImxpbmsiOiJodHRwczovL2NhcmVlcnMuc3BlZWRpbnZlc3QuY29tL2NvbXBhbmllcy9iaXRwYW5kYS9qb2JzLzI1OTk2MDA3LXNlbmlvci1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (f/m/d),Tietoevry,"  Vienna, Austria   ",via Jobs For Ukraine,"With us you will be responsible for

‚Äì working in teams developing and implementing modern cloud solutions for data driven use cases for our customers

‚Äì helping to define technology roadmaps and solutions

‚Äì interacting with our customers through collaborative and partially virtual workshop settings

‚Äì providing consulting solutions including how to leverage standard Microsoft Azure PaaS services, data engineering services and or IoT services

We expect you to have

‚Äì a passion for data and connecting the dots

‚Äì technical understanding for data analysis

‚Äì worked with Business Intelligence and know what it‚Äôs for

‚Äì SQL knowledge

‚Äì Experience with processing of big data

‚Äì a consulting attitude and the ability to handle discussions in English and preferably also in German

As a person you are

‚Äì willing to learn and a quick adopter

‚Äì proactive and act with open mind by challenging the status quo

‚Äì passionate about everything around data: data warehousing, modelling, databases... data visualization

‚Äì having fun at work, passionate about customer‚Äôs success and personal growth

We offer

‚Äì an exciting career path with a wide variety of personal and professional development opportunities

‚Äì a large customer network and an industrialized consulting solution portfolio

‚Äì a great opportunity to take part in new cloud born solutions and services

‚Äì active participation in the development of our company together with talented colleagues and inspiring international environment

‚Äì excellent teamwork which is part of our values and the possibility to share your competences with your colleagues

‚Äì benefits like flexible working hours, home office, laptop and smartphone also for private use, health programs, team events, excellent public transport connection, food vouchers, fresh fruits, the perfect environment to prosper professionally etc.

‚Äì a salary above the defined IT collective agreement of minimum EUR 3.190,00 per month. The amount of overpayment depends on your skills as well as your experience

Further information

If you are interested to work for a highly customer focused company together with an ambitious team you are warmly welcome to send in your application.

Catharina Christian, Recruitment Specialist, Tietoevry Austria","[{'items': ['With us you will be responsible for\n\n‚Äì working in teams developing and implementing modern cloud solutions for data driven use cases for our customers\n\n‚Äì helping to define technology roadmaps and solutions\n\n‚Äì interacting with our customers through collaborative and partially virtual workshop settings\n\n‚Äì providing consulting solutions including how to leverage standard Microsoft Azure PaaS services, data engineering services and or IoT services\n\nWe expect you to have\n\n‚Äì a passion for data and connecting the dots\n\n‚Äì technical understanding for data analysis\n\n‚Äì worked with Business Intelligence and know what it‚Äôs for\n\n‚Äì SQL knowledge\n\n‚Äì Experience with processing of big data\n\n‚Äì a consulting attitude and the ability to handle discussions in English and preferably also in German\n\nAs a person you are\n\n‚Äì willing to learn and a quick adopter\n\n‚Äì proactive and act with open mind by challenging the status quo\n\n‚Äì passionate about everything around data: data warehousing, modelling, databases... data visualization\n\n‚Äì having fun at work, passionate about customer‚Äôs success and personal growth\n\nWe offer\n\n‚Äì an exciting career path with a wide variety of personal and professional development opportunities\n\n‚Äì a large customer network and an industrialized consulting solution portfolio\n\n‚Äì a great opportunity to take part in new cloud born solutions and services\n\n‚Äì active participation in the development of our company together with talented colleagues and inspiring international environment\n\n‚Äì excellent teamwork which is part of our values and the possibility to share your competences with your colleagues\n\n‚Äì benefits like flexible working hours, home office, laptop and smartphone also for private use, health programs, team events, excellent public transport connection, food vouchers, fresh fruits, the perfect environment to prosper professionally etc.\n\n‚Äì a salary above the defined IT collective agreement of minimum EUR 3.190,00 per month. The amount of overpayment depends on your skills as well as your experience\n\nFurther information\n\nIf you are interested to work for a highly customer focused company together with an ambitious team you are warmly welcome to send in your application.\n\nCatharina Christian, Recruitment Specialist, Tietoevry Austria']}]","[{'link': 'http://www.tietoevry.com/', 'text': 'tietoevry.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Tietoevry&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAII4go', 'text': 'See web results for Tietoevry'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSGru2eTHlRsQSmWJB0LVIxC77_e3qJpSzl4oT-LUA&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChmL20vZCkiLCJodGlkb2NpZCI6ImRmWUs4bDVCOUVvQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTMkpFWWpkT09HRk5OVkZVY21oQ1JsbGhiVkZHV1RZd2JEWjNNM0J4VkRKNldtczVZa0poV1c4MFJWRnlkMGhhVVVzdE5tcFVlakZ6Wkhjek4yMW9UakJtUjNOU1RFUm5ZVlZuWm5CVlJrZE5TVUpOVUVWVGJXcG9UazltVHpJdFZqTjZha2syWVY5b01IaGljMU01YlUxb1ExcExlRWh1VkdwUVNHUlFTRVl0YlMxTWNXNVZWRU5PV1d4WGRWVmlja3A0UkhWTVp6ZzRWMlp4WjFGbFlsRnhiSEJ4U2tGbFMxQnhSWFl6VDFsakVoYzVOMHhJV2tzdGFVNXhlVU4zWW10UWVVdFRhM1ZCUlJvaVFVeEZVemwxVGprMWJuTnVaMHcxYmtoemVtMXlOVlp2YVVWMGJsbERSM2hDZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIEpvYnMgRm9yIFVrcmFpbmUiLCJsaW5rIjoiaHR0cHM6Ly93d3cuam9icy1mb3ItdWtyYWluZS5hdC9qb2IvdGlldG9ldnJ5LXZpZW5uYS1mdWxsLXRpbWUtZGF0YS1lbmdpbmVlci1mLW0tZC8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
"Data Engineer - f√ºr DWH, BI und Analytics (mensch*) - Vollzeit...",Zurich Insurance Company Ltd.,"  Vienna, Austria   ",via Zurich Careers,"Sie brennen f√ºr Daten und bringen gro√ües Interesse an neuen Technologien mit? In dieser Rolle bekommen Sie die Gelegenheit, uns bei der Modernisierung und Umstellung auf Azure Databricks zu unterst√ºtzen.

Zur Verst√§rkung der IT-Abteilung ‚ÄûData Platform & SAP‚Äú suchen wir eine/n engagierte/n Mitarbeiter/in f√ºr folgende Aufgaben:
‚Ä¢ Design, Modellierung und Weiterentwicklung der zentralen Data-Warehouse-L√∂sung mit Schwerpunkt ETL
‚Ä¢ Transformation und Migration der bestehenden Legacy-DWH-Prozesse (auf Basis von IBM DB2 und Infosphere Warehouse) in Richtung Azure Databricks
‚Ä¢ Einhaltung der Architektur- bzw. Entwicklungsvorgaben und deren Qualit√§t
‚Ä¢ Automatisierung und Optimierung von DWH Workflows (End-to-End)
‚Ä¢ Enge Zusammenarbeit mit dem Fachbereich bei der Analyse und Entwicklung neuer Themenfelder
‚Ä¢ Erstellung der User Stories in Zusammenarbeit mit den Fachbereichen und Stakeholdern
‚Ä¢ Qualit√§tssicherung und technische Dokumentation der Beladeprozesse

Was zeichnet Sie aus?
‚Ä¢ Der Blick... auf Details und √ºber die einzelnen Applikationen hinweg macht Ihnen Freude
‚Ä¢ Verst√§ndnis und Neugierde f√ºr komplexe IT-Landschaften
‚Ä¢ Hohe Zahlenaffinit√§t sowie genauer und strukturierter Arbeitsstil
‚Ä¢ Sehr gute Kenntnisse von BI/DWH/ETL Werkzeugen insbesondere im Bereich der Azure Plattform (Databricks, Data Factory, Storage...)
‚Ä¢ Ausgepr√§gte Kenntnisse relationaler Datenbanktechnologien bzw. Spark-SQL
‚Ä¢ Guten Programmierkenntnisse (Scala, Python)
‚Ä¢ Kenntnisse der agilen Entwicklungsmethodik und Tools wie Confluence und ADO
‚Ä¢ Berufs- und Projekterfahrung im Bereich Data Warehouse sind von Vorteil
‚Ä¢ Sehr gute Deutsch- und Englischkenntnisse

Warum ist es gro√üartig bei Zurich zu arbeiten?
‚Ä¢ B√ºro mit Wohlf√ºhl-Ambiente - f√ºr jede T√§tigkeit das richtige Umfeld
‚Ä¢ Home-Office und flexibles Arbeiten ‚Äì Gleitzeit ohne Kernzeit
‚Ä¢ Perspektive f√ºr eigene Entwicklung ‚Äì Zurich Academy, LinkedIn Learning
‚Ä¢ Angebote f√ºr Ihre Gesundheit ‚Äì Fitnesscenter, Events, Kantine mit Vital-Men√º
‚Ä¢ Attraktive Konditionen f√ºr Versicherungsprodukte
‚Ä¢ Gelebte Diversity und soziales Engagement ‚Äì PrideZ-Initiative, Eltern-Buddy-Netzwerk, Sozialprojekte
‚Ä¢ Mitgestalten unserer Zukunft ‚Äì digital, innovativ und nachhaltig
‚Ä¢ ‚Ä¶und das ist nicht alles!

Das Bruttogehalt f√ºr diese Funktion betr√§gt mindestens EUR 44.340,24 pro Jahr (38,5 Stunden/Woche). Abh√§ngig von Ihrer Erfahrung und Ausbildung machen wir Ihnen ein passendes Angebot. Dabei orientieren wir uns an aktuellen Marktgeh√§ltern.

Was macht Zurich besonders?

‚ÄûVersicherungen sind langweilig, altmodisch und kompliziert.‚Äú Kommt Ihnen bekannt vor? Bei uns ist es definitiv anders! Wir sind mitrei√üend, unkompliziert und treffsicher ‚Äì einfach mutiger. Unsere 1.300 Kolleginnen und Kollegen arbeiten gemeinsam und nachhaltig am besten Kundenerlebnis. Mit Erfolg, denn unsere Produkte und Services sind mehrfach ausgezeichnet. So geh√∂ren wir zu den Top Ten der heimischen Versicherungen.

Sie finden sich in unseren Werten wieder und die Rolle w√§re ein passender Karriereschritt f√ºr Sie? Wir freuen uns auf Ihre Online-Bewerbung √ºber den Button Jetzt bewerben.

Bei Fragen stehen wir gerne zur Verf√ºgung:

Z√ºrich Versicherungs-Aktiengesellschaft

Human Resources

Mag. Daniela Stockinger

Leopold-Ungar-Platz 2

1190 Wien

Tel.: (01) 501 25 ‚Äì 1305

https://www.zurich.at/ueber-uns/karriere
‚Ä¢ ) Wir ermutigen alle Menschen sich zu bewerben, unabh√§ngig von Geschlecht, Alter, Hautfarbe, sexueller Orientierung, Beeintr√§chtigung oder Herkunft und anderen gesetzlich gesch√ºtzten Gr√ºnden.

LI-Hybrid","[{'items': ['Sie brennen f√ºr Daten und bringen gro√ües Interesse an neuen Technologien mit? In dieser Rolle bekommen Sie die Gelegenheit, uns bei der Modernisierung und Umstellung auf Azure Databricks zu unterst√ºtzen.\n\nZur Verst√§rkung der IT-Abteilung ‚ÄûData Platform & SAP‚Äú suchen wir eine/n engagierte/n Mitarbeiter/in f√ºr folgende Aufgaben:\n‚Ä¢ Design, Modellierung und Weiterentwicklung der zentralen Data-Warehouse-L√∂sung mit Schwerpunkt ETL\n‚Ä¢ Transformation und Migration der bestehenden Legacy-DWH-Prozesse (auf Basis von IBM DB2 und Infosphere Warehouse) in Richtung Azure Databricks\n‚Ä¢ Einhaltung der Architektur- bzw. Entwicklungsvorgaben und deren Qualit√§t\n‚Ä¢ Automatisierung und Optimierung von DWH Workflows (End-to-End)\n‚Ä¢ Enge Zusammenarbeit mit dem Fachbereich bei der Analyse und Entwicklung neuer Themenfelder\n‚Ä¢ Erstellung der User Stories in Zusammenarbeit mit den Fachbereichen und Stakeholdern\n‚Ä¢ Qualit√§tssicherung und technische Dokumentation der Beladeprozesse\n\nWas zeichnet Sie aus?\n‚Ä¢ Der Blick... auf Details und √ºber die einzelnen Applikationen hinweg macht Ihnen Freude\n‚Ä¢ Verst√§ndnis und Neugierde f√ºr komplexe IT-Landschaften\n‚Ä¢ Hohe Zahlenaffinit√§t sowie genauer und strukturierter Arbeitsstil\n‚Ä¢ Sehr gute Kenntnisse von BI/DWH/ETL Werkzeugen insbesondere im Bereich der Azure Plattform (Databricks, Data Factory, Storage...)\n‚Ä¢ Ausgepr√§gte Kenntnisse relationaler Datenbanktechnologien bzw. Spark-SQL\n‚Ä¢ Guten Programmierkenntnisse (Scala, Python)\n‚Ä¢ Kenntnisse der agilen Entwicklungsmethodik und Tools wie Confluence und ADO\n‚Ä¢ Berufs- und Projekterfahrung im Bereich Data Warehouse sind von Vorteil\n‚Ä¢ Sehr gute Deutsch- und Englischkenntnisse\n\nWarum ist es gro√üartig bei Zurich zu arbeiten?\n‚Ä¢ B√ºro mit Wohlf√ºhl-Ambiente - f√ºr jede T√§tigkeit das richtige Umfeld\n‚Ä¢ Home-Office und flexibles Arbeiten ‚Äì Gleitzeit ohne Kernzeit\n‚Ä¢ Perspektive f√ºr eigene Entwicklung ‚Äì Zurich Academy, LinkedIn Learning\n‚Ä¢ Angebote f√ºr Ihre Gesundheit ‚Äì Fitnesscenter, Events, Kantine mit Vital-Men√º\n‚Ä¢ Attraktive Konditionen f√ºr Versicherungsprodukte\n‚Ä¢ Gelebte Diversity und soziales Engagement ‚Äì PrideZ-Initiative, Eltern-Buddy-Netzwerk, Sozialprojekte\n‚Ä¢ Mitgestalten unserer Zukunft ‚Äì digital, innovativ und nachhaltig\n‚Ä¢ ‚Ä¶und das ist nicht alles!\n\nDas Bruttogehalt f√ºr diese Funktion betr√§gt mindestens EUR 44.340,24 pro Jahr (38,5 Stunden/Woche). Abh√§ngig von Ihrer Erfahrung und Ausbildung machen wir Ihnen ein passendes Angebot. Dabei orientieren wir uns an aktuellen Marktgeh√§ltern.\n\nWas macht Zurich besonders?\n\n‚ÄûVersicherungen sind langweilig, altmodisch und kompliziert.‚Äú Kommt Ihnen bekannt vor? Bei uns ist es definitiv anders! Wir sind mitrei√üend, unkompliziert und treffsicher ‚Äì einfach mutiger. Unsere 1.300 Kolleginnen und Kollegen arbeiten gemeinsam und nachhaltig am besten Kundenerlebnis. Mit Erfolg, denn unsere Produkte und Services sind mehrfach ausgezeichnet. So geh√∂ren wir zu den Top Ten der heimischen Versicherungen.\n\nSie finden sich in unseren Werten wieder und die Rolle w√§re ein passender Karriereschritt f√ºr Sie? Wir freuen uns auf Ihre Online-Bewerbung √ºber den Button Jetzt bewerben.\n\nBei Fragen stehen wir gerne zur Verf√ºgung:\n\nZ√ºrich Versicherungs-Aktiengesellschaft\n\nHuman Resources\n\nMag. Daniela Stockinger\n\nLeopold-Ungar-Platz 2\n\n1190 Wien\n\nTel.: (01) 501 25 ‚Äì 1305\n\nhttps://www.zurich.at/ueber-uns/karriere\n‚Ä¢ ) Wir ermutigen alle Menschen sich zu bewerben, unabh√§ngig von Geschlecht, Alter, Hautfarbe, sexueller Orientierung, Beeintr√§chtigung oder Herkunft und anderen gesetzlich gesch√ºtzten Gr√ºnden.\n\nLI-Hybrid']}]","[{'link': 'http://www.zurich.com/', 'text': 'zurich.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Zurich+Insurance+Company+Ltd.&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIIlgs', 'text': 'See web results for Zurich Insurance Company Ltd.'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvnn2zsjZTK_LRUs7pCqbDfAGwhCvweHT6icbh&s=0,"['21 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '21 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIC0gZsO8ciBEV0gsIEJJIHVuZCBBbmFseXRpY3MgKG1lbnNjaCopIC0gVm9sbHplaXQgKGJ6dy4gVFogYWIgMzJoL1dvY2hlKSIsImh0aWRvY2lkIjoiWmRsaUpLR0thOWdBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQ0NyY0NRVTFyTW14c1NVODBkMDR5TUY5alpFZFhhWE13UzA5U1ZXeHJSSGhqUW1Od2QwVmpjRkpyVGpCTlkxUjViVVZyV2w5SVJsTm1jazVwTTNKdWRqUmFhMlkzY2pWSGFuTk9MVFZJWldsVVRWcHRSM05yZGpKemVtdEJUVWhZVG1kUFMyTm1VMnM1WVU5aFMwaFlOSGR1TmtsUE9XTkVlRkpTY2xocGNHUjFPRmx0U1VaWlkxOWtiM2RDVFdOVFMzbHBhbkJPUW5CVFZqVjBXbWMxZUZacE5VRndaV0k0TXpNMGNHUnNhVXhCV21KdFlXRk9OSFZzV1dGQ2FITmZRVEV4VERjdFQwbHBUMnBzTUhSMFlraEROMWd6TUdRM2FtRlJRaTFsVG1neWQwWXdjRVJZWTBkM1dGOUlZa1ZqZG5WMVpHVnlUa2QxZEhGMVlqWlVNSFZNZW5GTGNXVTFNQzFCTUhkdFgwWnpWRVJ2WW5keFNYRmZTMGRNVjBOb1VGSnRSMHhtWm1Sc1owUmpMWEZSVmxWU1ZFSnRhVUZCWVUwU0Z6azNURWhhU3kxcFRuRjVRM2RpYTFCNVMxTnJkVUZGR2lKQlRFVlRPWFZQUzI1UlZrSlRlamhOVjFGcFZtWkdhVmhHTFRCVGVHdFhOa3RSIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBadXJpY2ggQ2FyZWVycyIsImxpbmsiOiJodHRwczovL3d3dy5jYXJlZXJzLnp1cmljaC5jb20vam9iL1dpZW4tRGF0YS1FbmdpbmVlci1mJUMzJUJDci1EV0glMkMtQkktdW5kLUFuYWx5c3RpY3MtJTI4bWVuc2NoJTI5LVZvbGx6ZWl0LSUyOGJ6d18tVFotYWItMzJoV29jaGUlMjkvNzc0Nzg4NTAyLz9yZWZlcmVyPWl0am9ic2F1c3RyaWEuYXRcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer - Excellent Benefits Package,Pricehubble,"  Vienna, Austria   ",via GrabJobs,"We are in need of an analytical Senior Data Engineer to join our cohesive team at PriceHubble in Wien.
Growing your career as a Full Time Senior Data Engineer is a terrific opportunity to develop relevant skills.
If you are strong in communication, adaptability and have the right passion for the job, then apply for the position of Senior Data Engineer at PriceHubble today!

Deine Rolle im Team
‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble's processes and the activities of PriceHubble's customers
‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products
‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases
‚Ä¢ Leverage the cutting edge of the industry's best practices and technology in data design and management to continuously improve the quality and efficiency of our data products
‚Ä¢ Participate in improving and expanding the teams' data and... engineering standards, and support peers and more junior engineers on their application
Technologien und Skills
‚Ä¢ AWS
‚Ä¢ Apache Spark
‚Ä¢ Azure
‚Ä¢ Python
‚Ä¢ Google Cloud Platform
‚Ä¢ Airflow
‚Ä¢ Kubeflow
Unsere Erwartungen an dich:
Qualifikationen
‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.
‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.
‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.
‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.
‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.
‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.
‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.
‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.
Erfahrung
‚Ä¢ 3+ years practice of agile methodologies and devops methods.
‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.
‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).
‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).
Ausbildung
‚Ä¢ BSc or MSc in computer science or related fields.

Benefits of working as a Senior Data Engineer in Wien:

‚óè Opportunity to Make a Difference
‚óè Room for Advancement
‚óè Leading Industry Pay","[{'items': [""We are in need of an analytical Senior Data Engineer to join our cohesive team at PriceHubble in Wien.\nGrowing your career as a Full Time Senior Data Engineer is a terrific opportunity to develop relevant skills.\nIf you are strong in communication, adaptability and have the right passion for the job, then apply for the position of Senior Data Engineer at PriceHubble today!\n\nDeine Rolle im Team\n‚Ä¢ Define and deliver datasets that will act as the source-of-truth for PriceHubble's processes and the activities of PriceHubble's customers\n‚Ä¢ Scale and optimize data pipelines and data management systems to deliver those data products\n‚Ä¢ Track, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases\n‚Ä¢ Leverage the cutting edge of the industry's best practices and technology in data design and management to continuously improve the quality and efficiency of our data products\n‚Ä¢ Participate in improving and expanding the teams' data and... engineering standards, and support peers and more junior engineers on their application\nTechnologien und Skills\n‚Ä¢ AWS\n‚Ä¢ Apache Spark\n‚Ä¢ Azure\n‚Ä¢ Python\n‚Ä¢ Google Cloud Platform\n‚Ä¢ Airflow\n‚Ä¢ Kubeflow\nUnsere Erwartungen an dich:\nQualifikationen\n‚Ä¢ You enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team.\n‚Ä¢ You are passionate about learning new things and transferring this knowledge to others.\n‚Ä¢ You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.\n‚Ä¢ Excellent skills in object-oriented programming, data structures and algorithms.\n‚Ä¢ Excellent skills designing distributed service architectures in a cloud environment.\n‚Ä¢ Structured and empathetic communicator, able to mentor other engineers and data scientists.\n‚Ä¢ Strong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences.\n‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union / UK but we are not able to sponsor visas.\nErfahrung\n‚Ä¢ 3+ years practice of agile methodologies and devops methods.\n‚Ä¢ 3+ years of experience in the Python data engineering ecosystem.\n‚Ä¢ Experience working with public cloud platforms (AWS, Azure or GCP).\n‚Ä¢ Extensive experience with data systems and microservices in the cloud, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark‚Ä¶).\nAusbildung\n‚Ä¢ BSc or MSc in computer science or related fields.\n\nBenefits of working as a Senior Data Engineer in Wien:\n\n‚óè Opportunity to Make a Difference\n‚óè Room for Advancement\n‚óè Leading Industry Pay""]}]","[{'link': 'http://pricehubble.com/', 'text': 'pricehubble.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Pricehubble&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIIygs', 'text': 'See web results for Pricehubble'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRcEqyKMxQJvyMvLo-dBMzMo_gcqvrPWI0a8v9BiOo&s,"['6 days ago', 'Full-time']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAtIEV4Y2VsbGVudCBCZW5lZml0cyBQYWNrYWdlIiwiaHRpZG9jaWQiOiJQVDZMWjM0YjdoY0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzVEVRMVlXWlhTbVE1UzJReFYzRnNYMlZSZFhVd09IRkxZMjFxY0dkMFFqVXRNR1p0VW5ac2MyMU5jRkExUlRGNU56WTRjRFp2VTBsZlREbGhTRGxhYXpFdFRIbEJWRmhmYURaMFExcGhaM0JaUzBwRmVsUktVV290UjI5SFZuVnlNMnBRWTJjNWVsRlFiWFE1VkhSbmRsVlJSV1pTTlhCM1JWRnFRMjkxUkdsM1NYSTFRa05uWTJkR1dteDRVbUZsY0hoTU4yVm5aVU0xY21OTVZtSkZVSEUxTkdRd00yNURWR1Y1TjAxWWF6ZE9USGhpU0dkRFZuRnhPSGxsUjBGRlZITXdZM2RVY3pOU2VWVjBNVzFEVFdsNmRtRmtMWGszTFhOVVp4SVhPVGRNU0ZwTExXbE9jWGxEZDJKclVIbExVMnQxUVVVYUlrRk1SVk01ZFZCRldXcFpUM1Z3VmtkVVdGaFBkRWh0V0ZsVWNIRm5Na3hHU1djIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBHcmFiSm9icyIsImxpbmsiOiJodHRwczovL2dyYWJqb2JzLmNvL2F1c3RyaWEvam9iL2Z1bGwtdGltZS9jdXN0b21lci1zZXJ2aWNlLWd1ZXN0LXNlcnZpY2VzL3Nlbmlvci1kYXRhLWVuZ2luZWVyLWV4Y2VsbGVudC1iZW5lZml0cy1wYWNrYWdlLTI0NTQyMTc0P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer eCommerce (m/w/x),REWE International Dienstleistungsgesellschaft m.b.H,"  Vienna, Austria   ",via Ai-Jobs.net,"UnternehmensbeschreibungAls IT der REWE Group Austria entwickeln wir gemeinsam mit unseren mehr als 500 Mitarbeitern innovative IT-Produkte und Services f√ºr alle Unternehmensbereiche im In- und Ausland und setzen damit Akzente f√ºr den modernen Handel. Im Bereich eCommerce bauen wir das beste Liefer- und Online-Shopping-Erlebnis f√ºr unsere Kunden. Spitzentechnologie ist unsere Leidenschaft und wir vertrauen in agile Softwareentwicklung. Wenn du dich die Gestaltung dieser eCommerce-Welt reizt und du eine Affinit√§t zu Zahlen und Daten hast, k√∂nntest Du gut zu uns passen. Wir sind auf der Suche nach einem Data Engineer, der f√ºr die Data Pipelines, sowie die darauf aufbauenden Data Stores verantwortlich ist. Du arbeitest eng mit den Stakeholdern im gesamten Unternehmen zusammen und konzentrierst Dich auf eine hochqualitative Entwicklung, die sich an den Gesch√§ftszielen orientiert.‚ÄØ StellenbeschreibungPlanung, Entwicklung und Umsetzung einer optimalen Datenarchitektur auf der Google... Plattform, um eine qualitativ hochwertige Basis f√ºr Anwendungsf√§lle im Bereich Analytics und Machine Learning zur Verf√ºgung zu stellen Kooperation mit Analysten, Produktmanagern und Backend Entwicklern, um Datenanforderungen zu verstehen und umzusetzen Unterst√ºtzung beim Entwerfen und Erstellen von neuen Daten Extraktions-, Transformations- und Ladeprozessen von unterschiedlichen Datenquellen Verwendung und Sicherstellung von state-of-the-art Methoden (CI/CD), um eine zukunftssichere und skalierbare Plattform bereit zu stellen QualifikationenErfahrung mit Cloud Plattformen, bevorzugt der Google Cloud Erfahrung mit der Erstellung von skalierbaren Data Pipelines Vertraut mit kundenspezifischem ETL-Design und dessen Wartung Kenntnisse der Datenformate XML & JSON Erfahrung mit relationalen Datenbanken (Oracle, Postgre SQL oder vergleichbar) Programmiersprachen wie R, Python, Java etc. der Erstellung von Daten Workflows via Kafka, Apache NiFi, Apache Airflow oder vergleichbar der Kommunikation √ºber REST APIs Allgemein Erfahrung in der Bereitstellung einer skalierten Daten- und Analyseplattform Selbstst√§ndige und strukturierte Arbeitsweise Hohe Eigenverantwortung und F√§higkeit, neue Technologien in einem schnelllebigen Umfeld zu erlernen Englischkenntnisse in Wort und Schrift Zus√§tzliche InformationenLangfristige, abwechslungsreiche T√§tigkeit bei einem verl√§sslichen Arbeitgeber in einem kollegialen TeamFamilienfreundliche Unternehmenskultur mit flexiblen Arbeitszeiten und Homeoffice unter Ber√ºcksichtigung deiner individuellen Bed√ºrfnisseZahlreiche Ausbildungs- und Weiterentwicklungsm√∂glichkeiten im Konzern (5% der Arbeitszeit f√ºr selbstorganisierte Weiterbildung)Mitarbeiter:innen-Rabatte bei Einkauf und ReisenEin Jahresbruttogehalt ab ‚Ç¨ 60.200,-- auf Basis Vollzeit mit der Bereitschaft zur √úberzahlung bei entsprechender Erfahrung und Qualifikation. Wir suchen die Neugierigen, die Verl√§sslichen, die Motivierten, die Vielseitigen, die Ungew√∂hnlichen, die Offenen, die Fokussierten, die Umdenkenden, die Mitdenkenden, die Nachdenkenden und vor allem die Menschlichen, die Neues entdecken wollen.Wir f√∂rdern ein vielf√§ltiges und inklusives Arbeitsumfeld. Daher freuen wir uns √ºber Bewerbungen von Menschen unterschiedlichen Geschlechts, Alters, kulturellem oder sozialem Hintergrund, sexueller Identit√§t und Bewerbungen von Menschen mit Behinderungen. Zus√§tzlich m√∂chten wir den Anteil von Frauen in technischen Berufsfeldern erh√∂hen und freuen wir uns f√ºr diese Position besonders √ºber Bewerbungen von Frauen","[{'items': ['UnternehmensbeschreibungAls IT der REWE Group Austria entwickeln wir gemeinsam mit unseren mehr als 500 Mitarbeitern innovative IT-Produkte und Services f√ºr alle Unternehmensbereiche im In- und Ausland und setzen damit Akzente f√ºr den modernen Handel. Im Bereich eCommerce bauen wir das beste Liefer- und Online-Shopping-Erlebnis f√ºr unsere Kunden. Spitzentechnologie ist unsere Leidenschaft und wir vertrauen in agile Softwareentwicklung. Wenn du dich die Gestaltung dieser eCommerce-Welt reizt und du eine Affinit√§t zu Zahlen und Daten hast, k√∂nntest Du gut zu uns passen. Wir sind auf der Suche nach einem Data Engineer, der f√ºr die Data Pipelines, sowie die darauf aufbauenden Data Stores verantwortlich ist. Du arbeitest eng mit den Stakeholdern im gesamten Unternehmen zusammen und konzentrierst Dich auf eine hochqualitative Entwicklung, die sich an den Gesch√§ftszielen orientiert.\u202f StellenbeschreibungPlanung, Entwicklung und Umsetzung einer optimalen Datenarchitektur auf der Google... Plattform, um eine qualitativ hochwertige Basis f√ºr Anwendungsf√§lle im Bereich Analytics und Machine Learning zur Verf√ºgung zu stellen Kooperation mit Analysten, Produktmanagern und Backend Entwicklern, um Datenanforderungen zu verstehen und umzusetzen Unterst√ºtzung beim Entwerfen und Erstellen von neuen Daten Extraktions-, Transformations- und Ladeprozessen von unterschiedlichen Datenquellen Verwendung und Sicherstellung von state-of-the-art Methoden (CI/CD), um eine zukunftssichere und skalierbare Plattform bereit zu stellen QualifikationenErfahrung mit Cloud Plattformen, bevorzugt der Google Cloud Erfahrung mit der Erstellung von skalierbaren Data Pipelines Vertraut mit kundenspezifischem ETL-Design und dessen Wartung Kenntnisse der Datenformate XML & JSON Erfahrung mit relationalen Datenbanken (Oracle, Postgre SQL oder vergleichbar) Programmiersprachen wie R, Python, Java etc. der Erstellung von Daten Workflows via Kafka, Apache NiFi, Apache Airflow oder vergleichbar der Kommunikation √ºber REST APIs Allgemein Erfahrung in der Bereitstellung einer skalierten Daten- und Analyseplattform Selbstst√§ndige und strukturierte Arbeitsweise Hohe Eigenverantwortung und F√§higkeit, neue Technologien in einem schnelllebigen Umfeld zu erlernen Englischkenntnisse in Wort und Schrift Zus√§tzliche InformationenLangfristige, abwechslungsreiche T√§tigkeit bei einem verl√§sslichen Arbeitgeber in einem kollegialen TeamFamilienfreundliche Unternehmenskultur mit flexiblen Arbeitszeiten und Homeoffice unter Ber√ºcksichtigung deiner individuellen Bed√ºrfnisseZahlreiche Ausbildungs- und Weiterentwicklungsm√∂glichkeiten im Konzern (5% der Arbeitszeit f√ºr selbstorganisierte Weiterbildung)Mitarbeiter:innen-Rabatte bei Einkauf und ReisenEin Jahresbruttogehalt ab ‚Ç¨ 60.200,-- auf Basis Vollzeit mit der Bereitschaft zur √úberzahlung bei entsprechender Erfahrung und Qualifikation. Wir suchen die Neugierigen, die Verl√§sslichen, die Motivierten, die Vielseitigen, die Ungew√∂hnlichen, die Offenen, die Fokussierten, die Umdenkenden, die Mitdenkenden, die Nachdenkenden und vor allem die Menschlichen, die Neues entdecken wollen.Wir f√∂rdern ein vielf√§ltiges und inklusives Arbeitsumfeld. Daher freuen wir uns √ºber Bewerbungen von Menschen unterschiedlichen Geschlechts, Alters, kulturellem oder sozialem Hintergrund, sexueller Identit√§t und Bewerbungen von Menschen mit Behinderungen. Zus√§tzlich m√∂chten wir den Anteil von Frauen in technischen Berufsfeldern erh√∂hen und freuen wir uns f√ºr diese Position besonders √ºber Bewerbungen von Frauen']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=REWE+International+Dienstleistungsgesellschaft+m.b.H&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAII_Qs', 'text': 'See web results for REWE International Dienstleistungsgesellschaft m.b.H'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT-DoqqQVYV0Wz_CqYhjmaAUtQWSEslBp6iXfDG&s=0,"['1 month ago', 'Full-time', 'No degree mentioned']","{'posted_at': '1 month ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIGVDb21tZXJjZSAobS93L3gpIiwiaHRpZG9jaWQiOiJGRGstTXI5SXJ0d0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFc3dDQ293Q1FVMXJNbXhzUzBwQ2NVRTJXRGRDTFVKcE1rMXdMVXRTY1hKQ1dFa3pkV2gyYW5WdGVWQlBXREJ2Y1VSVGNYUkxkMk42TWs4d1VFbFpUMFl6YkVKVU1uaHVTR05GTm1rMlNsWkZkMnRrVWs1MVNFRXhabUZWVGtKa01HNUVjbk0wYVd4S05IazRReTF5WkRKNWFHeFBjWFY0TFdONFJGVmlhbTVDZW5WMlNqQnBRVEZJWkdKa1gxaEdOalZzU21WeFl6RjRSazlXUlhwUVFVSXdObFk1YWkxWGEzTk9TMVV5ZG1oRVMwUjZiRFZtYzJ4WVZXTm5OWE5rTm01d1dWRlRaMU5YYW5OSlEyWTVVRkp0ZUZsc1VEbG9Oa0ZFY0d0V2VVNXhSa0V5T0hvd1UyOVROQzFYTWtRM1JrbzBWbWsyWldNeWFsOTRRa1YxTTI1SU9XMUpWRVJ2U1VFM1VGZG9RM05YVFJJWE9UZE1TRnBMTFdsT2NYbERkMkpyVUhsTFUydDFRVVVhSWtGTVJWTTVkVTB4TTJVMVZtZHZOMFpDYURScE0yMTJTbVowYW1GQ05EVkZTWGMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY183IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEFpLUpvYnMubmV0IiwibGluayI6Imh0dHBzOi8vYWktam9icy5uZXQvam9iLzU2NTA3LWRhdGEtZW5naW5lZXItZWNvbW1lcmNlLW13eC8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Senior DevOps & Data Engineer (w/m/d),Iventa IT-Recruiting GmbH,"  Vienna, Austria   ",via WANE Jobs,"M√∂chtest du die IT-Infrastruktur einer f√ºhrenden Bankengruppe √ñsterreichs auf ein neues Level bringen und einen nachhaltigen Einfluss hinterlassen? Hast du eine generalistische Einstellung und ein breites IT-Know-How, das du gerne mit deinem Team teilst?

Wenn du auch offen und neugierig bist und die Flexibilit√§t sch√§tzt, zwischen Homeoffice und den B√ºros in Graz oder Wien zu w√§hlen, dann bist DU das perfekte MATCH f√ºr diese anspruchsvolle Senior-Position!

Starte mit Iventa IT-Recruiting in deinen neuen Job und entdecke neue Berufswelten!

Aufgaben
‚Ä¢ Optimierung der Entwicklungsumgebung im Datenbankumfeld, unter Ber√ºcksichtigung von Secure Software Development Lifecycle (SSDLC) Richtlinien
‚Ä¢ Konfiguration & Optimierung der CI/CD-Pipelines und Administration der eingesetzten Anwendungen (z.B. Jenkins)
‚Ä¢ Durchf√ºhrung von Administrationsaufgaben mit GitLab repository
‚Ä¢ Automatisierung der Datenbereitstellungsprozesse & Weiterentwicklung von ETL-Abl√§ufen
‚Ä¢ Erstellung von... Automatisierungsskripten & Konfiguration von Linux- bzw. Container-Services
‚Ä¢ Zusammenarbeit mit externen Partnern & unterst√ºtzende Mentoring Rolle f√ºr Junior-Teammitglieder innen

Profil
‚Ä¢ Mehrj√§hrige Berufserfahrung im IT-Bereich mit Fokus auf DevOps & Data Engineering
‚Ä¢ Fundierte Ausbildung (HTL, FH oder Universit√§t) von Vorteil aber keine Voraussetzung
‚Ä¢ Ausgezeichnete Kenntnisse in Oracle & SQL Datenbanken
‚Ä¢ Umfangreiche Erfahrung mit Linux-Systemen
‚Ä¢ Verst√§ndnis von DevOps-Prinzipien (z.B. GitOps) & Versionierung von Software mit GitLab
‚Ä¢ Von Vorteil: Erfahrung mit Kubernetes & Programmierkenntnisse in Java
‚Ä¢ Sehr gute Deutschkenntnisse, teamf√§hige Pers√∂nlichkeit mit einer l√∂sungsorientierten Arbeitsweise

Wir bieten
‚Ä¢ Flexible Arbeitszeit ohne Kernzeit und Homeoffice Option
‚Ä¢ Ein familienfreundliches Umfeld mit gro√üem Gestaltungsfreiraum
‚Ä¢ Essenszuschuss und diverse Verg√ºnstigungen
‚Ä¢ Weiterbildungsm√∂glichkeiten & regelm√§√üige Mitarbeiterveranstaltungen
‚Ä¢ Betriebliche Gesundheitsf√∂rderung & Zusatzversicherung
‚Ä¢ Ein motiviertes Team, das dich vom ersten Tag an herzlich willkommen hei√üt

F√ºr diese Position erwartet dich ein Bruttojahresgehalt ab EUR 75.000,- mit der Bereitschaft zur √úberzahlung je nach Qualifikation und Erfahrung","[{'items': ['M√∂chtest du die IT-Infrastruktur einer f√ºhrenden Bankengruppe √ñsterreichs auf ein neues Level bringen und einen nachhaltigen Einfluss hinterlassen? Hast du eine generalistische Einstellung und ein breites IT-Know-How, das du gerne mit deinem Team teilst?\n\nWenn du auch offen und neugierig bist und die Flexibilit√§t sch√§tzt, zwischen Homeoffice und den B√ºros in Graz oder Wien zu w√§hlen, dann bist DU das perfekte MATCH f√ºr diese anspruchsvolle Senior-Position!\n\nStarte mit Iventa IT-Recruiting in deinen neuen Job und entdecke neue Berufswelten!\n\nAufgaben\n‚Ä¢ Optimierung der Entwicklungsumgebung im Datenbankumfeld, unter Ber√ºcksichtigung von Secure Software Development Lifecycle (SSDLC) Richtlinien\n‚Ä¢ Konfiguration & Optimierung der CI/CD-Pipelines und Administration der eingesetzten Anwendungen (z.B. Jenkins)\n‚Ä¢ Durchf√ºhrung von Administrationsaufgaben mit GitLab repository\n‚Ä¢ Automatisierung der Datenbereitstellungsprozesse & Weiterentwicklung von ETL-Abl√§ufen\n‚Ä¢ Erstellung von... Automatisierungsskripten & Konfiguration von Linux- bzw. Container-Services\n‚Ä¢ Zusammenarbeit mit externen Partnern & unterst√ºtzende Mentoring Rolle f√ºr Junior-Teammitglieder innen\n\nProfil\n‚Ä¢ Mehrj√§hrige Berufserfahrung im IT-Bereich mit Fokus auf DevOps & Data Engineering\n‚Ä¢ Fundierte Ausbildung (HTL, FH oder Universit√§t) von Vorteil aber keine Voraussetzung\n‚Ä¢ Ausgezeichnete Kenntnisse in Oracle & SQL Datenbanken\n‚Ä¢ Umfangreiche Erfahrung mit Linux-Systemen\n‚Ä¢ Verst√§ndnis von DevOps-Prinzipien (z.B. GitOps) & Versionierung von Software mit GitLab\n‚Ä¢ Von Vorteil: Erfahrung mit Kubernetes & Programmierkenntnisse in Java\n‚Ä¢ Sehr gute Deutschkenntnisse, teamf√§hige Pers√∂nlichkeit mit einer l√∂sungsorientierten Arbeitsweise\n\nWir bieten\n‚Ä¢ Flexible Arbeitszeit ohne Kernzeit und Homeoffice Option\n‚Ä¢ Ein familienfreundliches Umfeld mit gro√üem Gestaltungsfreiraum\n‚Ä¢ Essenszuschuss und diverse Verg√ºnstigungen\n‚Ä¢ Weiterbildungsm√∂glichkeiten & regelm√§√üige Mitarbeiterveranstaltungen\n‚Ä¢ Betriebliche Gesundheitsf√∂rderung & Zusatzversicherung\n‚Ä¢ Ein motiviertes Team, das dich vom ersten Tag an herzlich willkommen hei√üt\n\nF√ºr diese Position erwartet dich ein Bruttojahresgehalt ab EUR 75.000,- mit der Bereitschaft zur √úberzahlung je nach Qualifikation und Erfahrung']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Iventa+IT-Recruiting+GmbH&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIIsAw', 'text': 'See web results for Iventa IT-Recruiting GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJ0gswC8ZClVJtusd7S5DkvlsMymmI6My0Ey0ftts&s,"['7 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGV2T3BzIFx1MDAyNiBEYXRhIEVuZ2luZWVyICh3L20vZCkiLCJodGlkb2NpZCI6Imh6LXVIRGFQdjU0QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTM3BzVVZOVVpWazVhbEp1WjFCVlZHSXpiVlZxU205UmFWVTJZbGs0TUZOYWJHWkJkRGQwYjFCWE5XeDVhbnBKUzFKQmVuTlFOMGhUUTBwdmVqWkpVMkp1YlVka1dITXlabEU0WDFCRWVuZ3dRM2s0V0U1Wk9YZFhhbWN4VFVoNFRHaHJZWHB4VjFSaU5HSjRhamhRUldRMFpFZzNSRm8yVldaMllsTjVOSGh5YW5wNVQzVnBXVzFsUjFOZldXOXpiM1E0UWxwclVubHdla2hTUmtsWGNrRkpTMlEzZVdWUVVGOVlUR1ZuYkcxdVQwdHNZVzlRU1VSRGFUVlRORGx4V0c1SlR6aGZFaGM1TjB4SVdrc3RhVTV4ZVVOM1ltdFFlVXRUYTNWQlJSb2lRVXhGVXpsMVRsRlJabVZqT1hkVUxUbEJjM1ZEUkhoNmFFSkJOakZpTTJ4aVVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBXQU5FIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9qb2JzLndhbmUuY29tL2pvYnMvc2VuaW9yLWRldm9wcy1kYXRhLWVuZ2luZWVyLXctbS1kLXdpZW4vMTA3MjA2NDk2MC0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Lead Data Analyst,Duty First Consulting,"  Vienna, Austria   ",via DataYoshi,"About The Role

As a company founded by service-disabled Veterans, we at DFC are driven by a duty to serve our clients, our employees, and our community. We are committed to helping organizations achieve their goals by cultivating a team of talented professionals that deliver exceptional service, creative insights, and high-quality results.

DFC seeks an experienced Lead Data Analyst to support a project supporting the Department of Veterans Affairs (VA), Veterans Benefits Administration (VBA). The project will support VBA's enterprise-level human capital ideation initiatives and customer experience portfolio and provide project management support, event management and execution, and business process engineering. This position focuses on providing vision and leadership to design, develop, and deliver modern analytics tools, statistical analysis and data analytic services, data management services.

What The Role Requires
‚Ä¢ Serve as an expert advisor and resource on data analytics... including analysis and visual communication of big data sets, in order to develop, implement, lead, and direct data management strategies that provide technical direction of data management capability areas.
‚Ä¢ Be responsible for understanding large data sets and leading and managing advance data techniques in support of emerging initiatives and projects.
‚Ä¢ Lead and report on data analysis efforts using a variety of tailored analytical techniques,
‚Ä¢ Review and present results to senior management and other end-users,
‚Ä¢ Collect, analyze, and report on data from various sources and systems,
‚Ä¢ Develop and implement a wide range of advanced qualitative and quantitative methods to assess and improve operational effectiveness,
‚Ä¢ Create and run SQL queries against data from a variety of sources,
‚Ä¢ Support development of data reports, including dashboards, data visualizations,
‚Ä¢ Lead data mining efforts on internal government and external public sources,
‚Ä¢ Provide viable reference material for users by writing and maintaining user documentation,
‚Ä¢ Maintain client confidence and protect operations by maintaining information confidentiality,
‚Ä¢ Work toward professional improvement and certifications, maintains current certifications, develops and maintains professional and technical knowledge by attending educational workshops.

What You Need To Be Successful
‚Ä¢ At least 5 years of experience in data analysis
‚Ä¢ Comprehensive knowledge and experience with operating enterprise level advanced analytical services, enterprise performance measures, and data management operations
‚Ä¢ Comprehensive knowledge of industry leading advanced data analytics technology for large and complex organizations
‚Ä¢ Ability to work well in team-based environment.
‚Ä¢ Ability to work independently and develop client relationships.
‚Ä¢ Ability to lead and facilitate client meetings, conference calls, and capture accurate meeting notes.
‚Ä¢ Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.
‚Ä¢ Well-organized with the ability to handle several projects/clients simultaneously.
‚Ä¢ Strong analytical skills, presentation development and writing skills.
‚Ä¢ Exceptional skills in Microsoft Office Suite, including Microsoft Excel
‚Ä¢ Experience with statistical software such as SPSS or SAS
‚Ä¢ Strong work ethic with a commitment to client service excellence
‚Ä¢ Strong client presence
‚Ä¢ Experience working with federal government projects is strongly preferred.

Other Important Information
‚Ä¢ Master's degree in mathematics, statistics, science, operational research, or a related field is required
‚Ä¢ Ability to obtain a US government security clearance, if needed, is required.
‚Ä¢ Applicants must have the legal right to work in the US for any employer; sponsorship is not available for this position.
‚Ä¢ Preference will be given to qualified Veteran candidates.

Is consulting the right career for you?

A career in consulting can offer a wide variety of experiences and is a great opportunity for personal and professional growth, but it often requires a bit more time and energy than the standard nine-to-five. The characteristics below are those of a typical consultant in this field; we encourage you to consider if these are applicable to you as you complete your application.
‚Ä¢ Thrives when working in a challenging, fast-paced environment.
‚Ä¢ Balances competing priorities and fluctuating workloads with composure.
‚Ä¢ Works well in teams or independently, as the job requires.
‚Ä¢ Commits the requisite hours and effort to ensure deliverables are submitted on time and error-free.
‚Ä¢ Dives into new and unfamiliar tasks, employing a learn-as-you-go mentality and problem-solving skills.
‚Ä¢ Has the foresight to strategically plan and anticipate next steps and outcomes?
‚Ä¢ Uses interpersonal skills to establish and uphold strong client relationships, representing the company positively.
‚Ä¢ Values quality in client deliverables and internal tasks
‚Ä¢ Enjoys having a high level of responsibility and task autonomy.
‚Ä¢ Acts professionally in all circumstances and enjoys creating and nurturing a professional network of peers, clients, and partners.
‚Ä¢ Duty First Consulting is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, creed, religion, ancestry, national origin, age, gender/sex, marital status, sexual orientation, physical or mental disability, military/veteran status, citizenship status, the basis of genetic information or any other group protected by Federal or State law or local ordinance. People with disabilities who need reasonable accommodation to apply or compete for employment may request such accommodation(s).

Job Posted by ApplicantPro","[{'items': [""About The Role\n\nAs a company founded by service-disabled Veterans, we at DFC are driven by a duty to serve our clients, our employees, and our community. We are committed to helping organizations achieve their goals by cultivating a team of talented professionals that deliver exceptional service, creative insights, and high-quality results.\n\nDFC seeks an experienced Lead Data Analyst to support a project supporting the Department of Veterans Affairs (VA), Veterans Benefits Administration (VBA). The project will support VBA's enterprise-level human capital ideation initiatives and customer experience portfolio and provide project management support, event management and execution, and business process engineering. This position focuses on providing vision and leadership to design, develop, and deliver modern analytics tools, statistical analysis and data analytic services, data management services.\n\nWhat The Role Requires\n‚Ä¢ Serve as an expert advisor and resource on data analytics... including analysis and visual communication of big data sets, in order to develop, implement, lead, and direct data management strategies that provide technical direction of data management capability areas.\n‚Ä¢ Be responsible for understanding large data sets and leading and managing advance data techniques in support of emerging initiatives and projects.\n‚Ä¢ Lead and report on data analysis efforts using a variety of tailored analytical techniques,\n‚Ä¢ Review and present results to senior management and other end-users,\n‚Ä¢ Collect, analyze, and report on data from various sources and systems,\n‚Ä¢ Develop and implement a wide range of advanced qualitative and quantitative methods to assess and improve operational effectiveness,\n‚Ä¢ Create and run SQL queries against data from a variety of sources,\n‚Ä¢ Support development of data reports, including dashboards, data visualizations,\n‚Ä¢ Lead data mining efforts on internal government and external public sources,\n‚Ä¢ Provide viable reference material for users by writing and maintaining user documentation,\n‚Ä¢ Maintain client confidence and protect operations by maintaining information confidentiality,\n‚Ä¢ Work toward professional improvement and certifications, maintains current certifications, develops and maintains professional and technical knowledge by attending educational workshops.\n\nWhat You Need To Be Successful\n‚Ä¢ At least 5 years of experience in data analysis\n‚Ä¢ Comprehensive knowledge and experience with operating enterprise level advanced analytical services, enterprise performance measures, and data management operations\n‚Ä¢ Comprehensive knowledge of industry leading advanced data analytics technology for large and complex organizations\n‚Ä¢ Ability to work well in team-based environment.\n‚Ä¢ Ability to work independently and develop client relationships.\n‚Ä¢ Ability to lead and facilitate client meetings, conference calls, and capture accurate meeting notes.\n‚Ä¢ Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.\n‚Ä¢ Well-organized with the ability to handle several projects/clients simultaneously.\n‚Ä¢ Strong analytical skills, presentation development and writing skills.\n‚Ä¢ Exceptional skills in Microsoft Office Suite, including Microsoft Excel\n‚Ä¢ Experience with statistical software such as SPSS or SAS\n‚Ä¢ Strong work ethic with a commitment to client service excellence\n‚Ä¢ Strong client presence\n‚Ä¢ Experience working with federal government projects is strongly preferred.\n\nOther Important Information\n‚Ä¢ Master's degree in mathematics, statistics, science, operational research, or a related field is required\n‚Ä¢ Ability to obtain a US government security clearance, if needed, is required.\n‚Ä¢ Applicants must have the legal right to work in the US for any employer; sponsorship is not available for this position.\n‚Ä¢ Preference will be given to qualified Veteran candidates.\n\nIs consulting the right career for you?\n\nA career in consulting can offer a wide variety of experiences and is a great opportunity for personal and professional growth, but it often requires a bit more time and energy than the standard nine-to-five. The characteristics below are those of a typical consultant in this field; we encourage you to consider if these are applicable to you as you complete your application.\n‚Ä¢ Thrives when working in a challenging, fast-paced environment.\n‚Ä¢ Balances competing priorities and fluctuating workloads with composure.\n‚Ä¢ Works well in teams or independently, as the job requires.\n‚Ä¢ Commits the requisite hours and effort to ensure deliverables are submitted on time and error-free.\n‚Ä¢ Dives into new and unfamiliar tasks, employing a learn-as-you-go mentality and problem-solving skills.\n‚Ä¢ Has the foresight to strategically plan and anticipate next steps and outcomes?\n‚Ä¢ Uses interpersonal skills to establish and uphold strong client relationships, representing the company positively.\n‚Ä¢ Values quality in client deliverables and internal tasks\n‚Ä¢ Enjoys having a high level of responsibility and task autonomy.\n‚Ä¢ Acts professionally in all circumstances and enjoys creating and nurturing a professional network of peers, clients, and partners.\n‚Ä¢ Duty First Consulting is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, creed, religion, ancestry, national origin, age, gender/sex, marital status, sexual orientation, physical or mental disability, military/veteran status, citizenship status, the basis of genetic information or any other group protected by Federal or State law or local ordinance. People with disabilities who need reasonable accommodation to apply or compete for employment may request such accommodation(s).\n\nJob Posted by ApplicantPro""]}]","[{'link': 'http://www.dutyfirstconsulting.com/', 'text': 'dutyfirstconsulting.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Duty+First+Consulting&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAII5Aw', 'text': 'See web results for Duty First Consulting'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTxm6gv50U1zZPtM05VEkda0ns41-lH3pHVKnY9RUA&s,"['8 days ago', 'Full-time']","{'posted_at': '8 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJMZWFkIERhdGEgQW5hbHlzdCIsImh0aWRvY2lkIjoiVU9Oa3Nfci1GVjBBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1NsSnBNbGxhTWs0MFZqa3hTMk14TW5CZlRWVktSazF0TURjeU1IcEhiWFpyTFZabmRHSjZYM0E0U21ORWFETlljM0ZWVlVSUGMwVTVWRFJqYkcweFJVeEhZVUp1UlhObWEwbGZPVjlzTVZOcWNIQjFlakJJU0Mxb1JWUTVUR0kwUldST2VrdHZiMnh3YzFNelEyZExWREpCVGpSR1EzcGhSamx6Y1hGUmVrbzFMVjlGYXpWcGVXeGZha1ppVVhNM1lteDZZa1p1ZURkaFNIaFRiM0pmZUd4VFpIaGpOM3B4ZFc1eFluTXpRMFl4TFRGTk5XVnRYMjl0VUZoc01GQTRZVVJQTm5WMUVoYzVOMHhJV2tzdGFVNXhlVU4zWW10UWVVdFRhM1ZCUlJvaVFVeEZVemwxVFRGRk9YbDFjRWh3WkRsdE1EQkJMV3RHTmtKdWFXNWhRakJWUVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBEYXRhWW9zaGkiLCJsaW5rIjoiaHR0cHM6Ly93d3cuZGF0YXlvc2hpLmNvbS9vZmZlci81NjQyNjUvbGVhZC1kYXRhLWFuYWx5c3Q/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,FH Ober√∂sterreich,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ Developing scripts for the extraction of structured and non-structured information (e.g. SQL databases, csv, xlsx, xml, txt, web pages and others).
‚Ä¢ Design data models considering best practices regarding efficiency and information security.
‚Ä¢ Create dedicated scripts to perform data transformation and store in redundant repositories.
‚Ä¢ Evaluate and collaborate in the implementation of solutions for handling big data environments.
‚Ä¢ Optimize legacy ETL processes and perform new developments.
‚Ä¢ Document the data processing pipelines and manage the code versioning.
‚Ä¢ Collaborate with the engineering team in the development or modification of the core existing platforms.
‚Ä¢ Contribute to publications
‚Ä¢ Take operational responsibility for the components that you develop.

Technologies and skills
‚Ä¢ Pandas
‚Ä¢ RDBMS
‚Ä¢ Dask
‚Ä¢ Anaconda
‚Ä¢ SQL
‚Ä¢ Hadoop
‚Ä¢ NumPy
‚Ä¢ Apache HTTP Server
‚Ä¢ Apache Spark
‚Ä¢ Jupyter (IPython)
‚Ä¢ Pyspark
‚Ä¢ MongoDB
‚Ä¢ NoSQL
‚Ä¢ Elasticsearch
‚Ä¢ Cassandra
‚Ä¢... XML
‚Ä¢ Docker
‚Ä¢ Python

Our expectations:

Qualifications
‚Ä¢ Deep understanding of the web scrapping approach, web page structures and techniques to extract information.
‚Ä¢ Using parallelism in the execution of ETL process, execution based on events.
‚Ä¢ Using Amazon cloud computing resources like EMR and S3 storage.
‚Ä¢ Use of Graph Database Neo4j and Cypher query language.
‚Ä¢ Working in an environment where you constantly experiment and iterate quickly

Experience
‚Ä¢ Experience using Python as programming language focus on data field (e.g. Anaconda, Jupyter Notebook, Pandas, Dask, PySpark, Numpy, Scikit, others).
‚Ä¢ Experience with the RDBMS and of SQL query language, database optimizations, indexing, replications.
‚Ä¢ Experience with NOSQL resources, like ElasticSearch, MongoDB, Apache Cassandra,etc.
‚Ä¢ Data lake principles and practical experience with big data solutions (e.g. Hadoop, Apache Spark)
‚Ä¢ Experience with deployment ETL process in Docker containers.
‚Ä¢ Experience with secure data at transit and rest (encryption) and techniques for clustering and replication implementation.

Education
‚Ä¢ MSC - Degree in computer science / software engineering","[{'items': ['Your role in the team\n‚Ä¢ Developing scripts for the extraction of structured and non-structured information (e.g. SQL databases, csv, xlsx, xml, txt, web pages and others).\n‚Ä¢ Design data models considering best practices regarding efficiency and information security.\n‚Ä¢ Create dedicated scripts to perform data transformation and store in redundant repositories.\n‚Ä¢ Evaluate and collaborate in the implementation of solutions for handling big data environments.\n‚Ä¢ Optimize legacy ETL processes and perform new developments.\n‚Ä¢ Document the data processing pipelines and manage the code versioning.\n‚Ä¢ Collaborate with the engineering team in the development or modification of the core existing platforms.\n‚Ä¢ Contribute to publications\n‚Ä¢ Take operational responsibility for the components that you develop.\n\nTechnologies and skills\n‚Ä¢ Pandas\n‚Ä¢ RDBMS\n‚Ä¢ Dask\n‚Ä¢ Anaconda\n‚Ä¢ SQL\n‚Ä¢ Hadoop\n‚Ä¢ NumPy\n‚Ä¢ Apache HTTP Server\n‚Ä¢ Apache Spark\n‚Ä¢ Jupyter (IPython)\n‚Ä¢ Pyspark\n‚Ä¢ MongoDB\n‚Ä¢ NoSQL\n‚Ä¢ Elasticsearch\n‚Ä¢ Cassandra\n‚Ä¢... XML\n‚Ä¢ Docker\n‚Ä¢ Python\n\nOur expectations:\n\nQualifications\n‚Ä¢ Deep understanding of the web scrapping approach, web page structures and techniques to extract information.\n‚Ä¢ Using parallelism in the execution of ETL process, execution based on events.\n‚Ä¢ Using Amazon cloud computing resources like EMR and S3 storage.\n‚Ä¢ Use of Graph Database Neo4j and Cypher query language.\n‚Ä¢ Working in an environment where you constantly experiment and iterate quickly\n\nExperience\n‚Ä¢ Experience using Python as programming language focus on data field (e.g. Anaconda, Jupyter Notebook, Pandas, Dask, PySpark, Numpy, Scikit, others).\n‚Ä¢ Experience with the RDBMS and of SQL query language, database optimizations, indexing, replications.\n‚Ä¢ Experience with NOSQL resources, like ElasticSearch, MongoDB, Apache Cassandra,etc.\n‚Ä¢ Data lake principles and practical experience with big data solutions (e.g. Hadoop, Apache Spark)\n‚Ä¢ Experience with deployment ETL process in Docker containers.\n‚Ä¢ Experience with secure data at transit and rest (encryption) and techniques for clustering and replication implementation.\n\nEducation\n‚Ä¢ MSC - Degree in computer science / software engineering']}]","[{'link': 'https://www.fh-ooe.at/', 'text': 'fh-ooe.at'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=FH+Ober%C3%B6sterreich&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIIlw0', 'text': 'See web results for FH Ober√∂sterreich'}]",,"['‚Ç¨44.8K a year', 'Full-time']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiI2WHJLVXZLYU9uMEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVEcxVlNrMDNWMXBoUTFCV1JqY3pUV3RmV0dwM2VHbEZlRVUwYVcxRmMxWkVVVkEwY1VSTmFGazBSRkZUUjNFM1NUVk5aME5FTVV4TWVFMXZUMkZQYkRSTWMyRkhSbmxKYm01eU0yZFJjR0ZJUkZsclJtazBla00xYkVaaFRYcFRUM1pHTldkTk1HUlFRbDlKV0RNMVgwMTVOM3BZVGpGaWFYRlFTblJUTVZCeVRIRTRhREZCVkdOWlkwMVZNbkppUXpsQlV6azNTakpzYlUxd1RDMXlOR0ZEUjBONFpUVTRRalZrYUhSbWVtdGpFaGM1TjB4SVdrc3RhVTV4ZVVOM1ltdFFlVXRUYTNWQlJSb2lRVXhGVXpsMVRXSXdSM2QxWlZCRU5YaFBialE1Y0dFMVIyaGtSM0pCYzFCNFVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTIiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iL2VlNjQ1M2YwNGRiOGRlYmFiNWU2YWI1M2E5YmFhNzkzP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Big Data DevOps Engineer,Binance,"  Vienna, Austria   ",via Karkidi,"Binance is the global blockchain company behind the world‚Äôs largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.

Are you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?

As the biggest service provider in cryptocurrency exchange technology, we have an immense amount of data; with careful mining, such information helps us build better strategies, optimize our stack, and drive business decisions.

We are looking for a motivated Big Data Engineer that will take ownership of our Big Data Infrastructure. Ideally someone that has experience in dealing with data pumping out from high throughput, low latency mission critical systems. With your strong technical capabilities, you will participate in the architecturing of the infrastructure which is capable of handling the ingress of... such data flow in realtime and hence trigger necessary business action/decision; but also persistence of such data for analytics and business intelligence.

This is a full-time position that can be remote from any location.

Responsibilities
‚Ä¢ Capture expectation from stakeholders and translate it into technical vision and goal
‚Ä¢ Design, deploy and operate the data platform and infrastructure
‚Ä¢ Continuous monitoring and improvement of the data service‚Äôs performance, capability, availability & scalability
‚Ä¢ Response to incidents promptly and identify potential issues
‚Ä¢ Improve oneself and service to the latest technology

Qualifications
‚Ä¢ 3-6+ years of Big Data DevOps experience
‚Ä¢ Familiar with data processing including ETL, ELT, realtime streaming & transformation
‚Ä¢ Familiar with various data structure / messaging format specification
‚Ä¢ Demonstration knowledge of various big data facilities, features and suitability of different use cases
‚Ä¢ Knowledge on common big data components such as Hadoop, Hive, Spark, Spark Streaming, Presto, HBase, ElasticSearch, Kafka, ZooKeeper, Redis, Airflow will be a big plus
‚Ä¢ Solid experience on big data processing, covering data capturing, transformation and data provisioning
‚Ä¢ Good experience in monitoring, optimizing and troubleshooting big data infrastructure
‚Ä¢ Proficient in shell scripting, Python and data query languages
‚Ä¢ Experiences in AWS data services is a plus
‚Ä¢ Strong teamwork, analytical mind, and keep striving for a better solution
‚Ä¢ Dedicated to commitment and quality of delivery

#LI-Remote #LI-EF1

Working at Binance
‚Ä¢ Do something meaningful; Be a part of the future of finance technology and the no.1 company in the industry
‚Ä¢ Fast moving, challenging and unique business problems
‚Ä¢ International work environment and flat organisation
‚Ä¢ Great career development opportunities in a growing company
‚Ä¢ Possibility for relocation and international transfers mid-career
‚Ä¢ Competitive salary
‚Ä¢ Flexible working hours, Casual work attire","[{'items': ['Binance is the global blockchain company behind the world‚Äôs largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\n\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\n\nAs the biggest service provider in cryptocurrency exchange technology, we have an immense amount of data; with careful mining, such information helps us build better strategies, optimize our stack, and drive business decisions.\n\nWe are looking for a motivated Big Data Engineer that will take ownership of our Big Data Infrastructure. Ideally someone that has experience in dealing with data pumping out from high throughput, low latency mission critical systems. With your strong technical capabilities, you will participate in the architecturing of the infrastructure which is capable of handling the ingress of... such data flow in realtime and hence trigger necessary business action/decision; but also persistence of such data for analytics and business intelligence.\n\nThis is a full-time position that can be remote from any location.\n\nResponsibilities\n‚Ä¢ Capture expectation from stakeholders and translate it into technical vision and goal\n‚Ä¢ Design, deploy and operate the data platform and infrastructure\n‚Ä¢ Continuous monitoring and improvement of the data service‚Äôs performance, capability, availability & scalability\n‚Ä¢ Response to incidents promptly and identify potential issues\n‚Ä¢ Improve oneself and service to the latest technology\n\nQualifications\n‚Ä¢ 3-6+ years of Big Data DevOps experience\n‚Ä¢ Familiar with data processing including ETL, ELT, realtime streaming & transformation\n‚Ä¢ Familiar with various data structure / messaging format specification\n‚Ä¢ Demonstration knowledge of various big data facilities, features and suitability of different use cases\n‚Ä¢ Knowledge on common big data components such as Hadoop, Hive, Spark, Spark Streaming, Presto, HBase, ElasticSearch, Kafka, ZooKeeper, Redis, Airflow will be a big plus\n‚Ä¢ Solid experience on big data processing, covering data capturing, transformation and data provisioning\n‚Ä¢ Good experience in monitoring, optimizing and troubleshooting big data infrastructure\n‚Ä¢ Proficient in shell scripting, Python and data query languages\n‚Ä¢ Experiences in AWS data services is a plus\n‚Ä¢ Strong teamwork, analytical mind, and keep striving for a better solution\n‚Ä¢ Dedicated to commitment and quality of delivery\n\n#LI-Remote #LI-EF1\n\nWorking at Binance\n‚Ä¢ Do something meaningful; Be a part of the future of finance technology and the no.1 company in the industry\n‚Ä¢ Fast moving, challenging and unique business problems\n‚Ä¢ International work environment and flat organisation\n‚Ä¢ Great career development opportunities in a growing company\n‚Ä¢ Possibility for relocation and international transfers mid-career\n‚Ä¢ Competitive salary\n‚Ä¢ Flexible working hours, Casual work attire']}]","[{'link': 'https://www.binance.com/', 'text': 'binance.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Binance&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIIyg0', 'text': 'See web results for Binance'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS0DorBj5jLTn6dv5WWLFIMQIiUkL2K4R3TObU2SyI&s,"['‚Ç¨75K‚Äì‚Ç¨120K a year', 'Full-time']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBEZXZPcHMgRW5naW5lZXIiLCJodGlkb2NpZCI6ImdiX1I5emlDU0V3QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTa0ZWTkd0UE5sZHZTM1JzZW14amVXVnVTRGN6UVhnd1YzbDNNR2RQWVRSbFpsOVlXazR5Wm5WRFVrZElaMHd3ZERSMVdsbGtZa1ZpVTNCT01XVjFTR3QzUzBGUGRrVTNlVWN4YmtsaVExQXRWVTE1Tm5vNVJITTBRVkZqTTFkcGJtbE9abUZvWHprdFowNUdVbXhaT0dwWVRYWkpkV05ZVUhGMVIzVnBTVXRoWnpjemVWWTRWRkJWVkRkNGVtUnRUVUpST0haTFptdDRYMTk2TUZaNlJHMWFjM2hpUVVwTE1FbGFZVFpCUjJwWkVoYzVOMHhJV2tzdGFVNXhlVU4zWW10UWVVdFRhM1ZCUlJvaVFVeEZVemwxVDBjd2QyUmllbmd4TlhWaVgzaHZkVE5YTWpjME5HdHlVVTB6WnciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBLYXJraWRpIiwibGluayI6Imh0dHBzOi8vd3d3LmthcmtpZGkuY29tL2pvYi1kZXRhaWxzLzkzNDctYmlnLWRhdGEtZGV2b3BzLWVuZ2luZWVyLWpvYj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer,Toggl, Anywhere ,via Remote Workers,"We are looking for an Analytics Engineer to design, develop, maintain, and troubleshoot SQL data models. The salary for this position is ‚Ç¨62,000 annually. You can work from anywhere in the world as long as your main location is between UTC-4 and UTC+8:00.
About the Team

We are a global team of 130+ awesome people working from over 40 countries around the globe. We hire globally, you work locally‚Äîin the heart of London, a beach outside of S√£o Paulo, or a quiet village near Florence, the choice is yours. Every few months we travel to meet up somewhere in the world and spend some quality time together. We place a huge amount of trust in our people, and we measure the outcomes rather than the work itself. Our values fuel our results.
The role

As an Analytics Engineer, your main responsibilities will be to:
‚Ä¢ Design, develop, maintain, and troubleshoot complex SQL data models in dbt
‚Ä¢ Ensure quality of data sources by writing tests, debugging data inaccuracies and inconsistencies
‚Ä¢... Collaborate with business stakeholders and the analytics team to design and develop end-to-end solutions ‚Äî while balancing business requirements, cost, security, and performance
‚Ä¢ Produce automated reports on top of a data warehouse.
‚Ä¢ Participate in code reviews to promote a high standard of work across the team
‚Ä¢ Develop our internal tools, processes, and workflows to help us deliver more efficiently to business stakeholders
About You
‚Ä¢ You have 2+ years of experience in analytics or a similar role that involves generating insights for business stakeholders, exploring data, SQL data modelling, and statistical analysis.
‚Ä¢ You have 1+ years of hands-on experience with dbt and a modern Data Warehouse like BigQuery or Snowflake.
‚Ä¢ You can extract requirements from even the most complex of business questions. You know how important iterating on analyses is, to stay close to business needs.
‚Ä¢ You have strong instincts and judgment about business implications of data analysis, as you collaborate with business stakeholders at all levels of seniority to understand their data needs.
‚Ä¢ You are comfortable working with git, SQL, python, and dev environments You pride yourself on writing performant, easy-to-read SQL.
‚Ä¢ You know how important QA and building trust in data is.
‚Ä¢ You care about details and have a mature attitude to documentation, security, and process ‚Äî all of which are important and inform everything we do.
‚Ä¢ You have worked in a SaaS, product or e-commerce company before.
‚Ä¢ You write and speak English well. You prefer to over- vs under-communicate. You like transparency, openness, and asking questions.

Bonus points for:
‚Ä¢ Deep experience in one or more business domains (e.g. marketing, product, growth, sales). You understand how to drive value in these domains.
‚Ä¢ Experience with our analytics stack (Prefect, Airbyte, dbt, BigQuery, Looker, Heap, Hex) is ideal. We're open to considering candidates that have experience in other cloud warehouse-focused analytics tools.
Benefits
‚Ä¢ Freedom to choose when and how much you work - we only measure results
‚Ä¢ 24 days of paid time off a year, plus your local holidays
‚Ä¢ In-person meetups for team-building (expenses covered)
‚Ä¢ 4-6 weeks paid sabbatical (depending on the tenure)
‚Ä¢ Laptop budget up to ‚Ç¨2,500 and it renews every 3 years
‚Ä¢ ‚Ç¨2,000 budget to set up your home office, and additional ‚Ç¨300 every year after 3 years of tenure
‚Ä¢ ‚Ç¨250 per month for co-working space membership and/or internet service at home
‚Ä¢ ‚Ç¨4,000 per year contribution to use for training, workshops, and conferences
‚Ä¢ ‚Ç¨2,000 per year contribution for any equipment or services to improve and/or maintain your physical and mental health
‚Ä¢ Support for buying tools you need for doing your best work (even eyeglasses if you need a new pair","[{'items': [""We are looking for an Analytics Engineer to design, develop, maintain, and troubleshoot SQL data models. The salary for this position is ‚Ç¨62,000 annually. You can work from anywhere in the world as long as your main location is between UTC-4 and UTC+8:00.\nAbout the Team\n\nWe are a global team of 130+ awesome people working from over 40 countries around the globe. We hire globally, you work locally‚Äîin the heart of London, a beach outside of S√£o Paulo, or a quiet village near Florence, the choice is yours. Every few months we travel to meet up somewhere in the world and spend some quality time together. We place a huge amount of trust in our people, and we measure the outcomes rather than the work itself. Our values fuel our results.\nThe role\n\nAs an Analytics Engineer, your main responsibilities will be to:\n‚Ä¢ Design, develop, maintain, and troubleshoot complex SQL data models in dbt\n‚Ä¢ Ensure quality of data sources by writing tests, debugging data inaccuracies and inconsistencies\n‚Ä¢... Collaborate with business stakeholders and the analytics team to design and develop end-to-end solutions ‚Äî while balancing business requirements, cost, security, and performance\n‚Ä¢ Produce automated reports on top of a data warehouse.\n‚Ä¢ Participate in code reviews to promote a high standard of work across the team\n‚Ä¢ Develop our internal tools, processes, and workflows to help us deliver more efficiently to business stakeholders\nAbout You\n‚Ä¢ You have 2+ years of experience in analytics or a similar role that involves generating insights for business stakeholders, exploring data, SQL data modelling, and statistical analysis.\n‚Ä¢ You have 1+ years of hands-on experience with dbt and a modern Data Warehouse like BigQuery or Snowflake.\n‚Ä¢ You can extract requirements from even the most complex of business questions. You know how important iterating on analyses is, to stay close to business needs.\n‚Ä¢ You have strong instincts and judgment about business implications of data analysis, as you collaborate with business stakeholders at all levels of seniority to understand their data needs.\n‚Ä¢ You are comfortable working with git, SQL, python, and dev environments You pride yourself on writing performant, easy-to-read SQL.\n‚Ä¢ You know how important QA and building trust in data is.\n‚Ä¢ You care about details and have a mature attitude to documentation, security, and process ‚Äî all of which are important and inform everything we do.\n‚Ä¢ You have worked in a SaaS, product or e-commerce company before.\n‚Ä¢ You write and speak English well. You prefer to over- vs under-communicate. You like transparency, openness, and asking questions.\n\nBonus points for:\n‚Ä¢ Deep experience in one or more business domains (e.g. marketing, product, growth, sales). You understand how to drive value in these domains.\n‚Ä¢ Experience with our analytics stack (Prefect, Airbyte, dbt, BigQuery, Looker, Heap, Hex) is ideal. We're open to considering candidates that have experience in other cloud warehouse-focused analytics tools.\nBenefits\n‚Ä¢ Freedom to choose when and how much you work - we only measure results\n‚Ä¢ 24 days of paid time off a year, plus your local holidays\n‚Ä¢ In-person meetups for team-building (expenses covered)\n‚Ä¢ 4-6 weeks paid sabbatical (depending on the tenure)\n‚Ä¢ Laptop budget up to ‚Ç¨2,500 and it renews every 3 years\n‚Ä¢ ‚Ç¨2,000 budget to set up your home office, and additional ‚Ç¨300 every year after 3 years of tenure\n‚Ä¢ ‚Ç¨250 per month for co-working space membership and/or internet service at home\n‚Ä¢ ‚Ç¨4,000 per year contribution to use for training, workshops, and conferences\n‚Ä¢ ‚Ç¨2,000 per year contribution for any equipment or services to improve and/or maintain your physical and mental health\n‚Ä¢ Support for buying tools you need for doing your best work (even eyeglasses if you need a new pair""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Toggl&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAII_w0', 'text': 'See web results for Toggl'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQQ-maK2Qjzb86cH7dA6GcCjDiR2VzMRNXE1imcEIA&s,"['5 days ago', 'Work from home', 'Full-time', 'No degree mentioned', 'Paid time off']","{'posted_at': '5 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJNSkZSTzJMS19hWUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVMXJNbXhzU2xkWE5tVmhUMkpDTVRBMmNuTlRUMnhYYzNKb1UxcGxTbXBCU1hweFh5MXlTM1ZPVFRsd1NqaDNNVkZhYWs4elMybEVRVTEzYWxCdlZ6QnhhUzF4U0dONVlWRnJSSEptUlcxVGExODFkazFQWVZoVmVUUXRTRGx6VUV4ME1XbzJOMUpCYjBkemNXMXJaeTEwTkRaclYyRnNSVEY1U3pWemFXbDRlVkJoV21SNmQzZFZTVEJ6ZEUxWGRUZEJjSEp5Wm1sTWNIWnRVbEpsVFU5M0VoYzVOMHhJV2tzdGFVNXhlVU4zWW10UWVVdFRhM1ZCUlJvaVFVeEZVemwxVGkwMWNYbFZXbWhZZDNwSFkweG9UVVpPTjBkelUyTjZhWFIzUVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBSZW1vdGUgV29ya2VycyIsImxpbmsiOiJodHRwczovL3JlbW90ZXdvcmtlcnMubmV0L3JlbW90ZS1qb2JzL2RhdGEtc2NpZW5jZS9kYXRhLWVuZ2luZWVyLWF0LXRvZ2dsP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (m/f/d) (377750PA) > Joboolo FR,Siemens,"  Vienna, Austria   ",via Job Search Engine Joboolo.com,"Would you like to shape the intelligent infrastructure ofthe future at one of the world‚Äôs most innovative companies? As part of acompany that uses smart digital solutions to contribute to the most responsibleresource utilization, that ensures a secure supply of drinking water and thatcombats climate change? Do yourpart for a better tomorrow ‚Äì as a Data Engineer (m/f/d) in Vienna.More on theSiemens Business you could be active for:

.The jobDefine datarequirements from IoT sources and other applications.Negotiate interfaces between applications.Design anddeploy data pipelines and other data infrastructure.Monitor,maintain, and update deployed pipelines.Optimizedata tools and help automate data science workflows.Ability totravel globally for this position.Lives andpromotes Siemens Values.Your profileBachelor‚Äôsdegree or master‚Äôs degree in a technical field.Minimum 3years of hands-on experience in working with data at scale.

Clearcommunication skills and ability to define technical... requirements.Comfortablewith a distributed setup and collaboration with data scientists.Programmingin Python (other experience relevant).Very goodknowledge of English and German is an advantageStrong SQLSkills and general database knowledge.API usage, definition, and implementation (REST, GraphQL).Infrastructureas code on AWS.A bonus would be experience with IoT data, sensor timeseries or building data. Additional valued technical skills include ci/cd on gitlab,docker and spark.Your benefitsFlexible working hoursUncomplicated home office rulesOn-sitecanteen Comprehensivecareer development opportunities Open andfamilial corporate structure and moreOur offer The annual gross salary in accordance with the collective agreement amounts toat least EUR .,
- for this function.

Overpayment is possible,depending on qualification and experience.
Siemens
Vienna Vienna","[{'items': ['Would you like to shape the intelligent infrastructure ofthe future at one of the world‚Äôs most innovative companies? As part of acompany that uses smart digital solutions to contribute to the most responsibleresource utilization, that ensures a secure supply of drinking water and thatcombats climate change? Do yourpart for a better tomorrow ‚Äì as a Data Engineer (m/f/d) in Vienna.More on theSiemens Business you could be active for:\n\n.The jobDefine datarequirements from IoT sources and other applications.Negotiate interfaces between applications.Design anddeploy data pipelines and other data infrastructure.Monitor,maintain, and update deployed pipelines.Optimizedata tools and help automate data science workflows.Ability totravel globally for this position.Lives andpromotes Siemens Values.Your profileBachelor‚Äôsdegree or master‚Äôs degree in a technical field.Minimum 3years of hands-on experience in working with data at scale.\n\nClearcommunication skills and ability to define technical... requirements.Comfortablewith a distributed setup and collaboration with data scientists.Programmingin Python (other experience relevant).Very goodknowledge of English and German is an advantageStrong SQLSkills and general database knowledge.API usage, definition, and implementation (REST, GraphQL).Infrastructureas code on AWS.A bonus would be experience with IoT data, sensor timeseries or building data. Additional valued technical skills include ci/cd on gitlab,docker and spark.Your benefitsFlexible working hoursUncomplicated home office rulesOn-sitecanteen Comprehensivecareer development opportunities Open andfamilial corporate structure and moreOur offer The annual gross salary in accordance with the collective agreement amounts toat least EUR .,\n- for this function.\n\nOverpayment is possible,depending on qualification and experience.\nSiemens\nVienna Vienna']}]","[{'link': 'http://www.siemens.com/', 'text': 'siemens.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Siemens&sa=X&ved=0ahUKEwjv-dvUgrmAAxUsQTABHUgSCRc4HhCYkAIItQ4', 'text': 'See web results for Siemens'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTlzAqPnfSVvT8elxQRpX9GAjy-nF5cwNpJGqtcEok&s,"['4 days ago', 'Full-time']","{'posted_at': '4 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkgKDM3Nzc1MFBBKSBcdTAwM2UgSm9ib29sbyBGUiIsImh0aWRvY2lkIjoiUDZ6eFB2OU9seFlBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1RHWk1UbWxUUnpoMVNWSjNiekZGYTBGR1dtMVNNVEo0VFVwV05IZE1ja3BaWVVsVE5sbFBjbXRpTVZsNlNFOUpXbUpaV2kxcVFYWjVlRlZ1WmtOUE56aE5kRlpzVFVWSWRWaG1ObXQ0T1ZaSlpGbE5lRUpVVEhnMU1EWlFTR3R2V0ZOaFptVkpRalo2VWpGS01XdHBablZFVkRWQmJGa3RNVmR1ZEZKS2VITndiemRtYkhWcFMwODRSMDlRTm00d1ppMVJNbGxCVVZZdFFWTXRUMnRGVDJNeU5XeGtOV3g2TmxGME5VaFlja1p6TVdKV2FVTnBNek5xWmkxS2Fta3hYMFExZFZWR0VoYzVOMHhJV2tzdGFVNXhlVU4zWW10UWVVdFRhM1ZCUlJvaVFVeEZVemwxVFhaU1puWTBNVEZUWlZkSFZtVmhaWHBoYkU5b05GZDFXa2Q1WnciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xOCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2IgU2VhcmNoIEVuZ2luZSBKb2Jvb2xvLmNvbSIsImxpbmsiOiJodHRwczovL2pvYm9vbG8uY29tL2F0L2pvYi1EYXRhK0FuYWx5c3QvaW50YXQzMzY1ODQ0P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Architect,Halvik, Anywhere ,via Wellfound,"Halvik is a highly successful company that puts people first, and we are looking for someone just like you. We are committed to delivering smarter IT-driven solutions bolstered by quality and innovation to help our customers succeed. Come be a part of something truly special!

This position will be responsible for serving as the primary data warehouse architect for a data services/visualization platform for a federal agency. The architect will lead the design of data lakes, data warehouses, and visualization services for that data. The architect will work with data/cloud engineers to design data pipelines to ingest, clean and transform both batch and streaming data.

Specific roles inside an AWS environment include: ¬∑ Leading the design of data warehouses, data lakes and datamarts including both the logical and physical models. ¬∑ Assist in soliciting and assessing requirements for the data warehouses/data lakes among data consumers/analysts, visualization specialists, programmers, and... engineers. ¬∑ Optimizing the design and tuning the performance of data warehouses for efficient loading and high performance for data queries.¬∑ Facilitating change control processes for the data model within the repositories including integrating with CI/CD pipelines.¬∑ Designing and implementing a metadata repository to be used for data discovery/catalog services across the enterprise.

Required SkillsBachelor‚Äôs degree and one of these certifications; AWS Cloud Architect Certification or AWS ML Certification or AWS Data Analytics Certification is required.

10+ years of experience to include: Architecting a data lake and/or data warehouse model including defining the use of standard conventions using cloud components (AWS S3, AWS Redshift, AWS Aurora Postgres); Creating logical and physical data models for data repositories containing a number of heterogenous sources; Optimizing data warehouses for high performance for varying types of use cases and Implementing various archiving and partitioning approaches to optimize data ingestion, data storage costs.

Exposure to Amazon Textract or AWS comprehend services. Python, R programming with API integration is desired. Experience with AI/ML or NLP technologies is required if not certified.

Halvik focuses on Information Technology, Information Services, and Software. Their company has offices in Vienna and Vienna. They have a mid-size team that's between 51-200 employees.

You can view their website at http://www.halvik.com/ or find them on LinkedIn","[{'items': [""Halvik is a highly successful company that puts people first, and we are looking for someone just like you. We are committed to delivering smarter IT-driven solutions bolstered by quality and innovation to help our customers succeed. Come be a part of something truly special!\n\nThis position will be responsible for serving as the primary data warehouse architect for a data services/visualization platform for a federal agency. The architect will lead the design of data lakes, data warehouses, and visualization services for that data. The architect will work with data/cloud engineers to design data pipelines to ingest, clean and transform both batch and streaming data.\n\nSpecific roles inside an AWS environment include: ¬∑ Leading the design of data warehouses, data lakes and datamarts including both the logical and physical models. ¬∑ Assist in soliciting and assessing requirements for the data warehouses/data lakes among data consumers/analysts, visualization specialists, programmers, and... engineers. ¬∑ Optimizing the design and tuning the performance of data warehouses for efficient loading and high performance for data queries.¬∑ Facilitating change control processes for the data model within the repositories including integrating with CI/CD pipelines.¬∑ Designing and implementing a metadata repository to be used for data discovery/catalog services across the enterprise.\n\nRequired SkillsBachelor‚Äôs degree and one of these certifications; AWS Cloud Architect Certification or AWS ML Certification or AWS Data Analytics Certification is required.\n\n10+ years of experience to include: Architecting a data lake and/or data warehouse model including defining the use of standard conventions using cloud components (AWS S3, AWS Redshift, AWS Aurora Postgres); Creating logical and physical data models for data repositories containing a number of heterogenous sources; Optimizing data warehouses for high performance for varying types of use cases and Implementing various archiving and partitioning approaches to optimize data ingestion, data storage costs.\n\nExposure to Amazon Textract or AWS comprehend services. Python, R programming with API integration is desired. Experience with AI/ML or NLP technologies is required if not certified.\n\nHalvik focuses on Information Technology, Information Services, and Software. Their company has offices in Vienna and Vienna. They have a mid-size team that's between 51-200 employees.\n\nYou can view their website at http://www.halvik.com/ or find them on LinkedIn""]}]","[{'link': 'https://www.google.com/search?hl=en&q=Halvik&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAII4Qo', 'text': 'See web results for Halvik'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT1EYRvxCZPd3wKNw_qtCTZ_GwahFKszAmpRfIW9Bg&s,"['Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEFyY2hpdGVjdCIsImh0aWRvY2lkIjoia0ZSREptckQ1djBBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVTFyTW14c1NXcDRabGx4Ym5kTGVqTmZWVXRsVm10U2FYQmFUMTh0V21oaU5IcGZRVGxETjNFMVNTMXFOVEZWTmpaYWRtcG1SRkF6UVZOSVYxRXhSR042Y1d0bGNERnJaMWRIYUc5Q1NIZFpNbHBEVjNwbVVXMXdRa2cwUld4TlpERkRVRFkzUTB4dGJsbGpiVkJsVURaNmVsaFROalp2TjJWUVdsVnJSMlJaZFdWVFVrTlhVSFZSVG5SZlZ6Rm5RVmxWTVRWWWFuWXpiRVF4YlRKNlJHZG5FaGN0Y2t4SVdrdERZMGMzZFdWd2RGRlFlazVUWkdkQlJSb2lRVXhGVXpsMVQzQm9kalF5UTNoMVdUUnpNR2R0UjNkSloxbDVaRU5JTUhsalFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiIubkZnMmVie2ZvbnQtd2VpZ2h0OjUwMH0uQmk2RGRje2ZvbnQtd2VpZ2h0OjUwMH1BcHBseSBkaXJlY3RseSBvbiBXZWxsZm91bmQiLCJsaW5rIjoiaHR0cHM6Ly93ZWxsZm91bmQuY29tL2NvbXBhbnkvaGFsdmlrLTEvam9icy8yNzIwOTg1LWRhdGEtYXJjaGl0ZWN0P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer,SMATRICS GmbH & Co Kg,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ Further development of the existing BI landscape at SMATRICS in order to
‚Ä¢ To meet the requirements of internal and external customers with high quality
‚Ä¢ Creation of process and operating procedures for our BI services, so that the reporting
‚Ä¢ Requirements met with high quality and within the agreed time frame
‚Ä¢ can become
‚Ä¢ Support for internal customers / users at SMATRICS so that they can
‚Ä¢ Handle tools and reports correctly
‚Ä¢ The further development of BI skills in coordination with the relevant
‚Ä¢ stakeholders at SMATRICS
‚Ä¢ ÔÇ∑ Data analysis - gaining new insights and connections from the data

Technologies and skills
‚Ä¢ SQL
‚Ä¢ NoSQL
‚Ä¢ Snowflake
‚Ä¢ AWS

Our expectations:

Qualifications
‚Ä¢ Knowledge of the relevant tech stack is an advantage
‚Ä¢ Basic knowledge of cloud systems (AWS an advantage)
‚Ä¢ High result and customer orientation
‚Ä¢ Strong team player & the ability to manage a wide range of people (from IT/BI
‚Ä¢ experts to normal users).
‚Ä¢ High level of... independence and initiative

Experience
‚Ä¢ Proven experience in setting up and managing BI solutions
‚Ä¢ Experience with database systems esp

Education
‚Ä¢ Successfully completed (business) computer science studies, completed IT-related training or relevant professional experience in the field of data analytics, business intelligence, data science

Benefits
‚Ä¢ Meal Vouchers
‚Ä¢ Company Doctor
‚Ä¢ Company Phone for Private Use
‚Ä¢ Employee Discount
‚Ä¢ Educational Leave/Sabbatical
‚Ä¢ * Health Care Benefits
‚Ä¢ Employee Gifts
‚Ä¢ * Company Notebook for Private Use
‚Ä¢ Excellent Traffic Connections
‚Ä¢ *
‚Ä¢ Flexible Working Hours
‚Ä¢ Bicycle Parking Space
‚Ä¢ Fitness Offers
‚Ä¢ * Fresh Fruit
‚Ä¢ Snacks, Sweets
‚Ä¢ Coffee, Tea, etc.
‚Ä¢ Mentor Program","[{'items': ['Your role in the team\n‚Ä¢ Further development of the existing BI landscape at SMATRICS in order to\n‚Ä¢ To meet the requirements of internal and external customers with high quality\n‚Ä¢ Creation of process and operating procedures for our BI services, so that the reporting\n‚Ä¢ Requirements met with high quality and within the agreed time frame\n‚Ä¢ can become\n‚Ä¢ Support for internal customers / users at SMATRICS so that they can\n‚Ä¢ Handle tools and reports correctly\n‚Ä¢ The further development of BI skills in coordination with the relevant\n‚Ä¢ stakeholders at SMATRICS\n‚Ä¢ \uf0b7 Data analysis - gaining new insights and connections from the data\n\nTechnologies and skills\n‚Ä¢ SQL\n‚Ä¢ NoSQL\n‚Ä¢ Snowflake\n‚Ä¢ AWS\n\nOur expectations:\n\nQualifications\n‚Ä¢ Knowledge of the relevant tech stack is an advantage\n‚Ä¢ Basic knowledge of cloud systems (AWS an advantage)\n‚Ä¢ High result and customer orientation\n‚Ä¢ Strong team player & the ability to manage a wide range of people (from IT/BI\n‚Ä¢ experts to normal users).\n‚Ä¢ High level of... independence and initiative\n\nExperience\n‚Ä¢ Proven experience in setting up and managing BI solutions\n‚Ä¢ Experience with database systems esp\n\nEducation\n‚Ä¢ Successfully completed (business) computer science studies, completed IT-related training or relevant professional experience in the field of data analytics, business intelligence, data science\n\nBenefits\n‚Ä¢ Meal Vouchers\n‚Ä¢ Company Doctor\n‚Ä¢ Company Phone for Private Use\n‚Ä¢ Employee Discount\n‚Ä¢ Educational Leave/Sabbatical\n‚Ä¢ * Health Care Benefits\n‚Ä¢ Employee Gifts\n‚Ä¢ * Company Notebook for Private Use\n‚Ä¢ Excellent Traffic Connections\n‚Ä¢ *\n‚Ä¢ Flexible Working Hours\n‚Ä¢ Bicycle Parking Space\n‚Ä¢ Fitness Offers\n‚Ä¢ * Fresh Fruit\n‚Ä¢ Snacks, Sweets\n‚Ä¢ Coffee, Tea, etc.\n‚Ä¢ Mentor Program']}]","[{'link': 'http://smatrics.com/', 'text': 'smatrics.com'}, {'link': 'https://www.google.com/search?hl=en&q=SMATRICS+GmbH+%26+Co+Kg&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIlgs', 'text': 'See web results for SMATRICS GmbH & Co Kg'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS_IXma-OM19G0veF7bhbWxUEEGX76eUVkEcQAvWBY&s,"['‚Ç¨53.2K a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiI4bC1IT3owZDNUb0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzU2xWUFpFdG9lV3gxVm10ZlIxTXdWSE5CWkhJMlpraEhTVWhJTkRVMU9IaE1lRlF3WVZoZlVISkhSMWRyZEhKTWRYY3diWEZ4ZGpCU1N6Y3pRM2gyZEZKdmVrUkdRM2xsYVVGMFgwVldPRGM0V2xoaU1WYzJTVlF3WkhKQ2RtMUpXVkZvZGxKT1IwWm1ZMmgwZG1KblFVTlljMDV0Y21KR1h6QTNlbVZRY1ZaNFh6UlpWMlpxVVVkRWFWbFJNVE4yU2poemJXaFROMnR1ZGpWZkxWWmhiM1ZHVlc5YWNVNW9jMDlFYkhZeVUydEZFaGN0Y2t4SVdrdERZMGMzZFdWd2RGRlFlazVUWkdkQlJSb2lRVXhGVXpsMVQydDJNblZXVTNCUU9UUkxaRWxuV2pKaU9FdFhOM1JETjJGVGR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBERVZqb2JzLmF0IiwibGluayI6Imh0dHBzOi8vZW4uZGV2am9icy5hdC9qb2IvMTQ0NmYxYzcwYjdkMDQ1YjBkM2M5OTE4NGU1Y2Q4ZjA/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Praktikum Data Engineering & Applied Intelligence (all genders),Accenture,"  Vienna, Austria   ",via Accenture,"Du brennst f√ºr Data Engineering, Big Data, Business Intelligence und Machine Learning? Du willst die Theorie deines Studiums mit der Praxis bei Accenture verbinden und bei echten Projekten digitale Gesch√§ftsprozesse unserer Kunden unter die Lupe nehmen? Das ist genau dein Ding?

Dann lebe deine Leidenschaft in einer Position, in der du gemeinsam mit deinem Team Unternehmen dabei unterst√ºtzt aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln und das Potenzial von Automatisierungs-, Analytics- und KI-L√∂sungen voll auszusch√∂pfen.

Diese Position ist in Voll- und Teilzeit m√∂glich. Dar√ºber hinaus bieten wir Arbeitszeitflexibilit√§t und Homeoffice-M√∂glichkeiten an.

Das erwartet dich
‚Ä¢ Genug von der Theorie? Bei uns setzt du deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr Innovation und digitale Gesch√§ftsprozesse zu bilden
‚Ä¢ W√§hle den Bereich, f√ºr den du brennst: Data Engineering, Data Science, Machine... Learning, Big Data, Data Warehouse uvm.
‚Ä¢ Du arbeitest in interdisziplin√§ren Projektteams hautnah beim Kunden vor Ort, unterst√ºtzt bei der Modellierung komplexer Datenmodelle, konzipierst Pr√§sentationen und Workshops und bist bei der Umsetzung live dabei

Diese Position ist in Voll- und Teilzeit m√∂glich. Dar√ºber hinaus bieten wir Arbeitszeitflexibilit√§t und Home-Office M√∂glichkeiten an","[{'items': ['Du brennst f√ºr Data Engineering, Big Data, Business Intelligence und Machine Learning? Du willst die Theorie deines Studiums mit der Praxis bei Accenture verbinden und bei echten Projekten digitale Gesch√§ftsprozesse unserer Kunden unter die Lupe nehmen? Das ist genau dein Ding?\n\nDann lebe deine Leidenschaft in einer Position, in der du gemeinsam mit deinem Team Unternehmen dabei unterst√ºtzt aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln und das Potenzial von Automatisierungs-, Analytics- und KI-L√∂sungen voll auszusch√∂pfen.\n\nDiese Position ist in Voll- und Teilzeit m√∂glich. Dar√ºber hinaus bieten wir Arbeitszeitflexibilit√§t und Homeoffice-M√∂glichkeiten an.\n\nDas erwartet dich\n‚Ä¢ Genug von der Theorie? Bei uns setzt du deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr Innovation und digitale Gesch√§ftsprozesse zu bilden\n‚Ä¢ W√§hle den Bereich, f√ºr den du brennst: Data Engineering, Data Science, Machine... Learning, Big Data, Data Warehouse uvm.\n‚Ä¢ Du arbeitest in interdisziplin√§ren Projektteams hautnah beim Kunden vor Ort, unterst√ºtzt bei der Modellierung komplexer Datenmodelle, konzipierst Pr√§sentationen und Workshops und bist bei der Umsetzung live dabei\n\nDiese Position ist in Voll- und Teilzeit m√∂glich. Dar√ºber hinaus bieten wir Arbeitszeitflexibilit√§t und Home-Office M√∂glichkeiten an']}]","[{'link': 'http://www.accenture.com/', 'text': 'accenture.com'}, {'link': 'https://www.google.com/search?hl=en&q=Accenture&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIyQs', 'text': 'See web results for Accenture'}]",,['Internship'],{'schedule_type': 'Internship'},eyJqb2JfdGl0bGUiOiJQcmFrdGlrdW0gRGF0YSBFbmdpbmVlcmluZyBcdTAwMjYgQXBwbGllZCBJbnRlbGxpZ2VuY2UgKGFsbCBnZW5kZXJzKSIsImh0aWRvY2lkIjoiWkRicjZNUHp0dGNBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXJjQ0N2Y0JRVTFyTW14c1NucGlaM2g0VFV4RGRVdFVWVmhuUVZacldtWjNlSEE0VmxWMVpraDRWRmxIZUhKTlRFUTNURzQwTFVNMFFqQTVkbDk2VDNGSWVWcG1TblZvVkhwaFFVdE1RazV1YUdFM2FHeGxWMVpRTFhORmJFMUpTRVZGZEhCdWVqSndlaTFSUXkxaWVqaDNkM0U0YjI1WmJDMVBORU5IY0UxaldUTTFOMDlUWlhsdFZVZDFTM1I1UzBsNVUwcFlVQzFEVG1RM1pTMWZNbHBpY0dSSVRHOTVYMmxoY2xSUk5qRnViMHg1WWpZNWVVaDJUWGQzZGtzNFpHaDBkMHA0U3psbmRVVXphMkUxVTNaQlEzQk5OUzFMTTJ3Mk5VSmhZVk5mUkVjNGRETlNVR3d3ZFhoWFdtaFZMVlE1VlZOdWFrcEdVRjlwYXhJWExYSk1TRnBMUTJOSE4zVmxjSFJSVUhwT1UyUm5RVVVhSWtGTVJWTTVkVTVFZW01RmVuUkJWSE51Wm1KdlZrWm9WbVZsYWxjemJWRXlkMmMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY180IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEFjY2VudHVyZSIsImxpbmsiOiJodHRwczovL3d3dy5hY2NlbnR1cmUuY29tL2F0LWRlL2NhcmVlcnMvam9iZGV0YWlscz9pZD1SMDAwMDEwNzNfZGVcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Software-Engineer f√ºr Data Analytics und Chatbot Design (all genders),Unisys,"  Vienna, Austria   ",via Unisys Jobs,"We Believe in Better!

We are a global information technology company that builds high-performance, security-centric solutions that can help change the world. Enhancing people‚Äôs lives through secure, reliable advanced technology is our vision.

At Unisys, we believe in better! Here, you have the opportunity to learn new skills, apply your expertise, and solve complex problems with cutting edge technologies and solutions. You are part of a global diverse team that supports you, drives change, and delivers successful results consistently.

Our associates are at the forefront of everything we do, driving our clients‚Äô successes while giving back to communities and making this world a safer and more secure place to live and work. Our success is a direct result of the work of our people who live and breathe our Core Beliefs. Simply put, we believe in better lives. Join us!

Learn more about Unisys and our key solution offerings: Unisys, Stealth‚Ñ¢, CloudForte¬Æ, InteliServe‚Ñ¢

What success... looks like in this role:

Wir bieten Ihnen eine abwechslungsreiche Aufgabenfeld in IT-Projekten, in denen Sie in einem Team gemeinsam mit dem Kunden komplexe L√∂sungen im Bereich ChatBot Design erarbeiten und umsetzen werden.
‚Ä¢ Selbstst√§ndige und eigenverantwortliche Analyse von Anforderungen aus den Fachabteilungen und Gesch√§ftsprozessen von Kunden aus dem √∂ffentlichen Bereich
‚Ä¢ Erarbeitung von funktionalen Spezifikationen zur Abbildung der Anforderungen in den Systemen und Prozessen des Kunden
‚Ä¢ Abstimmung des L√∂sungsdesigns mit den Architekten der betroffenen Systeme und Unterst√ºtzung bei der Umsetzung

You will be successful in this role if you have:
‚Ä¢ Abgeschlossene technische Ausbildung (HTL, FH, TU) im Bereich Informatik oder Wirtschaftsinformatik
‚Ä¢ (mehrj√§hrige) Praxis-/Projekterfahrung im Bereich Requirements Management und IT-Analyse/-Design
‚Ä¢ Mehrj√§hrige Berufs- und Projekterfahrung im Bereich der √∂ffentlichen Verwaltung (bevorzugt) oder im Bereich Telekommunikation, Banken
‚Ä¢ Ausbildung/Praxiserfahrung im Bereich Agile SW-Entwicklung/SCRUM
‚Ä¢ Erfahrungen im Bereich der Analyse und Implementierung von ChatBots
‚Ä¢ Optional: Erfahrung mit PowerBI, SparkR, PySpark, YARN, Solr, PyTorch
‚Ä¢ Kenntnisse im Bereich SW-Engineering (z.B.: Java / Javascript, Eclipse, Python (scikit-learn, keras, pytorch), R)
‚Ä¢ Datenbank Kenntnisse (z.B. MySQL, Oracle, SQL-Server)
‚Ä¢ Sprachen: Deutsch und Englisch in Wort und Schrift","[{'items': ['We Believe in Better!\n\nWe are a global information technology company that builds high-performance, security-centric solutions that can help change the world. Enhancing people‚Äôs lives through secure, reliable advanced technology is our vision.\n\nAt Unisys, we believe in better! Here, you have the opportunity to learn new skills, apply your expertise, and solve complex problems with cutting edge technologies and solutions. You are part of a global diverse team that supports you, drives change, and delivers successful results consistently.\n\nOur associates are at the forefront of everything we do, driving our clients‚Äô successes while giving back to communities and making this world a safer and more secure place to live and work. Our success is a direct result of the work of our people who live and breathe our Core Beliefs. Simply put, we believe in better lives. Join us!\n\nLearn more about Unisys and our key solution offerings: Unisys, Stealth‚Ñ¢, CloudForte¬Æ, InteliServe‚Ñ¢\n\nWhat success... looks like in this role:\n\nWir bieten Ihnen eine abwechslungsreiche Aufgabenfeld in IT-Projekten, in denen Sie in einem Team gemeinsam mit dem Kunden komplexe L√∂sungen im Bereich ChatBot Design erarbeiten und umsetzen werden.\n‚Ä¢ Selbstst√§ndige und eigenverantwortliche Analyse von Anforderungen aus den Fachabteilungen und Gesch√§ftsprozessen von Kunden aus dem √∂ffentlichen Bereich\n‚Ä¢ Erarbeitung von funktionalen Spezifikationen zur Abbildung der Anforderungen in den Systemen und Prozessen des Kunden\n‚Ä¢ Abstimmung des L√∂sungsdesigns mit den Architekten der betroffenen Systeme und Unterst√ºtzung bei der Umsetzung\n\nYou will be successful in this role if you have:\n‚Ä¢ Abgeschlossene technische Ausbildung (HTL, FH, TU) im Bereich Informatik oder Wirtschaftsinformatik\n‚Ä¢ (mehrj√§hrige) Praxis-/Projekterfahrung im Bereich Requirements Management und IT-Analyse/-Design\n‚Ä¢ Mehrj√§hrige Berufs- und Projekterfahrung im Bereich der √∂ffentlichen Verwaltung (bevorzugt) oder im Bereich Telekommunikation, Banken\n‚Ä¢ Ausbildung/Praxiserfahrung im Bereich Agile SW-Entwicklung/SCRUM\n‚Ä¢ Erfahrungen im Bereich der Analyse und Implementierung von ChatBots\n‚Ä¢ Optional: Erfahrung mit PowerBI, SparkR, PySpark, YARN, Solr, PyTorch\n‚Ä¢ Kenntnisse im Bereich SW-Engineering (z.B.: Java / Javascript, Eclipse, Python (scikit-learn, keras, pytorch), R)\n‚Ä¢ Datenbank Kenntnisse (z.B. MySQL, Oracle, SQL-Server)\n‚Ä¢ Sprachen: Deutsch und Englisch in Wort und Schrift']}]","[{'link': 'http://www.unisys.com/', 'text': 'unisys.com'}, {'link': 'https://www.google.com/search?hl=en&q=Unisys&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAII-ws', 'text': 'See web results for Unisys'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR9RyElVP39XOtfzbn-mm8GPbICWcspli9TbGruLqA&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTb2Z0d2FyZS1FbmdpbmVlciBmw7xyIERhdGEgQW5hbHl0aWNzIHVuZCBDaGF0Ym90IERlc2lnbiAoYWxsIGdlbmRlcnMpIiwiaHRpZG9jaWQiOiJFNUNwd3ROdmd0WUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcmNDQ3ZjQlFVMXJNbXhzUzFJeVMxVTJlamhETkVSQk5HNDBka0paY2tSZlRXRXlabEpQYlRGTVIyMU5NRlYyZUhremNHMXVjMUZxZEVSUVdWQTJhMkptVUhkRmVFWXhOREJ2Y0U1d1JGSnRYMjkzY1Y5QlZtbDZWVEJSVmxkbk5WaHdYeTB0TWs1cmRVbHBkV3BPTkZkMlZtTkdjR1l3YUhSWlNIQmlMVEJQYUhoME5uZFFXbmxRV0hONWQxZzBkM1E1ZVU1SGNtcENkMnRqUzFaVFVGQlRaekJNYTJ0UFIycExjVll5WkU5c1JHUjVWbmh2Wm5WWGNrSkJkMUp4YzBsSFlrWnRTR1pqYTJ0QlJsQjRhVzE1YUdWcE5qVk5WVzVPTUZwWU1VZDBOVlU0TkVrMGVVOVhkRnBzYjJkb1EyeERlalpXU1VWWFRXbHVXUklYTFhKTVNGcExRMk5ITjNWbGNIUlJVSHBPVTJSblFVVWFJa0ZNUlZNNWRVMW1ZbVExVEZkVlIyeDRkMHhwUTFCVGExSndUM2xWVDJkU2FtYyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzYiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gVW5pc3lzIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9qb2JzLnVuaXN5cy5jb20vdXMvZW4vam9iL1JFUTUzNTU4MS9Tb2Z0d2FyZS1FbmdpbmVlci1mJUMzJUJDci1EYXRhLUFuYWx5dGljcy11bmQtQ2hhdGJvdC1EZXNpZ24tYWxsLWdlbmRlcnM/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,Maharishi Foundation International, Anywhere ,via Remote Workers,"JOB SUMMARY

As a Data Engineer at MFI, you will play a crucial role in leveraging data to drive product discovery, development, and strategy. You will be responsible for identifying and answering key questions, generating actionable insights, and ensuring data-informed decision making. Working in a fully remote team of over 50 individuals, you will collaborate with product management and engineering teams to align tracking requirements and forecast the impact of potential new features. Effective communication and the ability to translate business requirements into actionable metrics and analyses will be essential to your success.
ABOUT US

Maharishi Foundation International (MFI) is a US-registered non-profit that supports the development of new technologies and outreach opportunities for the worldwide Transcendental Meditation¬Æ (TM¬Æ) organisations. Over the past 60 years, more than 10 million people worldwide have learned the TM technique through personal instruction by tens of... thousands of certified teachers.

MFI is a growing, fully remote team of over 50 people, located around the globe but mainly in North America and Europe. As an organisation we are committed to leveraging modern technology and progressive management practices to make the TM technique and its related programmes more available to people everywhere.

We favor a healthy and balanced work environment with opportunities for personal development.
ABOUT YOU

As the ideal candidate for the Data Engineer role at Maharishi Foundation International, you possess a unique set of skills and qualities that make you a valuable addition to our team. Here's what we're looking for:
‚Ä¢ Data Enthusiast: You have a genuine love for working with data, and you find joy in uncovering valuable insights and patterns. You have a keen eye for detail and are dedicated to ensuring data accuracy and integrity.
‚Ä¢ Customer-Focused Mindset: You are passionate about helping our product teams provide exceptional value to our customers. You understand that data-driven insights play a crucial role in delivering the best user experience and are motivated by contributing to customer satisfaction and success.
‚Ä¢ Collaborative Team Player : You thrive in a collaborative environment and enjoy working closely with cross-functional teams. You understand that great results come from the collective efforts of talented individuals working together towards a common goal. Your collaborative nature enables you to effectively partner with product management, engineering, and marketing teams.
‚Ä¢ Analytical Thinker: You possess strong analytical thinking skills, allowing you to dissect complex problems and provide data-driven solutions. You enjoy diving deep into data, performing statistical analyses, and employing critical thinking to extract meaningful insights.
‚Ä¢ Adaptability: You are comfortable working in a dynamic and fast-paced environment. You can quickly adapt to new technologies, tools, and methodologies to ensure efficient and effective data engineering practices. Your agility allows you to handle multiple tasks and priorities without compromising quality.
‚Ä¢ Passion for Continuous Learning: You have a growth mindset and a genuine curiosity to stay updated with the latest advancements in data engineering. You actively seek opportunities to expand your knowledge and skills, whether it's learning new programming languages, exploring emerging technologies, or staying abreast of industry trends.
‚Ä¢ Mission Alignment: You resonate with the mission of Maharishi Foundation International and are motivated to contribute to its achievement. You understand the transformative power of Transcendental Meditation¬Æ and are excited to be part of an organization that leverages data and technology to make it more accessible to people worldwide.

If you embody these qualities and are ready to join a diverse and collaborative team dedicated to leveraging data for positive change, we encourage you to apply for the Data Engineer role at Maharishi Foundation International. Together, we can make a difference in the lives of millions by harnessing the power of data and technology.
RESPONSIBILITIES
‚Ä¢ Utilize data to identify, prioritize, and answer questions critical to the product discovery and development process.
‚Ä¢ Conduct exploratory data analyses to generate actionable insights that shape our product strategy.
‚Ä¢ Define, implement, and monitor key metrics in dashboards to ensure data-informed decision making.
‚Ä¢ Support the planning process by forecasting the impact of potential new features.
‚Ä¢ Collaborate with product management and engineering teams to align tracking requirements.
‚Ä¢ Effectively communicate relevant insights to motivate the product team.
‚Ä¢ Build and maintain AWS ETL data pipelines with a minimum of 2 years of experience.
‚Ä¢ Connect to APIs and services to gather and integrate data effectively.
‚Ä¢ Demonstrate a basic understanding of different databases and data schema architecture in larger environments.

SKILLS AND REQUIREMENTS
‚Ä¢ 5 years of experience in a data analytics role.
‚Ä¢ Strong proficiency in SQL.
‚Ä¢ 3+ years of experience with at least one statistical programming language (R or Python are a plus).
‚Ä¢ Strong analytical thinking and product management knowledge.
‚Ä¢ Experience with A/B testing and its statistical foundations.
‚Ä¢ Strong knowledge of descriptive statistics and intermediate knowledge of inferential statistics.
‚Ä¢ 3+ years of work experience in a digital product company.
‚Ä¢ Experience working in a global non-profit, working with a remote team or in a multinational organization preferred
‚Ä¢ Fluency in English (written and verbal)

Desired Skills:
‚Ä¢ Proficiency in data visualization tools such as Quicksight, Looker Studio, Tableau, Power BI, or similar platforms.
‚Ä¢ Understanding of marketing concepts, consumer behavior, and customer journey mapping.
‚Ä¢ Experience with digital marketing platforms (e.g., Google Ads, Facebook Ads, email marketing tools) and analytics.
‚Ä¢ Familiarity with marketing automation tools and workflows.

If you are passionate about this work but do not have all of the skills listed we are still interested in speaking with you and encourage you to apply!
PAY AND BENEFITS

Our pay levels are set according to a formula that combines above-median market rate data for the role (we pay 55th percentile of New York market rate for this role, based on Payscale data) adjusted for your local cost of living based on Numbeo data.

We take the issue of equitable pay very seriously, and we apply our pay formula to all workers who work 80% or more of full time hours with us.
DIVERSITY AND INCLUSION

We care about diversity - we strive to ensure all of our team feel included and can bring their whole selves to work but we also know that this work is never ‚Äòdone‚Äô or complete, and that we can always improve.

Our team is fully remote, living and working across 20 countries across the world, and we‚Äôd love to hear how you can add to our special culture at MFI","[{'items': [""JOB SUMMARY\n\nAs a Data Engineer at MFI, you will play a crucial role in leveraging data to drive product discovery, development, and strategy. You will be responsible for identifying and answering key questions, generating actionable insights, and ensuring data-informed decision making. Working in a fully remote team of over 50 individuals, you will collaborate with product management and engineering teams to align tracking requirements and forecast the impact of potential new features. Effective communication and the ability to translate business requirements into actionable metrics and analyses will be essential to your success.\nABOUT US\n\nMaharishi Foundation International (MFI) is a US-registered non-profit that supports the development of new technologies and outreach opportunities for the worldwide Transcendental Meditation¬Æ (TM¬Æ) organisations. Over the past 60 years, more than 10 million people worldwide have learned the TM technique through personal instruction by tens of... thousands of certified teachers.\n\nMFI is a growing, fully remote team of over 50 people, located around the globe but mainly in North America and Europe. As an organisation we are committed to leveraging modern technology and progressive management practices to make the TM technique and its related programmes more available to people everywhere.\n\nWe favor a healthy and balanced work environment with opportunities for personal development.\nABOUT YOU\n\nAs the ideal candidate for the Data Engineer role at Maharishi Foundation International, you possess a unique set of skills and qualities that make you a valuable addition to our team. Here's what we're looking for:\n‚Ä¢ Data Enthusiast: You have a genuine love for working with data, and you find joy in uncovering valuable insights and patterns. You have a keen eye for detail and are dedicated to ensuring data accuracy and integrity.\n‚Ä¢ Customer-Focused Mindset: You are passionate about helping our product teams provide exceptional value to our customers. You understand that data-driven insights play a crucial role in delivering the best user experience and are motivated by contributing to customer satisfaction and success.\n‚Ä¢ Collaborative Team Player : You thrive in a collaborative environment and enjoy working closely with cross-functional teams. You understand that great results come from the collective efforts of talented individuals working together towards a common goal. Your collaborative nature enables you to effectively partner with product management, engineering, and marketing teams.\n‚Ä¢ Analytical Thinker: You possess strong analytical thinking skills, allowing you to dissect complex problems and provide data-driven solutions. You enjoy diving deep into data, performing statistical analyses, and employing critical thinking to extract meaningful insights.\n‚Ä¢ Adaptability: You are comfortable working in a dynamic and fast-paced environment. You can quickly adapt to new technologies, tools, and methodologies to ensure efficient and effective data engineering practices. Your agility allows you to handle multiple tasks and priorities without compromising quality.\n‚Ä¢ Passion for Continuous Learning: You have a growth mindset and a genuine curiosity to stay updated with the latest advancements in data engineering. You actively seek opportunities to expand your knowledge and skills, whether it's learning new programming languages, exploring emerging technologies, or staying abreast of industry trends.\n‚Ä¢ Mission Alignment: You resonate with the mission of Maharishi Foundation International and are motivated to contribute to its achievement. You understand the transformative power of Transcendental Meditation¬Æ and are excited to be part of an organization that leverages data and technology to make it more accessible to people worldwide.\n\nIf you embody these qualities and are ready to join a diverse and collaborative team dedicated to leveraging data for positive change, we encourage you to apply for the Data Engineer role at Maharishi Foundation International. Together, we can make a difference in the lives of millions by harnessing the power of data and technology.\nRESPONSIBILITIES\n‚Ä¢ Utilize data to identify, prioritize, and answer questions critical to the product discovery and development process.\n‚Ä¢ Conduct exploratory data analyses to generate actionable insights that shape our product strategy.\n‚Ä¢ Define, implement, and monitor key metrics in dashboards to ensure data-informed decision making.\n‚Ä¢ Support the planning process by forecasting the impact of potential new features.\n‚Ä¢ Collaborate with product management and engineering teams to align tracking requirements.\n‚Ä¢ Effectively communicate relevant insights to motivate the product team.\n‚Ä¢ Build and maintain AWS ETL data pipelines with a minimum of 2 years of experience.\n‚Ä¢ Connect to APIs and services to gather and integrate data effectively.\n‚Ä¢ Demonstrate a basic understanding of different databases and data schema architecture in larger environments.\n\nSKILLS AND REQUIREMENTS\n‚Ä¢ 5 years of experience in a data analytics role.\n‚Ä¢ Strong proficiency in SQL.\n‚Ä¢ 3+ years of experience with at least one statistical programming language (R or Python are a plus).\n‚Ä¢ Strong analytical thinking and product management knowledge.\n‚Ä¢ Experience with A/B testing and its statistical foundations.\n‚Ä¢ Strong knowledge of descriptive statistics and intermediate knowledge of inferential statistics.\n‚Ä¢ 3+ years of work experience in a digital product company.\n‚Ä¢ Experience working in a global non-profit, working with a remote team or in a multinational organization preferred\n‚Ä¢ Fluency in English (written and verbal)\n\nDesired Skills:\n‚Ä¢ Proficiency in data visualization tools such as Quicksight, Looker Studio, Tableau, Power BI, or similar platforms.\n‚Ä¢ Understanding of marketing concepts, consumer behavior, and customer journey mapping.\n‚Ä¢ Experience with digital marketing platforms (e.g., Google Ads, Facebook Ads, email marketing tools) and analytics.\n‚Ä¢ Familiarity with marketing automation tools and workflows.\n\nIf you are passionate about this work but do not have all of the skills listed we are still interested in speaking with you and encourage you to apply!\nPAY AND BENEFITS\n\nOur pay levels are set according to a formula that combines above-median market rate data for the role (we pay 55th percentile of New York market rate for this role, based on Payscale data) adjusted for your local cost of living based on Numbeo data.\n\nWe take the issue of equitable pay very seriously, and we apply our pay formula to all workers who work 80% or more of full time hours with us.\nDIVERSITY AND INCLUSION\n\nWe care about diversity - we strive to ensure all of our team feel included and can bring their whole selves to work but we also know that this work is never ‚Äòdone‚Äô or complete, and that we can always improve.\n\nOur team is fully remote, living and working across 20 countries across the world, and we‚Äôd love to hear how you can add to our special culture at MFI""]}]","[{'link': 'https://www.google.com/search?hl=en&q=Maharishi+Foundation+International&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIrgw', 'text': 'See web results for Maharishi Foundation International'}]",,"['5 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '5 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJ4RmVQNzM2RTNPUUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzUzI5Sk5WcHhSbHB6WW5oaFJFUjFUelJoVUd0ZmJtNVlWbGR0UzBjMlR6VjRhMFkyVUVSeGFraGlkRFp5YWxaS2VURTROblJmYzB0T09XeDNVV2gwU21kaVEyUnhkRlExVVZSeVkwbEZlR3QwY21SWWFsRjJjRWRUZEhSU1UyeFRlVkpJWDBwd2QyWmhUMnhDTUhaRGVFbGpTMVZaTUcxRlgwc3lNa2hwV1c1S2VHY3pWVFpuYzI1NVMxUlpWVGhYWm1sNlNETkdhMlZLZGtsRmNtTmpWWEJ5YUVkak1YWnZXRWhhV1ZoNGVteHZFaGN0Y2t4SVdrdERZMGMzZFdWd2RGRlFlazVUWkdkQlJSb2lRVXhGVXpsMVRWaFdVRUYyTWpaYUxUQTJZMnBVUlZOTGNVOTZXbWRSTFVzMmR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBSZW1vdGUgV29ya2VycyIsImxpbmsiOiJodHRwczovL3JlbW90ZXdvcmtlcnMubmV0L3JlbW90ZS1qb2JzL2RhdGEtc2NpZW5jZS9kYXRhLWVuZ2luZWVyLWF0LW1haGFyaXNoaS1mb3VuZGF0aW9uLWludGVybmF0aW9uYWw/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (w/m/x),APC Business Services GmbH,"  Vienna, Austria   ",via Jooble,"Data Engineer (w/m/x)
Business Intelligence & Data Science Wien , Vienna 5332 Jul 6, 2023 Freelancer

Our client, a global player in transportation, is seeking an experienced and driven Data Engineer (m/w/x) to join the team in Vienna.
Responsibilities & Skills

Strong skills in data integration and data gathering methodologies

Experience with Public Cloud services and service-oriented architecture

Understanding of ETL/ELT infrastructures and cloud architectures

Expertise in big data and event streaming architecture , streaming, implementation and maintenance

Expertise in creating data pipelines, working with various messaging systems (Kafka, Pub/Sub), using SWL to create and query tables as well as creaking spark streaming jobs

strong problem-solving and troubleshooting skills

Working proficiency in Englisch

Join a dynamic and innovative team, and contribute to the growth and success of a global transportation company. A competitive compensation, opportunities for professional... development, and a stimulating work environment is offered. Apply now and be part of a data-driven journey!
Facts

Start: End of August 2023
Place of work: 1030 Vienna
Scope of work: 100 % - Vienna/ remote 20/80 %
Language: working language English, German advantageous
Duration: short term (31.12.2023), with an option to extend
JobID: 5332
APC - A Perfect Choice","[{'items': ['Data Engineer (w/m/x)\nBusiness Intelligence & Data Science Wien , Vienna 5332 Jul 6, 2023 Freelancer\n\nOur client, a global player in transportation, is seeking an experienced and driven Data Engineer (m/w/x) to join the team in Vienna.\nResponsibilities & Skills\n\nStrong skills in data integration and data gathering methodologies\n\nExperience with Public Cloud services and service-oriented architecture\n\nUnderstanding of ETL/ELT infrastructures and cloud architectures\n\nExpertise in big data and event streaming architecture , streaming, implementation and maintenance\n\nExpertise in creating data pipelines, working with various messaging systems (Kafka, Pub/Sub), using SWL to create and query tables as well as creaking spark streaming jobs\n\nstrong problem-solving and troubleshooting skills\n\nWorking proficiency in Englisch\n\nJoin a dynamic and innovative team, and contribute to the growth and success of a global transportation company. A competitive compensation, opportunities for professional... development, and a stimulating work environment is offered. Apply now and be part of a data-driven journey!\nFacts\n\nStart: End of August 2023\nPlace of work: 1030 Vienna\nScope of work: 100 % - Vienna/ remote 20/80 %\nLanguage: working language English, German advantageous\nDuration: short term (31.12.2023), with an option to extend\nJobID: 5332\nAPC - A Perfect Choice']}]","[{'link': 'https://www.google.com/search?hl=en&q=APC+Business+Services+GmbH&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAII4ww', 'text': 'See web results for APC Business Services GmbH'}]",,"['8 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '8 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyICh3L20veCkiLCJodGlkb2NpZCI6IjNLVm9lS04zQkVFQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTMHBoVkdoRk9YRlVTbkU0Y1RJNU9VMVJWbWRtU1hBMFJYVm5hMGQ2Y0RGVlgyNXpjR1I2VUc5NmMybFlTVkJaVFVaNlFWcERaVVpIVERSVFJIRlZWM1pIWVRWeFJqTmxZM1JPYVdGaWVVOUpSV3BoZURsdmVVNVFWRVJDVDJOdFMzQjViamhGZDI1dFVtZFNSMDVZVEVZMFNqaE1TWEJ6VmpOWGJVbzFiSEpZZGt4aVVuZDBhV2REUWpKM2NETm1jbE0xWnpnMVpFMXlUbkJSU1hoaU9FaExiMnQwVkVwTFRrbG9RMUJKU0ZkamNXTkNSRWN0WVVkNE5WSXRRa3hRVG1STk9TMXdFaGN0Y2t4SVdrdERZMGMzZFdWd2RGRlFlazVUWkdkQlJSb2lRVXhGVXpsMVRsTjJSM0IzUVZObVVFSklTRlUyTFdwcVVIcHBkMUpJYjFGalFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb29ibGUiLCJsaW5rIjoiaHR0cHM6Ly9hdC5qb29ibGUub3JnL2pkcC8tODQ0MDgzODE5Mjc1NjE3MzQ1NS9EYXRhLUVuZ2luZWVyLSh3JTJGbSUyRngpLVdpZW4/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
"Legal Engineer: Product Manager, Data Protection Specialist...",Prighter, Anywhere ,via Prighter,"We are a high growth company offering privacy related services and develop our inhouse legaltech products form the cases we handle as a law firm. We just expanded to the UK and are looking for a Legal Engineer (Product Manager, Data Protection Specialist, national and international Business Developer). Ad your skills and experiences to our team and become an integral part of our adventure!

Please view the [Job Description Document](https://prighter.com/static/documents/210725_Legal_Hire_JD_UK.pdf) to learn more about the Job.
‚Ä¢ *If you‚Äôre interested in this opportunity, or want to learn more about it, please reach out directly to [jobs@prighter.com](mailto:jobs@prighter.com) with your CV and a sample of your previous projects.**","[{'items': ['We are a high growth company offering privacy related services and develop our inhouse legaltech products form the cases we handle as a law firm. We just expanded to the UK and are looking for a Legal Engineer (Product Manager, Data Protection Specialist, national and international Business Developer). Ad your skills and experiences to our team and become an integral part of our adventure!\n\nPlease view the [Job Description Document](https://prighter.com/static/documents/210725_Legal_Hire_JD_UK.pdf) to learn more about the Job.\n‚Ä¢ *If you‚Äôre interested in this opportunity, or want to learn more about it, please reach out directly to [jobs@prighter.com](mailto:jobs@prighter.com) with your CV and a sample of your previous projects.**']}]","[{'link': 'https://www.google.com/search?hl=en&q=Prighter&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIlQ0', 'text': 'See web results for Prighter'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT184Qkr3Nn7ImawuKzmtM_FdIiG1FWIBu5aT2Otb7kcou7823_yAr-&s,"['¬£30K‚Äì¬£105K a year', 'Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJMZWdhbCBFbmdpbmVlcjogUHJvZHVjdCBNYW5hZ2VyLCBEYXRhIFByb3RlY3Rpb24gU3BlY2lhbGlzdCwgbmF0aW9uYWwgYW5kIGludGVybmF0aW9uYWwgQnVzaW5lc3MgRGV2ZWxvcGVyIChmdWxsIHRpbWUpIiwiaHRpZG9jaWQiOiJBcEpzblJnN3U1RUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNDQ3JjQ1FVMXJNbXhzUzJGVFRFSkdVMnhKVjJRME0zZHBRbU5rTXpNMFlUWkdiSFZqV2xsbE5HRjBhMGRzYVVwSlExWk9TVGR5Vmt0RVlWOW9ZUzB3VGtrMmQzWmFjQzFITUZOZmVrVXlORk5TTldWUlFWWXliV2hZV1d0MmRuTkVlbkYzZVVoMVZHcFdjWFJ6UVVwM1ZXRnNVSFk1YVZwMU5ISnRaVk5pYjBSelJYSTJSWEJ1ZGxGb1RTMWxXWEZuVFRaeFZETlFZMkZHWmt4MFVrOTJXa0YwVTFOcmRtaHpjWFkzYUhkNGEzaGZWM0ZtYmxJeE1teHNOa05rTkhwa1NHbFFVMDFrYTJwM1RHNXJSWEZ1VERGV1V6RXRjSEYzTVVWWFNYWnZYMnc1TmxwMVgyUjVRMWhoWlhWak5UZFFiM2d0VjFWUFlVaERibTFGTkdGVldtUlRZVTl1VWw5RWNtcDVlVGQ1UWw5Q1ZsUmljR2xHUWxwTE9FRXpjMGgwYjBWS1oyTXRkRnBRWVZOeFluZGlSRVZxWkdRMlVXRXRWVEFTRnkxeVRFaGFTME5qUnpkMVpYQjBVVkI2VGxOa1owRkZHaUpCVEVWVE9YVlFjVVZQZVdWM2QzbGhPRkpmWlhGVWVuSlFZbXAyYlZoS1RUQjMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBQcmlnaHRlciIsImxpbmsiOiJodHRwczovL3ByaWdodGVyLmNvbS9jb21wYW55L2NhcmVlcnMvbGVnYWwtZW5naW5lZXItcHJvZHVjdC1tYW5hZ2VyLWRhdGEtcHJvdGVjdGlvbi1zcGVjaWFsaXN0LW5hdGlvbmFsLWFuZC1pbnRlcm5hdGlvbmFsLWJ1c2luZXNzLWRldmVsb3Blci1mdWxsLXRpbWUvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer /m/f/d/ - Immediate Start,Berger Logistik,"  Vienna, Austria   ",via GrabJobs,"We are hiring a resilient Senior Data Engineer (m/f/d) to join our amazing team at Berger Logistik in W√∂rgl.
Growing your career as a Full Time Senior Data Engineer (m/f/d) is an exceptional opportunity to develop competitive skills.
If you are strong in critical thinking, attention to detail and have the right determination for the job, then apply for the position of Senior Data Engineer (m/f/d) at Berger Logistik today!

Berger Logistik GmbH is part of a group of companies in the field of logistics and vehicle technology. As an established medium-sized company based in Tyrol and several locations in Austria, we focus on high-quality, tailor-made logistics products and industry solutions with a European and global orientation for all modes of transport (road, ocean, rail, and air): with excellent service, excellent know-how and our own, highly modern, and ecologically payload-optimized truck fleet.

We are currently looking for a committed and experienced person to start immediately... at our location in W√∂rgl, Tyrol or remotely:

Senior Data Engineer (m/f/d)

Your tasks and priorities
‚Ä¢ Managing Datawarehouse operations
‚Ä¢ Building data processing pipelines and defining data architectures
‚Ä¢ Leveraging the automation of standard tasks, allowing more time to focus on creative ones
‚Ä¢ Working with an agile team and contributing to the continuous improvement of the teams‚Äô skills and practices

Your profile
‚Ä¢ Experience working with various databases (SQL and NoSQL)
‚Ä¢ Experience in programming and a demonstrable ability to learn new programming languages (There is no strict requirement on the knowledge of any particular language. Commonly used languages include Python, C#, PowerShell and various dialects and procedural extensions of SQL.)
‚Ä¢ Understanding of modern cloud-based data architecture and cloud services, preferably with Microsoft Azure
‚Ä¢ Willingness to take on technical challenges
‚Ä¢ Committed to self-learning, knowledge sharing and teamwork
‚Ä¢ Strong focus on stakeholders and quality
‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand different technical ecosystems and data, as well as an ability to communicate complex technical problems and their solutions clearly
‚Ä¢ English and German proficiency (German less important for candidates with excellent technical skills)

Nice to Have
‚Ä¢ Experience working with data analysts and a good understanding of their needs
‚Ä¢ Knowledge of a reporting frontend
‚Ä¢ Knowledge of a web frontend programming language (JavaScript, React, Angular‚Ä¶)
‚Ä¢ Working with APIs
‚Ä¢ Knowledge of Graph DBS

Our offer
‚Ä¢ Supportive, motivated, and dynamic team
‚Ä¢ Flexible working time and location arrangements (within EU)
‚Ä¢ Exciting tasks, technical challenges, and development opportunities
‚Ä¢ Flat hierarchies, direct and uncomplicated communication
‚Ä¢ Current Microsoft Cloud Technology Stack, constantly improved by the team
‚Ä¢ State-of-the-art IT and communications equipment
‚Ä¢ Mobility package (‚ÄòKlimaTicket Tyrol‚Äô for public transport, bike leasing)
‚Ä¢ Additional company benefits such as childcare facilities at company headquarters, training and further education opportunities, electric cars & e-bikes for personal errands, company events

We will determine classification and salary based on your professional and personal competence in line with the market. For this position the salary consists of EUR 75,000.00/year. With appropriate qualifications and professional experience, there is willingness to significantly overpay. Have we piqued your interest, and would you like to become part of our team? Then please send your application to:

Berger Logistik GmbH
Bahnhofplatz 1
6300 W√∂rgl

E-Mail auf karriere.at ansehen

Please send us your CV in PDF format, your LinkedIn or Git Hub profile.Statement on equal opportunities
We promote an inclusive and open working environment where everyone can show themselves as they are. At Berger Logistik GmbH, every applicant is welcome: regardless of origin, nationality, faith, disability, age, marital status, partnership status, sexual orientation, gender and other legally protected grounds.

Benefits of working as a Senior Data Engineer (m/f/d) in W√∂rgl:

‚óè Career Growth Potential
‚óè Opportunities to grow
‚óè Advantageous package","[{'items': ['We are hiring a resilient Senior Data Engineer (m/f/d) to join our amazing team at Berger Logistik in W√∂rgl.\nGrowing your career as a Full Time Senior Data Engineer (m/f/d) is an exceptional opportunity to develop competitive skills.\nIf you are strong in critical thinking, attention to detail and have the right determination for the job, then apply for the position of Senior Data Engineer (m/f/d) at Berger Logistik today!\n\nBerger Logistik GmbH is part of a group of companies in the field of logistics and vehicle technology. As an established medium-sized company based in Tyrol and several locations in Austria, we focus on high-quality, tailor-made logistics products and industry solutions with a European and global orientation for all modes of transport (road, ocean, rail, and air): with excellent service, excellent know-how and our own, highly modern, and ecologically payload-optimized truck fleet.\n\nWe are currently looking for a committed and experienced person to start immediately... at our location in W√∂rgl, Tyrol or remotely:\n\nSenior Data Engineer (m/f/d)\n\nYour tasks and priorities\n‚Ä¢ Managing Datawarehouse operations\n‚Ä¢ Building data processing pipelines and defining data architectures\n‚Ä¢ Leveraging the automation of standard tasks, allowing more time to focus on creative ones\n‚Ä¢ Working with an agile team and contributing to the continuous improvement of the teams‚Äô skills and practices\n\nYour profile\n‚Ä¢ Experience working with various databases (SQL and NoSQL)\n‚Ä¢ Experience in programming and a demonstrable ability to learn new programming languages (There is no strict requirement on the knowledge of any particular language. Commonly used languages include Python, C#, PowerShell and various dialects and procedural extensions of SQL.)\n‚Ä¢ Understanding of modern cloud-based data architecture and cloud services, preferably with Microsoft Azure\n‚Ä¢ Willingness to take on technical challenges\n‚Ä¢ Committed to self-learning, knowledge sharing and teamwork\n‚Ä¢ Strong focus on stakeholders and quality\n‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand different technical ecosystems and data, as well as an ability to communicate complex technical problems and their solutions clearly\n‚Ä¢ English and German proficiency (German less important for candidates with excellent technical skills)\n\nNice to Have\n‚Ä¢ Experience working with data analysts and a good understanding of their needs\n‚Ä¢ Knowledge of a reporting frontend\n‚Ä¢ Knowledge of a web frontend programming language (JavaScript, React, Angular‚Ä¶)\n‚Ä¢ Working with APIs\n‚Ä¢ Knowledge of Graph DBS\n\nOur offer\n‚Ä¢ Supportive, motivated, and dynamic team\n‚Ä¢ Flexible working time and location arrangements (within EU)\n‚Ä¢ Exciting tasks, technical challenges, and development opportunities\n‚Ä¢ Flat hierarchies, direct and uncomplicated communication\n‚Ä¢ Current Microsoft Cloud Technology Stack, constantly improved by the team\n‚Ä¢ State-of-the-art IT and communications equipment\n‚Ä¢ Mobility package (‚ÄòKlimaTicket Tyrol‚Äô for public transport, bike leasing)\n‚Ä¢ Additional company benefits such as childcare facilities at company headquarters, training and further education opportunities, electric cars & e-bikes for personal errands, company events\n\nWe will determine classification and salary based on your professional and personal competence in line with the market. For this position the salary consists of EUR 75,000.00/year. With appropriate qualifications and professional experience, there is willingness to significantly overpay. Have we piqued your interest, and would you like to become part of our team? Then please send your application to:\n\nBerger Logistik GmbH\nBahnhofplatz 1\n6300 W√∂rgl\n\nE-Mail auf karriere.at ansehen\n\nPlease send us your CV in PDF format, your LinkedIn or Git Hub profile.Statement on equal opportunities\nWe promote an inclusive and open working environment where everyone can show themselves as they are. At Berger Logistik GmbH, every applicant is welcome: regardless of origin, nationality, faith, disability, age, marital status, partnership status, sexual orientation, gender and other legally protected grounds.\n\nBenefits of working as a Senior Data Engineer (m/f/d) in W√∂rgl:\n\n‚óè Career Growth Potential\n‚óè Opportunities to grow\n‚óè Advantageous package']}]","[{'link': 'https://www.google.com/search?hl=en&q=Berger+Logistik&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIyQ0', 'text': 'See web results for Berger Logistik'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRcEqyKMxQJvyMvLo-dBMzMo_gcqvrPWI0a8v9BiOo&s,"['19 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '19 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAvbS9mL2QvIC0gSW1tZWRpYXRlIFN0YXJ0IiwiaHRpZG9jaWQiOiJnaHdsY0g0OUtTUUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzVEhwQ2JsSkdWRkJLVW0xQ01FUk5ZMjkyUmxWcGNtcHRVV2hFYVUwelRHWkpObUpGU1d0Sk9Gb3RMV3BPYTNCeVJESnBabFZ6T0hFemMxOUxRa3N5UkRCTlJrRkZZbGh0VDJwRVUwdDVRMlppUzFsdldGazFRa2R6WDNONlkxZDFPWE0wTjJvMU1VVlhYMlJxWlVaSlpVUm5OalpQVkU1SGRVeENiV3RwWmxoSVVXWjNlVVU1TkZSSExXYzBURkF6Tkc1S1NUUlhURzF3YzBsS2NpMDNYMFZDUkdoVE5VVmxTR2d0Y1RWR2JrSkhSVlJuVlhrMGJVOXhUelIzTlRNM01HMVdkRU5vRWhjdGNreElXa3REWTBjM2RXVndkRkZRZWs1VFpHZEJSUm9pUVV4RlV6bDFVRkJtYkRGZlpUbFFUbmxvVkhneGFpMVpNakYzUWtSYVQxUk5RUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEyIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIEdyYWJKb2JzIiwibGluayI6Imh0dHBzOi8vZ3JhYmpvYnMuY28vYXVzdHJpYS9qb2IvZnVsbC10aW1lL21hcmtldGluZy1tZWRpYS9zZW5pb3ItZGF0YS1lbmdpbmVlci1tZmQtaW1tZWRpYXRlLXN0YXJ0LTI0MTE4MzEwP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer,VERBUND AG,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ You contribute to the continuous improvement of existing data analytics
‚Ä¢ They help in the development of data-driven applications
‚Ä¢ They automate and streamline data preparation jobs
‚Ä¢ You create data models of information systems and implement them
‚Ä¢ With your contribution, the sustainable energy supply from hydropower is optimized

Technologies and skills
‚Ä¢ Python
‚Ä¢ Azure
‚Ä¢ JavaScript
‚Ä¢ Java
‚Ä¢ SQL
‚Ä¢ Apache Spark
‚Ä¢ PostgreSQL

Our expectations:

Qualifications
‚Ä¢ Good knowledge of SQL and relational database systems (e.g. Postgres)
‚Ä¢ Programming skills in Java, Spark, Python and/or JavaScript
‚Ä¢ Knowledge of big data in cloud environments (ideally Azure)
‚Ä¢ Knowledge of information systems, data modeling and algorithms

Experience
‚Ä¢ Several years of relevant work experience

Education
‚Ä¢ Completed training in the field of computer science (HTL/FH/University) or comparable training

Benefits
‚Ä¢ * Company Doctor
‚Ä¢ Flexible Working Hours","[{'items': ['Your role in the team\n‚Ä¢ You contribute to the continuous improvement of existing data analytics\n‚Ä¢ They help in the development of data-driven applications\n‚Ä¢ They automate and streamline data preparation jobs\n‚Ä¢ You create data models of information systems and implement them\n‚Ä¢ With your contribution, the sustainable energy supply from hydropower is optimized\n\nTechnologies and skills\n‚Ä¢ Python\n‚Ä¢ Azure\n‚Ä¢ JavaScript\n‚Ä¢ Java\n‚Ä¢ SQL\n‚Ä¢ Apache Spark\n‚Ä¢ PostgreSQL\n\nOur expectations:\n\nQualifications\n‚Ä¢ Good knowledge of SQL and relational database systems (e.g. Postgres)\n‚Ä¢ Programming skills in Java, Spark, Python and/or JavaScript\n‚Ä¢ Knowledge of big data in cloud environments (ideally Azure)\n‚Ä¢ Knowledge of information systems, data modeling and algorithms\n\nExperience\n‚Ä¢ Several years of relevant work experience\n\nEducation\n‚Ä¢ Completed training in the field of computer science (HTL/FH/University) or comparable training\n\nBenefits\n‚Ä¢ * Company Doctor\n‚Ä¢ Flexible Working Hours']}]","[{'link': 'http://www.verbund.com/', 'text': 'verbund.com'}, {'link': 'https://www.google.com/search?hl=en&q=VERBUND+AG&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAII_A0', 'text': 'See web results for VERBUND AG'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQdVF5CzOQ8eStg-D8_2Rs9oW0Cp_nHj7A1S9a2QBc&s,"['‚Ç¨44,170 a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJZM1dIbzR4dXY4TUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVEVsTFVGUldlazg0YVMxb2VrczRSbkJ6VFhacWNFaHBVV1p2YlhBek5Xd3piRVIxYURWT2VERmpjREJhTXpaRmFuaExVM0J4Wm1FemNFazBVbXhTVG01SGNtSm9WMHBwUW5WbmVXaHFWbmhDYUZKalVrMUVUME5qVGpSWUxVMTRjaTB0Ums5Sk9FZzBjbTl4YjJkTGF6Um5jSFZoVXpkRE4wTnZiV0pQVUVNMFdrODFZMUoxV2xwRWRGOWtZamN0U1V4V2NrMVJPRTQ1TlU5cFR6RTBZVUU0VUhwQlJWSmpabXhITldoM0xXdHpFaGN0Y2t4SVdrdERZMGMzZFdWd2RGRlFlazVUWkdkQlJSb2lRVXhGVXpsMVQxSk9hRGR6V25CbGVEWm9VemxVWTJ0UVVESk9kV3A2Vld0SWR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iLzJjNjIzY2ZlMjdhOGRkYjQzZTUzOTQ5Yjk5MDQ1OTc2P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer Professional (m/w/d),Hays √ñsterreich Working for your tomorrow,"  Vienna, Austria   ",via Big Country Jobs,"Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.
Mein Arbeitgeber
‚Ä¢ F√ºhrendes Dienstleistungsunternehmen sowie wichtiger Teil der √∂sterreichischen Infrastruktur, das sich durch ein umfangreiches Netzwerk, innovative L√∂sungen und Engagement f√ºr Nachhaltigkeit auszeichnet.

Aufgaben
‚Ä¢ Erarbeitung von L√∂sungskonzepten nach fachlichen Anforderungen
‚Ä¢ Unterst√ºtzung bzw. Beratung der internen Kund innen bei der Erstellung der Anforderungen sowie deren Aufwandsch√§tzung
‚Ä¢ (Mit-) Arbeit an Konzeption und Design von Datenquelle(n) bis BI Reports
‚Ä¢ Aufbau und die Verfeinerung der Architektur der Plattfor

Profil
‚Ä¢ Einschl√§gige Erfahrung als Data Engineer, bevorzugt mit dem Azure-spezifischen Stack (Azure Synapse Analytics, Azure Data Lake, Azure Data Factory, Azure Databricks)
‚Ä¢ Erfahrung mit Infrastructure as Code und CD Pipelines von Vorteil
‚Ä¢ Erfahrung mit SQL, C# Skills von Vorteil
‚Ä¢ Erfahrung mit der Qualit√§tssicherung in ETL Prozessen von Vorteil

Wir bieten
‚Ä¢ Sicherer Arbeitsplatz
‚Ä¢ Flexible Zeiteinteilung
‚Ä¢ Bis zu 100% remote m√∂glich (Voraussetzung: Hauptwohnsitz in √ñsterreich)
‚Ä¢ Verg√ºnstigte Urlaubsangebote & diverse Einkaufsvorteile
‚Ä¢ Umfangreiche Weiterbildungs- und Entwicklungsm√∂glichkeiten
Gehaltsinformationen
‚Ä¢ Es wird ein marktkonformes Bruttojahresgehalt von ‚Ç¨ 65.000 brutto j√§hrlich geboten. Selbstverst√§ndlich ist die Bereitschaft zu √úberzahlung abh√§ngig von Berufserfahrung und Qualifikation gegeben","[{'items': ['Der Bereich IT ist unsere Kernkompetenz, auf deren Grundlage sich Hays entwickelt hat. Wir sind das gr√∂√üte privatwirtschaftlich organisierte IT-Personaldienstleistungsunternehmen in Deutschland und haben f√ºr jede Karrierestufe das passende Angebot - egal ob Sie an Vakanzen in agilen KMUs oder starken DAX-Konzernen interessiert sind. Wir beherrschen die komplette IT-Klaviatur von Support bis zur Softwarearchitektur oder Digitalisierung - dank unseres umfangreichen Portfolios ist f√ºr jeden etwas dabei. So konnten wir in den vergangenen Jahrzehnten im Rahmen einer Life-Long-Partnerschaft unz√§hlige Fach- und F√ºhrungskr√§fte aus der IT dabei unterst√ºtzen, die Weichen f√ºr eine erfolgreiche Karriere zu stellen. Unser Beratungsteam ist spezialisiert und somit in der Lage, auf Ihre W√ºnsche und Vorstellungen einzugehen und Sie auf Bewerbungsgespr√§che und Vertragsverhandlungen bestens vorzubereiten. Probieren Sie es aus und erfahren Sie, was der Markt Ihnen zu bieten hat - v√∂llig kostenfrei... diskret und unverbindlich! Wir freuen uns auf Sie.\nMein Arbeitgeber\n‚Ä¢ F√ºhrendes Dienstleistungsunternehmen sowie wichtiger Teil der √∂sterreichischen Infrastruktur, das sich durch ein umfangreiches Netzwerk, innovative L√∂sungen und Engagement f√ºr Nachhaltigkeit auszeichnet.\n\nAufgaben\n‚Ä¢ Erarbeitung von L√∂sungskonzepten nach fachlichen Anforderungen\n‚Ä¢ Unterst√ºtzung bzw. Beratung der internen Kund innen bei der Erstellung der Anforderungen sowie deren Aufwandsch√§tzung\n‚Ä¢ (Mit-) Arbeit an Konzeption und Design von Datenquelle(n) bis BI Reports\n‚Ä¢ Aufbau und die Verfeinerung der Architektur der Plattfor\n\nProfil\n‚Ä¢ Einschl√§gige Erfahrung als Data Engineer, bevorzugt mit dem Azure-spezifischen Stack (Azure Synapse Analytics, Azure Data Lake, Azure Data Factory, Azure Databricks)\n‚Ä¢ Erfahrung mit Infrastructure as Code und CD Pipelines von Vorteil\n‚Ä¢ Erfahrung mit SQL, C# Skills von Vorteil\n‚Ä¢ Erfahrung mit der Qualit√§tssicherung in ETL Prozessen von Vorteil\n\nWir bieten\n‚Ä¢ Sicherer Arbeitsplatz\n‚Ä¢ Flexible Zeiteinteilung\n‚Ä¢ Bis zu 100% remote m√∂glich (Voraussetzung: Hauptwohnsitz in √ñsterreich)\n‚Ä¢ Verg√ºnstigte Urlaubsangebote & diverse Einkaufsvorteile\n‚Ä¢ Umfangreiche Weiterbildungs- und Entwicklungsm√∂glichkeiten\nGehaltsinformationen\n‚Ä¢ Es wird ein marktkonformes Bruttojahresgehalt von ‚Ç¨ 65.000 brutto j√§hrlich geboten. Selbstverst√§ndlich ist die Bereitschaft zu √úberzahlung abh√§ngig von Berufserfahrung und Qualifikation gegeben']}]","[{'link': 'https://www.google.com/search?hl=en&q=Hays+%C3%96sterreich+Working+for+your+tomorrow&sa=X&ved=0ahUKEwiggfjVgrmAAxU7j4kEHUxqBxA4KBCYkAIIrw4', 'text': 'See web results for Hays √ñsterreich Working for your tomorrow'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvIbD0b-JZO9EOSPvXcS2sFRhxy1ho8zUBNqnmr3Px4NRccJpy_8gR&s,"['7 hours ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 hours ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIFByb2Zlc3Npb25hbCAobS93L2QpIiwiaHRpZG9jaWQiOiJMSFZkVDVLQjh5Y0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzVEVOa04wd3RhREJ1VVc1ME1tdG1YMms1Wmt0c05rWnBVRzk1T1V4SU5VdHhUbFJHWlVGak4zaDFYMkZXUlZRNFZtMTFTMG81V2w5dlNEQnFhRGd4VVhWYWJHZGlZVlpmVFc1Q2FXOXZSV3REYmxNNFUwdFJWbFExVG1sdVoxcGplRlp6UnpKb1RYazVNRk5UYUhaUk5rRmxRMTgwTlhnNWRUaFdZVE10ZDBGWlZqWnZlSHB4U1hCYWNqSlVjREJ6ZEhWbWQxZHhhVFF6UVdKSkxYQkxSbWgwVGtKSlNsaHpPRXBRWVRKbVVGSmFVbWxuTXpWdVVXdEdPVk5wZEUxSVZUUXhZVkkyY21kbVZqWkJOVlpJZUV0MmNXcEJOREJwTlZvelp4SVhMWEpNU0ZwTFEyTkhOM1ZsY0hSUlVIcE9VMlJuUVVVYUlrRk1SVk01ZFU1amRsRnpWRzVIVkRONmRsbzFaVlJ3VmpCS01WRjJXRmhNU0djIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQmlnIENvdW50cnkgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMuYmlnY291bnRyeWhvbWVwYWdlLmNvbS9qb2JzL2RhdGEtZW5naW5lZXItcHJvZmVzc2lvbmFsLW0tdy1kLXdpZW4vMTA3Njk3NjAxNy0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Scientist/Engineer f/m/d,New York Air Brake Corp,"  Vienna, Austria   ",via Jobilize,"IFE is the worldwide leading manufacturer of automatic entrance systems for railway vehicles. Wouldn‚Äôt it be great to play an active part in shaping the future of mobility?
We are an innovative company and use data from our door systems on railroad vehicles to predict future failures using Big Data analytics in the cloud. For this purpose, we are looking for someone to join our team for data analysis and development of algorithms for Condition Based Maintenance (CBM).
YOUR TASKS
ANALYZE. the process and environment data of our train door systems.
IDENTIFICATION. of anomalies
DEVELOPMENT. of machine learning models
DATA ENGINEERING. to further develop our data processing pipeline.
COLLABORATION. through cross-disciplinary teamwork with development and services
COMMUNICATION . and visualization of results
SHAPING. the mobility of the future

YOUR PROFILE
Master in Data Science, Industrial IT
very good knowledge in Python or R
experience with SPARK (DATABRICKS, Azure, AWS) an... advantage
experience with version management like Git, Devops
good technical understanding (electrical engineering, mechanical engineering, physics, . ) an advantage
experience in leading interdisciplinary teams
ability to work independently
very good knowledge of German and English
WHAT WE OFFER
Continuous innovation pushes the technological progress of our automatic entrance systems, which are geared towards quality, safety and reliability, and distinguishes us as an internationally reliable partner.
We offer you an exciting and varied job in an international environment as well as an attractive set of benefits. These range from flexible working time (up to 50% homeoffice) models through professional and personal development opportunities to sports and health care programmes.
The minimum salary for this position is EUR 3.500,00 gross monthly or more depending on qualifications and experience.

ARE YOU INTERESTED?
Apply now online if you want to advance in a strong team. We look forward to receiving your application","[{'items': ['IFE is the worldwide leading manufacturer of automatic entrance systems for railway vehicles. Wouldn‚Äôt it be great to play an active part in shaping the future of mobility?\nWe are an innovative company and use data from our door systems on railroad vehicles to predict future failures using Big Data analytics in the cloud. For this purpose, we are looking for someone to join our team for data analysis and development of algorithms for Condition Based Maintenance (CBM).\nYOUR TASKS\nANALYZE. the process and environment data of our train door systems.\nIDENTIFICATION. of anomalies\nDEVELOPMENT. of machine learning models\nDATA ENGINEERING. to further develop our data processing pipeline.\nCOLLABORATION. through cross-disciplinary teamwork with development and services\nCOMMUNICATION . and visualization of results\nSHAPING. the mobility of the future\n\nYOUR PROFILE\nMaster in Data Science, Industrial IT\nvery good knowledge in Python or R\nexperience with SPARK (DATABRICKS, Azure, AWS) an... advantage\nexperience with version management like Git, Devops\ngood technical understanding (electrical engineering, mechanical engineering, physics, . ) an advantage\nexperience in leading interdisciplinary teams\nability to work independently\nvery good knowledge of German and English\nWHAT WE OFFER\nContinuous innovation pushes the technological progress of our automatic entrance systems, which are geared towards quality, safety and reliability, and distinguishes us as an internationally reliable partner.\nWe offer you an exciting and varied job in an international environment as well as an attractive set of benefits. These range from flexible working time (up to 50% homeoffice) models through professional and personal development opportunities to sports and health care programmes.\nThe minimum salary for this position is EUR 3.500,00 gross monthly or more depending on qualifications and experience.\n\nARE YOU INTERESTED?\nApply now online if you want to advance in a strong team. We look forward to receiving your application']}]","[{'link': 'http://www.nyab.com/', 'text': 'nyab.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=New+York+Air+Brake+Corp&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAII4go', 'text': 'See web results for New York Air Brake Corp'}]",,"['3 days ago', 'Full-time']","{'posted_at': '3 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdC9FbmdpbmVlciBmL20vZCIsImh0aWRvY2lkIjoiU0RjenZTYlJyckFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1RFSmlkRFpSZGs5NU9YRm9SSEZITW5GWFlXWjNObEprVlVsWmVtMDVZblphUjNjd2JXOUtObUY1UVZOcVowSTVka2hPTUZFd2QxaFJhWFptVkRWWVJDMUpVRFUyVlVNemRGUkhUV1puZFRkVE5qSm9iWE5vYTBGVlQyVk1MUzB3YjJSWVNreFZZVFl5V1ZoUlRUVXhjbmhMU201VmJFc3pXa1ZaT0VaWVRFUldkMkUwZDB0RWJpMUNTa3gxVmt0RlJXZDROazloYWtvNGJGRlBlVTA1YzFKUWRIa3dVbGN3TFdoclpUWkpkM1JKYm5ScVoxQjFka001UkVWRlUyb3plRnBhTW5NM0VoZGZOMHhJV2twTU5FNU9iV1IzWW10UVgyOTFNamhCY3hvaVFVeEZVemwxVDBKMFMzbGFWemxvWkZoRGMyNWpZbXB1WmxRNVZIQTBTbnA2VVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIEpvYmlsaXplIiwibGluayI6Imh0dHBzOi8vd3d3LmpvYmlsaXplLmNvbS9qb2Ivdmllbm5hLWRhdGEtc2NpZW50aXN0LWVuZ2luZWVyLWYtbS1kLW5ldy15b3JrLWFpci1icmFrZS1jb3JwLWhpcmluZz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer - Feature,PriceHubble,"  Vienna, Austria   ",via Wellfound,"PriceHubble is a PropTech company, set to radically improve the understanding and transparency of real estate markets based on data-driven insights. We aggregate and analyse a wide variety of data, run big data analytics and use state-of-the art machine learning to generate stable and reliable valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Prague, Amsterdam, Vienna and Tokyo. We work on international markets and we are backed by world-class investors. We have a startup environment, low bureaucracy and an international team and business.

Your role

You will be a member of one of the teams responsible for transforming data into insights that could be published via our products. You enjoy working on a wide range of features on an international multi disciplinary team. You are passionate about learning new things and care about being part of the design process, developing new features, maintaining... existing code and contributing to the overall architecture design. You are a team player and speak your mind, you measure success not by the number of hours spent but by what is accomplished.

Responsibilities
‚Ä¢ Design, build and run data pipelines to source, ingest, integrate and publish data
‚Ä¢ Continuous improvement applying engineering best practices to development, monitoring, and data quality of the data pipelines
‚Ä¢ Identify new data sources that could be used for new features
‚Ä¢ Coach the team on data handling best practices

Requirements
‚Ä¢ Proven relevant experience in a similar position
‚Ä¢ Demonstrable ability to work creatively and analytically with a growth mindset
‚Ä¢ Experience manipulating data using Python and maintaining pipelines
‚Ä¢ Experience with relational databases
‚Ä¢ Experience with Docker and Kubernetes orchestration is an advantage
‚Ä¢ Understanding of basic data structures and algorithms
‚Ä¢ Familiarity with some of the tools we use is a plus (Pandas, Luigi, Airflow, PySpark, PostGIS)
‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas.

Benefits

Join an ambitious and hungry team and enjoy the following benefits:

üí∞ Competitive salary because we always want to attract the best talents.

üìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.

üè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.

üïì Flexible working hours and work life balance.

PriceHubble focuses on Real Estate. Their company has offices in Paris, Zurich, Berlin, and Tokyo. They have a small team that's between 11-50 employees.

You can view their website at https://pricehubble.com or find them on Twitter and LinkedIn","[{'items': [""PriceHubble is a PropTech company, set to radically improve the understanding and transparency of real estate markets based on data-driven insights. We aggregate and analyse a wide variety of data, run big data analytics and use state-of-the art machine learning to generate stable and reliable valuations and predictive analytics for the real estate market. We are headquartered in Z√ºrich, with offices in Berlin, Hamburg, Paris, Prague, Amsterdam, Vienna and Tokyo. We work on international markets and we are backed by world-class investors. We have a startup environment, low bureaucracy and an international team and business.\n\nYour role\n\nYou will be a member of one of the teams responsible for transforming data into insights that could be published via our products. You enjoy working on a wide range of features on an international multi disciplinary team. You are passionate about learning new things and care about being part of the design process, developing new features, maintaining... existing code and contributing to the overall architecture design. You are a team player and speak your mind, you measure success not by the number of hours spent but by what is accomplished.\n\nResponsibilities\n‚Ä¢ Design, build and run data pipelines to source, ingest, integrate and publish data\n‚Ä¢ Continuous improvement applying engineering best practices to development, monitoring, and data quality of the data pipelines\n‚Ä¢ Identify new data sources that could be used for new features\n‚Ä¢ Coach the team on data handling best practices\n\nRequirements\n‚Ä¢ Proven relevant experience in a similar position\n‚Ä¢ Demonstrable ability to work creatively and analytically with a growth mindset\n‚Ä¢ Experience manipulating data using Python and maintaining pipelines\n‚Ä¢ Experience with relational databases\n‚Ä¢ Experience with Docker and Kubernetes orchestration is an advantage\n‚Ä¢ Understanding of basic data structures and algorithms\n‚Ä¢ Familiarity with some of the tools we use is a plus (Pandas, Luigi, Airflow, PySpark, PostGIS)\n‚Ä¢ We are interested in every qualified candidate who is eligible to work in the European Union but we are not able to sponsor visas.\n\nBenefits\n\nJoin an ambitious and hungry team and enjoy the following benefits:\n\nüí∞ Competitive salary because we always want to attract the best talents.\n\nüìò Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.\n\nüè¢ Very well-located offices with a great remote work policy and the possibility to work from different places.\n\nüïì Flexible working hours and work life balance.\n\nPriceHubble focuses on Real Estate. Their company has offices in Paris, Zurich, Berlin, and Tokyo. They have a small team that's between 11-50 employees.\n\nYou can view their website at https://pricehubble.com or find them on Twitter and LinkedIn""]}]","[{'link': 'http://pricehubble.com/', 'text': 'pricehubble.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=PriceHubble&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIlAs', 'text': 'See web results for PriceHubble'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQR6qmgFjnAixdzFOWDAK1-Es2iXVhOnM1Ml-p-dQY&s,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciAtIEZlYXR1cmUiLCJodGlkb2NpZCI6ImZzLXJZZlJPSkFNQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTVzlaVEc1Mk5IZGtWa1pZZFdGWVQzaFhiQzAzTVU5S1FYWlRibWhJVjBnNWEzQlpTVk4zTTB0d2VscE5lazVWYjFGak1XWjRTbTQxU2poRGQybGZWWEYwV25sR1VqbFpSaTA0YXpsTFdGOVRSbmxKUzJsek5UTkdaVll5YzNsVFFYbFZSRVZ3TUVFM1JHMDJlV3ROTjFwQmVUVnZha041V1hsWldVWjZOMFZKZERkRU1XMHhaSFpHU2tsVlZFWldkRU5VV2xZNWJuVkRUakZuYzA1T1dFTXhlVEpJWlRSR1RGQjZVbmhCVlhkdFVHNUtRa1Z1YkhoUmNIVkhlV2Q0TWtSaE5GOWFFaGRmTjB4SVdrcE1ORTVPYldSM1ltdFFYMjkxTWpoQmN4b2lRVXhGVXpsMVRqQmtjRVJGUVROQlZrMXZja0ZvVWxWcWR6TjRjRWRFYTJSVFVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBXZWxsZm91bmQiLCJsaW5rIjoiaHR0cHM6Ly93ZWxsZm91bmQuY29tL2NvbXBhbnkvcHJpY2VodWJibGUvam9icy8yMTk0NzI2LXNlbmlvci1kYXRhLWVuZ2luZWVyLWZlYXR1cmU/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (all genders),Accenture GmbH,  Austria   ,via WJTV Jobs,"In unserem Data & AI Network kombinieren wir unser strategisches, digitales und technologisches Know-how, um Unternehmen auf ein neues Innovations- und Performance-Level zu heben.

Wir agieren industrie√ºbergreifend, sodass du t√§glich Neues dazulernst und deine Karriere ein ganzes St√ºck nach vorn bringen kannst. Werde nicht nur ein Teil der datenzentrierten Transformation sondern sei vorne mit dabei. Bei Accenture gestaltest du dir selbst das Umfeld, in dem du aufgehst - mit Arbeitsweisen, die zu dir passen. Du bleibst flexibel. Und wirst Teil eines Teams voller einzigartiger Menschen, die gemeinsam etwas bewegen.

Aufgaben

Unterst√ºtzte unseren Kunden dabei, aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln

Deine Mission

Das erwartet dich:
‚Ä¢ Sei Data Driven und kreativ
‚Ä¢ Setze deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr die datengetriebene Unternehmen zu schaffen Kollaboriere im Team & nutze... die Synergien
‚Ä¢ Als Teil eines interdisziplin√§ren Teams fokussierst du dich, auf Datenquellen zu identifizieren, komplexe Datenmodele zu modellieren und produktive Datenpipelines sowohl in der Cloud als auch on-Premise zu entwickeln Agiere als trusted Advisor
‚Ä¢ Dabei stehst du mit den Entscheidungstr√§gern auf Kundenseite im engen Kontakt und sorgst daf√ºr, dass die End-2-End Datenpipelines als wesentlicher Basis f√ºr die Industrialisierung von K√ºnstlicher Intelligenz erfolgreich implementiert werdenmehr anzeigen weniger anzeigen

Profil

Qualifikationen

Darauf freuen wir uns:
‚Ä¢ Abgeschlossenes Studium oder abgeschlossene Berufsausbildung im IT-Bereich (HTL), bevorzugt mit Schwerpunkt Data Engineering, Informatik, IT oder Software Engineering
‚Ä¢ Elementare oder fortgeschrittene Kenntnisse in diesen Bereichen setzen wir voraus:
‚Ä¢ Software Engineering (z.B.: Python, Scala, Java)
‚Ä¢ Version Control System (z.B.: Git)
‚Ä¢ Datenmanipulierung (z.B.: SQL, R, Spark)
‚Ä¢ On-premise & Cloud Data Warehouse/Data Integration (z.B.: Talend, Microsoft Datafactory/SSIS, Azure Synapse, Telegraf)
‚Ä¢ On-premise & Cloud SQL Datenbanken (z.B.: MS SQL Server, Oracle, Postgres)
‚Ä¢ Folgende Kenntnisse in einem oder mehrerer dieser Bereiche sind w√ºnschenswert:
‚Ä¢ Continuous Integration & Delivery (z.B.: Unit Testing, Jenkins, Release Management)
‚Ä¢ Cloud Architekturen (z.B.: AWS, Azure, GCP - Zertifizierungen erw√ºnscht)
‚Ä¢ On-premise & Cloud Big Data /In-Memory-Datenbanken (z.B.: Snowflake, Cloudera)
‚Ä¢ On-premise & Cloud NoSQL Datenbanken (z.B.: MongoDB, InfluxDB)
‚Ä¢ Web APIs (z.B.: Rest, Soap)
‚Ä¢ Projektbezogene Mobilit√§t, Kommunikationsst√§rke auf Deutsch und Englisch sowie eine hohe Kundenorientierung

Wir bieten
‚Ä¢ Flexible Arbeitszeitmodelle, Arbeiten in Teilzeit und Homeoffice
‚Ä¢ √úberstundenausgleich
‚Ä¢ Top-Perspektiven durch regelm√§√üige Trainings, Fort- und Weiterbildungsm√∂glichkeiten
‚Ä¢ Interessante Entwicklungsm√∂glichkeiten und attraktive Karrierepfade
‚Ä¢ Den Zugriff auf den Wissens- und Erfahrungsschatz im globalen Accenture-Netzwerk

Du und Accenture

In dieser Rolle bist du Teil von Accenture Technology . Wir nutzen das gesamte Spektrum digitaler Technologien, um den Alltag unserer Kunden zu vereinfachen. Und ihr Business in die Zukunft zu f√ºhren. Von bis , von bis . Die Accenture-Kultur: Hier machst DU den Unterschied

Deine F√§higkeiten, dein Naturell und deine Ambitionen machen dich einzigartig. Und wenn die unterschiedlichsten Talente, St√§rken und Sichtweisen aufeinandertreffen, entsteht etwas Gro√üartiges: Ideen, die in der Welt etwas bewegen. Deshalb setzen wir bei Accenture auf Diversit√§t und freie Entfaltung. Schaffe dir ein Arbeitsumfeld, in dem du aufgehst. Mit Aufgaben, die dir am Herzen liegen. Mit einem Workload, der zu dir passt. Und mit einer Arbeitsweise, die sich an deinen Zielen orientiert. Wie du dich vernetzen, weiterbilden und pers√∂nlich wachsen willst, liegt bei dir. Es ist deine Karriere. Wir helfen dir, sie so zu gestalten, wie du es dir vorstellst

Neben spannenden Projekten bieten wir dir ein attraktives Verg√ºtungspaket, flexible Arbeitszeiten, ein modernes Umfeld und viele weitere zus√§tzliche Benefits. Du hast bei uns die M√∂glichkeit, basierend auf deiner individuellen Leistung aktiv dein Jahreseinkommen positiv zu beeinflussen welches f√ºr diese Position bei einem Jahresbruttogehalt von ‚Ç¨ 38.000 startet.

JETZT BEWERBEN REGISTRIERE DICH F√úR DEN JOB-ALARM TEILEN TEILEN Job Link: Copy

Statement zur Chancengleichheit

Wir suchen Menschen mit eigenem Lebensentwurf und ungew√∂hnlichem Lebenslauf. Individuell statt uniform. Vielfalt statt Norm. Diversit√§t ist unsere St√§rke und eine wesentliche Komponente der Unternehmenskultur von Accenture. Wir f√∂rdern ein integratives und offenes Arbeitsumfeld, in dem sich jeder so zeigen kann, wie er ist. Bei Accenture ist jeder Bewerber willkommen: unabh√§ngig von Herkunft, Nationalit√§t, Glaube, Behinderung, Alter, Familienstand, Partnerschaftsstatus, sexueller Orientierung, Geschlecht und anderen gesetzlich gesch√ºtzten Gr√ºnden","[{'items': ['In unserem Data & AI Network kombinieren wir unser strategisches, digitales und technologisches Know-how, um Unternehmen auf ein neues Innovations- und Performance-Level zu heben.\n\nWir agieren industrie√ºbergreifend, sodass du t√§glich Neues dazulernst und deine Karriere ein ganzes St√ºck nach vorn bringen kannst. Werde nicht nur ein Teil der datenzentrierten Transformation sondern sei vorne mit dabei. Bei Accenture gestaltest du dir selbst das Umfeld, in dem du aufgehst - mit Arbeitsweisen, die zu dir passen. Du bleibst flexibel. Und wirst Teil eines Teams voller einzigartiger Menschen, die gemeinsam etwas bewegen.\n\nAufgaben\n\nUnterst√ºtzte unseren Kunden dabei, aus ihren Daten neue, optimierte Gesch√§ftsmodelle zu entwickeln\n\nDeine Mission\n\nDas erwartet dich:\n‚Ä¢ Sei Data Driven und kreativ\n‚Ä¢ Setze deinen analytischen Verstand und dein kreatives Denken gezielt ein, um mit den Datenplattformen der Zukunft die Basis f√ºr die datengetriebene Unternehmen zu schaffen Kollaboriere im Team & nutze... die Synergien\n‚Ä¢ Als Teil eines interdisziplin√§ren Teams fokussierst du dich, auf Datenquellen zu identifizieren, komplexe Datenmodele zu modellieren und produktive Datenpipelines sowohl in der Cloud als auch on-Premise zu entwickeln Agiere als trusted Advisor\n‚Ä¢ Dabei stehst du mit den Entscheidungstr√§gern auf Kundenseite im engen Kontakt und sorgst daf√ºr, dass die End-2-End Datenpipelines als wesentlicher Basis f√ºr die Industrialisierung von K√ºnstlicher Intelligenz erfolgreich implementiert werdenmehr anzeigen weniger anzeigen\n\nProfil\n\nQualifikationen\n\nDarauf freuen wir uns:\n‚Ä¢ Abgeschlossenes Studium oder abgeschlossene Berufsausbildung im IT-Bereich (HTL), bevorzugt mit Schwerpunkt Data Engineering, Informatik, IT oder Software Engineering\n‚Ä¢ Elementare oder fortgeschrittene Kenntnisse in diesen Bereichen setzen wir voraus:\n‚Ä¢ Software Engineering (z.B.: Python, Scala, Java)\n‚Ä¢ Version Control System (z.B.: Git)\n‚Ä¢ Datenmanipulierung (z.B.: SQL, R, Spark)\n‚Ä¢ On-premise & Cloud Data Warehouse/Data Integration (z.B.: Talend, Microsoft Datafactory/SSIS, Azure Synapse, Telegraf)\n‚Ä¢ On-premise & Cloud SQL Datenbanken (z.B.: MS SQL Server, Oracle, Postgres)\n‚Ä¢ Folgende Kenntnisse in einem oder mehrerer dieser Bereiche sind w√ºnschenswert:\n‚Ä¢ Continuous Integration & Delivery (z.B.: Unit Testing, Jenkins, Release Management)\n‚Ä¢ Cloud Architekturen (z.B.: AWS, Azure, GCP - Zertifizierungen erw√ºnscht)\n‚Ä¢ On-premise & Cloud Big Data /In-Memory-Datenbanken (z.B.: Snowflake, Cloudera)\n‚Ä¢ On-premise & Cloud NoSQL Datenbanken (z.B.: MongoDB, InfluxDB)\n‚Ä¢ Web APIs (z.B.: Rest, Soap)\n‚Ä¢ Projektbezogene Mobilit√§t, Kommunikationsst√§rke auf Deutsch und Englisch sowie eine hohe Kundenorientierung\n\nWir bieten\n‚Ä¢ Flexible Arbeitszeitmodelle, Arbeiten in Teilzeit und Homeoffice\n‚Ä¢ √úberstundenausgleich\n‚Ä¢ Top-Perspektiven durch regelm√§√üige Trainings, Fort- und Weiterbildungsm√∂glichkeiten\n‚Ä¢ Interessante Entwicklungsm√∂glichkeiten und attraktive Karrierepfade\n‚Ä¢ Den Zugriff auf den Wissens- und Erfahrungsschatz im globalen Accenture-Netzwerk\n\nDu und Accenture\n\nIn dieser Rolle bist du Teil von Accenture Technology . Wir nutzen das gesamte Spektrum digitaler Technologien, um den Alltag unserer Kunden zu vereinfachen. Und ihr Business in die Zukunft zu f√ºhren. Von bis , von bis . Die Accenture-Kultur: Hier machst DU den Unterschied\n\nDeine F√§higkeiten, dein Naturell und deine Ambitionen machen dich einzigartig. Und wenn die unterschiedlichsten Talente, St√§rken und Sichtweisen aufeinandertreffen, entsteht etwas Gro√üartiges: Ideen, die in der Welt etwas bewegen. Deshalb setzen wir bei Accenture auf Diversit√§t und freie Entfaltung. Schaffe dir ein Arbeitsumfeld, in dem du aufgehst. Mit Aufgaben, die dir am Herzen liegen. Mit einem Workload, der zu dir passt. Und mit einer Arbeitsweise, die sich an deinen Zielen orientiert. Wie du dich vernetzen, weiterbilden und pers√∂nlich wachsen willst, liegt bei dir. Es ist deine Karriere. Wir helfen dir, sie so zu gestalten, wie du es dir vorstellst\n\nNeben spannenden Projekten bieten wir dir ein attraktives Verg√ºtungspaket, flexible Arbeitszeiten, ein modernes Umfeld und viele weitere zus√§tzliche Benefits. Du hast bei uns die M√∂glichkeit, basierend auf deiner individuellen Leistung aktiv dein Jahreseinkommen positiv zu beeinflussen welches f√ºr diese Position bei einem Jahresbruttogehalt von ‚Ç¨ 38.000 startet.\n\nJETZT BEWERBEN REGISTRIERE DICH F√úR DEN JOB-ALARM TEILEN TEILEN Job Link: Copy\n\nStatement zur Chancengleichheit\n\nWir suchen Menschen mit eigenem Lebensentwurf und ungew√∂hnlichem Lebenslauf. Individuell statt uniform. Vielfalt statt Norm. Diversit√§t ist unsere St√§rke und eine wesentliche Komponente der Unternehmenskultur von Accenture. Wir f√∂rdern ein integratives und offenes Arbeitsumfeld, in dem sich jeder so zeigen kann, wie er ist. Bei Accenture ist jeder Bewerber willkommen: unabh√§ngig von Herkunft, Nationalit√§t, Glaube, Behinderung, Alter, Familienstand, Partnerschaftsstatus, sexueller Orientierung, Geschlecht und anderen gesetzlich gesch√ºtzten Gr√ºnden']}]","[{'link': 'http://www.accenture.com/at-de', 'text': 'accenture.com/at-de'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Accenture+GmbH&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIxgs', 'text': 'See web results for Accenture GmbH'}]",,"['20 hours ago', 'Part-time']","{'posted_at': '20 hours ago', 'schedule_type': 'Part-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChhbGwgZ2VuZGVycykiLCJodGlkb2NpZCI6ImFYbGNMQ09sdV9jQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNUSFpoTkZNeVJEUkpha3BVZEZCU2NHdFplbkZYTkVvelYwUnhWRnB5U1ZsbExUUmhaRmRXVTI4MmJrVjBjM3BpWm1SWFFua3pMVzlCVm5sRE9XVmFNWFJKWWxOTFJEbGFha1JPTW1kMGRuSTNSVTVZTUdGaVdEUlZhV2RDVVRoV09YRnljVlpuZUZaUlZtRnBTblEwZFRaalVXVnpWR3AwWTNvek1tOHRUekl4Y0VkNVNGbERiMU5TY0ZoamJHZHhWa05GU0VkbmNYUm9WbWwwYmtkdmNEUm1PRWxYU1Y4M01GUnNkakkzTlRWRkVoZGZOMHhJV2twTU5FNU9iV1IzWW10UVgyOTFNamhCY3hvaVFVeEZVemwxVUVSWFZrZEJSRzR3VjBONFJtRlhUMXBQTmtreE1tOXplREJ6UVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFdKVFYgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMud2p0di5jb20vam9icy9kYXRhLWVuZ2luZWVyLWFsbC1nZW5kZXJzLWF1c3RyaWEvMTA3NjgwNzY1NS0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Software Engineer Data Warehouse,willhaben,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ As a team player, you are the driving force in all technical matters within the Data & Insights team.
‚Ä¢ You not only want to implement specifications, but also help shape and further develop our data platform.
‚Ä¢ You work with modern cloud technologies (AWS, Snowflake, Kubernetes) at Austria's largest online marketplace.
‚Ä¢ You ensure that our analysts have all the tools they need for their day-to-day work, continuously develop the existing cloud data warehouse and connect new data that is important for the business.
‚Ä¢ You like to try out new technologies in cooperation with our group mothers and keep up to date with trends in the data engineering scene.

Technologies and skills
‚Ä¢ SQL
‚Ä¢ Kubernetes
‚Ä¢ Snowflake
‚Ä¢ GitLab
‚Ä¢ AWS
‚Ä¢ Python
‚Ä¢ Argo Workflow

Our expectations:

Qualifications
‚Ä¢ You are used to automating routine tasks and have experience with Python.
‚Ä¢ You are very familiar with Cloud SQL databases.

Experience
‚Ä¢ You have at least 2 years of professional... experience in data engineering.
‚Ä¢ You have a good understanding of analysis-oriented data structures and have experience in implementing ETL pipelines (e.g. dbt).

Education
‚Ä¢ Benefits
‚Ä¢ Company Doctor
‚Ä¢ Health Care Benefits
‚Ä¢ Animals Welcome
‚Ä¢ Fresh Fruit
‚Ä¢ Employee Gifts
‚Ä¢ * Employee Stock Option
‚Ä¢ Team Budget for Free Use
‚Ä¢ Excellent Traffic Connections
‚Ä¢ No All-In Contracts
‚Ä¢ Fitness Offers
‚Ä¢ * Tabletop Soccer, etc.
‚Ä¢ Massage, Yoga, etc.
‚Ä¢ Mentor Program
‚Ä¢ * Coffee, Tea, etc.
‚Ä¢ Employee Discount
‚Ä¢ Employee Parking Space
‚Ä¢ Company Notebook for Private Use
‚Ä¢ Bicycle Parking Space
‚Ä¢ * Flexible Working Hours
‚Ä¢ Educational Leave/Sabbatical
‚Ä¢ Bonus Payments","[{'items': [""Your role in the team\n‚Ä¢ As a team player, you are the driving force in all technical matters within the Data & Insights team.\n‚Ä¢ You not only want to implement specifications, but also help shape and further develop our data platform.\n‚Ä¢ You work with modern cloud technologies (AWS, Snowflake, Kubernetes) at Austria's largest online marketplace.\n‚Ä¢ You ensure that our analysts have all the tools they need for their day-to-day work, continuously develop the existing cloud data warehouse and connect new data that is important for the business.\n‚Ä¢ You like to try out new technologies in cooperation with our group mothers and keep up to date with trends in the data engineering scene.\n\nTechnologies and skills\n‚Ä¢ SQL\n‚Ä¢ Kubernetes\n‚Ä¢ Snowflake\n‚Ä¢ GitLab\n‚Ä¢ AWS\n‚Ä¢ Python\n‚Ä¢ Argo Workflow\n\nOur expectations:\n\nQualifications\n‚Ä¢ You are used to automating routine tasks and have experience with Python.\n‚Ä¢ You are very familiar with Cloud SQL databases.\n\nExperience\n‚Ä¢ You have at least 2 years of professional... experience in data engineering.\n‚Ä¢ You have a good understanding of analysis-oriented data structures and have experience in implementing ETL pipelines (e.g. dbt).\n\nEducation\n‚Ä¢ Benefits\n‚Ä¢ Company Doctor\n‚Ä¢ Health Care Benefits\n‚Ä¢ Animals Welcome\n‚Ä¢ Fresh Fruit\n‚Ä¢ Employee Gifts\n‚Ä¢ * Employee Stock Option\n‚Ä¢ Team Budget for Free Use\n‚Ä¢ Excellent Traffic Connections\n‚Ä¢ No All-In Contracts\n‚Ä¢ Fitness Offers\n‚Ä¢ * Tabletop Soccer, etc.\n‚Ä¢ Massage, Yoga, etc.\n‚Ä¢ Mentor Program\n‚Ä¢ * Coffee, Tea, etc.\n‚Ä¢ Employee Discount\n‚Ä¢ Employee Parking Space\n‚Ä¢ Company Notebook for Private Use\n‚Ä¢ Bicycle Parking Space\n‚Ä¢ * Flexible Working Hours\n‚Ä¢ Educational Leave/Sabbatical\n‚Ä¢ Bonus Payments""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=willhaben&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAII-Qs', 'text': 'See web results for willhaben'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS-uAEWU17wFmc8-7Tz8vHy-H2LE_G8KONTdCQzV_A&s,"['6 days ago', '‚Ç¨52K a year', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTb2Z0d2FyZSBFbmdpbmVlciBEYXRhIFdhcmVob3VzZSIsImh0aWRvY2lkIjoiZzRmNVd2UXRLSEFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1REZ3pOMjlKZEhCVVoxZERhMGw1WkhKdWVYbFplbVZDY0ZjM1ZrNVhlaTFITlRKRGFGVmpkalZvVlVKbGRUUmhXbXBZU0ROemFVdE9VRFJSVWpGeGFsOWZWalZrVjBwaGQwaGZiVXAwVUhoMlNsVkpiWGsyYVRGWVYweFJhRjlTT1RKSVFrMU9VMEprVlRCbmVYZG1OVGRFUTFOSFdIQTRWMUJVTmxWeGMzSkxTRlJrWWxsQ1kxSjBXVkZTWHkxU2FWUnNSazFuU25CUFlrSlRjbUZuWVVGeExYWkhjMmxSZUVsTFdta3hRWGRGRWhkZk4weElXa3BNTkU1T2JXUjNZbXRRWDI5MU1qaEJjeG9pUVV4RlV6bDFUM1kwT1VWelN5MVNaMGhrV0VwS1dWQndZazlTY1RKa2MzWmtkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzciLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iLzI4NjVkMjUwY2U2YWYwYjcwZDJjZGExODVhODY0MzY5P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Junior Data Engineer,solvistas GmbH,"  Vienna, Austria  (+1 other)    ",via DEVjobs.at,"Your role in the team
‚Ä¢ You use methods to check and improve data quality
‚Ä¢ You support the data preparation on the way to harmonization and further processing (cleansing, ingestion, ...)
‚Ä¢ You help your team to develop and optimize reliable data routes (batch processing, streams, ...)
‚Ä¢ You ensure robust CI/CD workflows (Jenkins, Git, ...) and help set up, configure and optimize the infrastructure
‚Ä¢ You support your team in looking after our customers and implementing their wishes
‚Ä¢ You are involved in data modeling and may also want to get involved in data visualization

Technologies and skills
‚Ä¢ Jenkins
‚Ä¢ SQL
‚Ä¢ PL/SQL

Our expectations:

Qualifications
‚Ä¢ SQL/PL-SQL knowledge
‚Ä¢ Very good knowledge of German (level at least B2, oral and written)
‚Ä¢ Curiosity and interest in working with customers

Experience
‚Ä¢ First experience in the DWH area and with different database systems

Education
‚Ä¢ Ongoing or completed technical training (degree, FH, HTL ...) in which you discovered your... interest in data science

Benefits
‚Ä¢ *
‚Ä¢ Fresh Fruit
‚Ä¢ Health Care Benefits
‚Ä¢ Meal Vouchers
‚Ä¢ Flexible Working Hours
‚Ä¢ Excellent Traffic Connections","[{'items': ['Your role in the team\n‚Ä¢ You use methods to check and improve data quality\n‚Ä¢ You support the data preparation on the way to harmonization and further processing (cleansing, ingestion, ...)\n‚Ä¢ You help your team to develop and optimize reliable data routes (batch processing, streams, ...)\n‚Ä¢ You ensure robust CI/CD workflows (Jenkins, Git, ...) and help set up, configure and optimize the infrastructure\n‚Ä¢ You support your team in looking after our customers and implementing their wishes\n‚Ä¢ You are involved in data modeling and may also want to get involved in data visualization\n\nTechnologies and skills\n‚Ä¢ Jenkins\n‚Ä¢ SQL\n‚Ä¢ PL/SQL\n\nOur expectations:\n\nQualifications\n‚Ä¢ SQL/PL-SQL knowledge\n‚Ä¢ Very good knowledge of German (level at least B2, oral and written)\n‚Ä¢ Curiosity and interest in working with customers\n\nExperience\n‚Ä¢ First experience in the DWH area and with different database systems\n\nEducation\n‚Ä¢ Ongoing or completed technical training (degree, FH, HTL ...) in which you discovered your... interest in data science\n\nBenefits\n‚Ä¢ *\n‚Ä¢ Fresh Fruit\n‚Ä¢ Health Care Benefits\n‚Ä¢ Meal Vouchers\n‚Ä¢ Flexible Working Hours\n‚Ä¢ Excellent Traffic Connections']}]","[{'link': 'http://www.solvistas.com/', 'text': 'solvistas.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=solvistas+GmbH&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIrww', 'text': 'See web results for solvistas GmbH'}]",,"['‚Ç¨39,956 a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJKdW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiRXVLcU9lRnd4aHdBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RIZFBibk0xWm1Oc1REZFVTWFpGZVVkcmMwdEVSWHBoTUZZeFVIbzVkREYzVGxWRlpFVkpSMUZmYTNWa2FHeHVMV3R0WW1adVFrNU5jV3hoYkVzd2JqVjNTMVIwY1ZsdlJFaFhRMjVqYW1oS1QwWXpaSFoyUlRscVNFYzRObTE0WmpsRWQybHBjV2gyVG5VeFdFSmxZWEpvT1d0UWJHNVNNazV3TVdGRVVWOW5kVVUwYVZSc05HdHVkbk41ZDI1NGNYWXdZazF4UWxkUVFtZGtaVnBIWVhSTU0yVmZhbGQ1YkZWVGFEQktTVEZGRWhkZk4weElXa3BNTkU1T2JXUjNZbXRRWDI5MU1qaEJjeG9pUVV4RlV6bDFUMmhqTWpsMWJ6UkJVVWRKWkdsd1VXWnllRzVvTjAxWllURlVVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzgiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iLzE3Yzk1YTJkNmEwNDViZTdiYTA3YmFiZWFmYTJkYjQ1P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
General Application Data Engineer (Remote),Z√ºhlke Group, Anywhere ,via Pangian.com,"100% remote job

General Application Data Engineer | Z√ºhlke Group | Austria

Data & AI

We truly appreciate your interest in Z√ºhlke and regret that at the moment we cannot offer you a suitable position in the area of Data. Although, we would appreciate to receive your general application. Forward us your current CV with a short description about your desired activities at Z√ºhlke. We look forward to receiving your online application.

We will contact you as soon as we get an interesting new role that matches your profile in the near future!

What your job will involve:
‚Ä¢ Whether in the cloud or in an on-premise data center: you master the big data world and help our customers to make their own data fit operational business use cases.
‚Ä¢ Your work at Z√ºhlke is varied ‚Äì ranging from designing and implementing data pipelines on common hyperscalers to assessing existing data lake architectures and consulting best practices.
‚Ä¢ You are an important expert for data platforms, keep yourself... informed about trends in the market and always keep an eye on current developments.
‚Ä¢ You develop, test, and monitor distributed data processing pipelines and work closely with our data scientists on the development of data-driven applications.
‚Ä¢ You prepare performance- and cost estimates for various use cases.
‚Ä¢ You develop and create compelling dashboards to visualize the processed data.

What you offer:
‚Ä¢ You don‚Äôt feel intimidated by big data, heterogenous data sources, massively scalable databases, cloud infrastructures, or distributed algorithms.
‚Ä¢ You have a passion for sustainable software development and have already gained several years of experience working in technical roles.
‚Ä¢ In addition to your proficient knowledge of at least one programming language (Python, Java, C#, etc.) you have hands-on experience or a keen interest in data engineering and persistence technologies such as: Airflow, Hadoop, Nifi, Spark, Kafka, Hive, RDBMS and typical NoSQL stores, S3.
‚Ä¢ You have a good understanding of the possibilities of large public cloud environments and preferably have already used MS Azure or Amazon AWS clouds, with the aid of Infrastructure as Code and Continuous Integration & Deployment. Experience with MLOps is a plus.
‚Ä¢ You are a customer-focused team player who is passionate about innovation and agility. You work in a self-organised way from idea to successful implementation.
‚Ä¢ You have a university degree (Uni, FH) in Computer Science, Mathematics or a comparable education
‚Ä¢ Excellent English language skills are required for this position. Fluent command of German would be an advantage.

You can‚Äôt cover everything? No problem. We don‚Äôt expect you to be able to do everything, but rather that you use your knowledge in a targeted manner and communicate with your colleagues and customers on an equal footing. Specialized knowledge is just as important as openness and last but not least your ability and interest in learning and applying new things.

What do we have to offer you?
‚Ä¢ Unique culture: we communicate openly with each other, assess ourselves honestly and enjoy working in a team.
‚Ä¢ Foster ‚Äúon the job‚Äù learning: we are committed to the growth of our people and are investing in their development. We‚Äôre empowering them to build the skills they need to make a positive impact, both personally and for our clients, today and in the future.
‚Ä¢ Good work-life balance: a family-friendly workplace, flexible working hours.
‚Ä¢ A profit share scheme: in addition to your annual salary, you‚Äôll receive a profit share defined by the company‚Äôs success in the previous year.
‚Ä¢ Other benefits: social and employee events including the annual team camp, high-end notebooks.

ATTENTION: Please note, that you are applying for a position in Vienna/Austria.

Are you interested in working with us?

Create your future today and apply for a job at Z√ºhlke!

Vienna , Remote Austria

Apply now

Melisa Hadzimuratovic

Recruiting & Talent Relations

melisa.hadzimuratovic@zuehlke-careers.com

You must have JavaScript enabled to use this form.

First Name

Surname

Email

Phone

Message

Leave this field blank

Mehr anzeigen

Weniger anzeigen

Tagged as: remote, remote job, virtual, Virtual Job, virtual position, Work at Home, work from home","[{'items': ['100% remote job\n\nGeneral Application Data Engineer | Z√ºhlke Group | Austria\n\nData & AI\n\nWe truly appreciate your interest in Z√ºhlke and regret that at the moment we cannot offer you a suitable position in the area of Data. Although, we would appreciate to receive your general application. Forward us your current CV with a short description about your desired activities at Z√ºhlke. We look forward to receiving your online application.\n\nWe will contact you as soon as we get an interesting new role that matches your profile in the near future!\n\nWhat your job will involve:\n‚Ä¢ Whether in the cloud or in an on-premise data center: you master the big data world and help our customers to make their own data fit operational business use cases.\n‚Ä¢ Your work at Z√ºhlke is varied ‚Äì ranging from designing and implementing data pipelines on common hyperscalers to assessing existing data lake architectures and consulting best practices.\n‚Ä¢ You are an important expert for data platforms, keep yourself... informed about trends in the market and always keep an eye on current developments.\n‚Ä¢ You develop, test, and monitor distributed data processing pipelines and work closely with our data scientists on the development of data-driven applications.\n‚Ä¢ You prepare performance- and cost estimates for various use cases.\n‚Ä¢ You develop and create compelling dashboards to visualize the processed data.\n\nWhat you offer:\n‚Ä¢ You don‚Äôt feel intimidated by big data, heterogenous data sources, massively scalable databases, cloud infrastructures, or distributed algorithms.\n‚Ä¢ You have a passion for sustainable software development and have already gained several years of experience working in technical roles.\n‚Ä¢ In addition to your proficient knowledge of at least one programming language (Python, Java, C#, etc.) you have hands-on experience or a keen interest in data engineering and persistence technologies such as: Airflow, Hadoop, Nifi, Spark, Kafka, Hive, RDBMS and typical NoSQL stores, S3.\n‚Ä¢ You have a good understanding of the possibilities of large public cloud environments and preferably have already used MS Azure or Amazon AWS clouds, with the aid of Infrastructure as Code and Continuous Integration & Deployment. Experience with MLOps is a plus.\n‚Ä¢ You are a customer-focused team player who is passionate about innovation and agility. You work in a self-organised way from idea to successful implementation.\n‚Ä¢ You have a university degree (Uni, FH) in Computer Science, Mathematics or a comparable education\n‚Ä¢ Excellent English language skills are required for this position. Fluent command of German would be an advantage.\n\nYou can‚Äôt cover everything? No problem. We don‚Äôt expect you to be able to do everything, but rather that you use your knowledge in a targeted manner and communicate with your colleagues and customers on an equal footing. Specialized knowledge is just as important as openness and last but not least your ability and interest in learning and applying new things.\n\nWhat do we have to offer you?\n‚Ä¢ Unique culture: we communicate openly with each other, assess ourselves honestly and enjoy working in a team.\n‚Ä¢ Foster ‚Äúon the job‚Äù learning: we are committed to the growth of our people and are investing in their development. We‚Äôre empowering them to build the skills they need to make a positive impact, both personally and for our clients, today and in the future.\n‚Ä¢ Good work-life balance: a family-friendly workplace, flexible working hours.\n‚Ä¢ A profit share scheme: in addition to your annual salary, you‚Äôll receive a profit share defined by the company‚Äôs success in the previous year.\n‚Ä¢ Other benefits: social and employee events including the annual team camp, high-end notebooks.\n\nATTENTION: Please note, that you are applying for a position in Vienna/Austria.\n\nAre you interested in working with us?\n\nCreate your future today and apply for a job at Z√ºhlke!\n\nVienna , Remote Austria\n\nApply now\n\nMelisa Hadzimuratovic\n\nRecruiting & Talent Relations\n\nmelisa.hadzimuratovic@zuehlke-careers.com\n\nYou must have JavaScript enabled to use this form.\n\nFirst Name\n\nSurname\n\nEmail\n\nPhone\n\nMessage\n\nLeave this field blank\n\nMehr anzeigen\n\nWeniger anzeigen\n\nTagged as: remote, remote job, virtual, Virtual Job, virtual position, Work at Home, work from home']}]","[{'link': 'http://www.zuehlke.com/', 'text': 'zuehlke.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Z%C3%BChlke+Group&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAII5Aw', 'text': 'See web results for Z√ºhlke Group'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQVFDVG-gfY7OJUE-JAJOp8Uny8-fNx7AG9y4YM0W8&s,"['27 days ago', 'Work from home', 'Full-time']","{'posted_at': '27 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJHZW5lcmFsIEFwcGxpY2F0aW9uIERhdGEgRW5naW5lZXIgKFJlbW90ZSkiLCJodGlkb2NpZCI6IkFlVW03NzQ5TmswQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTamRyZVRsbU9FTkZWMG8yV1dSWVozbENaVms1V1dabU1YVTJOM05SY0VGcU0yWTBVVFpWT0cxdWRrRktSUzF6TVhJeVgyOTBjVXQyUldObWFsVkpNemRoUTA5Q1ZpMHlhVlpZZVZBeVkxWmpZVTk2TFhWdmNVZHBPVUZVVlRRME5tbzRjblZJY0U5UFFtUnlZMVp6ZDB4SFFVNUVjbXQzVDNwWFIzbDBSazVLVm5GT2RVeDFhMXBYWlhabVNETTJjWEo1YWxwUGRGTTRSamh2ZUdwU1VrWlJhMHRwYmxwWFNIbExiREZzUmtKWmVWRTBiREJZYTJ4UmF6VlpaV1l3VXpCdllqaGpFaGRmTjB4SVdrcE1ORTVPYldSM1ltdFFYMjkxTWpoQmN4b2lRVXhGVXpsMVR6UXhSM28wWjJObWMzTldkakpEY0VGZlFtRkNZbXd0YTNSdVp3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTAiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gUGFuZ2lhbi5jb20iLCJsaW5rIjoiaHR0cHM6Ly9wYW5naWFuLmNvbS9qb2IvZ2VuZXJhbC1hcHBsaWNhdGlvbi1kYXRhLWVuZ2luZWVyLXJlbW90ZS8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Reporting-spezialist/in business-intelligence-analyst/in data...,Huk coburg Versicherungsgruppe,"  Vienna, Austria   ",via Jobilize,"QlikView, SQL Server Integration Services, Monitoring, IT, ETL, Datenanalyse, Data Engineering, Berichtswesen, Tableau, Agile Methoden, Power BI, Informatik, SQL, Business Intelligence, Microsoft SQL Server Data Engineer / BI Analyst / Power BI Reporting Specialist:
in Full-time, starting immediately in Coburg, temporary for 2 years.
Experienced professionals and newcomers will find many attractive challenges with us, in addition to a great team of more than 10,000 nice colleagues and over 770 different job profiles that a modern insurance company faces:
Will the car of the future cause fewer accidents? What will old-age provision look like when everyone lives to be 100? We deal with the questions of tomorrow - to provide needs-based coverage for our more than 12 million customers - at our headquarters in Coburg, Upper Franconia, and at our 38 field offices in both the office and the field.
What you can look forward to Responsibility for the conception, creation and further... development of dashboards for the presentation of relevant KPIs.
Continuous optimization of the reporting structure to improve internal processes and control-relevant KPIs.
Design u.
Implementation of requirements from the services as well as analysis and optimization of the corresponding ETL processes.
Elaboration, further development and optimization of a transparent, highly automated performance monitoring.
Cost analysis to control budget compliance and measure actual performance against business plan Measurement of efficiency and effectiveness and preparation of results for different hierarchical levels.
Content support for overarching control processes with internal interfaces and contact:
inside What you bring with you Completed studies in (business) computer science, economics or a comparable field.
First professional experience as a ""Data Engineer"" or in a comparable position in an agile environment desirable Good experience with data visualization tools such as MS Power BI, Tableau, QlikView or similar.
Practical knowledge of using ETL tools, such as SQL Server Integration Services (SSIS).
Strong enthusiasm for numbers and IT as well as strong affinity for data analysis, modeling, visualization.
Strong communication skills, strong ability to self-organize and enjoy working on your own initiative Quick response, decision-making and responsibility with a strong results-oriented approach to work.
What we offer Flexible working:
Flexible working for us means you adjust your working hours to your circumstances.
There is no core or minimum working time with us.
Instead, you perform your workload within a defined working time framework - adapted to local requirements if necessary.
Thanks to mobile work under certain conditions even up to half of the monthly working time from home or on the road.
Family-friendly working:
We attach importance to an optimal compatibility of family and career.
For us, this includes support for childcare and vacation care, as well as care for relatives, as well as the opportunity to take a management position part-time.
Since 2007, the audit berufundfamilie distinguishes us as a family-friendly employer.
Results-oriented remuneration:
in addition to your twelve monthly salaries, you will receive two collectively agreed special payments each year.
And so that performance is also worthwhile, you participate in a performance and results-based remuneration, with the chance to receive more than one additional monthly salary.
Your many years of loyalty to the company will also pay off:
you will receive an anniversary payment, graded according to your length of service.
Lifelong learning:
If you are working on the future, you must not remain in yesterday.
So that you are always up to date, we promote your professional development measures - internally and externally.
However, not only the acquisition of company- or job-specific qualifications is the focus of our training measures, but also the private promotion of individually desired skills - for example, language courses, driving safety training and much more.
Healthy work:
Keep fit and healthy.
We support you with free sports offers in our company-owned sports facilities or a subsidy for your membership in a gym.
Particularly active employees can participate in various HUK sports groups in their free time:
e.g.
running, biking or team sports such as soccer or basketball.
Or learn how to integrate a healthy lifestyle into your everyday life, both professionally and privately, in lectures and seminars.
And because health also concerns nutrition, enjoy healthy and handmade delicacies in our coffee bars or the company restaurant.
Have we piqued your interest? Then apply now! If you have any questions, please do not hesitate to contact Ms.
Uta Orlam√ºnde under the telephone number +49 9561 96-13483, karriere@huk-coburg.de at your disposal","[{'items': ['QlikView, SQL Server Integration Services, Monitoring, IT, ETL, Datenanalyse, Data Engineering, Berichtswesen, Tableau, Agile Methoden, Power BI, Informatik, SQL, Business Intelligence, Microsoft SQL Server Data Engineer / BI Analyst / Power BI Reporting Specialist:\nin Full-time, starting immediately in Coburg, temporary for 2 years.\nExperienced professionals and newcomers will find many attractive challenges with us, in addition to a great team of more than 10,000 nice colleagues and over 770 different job profiles that a modern insurance company faces:\nWill the car of the future cause fewer accidents? What will old-age provision look like when everyone lives to be 100? We deal with the questions of tomorrow - to provide needs-based coverage for our more than 12 million customers - at our headquarters in Coburg, Upper Franconia, and at our 38 field offices in both the office and the field.\nWhat you can look forward to Responsibility for the conception, creation and further... development of dashboards for the presentation of relevant KPIs.\nContinuous optimization of the reporting structure to improve internal processes and control-relevant KPIs.\nDesign u.\nImplementation of requirements from the services as well as analysis and optimization of the corresponding ETL processes.\nElaboration, further development and optimization of a transparent, highly automated performance monitoring.\nCost analysis to control budget compliance and measure actual performance against business plan Measurement of efficiency and effectiveness and preparation of results for different hierarchical levels.\nContent support for overarching control processes with internal interfaces and contact:\ninside What you bring with you Completed studies in (business) computer science, economics or a comparable field.\nFirst professional experience as a ""Data Engineer"" or in a comparable position in an agile environment desirable Good experience with data visualization tools such as MS Power BI, Tableau, QlikView or similar.\nPractical knowledge of using ETL tools, such as SQL Server Integration Services (SSIS).\nStrong enthusiasm for numbers and IT as well as strong affinity for data analysis, modeling, visualization.\nStrong communication skills, strong ability to self-organize and enjoy working on your own initiative Quick response, decision-making and responsibility with a strong results-oriented approach to work.\nWhat we offer Flexible working:\nFlexible working for us means you adjust your working hours to your circumstances.\nThere is no core or minimum working time with us.\nInstead, you perform your workload within a defined working time framework - adapted to local requirements if necessary.\nThanks to mobile work under certain conditions even up to half of the monthly working time from home or on the road.\nFamily-friendly working:\nWe attach importance to an optimal compatibility of family and career.\nFor us, this includes support for childcare and vacation care, as well as care for relatives, as well as the opportunity to take a management position part-time.\nSince 2007, the audit berufundfamilie distinguishes us as a family-friendly employer.\nResults-oriented remuneration:\nin addition to your twelve monthly salaries, you will receive two collectively agreed special payments each year.\nAnd so that performance is also worthwhile, you participate in a performance and results-based remuneration, with the chance to receive more than one additional monthly salary.\nYour many years of loyalty to the company will also pay off:\nyou will receive an anniversary payment, graded according to your length of service.\nLifelong learning:\nIf you are working on the future, you must not remain in yesterday.\nSo that you are always up to date, we promote your professional development measures - internally and externally.\nHowever, not only the acquisition of company- or job-specific qualifications is the focus of our training measures, but also the private promotion of individually desired skills - for example, language courses, driving safety training and much more.\nHealthy work:\nKeep fit and healthy.\nWe support you with free sports offers in our company-owned sports facilities or a subsidy for your membership in a gym.\nParticularly active employees can participate in various HUK sports groups in their free time:\ne.g.\nrunning, biking or team sports such as soccer or basketball.\nOr learn how to integrate a healthy lifestyle into your everyday life, both professionally and privately, in lectures and seminars.\nAnd because health also concerns nutrition, enjoy healthy and handmade delicacies in our coffee bars or the company restaurant.\nHave we piqued your interest? Then apply now! If you have any questions, please do not hesitate to contact Ms.\nUta Orlam√ºnde under the telephone number +49 9561 96-13483, karriere@huk-coburg.de at your disposal']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Huk+coburg+Versicherungsgruppe&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIlw0', 'text': 'See web results for Huk coburg Versicherungsgruppe'}]",,"['3 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '3 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJSZXBvcnRpbmctc3BlemlhbGlzdC9pbiBidXNpbmVzcy1pbnRlbGxpZ2VuY2UtYW5hbHlzdC9pbiBkYXRhIGVuZ2luZWVyIGluZm9ybWF0aWtlci9pbiB3aXJ0c2NoYWYiLCJodGlkb2NpZCI6IkJhQ2M5OEJCOTZnQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0NDcmNDUVUxck1teHNUR3Q2Ukc1Q2VXMWlkVVY2Y1MxeFNGOUVOR3BFU0VoQ2MyWk5ZbFUwUVVRNFVHdHNiVXcyZVdjek9FUnZjalJhYlhwYVpYQm5ia2syWnpoM1pWbGhlVkJmTWxKMFZuZzRRVVZpTTI5bWFtWk9WalY1TjBNMlozZElaR3RhYUY4d1owczJSMUkzTlZoV1MwbFdOMDB6WjNWRlR6ZHRPR1JSTFRCNlltMHpkV3BhUkZsdVRtMUdWbGM1Um5WM1UyazBXVUZoVjFCRGIyeGtjVGxPU1c4eVEwUndSM2h4V2pSMFVHYzFOVEZLVkZadFlXNDVUMFpaVWw5S1dIRnFWR1ZNWkdreU1rSTBZbWhwWTJkWGFHbFdZWGhITFRGUWRFNHhNMDR4ZDJGZlpsTTVVVzl1TkRCdFlraDNWRjgzVldKd1NqZE1TMnh0TmpKTFJtUm9ibWhOUmt0MWFIbGFhRWxRT0hwV2QyRjBPVFZuY0VKSlYwcHlTR042UWpGR01DMUVOVFJPY0dWNVkyNDJkVFp6WkV0VVUwa1NGMTgzVEVoYVNrdzBUazV0WkhkaWExQmZiM1V5T0VGekdpSkJURVZUT1hWUGVtMWtWREV4U1ZSSlpYTlJhV1UzZGtrMVIxZFRaM1ZQZURsUiIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEyIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYmlsaXplIiwibGluayI6Imh0dHBzOi8vd3d3LmpvYmlsaXplLmNvbS9qb2Ivdmllbm5hLXJlcG9ydGluZy1zcGV6aWFsaXN0LWJ1c2luZXNzLWludGVsbGlnZW5jZS1hbmFseXN0LWRhdGEtZW5naW5lZXI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Product Owner - Computer Vision(m/f/d),Sportradar,"  Vienna, Austria   ",via Ai-Jobs.net,"Company DescriptionWe‚Äôre the world‚Äôs leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.Job DescriptionWith computer vision becoming one of the core technologies powering sports data collection and products across sports media, sports betting and coaching solutions, we are looking to expand our automated content product team responsible for building Sportradar's computer vision solutions for automated data collection for racket sports (currently tennis and table tennis). As a product owner in our automated content product team, you will work with an experienced team of computer vision developers, data engineers and data scientists to develop computer vision solution capable of automatically collecting event and tracking data from live tennis and table tennis matches. You... will have to communicate with stakeholders from other teams who are responsible for delivering inputs to your product or are the consumers of your product‚Äôs output. You will also collaborate with other product owners and domain product manager to align product development strategy and wider team goals. THE CHALLENGE: Working closely with senior management to ensure that products fit the company's strategic goals. Working collaboratively to produce and manage the company‚Äôs development roadmap and ensuring that there is always a suitably prioritized backlog of user stories ready for implementation. Being the ambassador for the product and the primary contact for queries relating to the product. Suggesting quality ideas to improve the products and producing user specifications with sufficient details about the product features that can be clearly understood by the development teams. Breaking down the specification into epics/features/user stories with the Agile development team. Understanding the business value behind feature requests and being able to prioritize them in the development backlog. Helping to solve product-related problems and highlighting risks and opportunities. Ensuring that projects stay on track to achieve delivery commitments, including problem-solving and trade-off analysis when necessary. Working with the development team and monitoring the progress of projects during the development cycle to ensure that they have the correct functionality according to the scope. Maintain regular communication with internal and external partners and customers. Taking part in demonstrations of software releases and collecting feedback on improvements for future development. Continually researching the market, our competitors, customer usage behavior and technology trends to ensure that we maintain market-leading products. YOUR PROFILE: Interest in machine learning and computer vision technology. IT-related university degree (BA / MA), or similar. Excellent verbal and written communication skills in English. Great presentation and leadership skills. Fundamental understanding of the research and software development processes. Familiarity with the principles of lean product management. Independent creative and strategic thinker with excellent problem-solving skills. High attention to detail in product design while not losing the big picture. Great organizational and time management skills and the ability to work across different teams. Knowledge of Excel, PowerPoint, Confluence and JIRA. Experience in the sports data collection or computer vision business is considered a plus. OUR OFFER Competitive salary and benefits. Work in an international team collaborating with colleagues from all over the world. Opportunity to work and develop in a dynamic Tech environment within an inspiring and fast-growing company. A challenging but rewarding and fun environment.The minimum monthly salary for this position is according to Collective Bargaining Agreement, over payment will be considered depending on qualifications and working experience.Additional InformationSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences","[{'items': [""Company DescriptionWe‚Äôre the world‚Äôs leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.Job DescriptionWith computer vision becoming one of the core technologies powering sports data collection and products across sports media, sports betting and coaching solutions, we are looking to expand our automated content product team responsible for building Sportradar's computer vision solutions for automated data collection for racket sports (currently tennis and table tennis). As a product owner in our automated content product team, you will work with an experienced team of computer vision developers, data engineers and data scientists to develop computer vision solution capable of automatically collecting event and tracking data from live tennis and table tennis matches. You... will have to communicate with stakeholders from other teams who are responsible for delivering inputs to your product or are the consumers of your product‚Äôs output. You will also collaborate with other product owners and domain product manager to align product development strategy and wider team goals. THE CHALLENGE: Working closely with senior management to ensure that products fit the company's strategic goals. Working collaboratively to produce and manage the company‚Äôs development roadmap and ensuring that there is always a suitably prioritized backlog of user stories ready for implementation. Being the ambassador for the product and the primary contact for queries relating to the product. Suggesting quality ideas to improve the products and producing user specifications with sufficient details about the product features that can be clearly understood by the development teams. Breaking down the specification into epics/features/user stories with the Agile development team. Understanding the business value behind feature requests and being able to prioritize them in the development backlog. Helping to solve product-related problems and highlighting risks and opportunities. Ensuring that projects stay on track to achieve delivery commitments, including problem-solving and trade-off analysis when necessary. Working with the development team and monitoring the progress of projects during the development cycle to ensure that they have the correct functionality according to the scope. Maintain regular communication with internal and external partners and customers. Taking part in demonstrations of software releases and collecting feedback on improvements for future development. Continually researching the market, our competitors, customer usage behavior and technology trends to ensure that we maintain market-leading products. YOUR PROFILE: Interest in machine learning and computer vision technology. IT-related university degree (BA / MA), or similar. Excellent verbal and written communication skills in English. Great presentation and leadership skills. Fundamental understanding of the research and software development processes. Familiarity with the principles of lean product management. Independent creative and strategic thinker with excellent problem-solving skills. High attention to detail in product design while not losing the big picture. Great organizational and time management skills and the ability to work across different teams. Knowledge of Excel, PowerPoint, Confluence and JIRA. Experience in the sports data collection or computer vision business is considered a plus. OUR OFFER Competitive salary and benefits. Work in an international team collaborating with colleagues from all over the world. Opportunity to work and develop in a dynamic Tech environment within an inspiring and fast-growing company. A challenging but rewarding and fun environment.The minimum monthly salary for this position is according to Collective Bargaining Agreement, over payment will be considered depending on qualifications and working experience.Additional InformationSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences""]}]","[{'link': 'http://sportradar.com/', 'text': 'sportradar.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Sportradar&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIzA0', 'text': 'See web results for Sportradar'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS_UXJyALf-Ch_c6AgAYfbJLkAZqV6oiTeUUzRj&s=0,"['18 days ago', '56.7K‚Äì105K a year', 'Full-time']","{'posted_at': '18 days ago', 'schedule_type': 'Full-time', 'salary': '56.7K‚Äì105K a year'}",eyJqb2JfdGl0bGUiOiJQcm9kdWN0IE93bmVyIC0gQ29tcHV0ZXIgVmlzaW9uKG0vZi9kKSIsImh0aWRvY2lkIjoiRzU3RHV6RFI0WTRBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1RHWmFTVWRDWHpSRlZWTkRkMWxhWmtGWWNWVnNkamw0WlZaamVETjVPR1ZVTlVoMlpIWnNObXcyV21sWWFtbGtjM0l4YkhwNlRWSTFXV2xXVjBOcU1tOUllbWQ0T0Rob2NuTnJaVkZ5TUZabGFFdDRRalZXV0VSSGJXNWtlR2RKUTJ0dFEwOWxSakpLZDFvMWVXZEhVMXB1YjNab2FFWjBUemhSTW5aMlUxWk1VVnB1UkRCT0xWZ3pkVTFpUjB0c1FVeG5UbmxHTVVOaFR5MWxiVXhvT1VaUVgyMWhPRm8zUTFCZmQzbFVhSFYzVEhGd2NVZHlNbXhwYXpscGRXbDBlbVF6WDA1aUVoZGZOMHhJV2twTU5FNU9iV1IzWW10UVgyOTFNamhCY3hvaVFVeEZVemwxVDBkQ1YwOUNhM1ZIVjE4NU4xRm1lRFpNUjBOcFNXUnhRemhHZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBBaS1Kb2JzLm5ldCIsImxpbmsiOiJodHRwczovL2FpLWpvYnMubmV0L2pvYi81ODM0Mi1wcm9kdWN0LW93bmVyLWNvbXB1dGVyLXZpc2lvbm1mZC8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer Supply Chain Optimization (f/m/d),ALDI Magyarorsz√°g, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Austria

This offer from ""ALDI Magyarorsz√°g"" has been enriched by Jobgether and got a 77.25% flex score.
How You‚Äôll Make Your Mark

In this position, you‚Äôll‚Ä¶
‚Ä¢ Shape actively the global supply chain of the ALDI SOUTH Group
‚Ä¢ Develop and evaluate different supply chain network scenarios, taking into account national and international market conditions
‚Ä¢ Contribute to data collection, data cleansing and reporting
‚Ä¢ Create decision models using commercial software at a strategic and tactical level in close cooperation with internal and external experts
‚Ä¢ Work on international projects with modern software solutions as well as actively advancing new modelling/simulation issues

Candidate Profile

The requirements for the role are‚Ä¶
‚Ä¢ Completed studies in the field of IT
‚Ä¢ Initial professional experience in the field of data engineering, business intelligence, data science, programming or databases
‚Ä¢ (Python, SQL) is beneficial
‚Ä¢ Very... good English skills
‚Ä¢ An affinity for project work
‚Ä¢ Committed and curious and has pronounced analytical skils
‚Ä¢ Process- and solution-oriented way of working

A Career that Benefits You

Our benefits for you are wide-ranging‚Ä¶
‚Ä¢ 6 weeks of annual leave every year for all
‚Ä¢ A range of subsidised childcare support options
‚Ä¢ Options to work remotely - from home or anywhere within Austria (13 days per month), and from abroad (up to 30 days per year, selected countries)
‚Ä¢ Mobile devices provided to enable flexible working
‚Ä¢ Relocation support (including visas/permits, home search and moving allowance)
‚Ä¢ Free and subsidised healthy food and drinks provided at work
‚Ä¢ Subsidized public transport
‚Ä¢ Bike leasing program to save up to 20% on bike costs to encourage sustainable transport and improve affordability
‚Ä¢ Discounts on a wide range of shopping in the categories like fashion, travel, sports and many more
‚Ä¢ All the training you need to excel in your role
‚Ä¢ Extensive personal and professional development
‚Ä¢ High level of responsibility in a diverse and international business environment
‚Ä¢ Collaboration with teams across borders

Remuneration

Gross annual salary starting from ‚Ç¨ 49,200.-*
‚Ä¢ willingness to overpay with appropriate qualification

Place of work

‚Äã4653 Eberstalzell, Solarstra√üe 7‚Äã

Start of work

‚ÄãAs soon as possible‚Äã

How to Apply

All applications take place through our online portal. Simply log on and submit your CV, photo, and all relevant certificates/qualifications","[{'items': ['This a Full Remote job, the offer is available from: Austria\n\nThis offer from ""ALDI Magyarorsz√°g"" has been enriched by Jobgether and got a 77.25% flex score.\nHow You‚Äôll Make Your Mark\n\nIn this position, you‚Äôll‚Ä¶\n‚Ä¢ Shape actively the global supply chain of the ALDI SOUTH Group\n‚Ä¢ Develop and evaluate different supply chain network scenarios, taking into account national and international market conditions\n‚Ä¢ Contribute to data collection, data cleansing and reporting\n‚Ä¢ Create decision models using commercial software at a strategic and tactical level in close cooperation with internal and external experts\n‚Ä¢ Work on international projects with modern software solutions as well as actively advancing new modelling/simulation issues\n\nCandidate Profile\n\nThe requirements for the role are‚Ä¶\n‚Ä¢ Completed studies in the field of IT\n‚Ä¢ Initial professional experience in the field of data engineering, business intelligence, data science, programming or databases\n‚Ä¢ (Python, SQL) is beneficial\n‚Ä¢ Very... good English skills\n‚Ä¢ An affinity for project work\n‚Ä¢ Committed and curious and has pronounced analytical skils\n‚Ä¢ Process- and solution-oriented way of working\n\nA Career that Benefits You\n\nOur benefits for you are wide-ranging‚Ä¶\n‚Ä¢ 6 weeks of annual leave every year for all\n‚Ä¢ A range of subsidised childcare support options\n‚Ä¢ Options to work remotely - from home or anywhere within Austria (13 days per month), and from abroad (up to 30 days per year, selected countries)\n‚Ä¢ Mobile devices provided to enable flexible working\n‚Ä¢ Relocation support (including visas/permits, home search and moving allowance)\n‚Ä¢ Free and subsidised healthy food and drinks provided at work\n‚Ä¢ Subsidized public transport\n‚Ä¢ Bike leasing program to save up to 20% on bike costs to encourage sustainable transport and improve affordability\n‚Ä¢ Discounts on a wide range of shopping in the categories like fashion, travel, sports and many more\n‚Ä¢ All the training you need to excel in your role\n‚Ä¢ Extensive personal and professional development\n‚Ä¢ High level of responsibility in a diverse and international business environment\n‚Ä¢ Collaboration with teams across borders\n\nRemuneration\n\nGross annual salary starting from ‚Ç¨ 49,200.-*\n‚Ä¢ willingness to overpay with appropriate qualification\n\nPlace of work\n\n\u200b4653 Eberstalzell, Solarstra√üe 7\u200b\n\nStart of work\n\n\u200bAs soon as possible\u200b\n\nHow to Apply\n\nAll applications take place through our online portal. Simply log on and submit your CV, photo, and all relevant certificates/qualifications']}]","[{'link': 'http://www.aldi.hu/', 'text': 'aldi.hu'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=ALDI+Magyarorsz%C3%A1g&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIIgQ4', 'text': 'See web results for ALDI Magyarorsz√°g'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQjv2fAbKHZQsgStSBV1t8pZrA0p9LaaodJ3RqTh5o&s,"['Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIFN1cHBseSBDaGFpbiBPcHRpbWl6YXRpb24gKGYvbS9kKSIsImh0aWRvY2lkIjoiVXJWZlN0bDlYX2NBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXJjQ0N2Y0JRVTFyTW14c1NtdHFhbEpOY25aYWVXTlpTbGQwUVZWRGNWbHBNWHBPTVdoelpVMVBhM2MxVEVzNVJsbFpaWGhYVGtGSGVFVk5VVE5OTW1KbVpYSXRRbUZIWTJWNVdIZG9XSE4zZVZsNlFsRkZOV1ozTnpacFZuaHVkek01ZWtoQlNuRkhSR1ZFTmpjelkxWkNOamR1VDBaR1NqUlBXVFZLVkZaV2RUZzFUazlOV0VoR1dGWkplbTFzWXpreWN6bHZiSFpaY3pCNmJEQTNWMjVsVlZOVmVtWkVNRWhPUVRkSmRtWXhSbVZITTJVNGFGaDBXbVU1V2pkdmJteEtPVXBXWnpoV1RsUmpPVkl5YVhaRlFUSlJRVTFmYjJJMFdXTnlTbTFXZFhOeE9WOTZRMGRVVlhsbFJ6UlljakJxTTI5M2RXOXhhbkV6YXhJWFh6ZE1TRnBLVERST1RtMWtkMkpyVUY5dmRUSTRRWE1hSWtGTVJWTTVkVTk1TTFCdU9GcE1YMnh5U1cxdlMwOXFRMGRTV2pBMWFFcG5UMmMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JnZXRoZXIiLCJsaW5rIjoiaHR0cHM6Ly9qb2JnZXRoZXIuY29tL29mZmVyLzY0OWIzNjJlNTE1MzYwYTA3Yjc3YjBlMC1kYXRhLWVuZ2luZWVyLXN1cHBseS1jaGFpbi1vcHRpbWl6YXRpb24tZm1kP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer,Capgemini,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ You are responsible for the design through to the implementation of data pipelines and data integration solutions (ELT/ETL).
‚Ä¢ You model and develop data storage solutions (data warehouse, data lake, etc.) to process large amounts of data
‚Ä¢ You drive the conception and further development of company-wide data platforms

Technologies and skills
‚Ä¢ C#
‚Ä¢ Power BI
‚Ä¢ Apache Spark
‚Ä¢ Apache Kafka
‚Ä¢ SQL
‚Ä¢ Python
‚Ä¢ Azure
‚Ä¢ AWS
‚Ä¢ Google Cloud Platform
‚Ä¢ Scala

Our expectations:

Qualifications
‚Ä¢ very good knowledge of SQL
‚Ä¢ very good knowledge of Python
‚Ä¢ Interest in technology trends and enjoy constantly learning new things
‚Ä¢ Business fluent knowledge of English and good knowledge of German
‚Ä¢ Ability to work in a team and convincing communication skills
‚Ä¢ Excellent analytical skills and a proactive way of working
‚Ä¢ Openness to possible international project assignments The following skills would be an advantage
‚Ä¢ Knowledge in the field of automation (CI/CD) and DevOps or... approaches such as DataOps, MLOps
‚Ä¢ Programming skills in other languages such as Scala or C#
‚Ä¢ Understanding of data science and AI and the resulting requirements for a data platform

Experience
‚Ä¢ several years of professional experience (3+ years) as a software developer or data engineer/ data warehouse engineer
‚Ä¢ Experience with data in the cloud, preferably Azure (AWS, Google Cloud)
‚Ä¢ Know-how and practical experience in data modeling (Kimball, DataVault) and in the implementation of DWH solutions
‚Ä¢ Experience with a data visualization tool (PowerBI, Tableau)
‚Ä¢ Experience with Big Data (Spark, Kafka, etc.)
‚Ä¢ Experience in (partial) project management

Education
‚Ä¢ Completed economic or technical studies (computer science, business informatics, mathematics, physics or a comparable course)

Benefits
‚Ä¢ * Massage, Yoga, etc.
‚Ä¢ * Company Notebook for Private Use
‚Ä¢ Meal Vouchers","[{'items': ['Your role in the team\n‚Ä¢ You are responsible for the design through to the implementation of data pipelines and data integration solutions (ELT/ETL).\n‚Ä¢ You model and develop data storage solutions (data warehouse, data lake, etc.) to process large amounts of data\n‚Ä¢ You drive the conception and further development of company-wide data platforms\n\nTechnologies and skills\n‚Ä¢ C#\n‚Ä¢ Power BI\n‚Ä¢ Apache Spark\n‚Ä¢ Apache Kafka\n‚Ä¢ SQL\n‚Ä¢ Python\n‚Ä¢ Azure\n‚Ä¢ AWS\n‚Ä¢ Google Cloud Platform\n‚Ä¢ Scala\n\nOur expectations:\n\nQualifications\n‚Ä¢ very good knowledge of SQL\n‚Ä¢ very good knowledge of Python\n‚Ä¢ Interest in technology trends and enjoy constantly learning new things\n‚Ä¢ Business fluent knowledge of English and good knowledge of German\n‚Ä¢ Ability to work in a team and convincing communication skills\n‚Ä¢ Excellent analytical skills and a proactive way of working\n‚Ä¢ Openness to possible international project assignments The following skills would be an advantage\n‚Ä¢ Knowledge in the field of automation (CI/CD) and DevOps or... approaches such as DataOps, MLOps\n‚Ä¢ Programming skills in other languages such as Scala or C#\n‚Ä¢ Understanding of data science and AI and the resulting requirements for a data platform\n\nExperience\n‚Ä¢ several years of professional experience (3+ years) as a software developer or data engineer/ data warehouse engineer\n‚Ä¢ Experience with data in the cloud, preferably Azure (AWS, Google Cloud)\n‚Ä¢ Know-how and practical experience in data modeling (Kimball, DataVault) and in the implementation of DWH solutions\n‚Ä¢ Experience with a data visualization tool (PowerBI, Tableau)\n‚Ä¢ Experience with Big Data (Spark, Kafka, etc.)\n‚Ä¢ Experience in (partial) project management\n\nEducation\n‚Ä¢ Completed economic or technical studies (computer science, business informatics, mathematics, physics or a comparable course)\n\nBenefits\n‚Ä¢ * Massage, Yoga, etc.\n‚Ä¢ * Company Notebook for Private Use\n‚Ä¢ Meal Vouchers']}]","[{'link': 'http://www.capgemini.com/', 'text': 'capgemini.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Capgemini&sa=X&ved=0ahUKEwjS88LYgrmAAxXZTjABHf6FDb44MhCYkAIItg4', 'text': 'See web results for Capgemini'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRwQjOPvV-LCr6vXzXmfGhT44dW61QQAB_S5f39&s=0,"['‚Ç¨55K a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiXzItQ2VXR1dLaEFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RIbEJiMnBKZUhWbFUzTlpRemRLUkhwck5qTnRRemROTUdoUloxaHRaVnBNWVVkblFXaExNak5GV2xFeE1VcDNjV0ZxVnpSalExWXRNRGxXWmtsQlRUSnFMVkZ6ZWxCcFlrRTBWMTltY1ZoMVJrYzFhRzF3VUdweVRERmZTV1ZTUkUxT1dVTkdOa3AxVG1VMVZFbDNlamx6WWsxSk5XbDFiR1V6YTNaRk5GaE1PR3A1ZVRsdFJsVklOVU5NZVd4R1IxZHhlUzFJTmw5UGNXbHNjazlFZEhKTGJXeDBjSEJMWWpOT1pESjRPVTF6RWhkZk4weElXa3BNTkU1T2JXUjNZbXRRWDI5MU1qaEJjeG9pUVV4RlV6bDFUMjF5Y1VSZmJHaHJRbU5JYTJ0NVVYbHpPVlpRVDFaNFMwZEJVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzE3IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIERFVmpvYnMuYXQiLCJsaW5rIjoiaHR0cHM6Ly9lbi5kZXZqb2JzLmF0L2pvYi81NzA4NTgzNjgwMDA5MjExMD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (f/m/x),IBM iX,"  Vienna, Austria   ",via Adzuna.at,"IBM iX - It's never been a better time to be a creator.

We are a consultancy, digital agency, design studio, and tech company all rolled into one. Our 1,200+ experts in DACH and Croatia guide people, brands, and organisations in an agile and collaborative way: from analysis and concept via business case, design vision, and MVP development to roll-out and operations. We believe ""Good Experience is Good Business"". That's why we put human experiences first in everything we do. Together we help to shape a sustainable future: with digital products, services, and experiences that connect people.

You feel at home in the world of digital trends and love to drive projects with real impact? Then become a part of our IBM iX Team now.

Your Responsibilities
‚Ä¢ You implement data models and manage data imports in Customer Data and Marketing Automation Platforms
‚Ä¢ You configure data pre-processing tasks as well as workflows in dedicated ETL solutions and define ETL/LTE rules for data processing
‚Ä¢... You adjust and extend the data model based on changing requirements and use cases
‚Ä¢ You are responsible for validating the quality of data and troubleshooting if needed
‚Ä¢ You are working closely with the Data Architect on designing logical data models
‚Ä¢ You support with the integration of Customer Data Platforms with BI solutions (Tableau, MicroStrategy, Microsoft BI etc.)

Your Skills
‚Ä¢ You have hands-on experience with relational database management and SQL/PLSQL/TSQL
‚Ä¢ You have already worked with consumption of REST APIs and supporting tools (e.g. Postman, etc.)
‚Ä¢ Knowledge of cloud-based data storage solutions (e.g. Amazon S3, Google Cloud Storage, Redshift, DynamoDB, Snowflake, Databricks, etc.)
‚Ä¢ You are skilled in using event streaming technologies (e.g. Kafka, Solace) and ETL tools (e.g. Informatica, Pentaho, etc.)
‚Ä¢ Practical experience in Python development (or similar programming language - e.g. Java) and knowledge of versioning control systems is a plus
‚Ä¢ You have good presentation and communication skills in English (at least C1), German is a plus

Our Benefits and Your Perspective

In order to bring our visionary ideas to life, we need high-flyers from a wide variety of fields who can cope with fast-paced digital expansion. Our Academy supports this in combination with various offers for our employees.
‚Ä¢ Academy & Co.
‚Ä¢ Discount programs
‚Ä¢ Coaching
‚Ä¢ Health & Fitness
‚Ä¢ Team events
‚Ä¢ Flexible working hours
‚Ä¢ 30 days of vacation

With us, you can shape your career yourself and benefit from our Academy training portfolio: we work with career pathways, 360¬∞ feedback and development plans to give our employees the best possible training opportunities.

We offer you a salary above minimum wage in keeping with the market. For legal reasons we would like to state that the minimum gross annual salary set by the collective bargaining agreement (KV) is EUR 44.660.

IBM iX is committed to creating an inclusive workplace offering equal opportunities to everyone. We especially encourage all people with their individual diverse backgrounds and perspectives to apply.

Questions about the job?

Please do not hesitate to contact:

Jil Perdacher

Talent Acquisition Consultant

+43 676 3205895

jil.perdacher@ibmix.at

Details √ºber diese Stelle
‚Ä¢ Titel: Data Engineer (f/m/x)
‚Ä¢ Kategorie(n): Technology
‚Ä¢ Art der Anstellung: Fulltime
‚Ä¢ Unternehmen: IBM iX austria GmbH
‚Ä¢ Standort(e): Graz, Home Office (Hybrid), Wels, Wien
‚Ä¢ Land: √ñsterreich
‚Ä¢ Job-ID: r817

Stellenangebot teilen","[{'items': ['IBM iX - It\'s never been a better time to be a creator.\n\nWe are a consultancy, digital agency, design studio, and tech company all rolled into one. Our 1,200+ experts in DACH and Croatia guide people, brands, and organisations in an agile and collaborative way: from analysis and concept via business case, design vision, and MVP development to roll-out and operations. We believe ""Good Experience is Good Business"". That\'s why we put human experiences first in everything we do. Together we help to shape a sustainable future: with digital products, services, and experiences that connect people.\n\nYou feel at home in the world of digital trends and love to drive projects with real impact? Then become a part of our IBM iX Team now.\n\nYour Responsibilities\n‚Ä¢ You implement data models and manage data imports in Customer Data and Marketing Automation Platforms\n‚Ä¢ You configure data pre-processing tasks as well as workflows in dedicated ETL solutions and define ETL/LTE rules for data processing\n‚Ä¢... You adjust and extend the data model based on changing requirements and use cases\n‚Ä¢ You are responsible for validating the quality of data and troubleshooting if needed\n‚Ä¢ You are working closely with the Data Architect on designing logical data models\n‚Ä¢ You support with the integration of Customer Data Platforms with BI solutions (Tableau, MicroStrategy, Microsoft BI etc.)\n\nYour Skills\n‚Ä¢ You have hands-on experience with relational database management and SQL/PLSQL/TSQL\n‚Ä¢ You have already worked with consumption of REST APIs and supporting tools (e.g. Postman, etc.)\n‚Ä¢ Knowledge of cloud-based data storage solutions (e.g. Amazon S3, Google Cloud Storage, Redshift, DynamoDB, Snowflake, Databricks, etc.)\n‚Ä¢ You are skilled in using event streaming technologies (e.g. Kafka, Solace) and ETL tools (e.g. Informatica, Pentaho, etc.)\n‚Ä¢ Practical experience in Python development (or similar programming language - e.g. Java) and knowledge of versioning control systems is a plus\n‚Ä¢ You have good presentation and communication skills in English (at least C1), German is a plus\n\nOur Benefits and Your Perspective\n\nIn order to bring our visionary ideas to life, we need high-flyers from a wide variety of fields who can cope with fast-paced digital expansion. Our Academy supports this in combination with various offers for our employees.\n‚Ä¢ Academy & Co.\n‚Ä¢ Discount programs\n‚Ä¢ Coaching\n‚Ä¢ Health & Fitness\n‚Ä¢ Team events\n‚Ä¢ Flexible working hours\n‚Ä¢ 30 days of vacation\n\nWith us, you can shape your career yourself and benefit from our Academy training portfolio: we work with career pathways, 360¬∞ feedback and development plans to give our employees the best possible training opportunities.\n\nWe offer you a salary above minimum wage in keeping with the market. For legal reasons we would like to state that the minimum gross annual salary set by the collective bargaining agreement (KV) is EUR 44.660.\n\nIBM iX is committed to creating an inclusive workplace offering equal opportunities to everyone. We especially encourage all people with their individual diverse backgrounds and perspectives to apply.\n\nQuestions about the job?\n\nPlease do not hesitate to contact:\n\nJil Perdacher\n\nTalent Acquisition Consultant\n\n+43 676 3205895\n\njil.perdacher@ibmix.at\n\nDetails √ºber diese Stelle\n‚Ä¢ Titel: Data Engineer (f/m/x)\n‚Ä¢ Kategorie(n): Technology\n‚Ä¢ Art der Anstellung: Fulltime\n‚Ä¢ Unternehmen: IBM iX austria GmbH\n‚Ä¢ Standort(e): Graz, Home Office (Hybrid), Wels, Wien\n‚Ä¢ Land: √ñsterreich\n‚Ä¢ Job-ID: r817\n\nStellenangebot teilen']}]","[{'link': 'http://www-935.ibm.com/services/in/gbs/interactive', 'text': 'www-935.ibm.com/services/in/gbs/interactive'}, {'link': 'https://www.google.com/search?q=IBM+iX&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAII4wo', 'text': 'See web results for IBM iX'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnUJNDjfmcL-P_2Ipf6ZuX_sSTbupiYKbXSKkI&s=0,"['2 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChmL20veCkiLCJodGlkb2NpZCI6InJpS3ZaUTVJaC1NQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTVTVDTTJSVVVEZEhPRnAyV2t4UE0ydGhWa2xqUTBJeFUyVklPV2xqWjJreGVtazFWWEJrVTNOUFoydEpiRXA2WW1kME1EVmZZa1pNWmxkSFdrY3pWbU15YW5Gc2FtMXBRbmxJYmxOc2NWb3RibmhrTUZwTU4xaEZSR2sxV21KNk16UlJXbFpuVjFOdlREQjRVMDFFTTFsMFkzRjRSbFpyTVdsMU5qaGpSRTFDUjFSa1YwaHphbkp1UWpGVFgwSjRXRFpzU1dwRVEyaFZaVWN5U1VkZk5FaHZSRTlYVEMxbVpsZERlbFZJT0d0WkVoZENZbEJJV2sxSVIwNVFMV2sxVG05UWFtWkRNbmxCVFJvaVFVeEZVemwxVG5kaGVsbERjWEIwYUdkMVNXUkNZVWhPTm5kNk4zQnpjVWh6VVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIEFkenVuYS5hdCIsImxpbmsiOiJodHRwczovL3d3dy5hZHp1bmEuYXQvZGV0YWlscy80MjMyNTMyMDI4P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Job in Germany: Data Scientist / Engineer (m/w/d),elobau GmbH & Co. KG,"  Vienna, Austria   ",via Recruit.net,"Data Scientist / Engineer (m/f/d) As a family-run foundation company with around 950 employees worldwide, we develop and manufacture sensor technology for mechanical engineering and vehicle systems for the commercial vehicle industry. Our quality products are characterized by a very high vertical range of manufacture and are produced climate neutrally in the Allg√§u region. For us, the maxim ""people in focus"" applies and sustainability has top priority. That is why we publish a common good economy report. What to expect from us As a Data Scientist / Engineer you will be responsible for building and managing our business intelligence landscape responsible Using machine learning and AI methods, you will analyze complex data and put the data sets Interdepartmentally available to your colleagues. You create algorithms for monitoring and optimizing our processes and facilities, paying particular attention to the efficiency of these You elaborate and implement new approaches and... technologies, and develop forecasting tools based on operational data in interdisciplinary teams Your colleagues can rely on your support in the creation of reports and our external service providers from the field of business intelligence can not wish for a better contact person What you bring to the table You have a degree in statistics, business information systems, data science or a comparable Education and could already gain experience in a comparable position Your already acquired knowledge from data analytics, in the development and implementation of algorithms as well as about artificial intelligence, machine learning, data science and data engineering facilitate your entry immensely You have already been able to gain experience in architecture design in the field of business intelligence, which means that you already have Knowledge in common BI tools could attain In the preparation and analysis of structured as well as unstructured data from different sources makes You no one what vor In German and English you communicate confidently in speech and writing What you can look forward to Basic remuneration in line with the market incl. 13th month salary and voluntary profit-sharing. Flexible working hours as well as lifetime working time account Modern working environment Individual training opportunities Company pension plan and capital-forming benefits Support for childcare during the vacations Social counseling in the company Occupational health management Subsidized EGYM Wellpass membership Complimentary water and coffee and fresh fruit daily Company parties 85% of our employees say that elobau is a very good employer (study Great Place to Work 2019). We look forward to your complete application documents, indicating the possible start date and your salary expectations. Please send us your application in PDF format (max. 8 MB) via our online portal. Our human resources department will be happy to answer any questions you may have","[{'items': ['Data Scientist / Engineer (m/f/d) As a family-run foundation company with around 950 employees worldwide, we develop and manufacture sensor technology for mechanical engineering and vehicle systems for the commercial vehicle industry. Our quality products are characterized by a very high vertical range of manufacture and are produced climate neutrally in the Allg√§u region. For us, the maxim ""people in focus"" applies and sustainability has top priority. That is why we publish a common good economy report. What to expect from us As a Data Scientist / Engineer you will be responsible for building and managing our business intelligence landscape responsible Using machine learning and AI methods, you will analyze complex data and put the data sets Interdepartmentally available to your colleagues. You create algorithms for monitoring and optimizing our processes and facilities, paying particular attention to the efficiency of these You elaborate and implement new approaches and... technologies, and develop forecasting tools based on operational data in interdisciplinary teams Your colleagues can rely on your support in the creation of reports and our external service providers from the field of business intelligence can not wish for a better contact person What you bring to the table You have a degree in statistics, business information systems, data science or a comparable Education and could already gain experience in a comparable position Your already acquired knowledge from data analytics, in the development and implementation of algorithms as well as about artificial intelligence, machine learning, data science and data engineering facilitate your entry immensely You have already been able to gain experience in architecture design in the field of business intelligence, which means that you already have Knowledge in common BI tools could attain In the preparation and analysis of structured as well as unstructured data from different sources makes You no one what vor In German and English you communicate confidently in speech and writing What you can look forward to Basic remuneration in line with the market incl. 13th month salary and voluntary profit-sharing. Flexible working hours as well as lifetime working time account Modern working environment Individual training opportunities Company pension plan and capital-forming benefits Support for childcare during the vacations Social counseling in the company Occupational health management Subsidized EGYM Wellpass membership Complimentary water and coffee and fresh fruit daily Company parties 85% of our employees say that elobau is a very good employer (study Great Place to Work 2019). We look forward to your complete application documents, indicating the possible start date and your salary expectations. Please send us your application in PDF format (max. 8 MB) via our online portal. Our human resources department will be happy to answer any questions you may have']}]","[{'link': 'http://www.elobau.com/', 'text': 'elobau.com'}, {'link': 'https://www.google.com/search?q=elobau+GmbH+%26+Co.+KG&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIIlws', 'text': 'See web results for elobau GmbH & Co. KG'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRwIHE72UF0OAPrPDZkFYzpx-W8h-a7BrDCQERR024&s,"['2 days ago', 'Full-time']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJKb2IgaW4gR2VybWFueTogRGF0YSBTY2llbnRpc3QgLyBFbmdpbmVlciAobS93L2QpIiwiaHRpZG9jaWQiOiJKV2dUTTFoSUZGZ0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcmNDQ3ZjQlFVMXJNbXhzU2xwcU1FcHJTMmgyY2xKclFuVnJVbFpoT0hVNU4xVkphekJzWnpOaVRFSnZNRmRhTUZoelMwY3dUbkY1WTJWUmQwZGlVRGRTT0hWT1dEaE1SVVUyYnpkZmNUUktlbDlhU25CaVIzbG5jRmRIYTBKNGJuaFNTVWxVTWtoNFJreHFSbTFsZVRkMGVVOUZNMjV2VjBSUFFYZFpkRVJ0VTFWWVVraFdNSFo1U0RSelQwTjBWVGMxTjNGV2FtcFBlVE40ZUhwd1pGZExRa0p5VFhKWFdWSXdNekZZU20xRlh6QmtjMVJEVWpOWWMweGlaRlJyWW5sbVRYQkVXazlEVFd0bmIycExaRjlCZEZkRk0zY3RNblZhYlZndFdGQktZM1pVTkhKamMyVm9WamxLTWtOalVuZFZNVzlmWDFCMVptTm9ZeElYUW1KUVNGcE5TRWRPVUMxcE5VNXZVR3BtUXpKNVFVMGFJa0ZNUlZNNWRVMWpRMnBZY1hCZlJrYzNUVWRpTUZGVGJsUXpVVzl0UlU5emJtYyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gUmVjcnVpdC5uZXQiLCJsaW5rIjoiaHR0cHM6Ly93d3cucmVjcnVpdC5uZXQvam9iL2VuZ2luZWVyLWpvYnMvQTQyMDhFMjc3MzAwRTYzMT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer,Neko Health, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe

This offer from ""Neko Health"" has been enriched by Jobgether and got a 72% flex score.

Join Neko Health as a Senior Data Engineer and make a difference in the health-tech industry! We're looking for an imaginative and talented individual who is eager to help us develop and operate our secure, world-scale, and performant health data platform.

For regulatory and legal reasons we are only looking for people that live in the EU.

About Neko Health

Neko Health is a Swedish health-tech company co-founded in 2018 by Hjalmar Nilsonne and Daniel Ek. Our vision is to create a healthcare system that can help people stay healthy through preventive measures and early detection. Neko has developed a new medical scanning technology concept to make it possible to do broad and non-invasive health data collection that is both convenient and affordable for the public. This requires completely reimagining the healthcare experience and... incorporating the latest advances in sensors and AI. We are a remote first company, but the company is based in Stockholm and has 40 employees across Europe.
About the role

We are currently in search of a highly skilled and experienced hands-on data engineer to join our esteemed team of algorithm and machine learning experts. Our teams are dedicated to developing cutting-edge algorithms and machine learning services for cardio, tissue, skin, and body assessment, leveraging the data from Neko Health body scans. The secure and reliable handling of substantial volumes of data from each scan, as well as the subsequent data processing, are vital to the success of our business.
What we are looking for

The ideal candidate for this role possesses broad expertise in Big Data and cloud infrastructure for machine learning services and data pipelines and a strong background in software development. This includes a proven track record of designing, operating, and enhancing infrastructure for machine learning services, as well as the design and implementation of robust data pipelines and dashboards.

Our health data platform is cloud native, and thus, we require a deep understanding of cloud platforms such as Azure, AWS, or GCP, coupled with proficiency in tools like Docker and Kubernetes. Candidates with specific experience in Azure and Databricks will be highly regarded for this position.

While a perfect match between your skillset and our technology stack is not essential, we place great value on your willingness and ability to learn and grow within our organization. We highly appreciate individuals with exceptional analytical and problem-solving skills, as well as a strong aptitude for thriving in a fast-paced environment. Given our remote-first work environment and cross-functional collaborations, strong communication skills and effective teamwork are essential.

If you meet these requirements and possess a genuine passion for working with data, we enthusiastically encourage you to apply for this exciting opportunity to contribute to our data-driven culture. Join our dynamic team and play a pivotal role in driving innovation through robust data engineering and machine learning infrastructure.

About the Engineering Team

Distributed and Remote First

We are 40 full time engineers at the company, working from Berlin, Chamonix, Hamburg, Lisbon, Marseille, Vilnius, and Stockholm and spanning diverse disciplines such as Hardware Engineering, Firmware Development, Electrical Design, Algorithm Development, Machine Learning Development, Optronics Research, Frontend Development and more.

Our headquarters and our hardware development team are in Stockholm, Sweden.

We are a Remote First company; however, it is of course much easier to work remotely as a software engineer than a hardware or firmware engineer (since they require access to hardware or devices occasionally). Software engineers based in Stockholm work maybe one day a week or one day every two weeks from the office.

We meet a couple of times per year to get to know each other and have fun.

Organization and Way of Working

The engineering team is divided into smaller cross functional project teams that each focus on a specific goal or target, where some groups are long-lived, and some are short-lived, depending on how big the goal or deliverable is. We strive to create groups which are cross-functional and able to complete their goals without dependence on other teams, even though this is of course not always possible.

Groups track goals on a yearly and quarterly basis with goal follow-up across the entire engineering organization on a bi-weekly basis.

Most groups do internal planning on a bi-weekly basis, but in the end it's up to the group to decide how they want to work.

We have, however, mandated that all groups must present their progress or failures or hacks at our bi-weekly engineering demo, a fun meeting/presentation where we talk about everything from short-circuiting power-modules, how hard it is to calibrate cameras or align polygons in space, to neat new command line tools for operations, a new auth mechanism in the backend, a cool new way to visualize health data or a new feature which helps our doctors be more productive.

We have a flexible workplace that focuses on work/life balance, and we strongly believe in our mission but do not think that achieving it requires sacrificing everything else","[{'items': ['This a Full Remote job, the offer is available from: Europe\n\nThis offer from ""Neko Health"" has been enriched by Jobgether and got a 72% flex score.\n\nJoin Neko Health as a Senior Data Engineer and make a difference in the health-tech industry! We\'re looking for an imaginative and talented individual who is eager to help us develop and operate our secure, world-scale, and performant health data platform.\n\nFor regulatory and legal reasons we are only looking for people that live in the EU.\n\nAbout Neko Health\n\nNeko Health is a Swedish health-tech company co-founded in 2018 by Hjalmar Nilsonne and Daniel Ek. Our vision is to create a healthcare system that can help people stay healthy through preventive measures and early detection. Neko has developed a new medical scanning technology concept to make it possible to do broad and non-invasive health data collection that is both convenient and affordable for the public. This requires completely reimagining the healthcare experience and... incorporating the latest advances in sensors and AI. We are a remote first company, but the company is based in Stockholm and has 40 employees across Europe.\nAbout the role\n\nWe are currently in search of a highly skilled and experienced hands-on data engineer to join our esteemed team of algorithm and machine learning experts. Our teams are dedicated to developing cutting-edge algorithms and machine learning services for cardio, tissue, skin, and body assessment, leveraging the data from Neko Health body scans. The secure and reliable handling of substantial volumes of data from each scan, as well as the subsequent data processing, are vital to the success of our business.\nWhat we are looking for\n\nThe ideal candidate for this role possesses broad expertise in Big Data and cloud infrastructure for machine learning services and data pipelines and a strong background in software development. This includes a proven track record of designing, operating, and enhancing infrastructure for machine learning services, as well as the design and implementation of robust data pipelines and dashboards.\n\nOur health data platform is cloud native, and thus, we require a deep understanding of cloud platforms such as Azure, AWS, or GCP, coupled with proficiency in tools like Docker and Kubernetes. Candidates with specific experience in Azure and Databricks will be highly regarded for this position.\n\nWhile a perfect match between your skillset and our technology stack is not essential, we place great value on your willingness and ability to learn and grow within our organization. We highly appreciate individuals with exceptional analytical and problem-solving skills, as well as a strong aptitude for thriving in a fast-paced environment. Given our remote-first work environment and cross-functional collaborations, strong communication skills and effective teamwork are essential.\n\nIf you meet these requirements and possess a genuine passion for working with data, we enthusiastically encourage you to apply for this exciting opportunity to contribute to our data-driven culture. Join our dynamic team and play a pivotal role in driving innovation through robust data engineering and machine learning infrastructure.\n\nAbout the Engineering Team\n\nDistributed and Remote First\n\nWe are 40 full time engineers at the company, working from Berlin, Chamonix, Hamburg, Lisbon, Marseille, Vilnius, and Stockholm and spanning diverse disciplines such as Hardware Engineering, Firmware Development, Electrical Design, Algorithm Development, Machine Learning Development, Optronics Research, Frontend Development and more.\n\nOur headquarters and our hardware development team are in Stockholm, Sweden.\n\nWe are a Remote First company; however, it is of course much easier to work remotely as a software engineer than a hardware or firmware engineer (since they require access to hardware or devices occasionally). Software engineers based in Stockholm work maybe one day a week or one day every two weeks from the office.\n\nWe meet a couple of times per year to get to know each other and have fun.\n\nOrganization and Way of Working\n\nThe engineering team is divided into smaller cross functional project teams that each focus on a specific goal or target, where some groups are long-lived, and some are short-lived, depending on how big the goal or deliverable is. We strive to create groups which are cross-functional and able to complete their goals without dependence on other teams, even though this is of course not always possible.\n\nGroups track goals on a yearly and quarterly basis with goal follow-up across the entire engineering organization on a bi-weekly basis.\n\nMost groups do internal planning on a bi-weekly basis, but in the end it\'s up to the group to decide how they want to work.\n\nWe have, however, mandated that all groups must present their progress or failures or hacks at our bi-weekly engineering demo, a fun meeting/presentation where we talk about everything from short-circuiting power-modules, how hard it is to calibrate cameras or align polygons in space, to neat new command line tools for operations, a new auth mechanism in the backend, a cool new way to visualize health data or a new feature which helps our doctors be more productive.\n\nWe have a flexible workplace that focuses on work/life balance, and we strongly believe in our mission but do not think that achieving it requires sacrificing everything else']}]","[{'link': 'http://www.nekohealth.com/', 'text': 'nekohealth.com'}, {'link': 'https://www.google.com/search?q=Neko+Health&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIIzAs', 'text': 'See web results for Neko Health'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRO86ZEHTrOXc8GrdsjguBzwKJqJjA0kqYBLJgijlk&s,"['6 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiN1lDaW9HcVAyVElBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1NreFhWMGM1WWpWNVRrcFlRMGREWjJKNUxYaFVXSFkxVTBWVFh6UmFZVFIwYTJSTE1UQlpaM0ZzUTJGemNrOVpOMG80WTJaRlZIUjBWQzFVV21kS1dXSmZia2hYUlZoVFdYSnpTM2hYYjBGeVR5MUNRMnM1ZW01c2RXa3hSaTFIWDBvemRrTkxPWGRwUldGVFR5MVlUMWwzYW05dFdsVmFTaTFDY2xKRFRYbzFNWEJ0WHpJMU1WcGtVV3gzWjBoSlRIWk5jMHA1ZVZnMGRFMXVhMFF6YWtJdE5HOUlSMWhCYjFONE1XVmZkWGh2VW5ZNVprcDFVMGd5TUVSWk1rRTRWVjlYU1hoc0VoZENZbEJJV2sxSVIwNVFMV2sxVG05UWFtWkRNbmxCVFJvaVFVeEZVemwxVGtoeWNuZzJWSGczU0RZdGRXUlBWVkV3ZUVKMVZuUjZjVEpSVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYmdldGhlciIsImxpbmsiOiJodHRwczovL2pvYmdldGhlci5jb20vb2ZmZXIvNjRjMDY5NDdjNjYzY2M1YzljZGY0NzdmLXNlbmlvci1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
"Chief Data Science and Data Engineering Officer, Vienna",EliteRecruitmentGroup,"  Vienna, Austria   ",via Jobs Trabajo.org,"Chief Data Science and Data Engineering Officer, Vienna

Vienna

Other

Stock options + basic freelance hourly rate

Posted: 24/07/2023

Healthcare Recruitment

Our client is a scale-up Recruitment group whose purpose is to enhance the Matching process between Employers and Candidates thanks to the extensive use of Data Engineering, Data Science and Automation.
Passion and innovation are their core values.

They have completed an initial ‚Äúlab phase‚Äù successfully with existing revenue, and they are in the process of scaling up (although still in the early stages of the scale-up). Their plan is to cover 15+ countries in the next 5 to 10 years in Europe, North America and Australasia.

They are currently looking for our 3rd Partner to hold the role of Chief Data Science/Engineering Officer for the company. The role would be on a freelance and part-time basis until our next funding round, expected in about 12 months. This initial period would give us the opportunity to work together and... get to know each other, which is meant to reduce risks from both sides.

Your first immediate mission would be to help us achieve a Minimum Viable Product readiness for our new data infrastructure (ETL‚Äôs) and insights in a short period.
They will be managing small teams of Data Engineers, and Data scientist freelancers and interns to achieve that. Current environment is AWS (Glue, RDB, etc)

BENEFITS:
There will be a grant of company options as soon as one month after joining the project.
During the first 12 months, the person will be rewarded in both hourly payments and further stock options. Please note: Being bootstrapped until then, the hourly payments would be minimal.

REQUIREMENTS:
We are looking for someone who:
> Is an expert in both Data Engineering and Data science and has an interest in recruitment, human resources and/or healthcare.
> Is willing to commit a significant amount of time to help us get started (different from an Ad Hoc consultant).

If you are interested please send us an email on info@eliterecruitmentgroup.com to receive more information. If your application is shortlisted, you will be answered to within 24 hours.

Job FeaturesJob Category

Other","[{'items': ['Chief Data Science and Data Engineering Officer, Vienna\n\nVienna\n\nOther\n\nStock options + basic freelance hourly rate\n\nPosted: 24/07/2023\n\nHealthcare Recruitment\n\nOur client is a scale-up Recruitment group whose purpose is to enhance the Matching process between Employers and Candidates thanks to the extensive use of Data Engineering, Data Science and Automation.\nPassion and innovation are their core values.\n\nThey have completed an initial ‚Äúlab phase‚Äù successfully with existing revenue, and they are in the process of scaling up (although still in the early stages of the scale-up). Their plan is to cover 15+ countries in the next 5 to 10 years in Europe, North America and Australasia.\n\nThey are currently looking for our 3rd Partner to hold the role of Chief Data Science/Engineering Officer for the company. The role would be on a freelance and part-time basis until our next funding round, expected in about 12 months. This initial period would give us the opportunity to work together and... get to know each other, which is meant to reduce risks from both sides.\n\nYour first immediate mission would be to help us achieve a Minimum Viable Product readiness for our new data infrastructure (ETL‚Äôs) and insights in a short period.\nThey will be managing small teams of Data Engineers, and Data scientist freelancers and interns to achieve that. Current environment is AWS (Glue, RDB, etc)\n\nBENEFITS:\nThere will be a grant of company options as soon as one month after joining the project.\nDuring the first 12 months, the person will be rewarded in both hourly payments and further stock options. Please note: Being bootstrapped until then, the hourly payments would be minimal.\n\nREQUIREMENTS:\nWe are looking for someone who:\n> Is an expert in both Data Engineering and Data science and has an interest in recruitment, human resources and/or healthcare.\n> Is willing to commit a significant amount of time to help us get started (different from an Ad Hoc consultant).\n\nIf you are interested please send us an email on info@eliterecruitmentgroup.com to receive more information. If your application is shortlisted, you will be answered to within 24 hours.\n\nJob FeaturesJob Category\n\nOther']}]","[{'link': 'https://www.google.com/search?q=EliteRecruitmentGroup&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAII_ws', 'text': 'See web results for EliteRecruitmentGroup'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRy7BDVLI1v0TTiEd_1-A9erQIeLXnbzmstT3FzCrk&s,"['6 days ago', 'Full-time']","{'posted_at': '6 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJDaGllZiBEYXRhIFNjaWVuY2UgYW5kIERhdGEgRW5naW5lZXJpbmcgT2ZmaWNlciwgVmllbm5hIiwiaHRpZG9jaWQiOiIxTTRxRm43XzlKMEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzVEc5T2IyWk9Za3BOWW0wMlp6TmFiR3BKYlhCMk0zRkdNRWxzWWt4M1JURnBVWEF3ZUhOUFJUZE1kRTAzTm5CcWFrbDNkMVpwZEV4elRteEhkRVZzVURaWk9GcEpPV2hLTkVOc09VZFBhMlJ3UVRFeFNXb3pZWEpNZVZOTFNsRnphUzFKZGkxNVZFeEJaVkZqWmt4SmRqTnRVa1ZuVERSc2JIWmhUV2hSVlc0M2JUQlBWelZsU2twSVkzaHZTVUprZUhGRVptZFBiMFJzU0hGZloyUkZUVWh5Ym5kVWNtMUphSEV6WW1Wak5sbGxUV0ozWnpsVmFrcHdORlpuY1ZGd09YRnFVa0pqU20xSlMyVnZUbU01ZDFST2QyTXROVlJ3VnpNNVp4SVhRbUpRU0ZwTlNFZE9VQzFwTlU1dlVHcG1Reko1UVUwYUlrRk1SVk01ZFUxVGRHb3pRa3RXWWxwT05sQm5YMDk1YUhBeFRFbzBkMWxqUTJjIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JzIFRyYWJham8ub3JnIiwibGluayI6Imh0dHBzOi8vYXQudHJhYmFqby5vcmcvc3RlbGxlbmFuZ2Vib3QtMTI1OC0yMDIzMDcyNS1jMDFmNDRlNTgzYzM0NTM0ZGJhZGUzODg2MzYwNGEyOD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer,Capgemini,"  Vienna, Austria   ",via DEVjobs.at,"Your role in the team
‚Ä¢ You are responsible for the design through to the implementation of data pipelines and data integration solutions (ELT/ETL).
‚Ä¢ You model and develop data storage solutions (data warehouse, data lake, etc.) to process large amounts of data
‚Ä¢ You drive the conception and further development of company-wide data platforms

Technologies and skills
‚Ä¢ C#
‚Ä¢ Power BI
‚Ä¢ Apache Spark
‚Ä¢ Apache Kafka
‚Ä¢ SQL
‚Ä¢ Python
‚Ä¢ Azure
‚Ä¢ AWS
‚Ä¢ Google Cloud Platform
‚Ä¢ Scala

Our expectations:

Qualifications
‚Ä¢ very good knowledge of SQL
‚Ä¢ very good knowledge of Python
‚Ä¢ Interest in technology trends and enjoy constantly learning new things
‚Ä¢ Business fluent knowledge of English and good knowledge of German
‚Ä¢ Ability to work in a team and convincing communication skills
‚Ä¢ Excellent analytical skills and a proactive way of working
‚Ä¢ Openness to possible international project assignments The following skills would be an advantage
‚Ä¢ Knowledge in the field of automation (CI/CD) and DevOps or... approaches such as DataOps, MLOps
‚Ä¢ Programming skills in other languages such as Scala or C#
‚Ä¢ Understanding of data science and AI and the resulting requirements for a data platform

Experience
‚Ä¢ several years of professional experience (3+ years) as a software developer or data engineer/ data warehouse engineer
‚Ä¢ Experience with data in the cloud, preferably Azure (AWS, Google Cloud)
‚Ä¢ Know-how and practical experience in data modeling (Kimball, DataVault) and in the implementation of DWH solutions
‚Ä¢ Experience with a data visualization tool (PowerBI, Tableau)
‚Ä¢ Experience with Big Data (Spark, Kafka, etc.)
‚Ä¢ Experience in (partial) project management

Education
‚Ä¢ Completed economic or technical studies (computer science, business informatics, mathematics, physics or a comparable course)

Benefits
‚Ä¢ * Massage, Yoga, etc.
‚Ä¢ * Company Notebook for Private Use
‚Ä¢ Meal Vouchers","[{'items': ['Your role in the team\n‚Ä¢ You are responsible for the design through to the implementation of data pipelines and data integration solutions (ELT/ETL).\n‚Ä¢ You model and develop data storage solutions (data warehouse, data lake, etc.) to process large amounts of data\n‚Ä¢ You drive the conception and further development of company-wide data platforms\n\nTechnologies and skills\n‚Ä¢ C#\n‚Ä¢ Power BI\n‚Ä¢ Apache Spark\n‚Ä¢ Apache Kafka\n‚Ä¢ SQL\n‚Ä¢ Python\n‚Ä¢ Azure\n‚Ä¢ AWS\n‚Ä¢ Google Cloud Platform\n‚Ä¢ Scala\n\nOur expectations:\n\nQualifications\n‚Ä¢ very good knowledge of SQL\n‚Ä¢ very good knowledge of Python\n‚Ä¢ Interest in technology trends and enjoy constantly learning new things\n‚Ä¢ Business fluent knowledge of English and good knowledge of German\n‚Ä¢ Ability to work in a team and convincing communication skills\n‚Ä¢ Excellent analytical skills and a proactive way of working\n‚Ä¢ Openness to possible international project assignments The following skills would be an advantage\n‚Ä¢ Knowledge in the field of automation (CI/CD) and DevOps or... approaches such as DataOps, MLOps\n‚Ä¢ Programming skills in other languages such as Scala or C#\n‚Ä¢ Understanding of data science and AI and the resulting requirements for a data platform\n\nExperience\n‚Ä¢ several years of professional experience (3+ years) as a software developer or data engineer/ data warehouse engineer\n‚Ä¢ Experience with data in the cloud, preferably Azure (AWS, Google Cloud)\n‚Ä¢ Know-how and practical experience in data modeling (Kimball, DataVault) and in the implementation of DWH solutions\n‚Ä¢ Experience with a data visualization tool (PowerBI, Tableau)\n‚Ä¢ Experience with Big Data (Spark, Kafka, etc.)\n‚Ä¢ Experience in (partial) project management\n\nEducation\n‚Ä¢ Completed economic or technical studies (computer science, business informatics, mathematics, physics or a comparable course)\n\nBenefits\n‚Ä¢ * Massage, Yoga, etc.\n‚Ä¢ * Company Notebook for Private Use\n‚Ä¢ Meal Vouchers']}]","[{'link': 'http://www.capgemini.com/', 'text': 'capgemini.com'}, {'link': 'https://www.google.com/search?q=Capgemini&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIIsww', 'text': 'See web results for Capgemini'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRwQjOPvV-LCr6vXzXmfGhT44dW61QQAB_S5f39&s=0,"['‚Ç¨55K a year', 'Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiXzItQ2VXR1dLaEFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RIVlhWazVhWHpCTk1GOUdiMHRYTkZWTmFYcFNlamh3ZG00dFUybE9WMlkxUVdreWIxODRTRk5FZVhOVFlVVk9Ra2d5UjJZNFpIZFNhRkJ0YUdsS1pqQjFlbEF6ZUhKaWFVRmpaakUyWjNkVGJVSTNSbEJCY1ZkdE5TMU9jME01YUd0RlFtdGlTR3MwWDJGUVZITTNNMVp6WlRGMWNHbEtjekZEZFcweVIwdHhibEJFVUd4TE1sTkdaakEyTkZOT01FODFlRmQ1V1ZOd1RqVjZXSEp0TjFvM1VXVkVkMlV4U2pOSFFXSTRZVkkwRWhkQ1lsQklXazFJUjA1UUxXazFUbTlRYW1aRE1ubEJUUm9pUVV4RlV6bDFUbkp3ZHpBMVZGOWljVFJoUlZJeFNuZGhWMkk0VFhnMlQwMUhadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzgiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iLzU3MDg1ODM2ODAwMDkyMTEwP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineering Product Manager (m/f/x),Dynatrace,  Austria   ,via Dynatrace Careers,"‚Ä¢ Define, manage, and execute a product roadmap for data engineering based on the needs of the business, stakeholder feedback, market trends, and technical considerations.
‚Ä¢ Inspire an experienced group of data engineers, breaking down complex problems into clearly defined requirements.
‚Ä¢ Closely collaborate with data governance covering legal, security, and data quality aspects.
‚Ä¢ Identify and monitor key performance indicators, using them to optimize and evolve our data strategy.
‚Ä¢ Focus on measurable results covering time to market, scalability of solutions, and return on investment.
‚Ä¢ Maintain a deep understanding of the data landscape, including emerging trends and market developments for new technologies to inform our data platform strategy.","[{'items': ['‚Ä¢ Define, manage, and execute a product roadmap for data engineering based on the needs of the business, stakeholder feedback, market trends, and technical considerations.\n‚Ä¢ Inspire an experienced group of data engineers, breaking down complex problems into clearly defined requirements.\n‚Ä¢ Closely collaborate with data governance covering legal, security, and data quality aspects.\n‚Ä¢ Identify and monitor key performance indicators, using them to optimize and evolve our data strategy.\n‚Ä¢ Focus on measurable results covering time to market, scalability of solutions, and return on investment.\n‚Ä¢ Maintain a deep understanding of the data landscape, including emerging trends and market developments for new technologies to inform our data platform strategy.']}]","[{'link': 'http://www.dynatrace.com/', 'text': 'dynatrace.com'}, {'link': 'https://www.google.com/search?q=Dynatrace&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAII5gw', 'text': 'See web results for Dynatrace'}]",,"['18 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '18 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyaW5nIFByb2R1Y3QgTWFuYWdlciAobS9mL3gpIiwiaHRpZG9jaWQiOiI4UGJqdTBIZkdITUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzVEcwMVJGQnBXVkJaZDBwb2RIcDZhbnA0YkVrelZIUkdaWEJPYkV4R1JHWjZWMHcxVDFFeE9YSmlhRmd5YUZwa2RFOUdZVnBwVjFONU9WOTFjMUEzZDJOQmFWSlpaMVpoYUc5cE9XTjFaM2hOU0VWSGIySmhkMlJEVld0dWIwSlVYMk5mTm0xSVNGWkNkVkpIVmtZNFlYSmlkMVF0VlV0U1REZDRiRzFRWVZOQlZHTTNMVWhhVVhGNllUSnJhMTlOZUhaU1RVMXlTbXhQVDA1R1JqUm9VblE0VDNwNlRUWklkM1pTZGpKVE1YSXRSRWhuZUZrMFJVZHJWWEpITVc0eE1qTnJSR1kzRWhkQ1lsQklXazFJUjA1UUxXazFUbTlRYW1aRE1ubEJUUm9pUVV4RlV6bDFUa2RwYzFWa2FIcDJWRGhZUTFoZlFVZEhWMlZZZVRSNExYTXhRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEwIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIER5bmF0cmFjZSBDYXJlZXJzIiwibGluayI6Imh0dHBzOi8vY2FyZWVycy5keW5hdHJhY2UuY29tL2pvYnMvYjU3MTFkOGMtYjQyMy00YjM3LWI4NTAtYWQyNjI5ZjcyNmI5Lz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Warehouse Developer - Oracle,Xcede,"  M√ºnchendorf, Austria   ",via Xcede,"Head office: Munich

One of the most cutting edge & established Investment Strategy and Data Management services in the world are looking for a Senior Data Warehouse Developer. They're part of a larger group which grossed +‚Ç¨150 Billion in 2022 allowing you access to a vast range of clients & projects, giving you the startup feel with the backing of a global superpower. You will be using your Data Warehousing skills to shape their Data landscape in the cloud & on premise.

The role‚Ä¶

In the short term, you will be designing and implementing data warehouses in their heterogeneous environment. You will create data models and use your programming skills in PL/SQL to develop data processes. Longer-term, you have the chance to choose from multiple progression options, whether that be upskilling and working with different tools, becoming a tech lead, taking responsibility of projects from a managerial perspective.

Your experience:
‚Ä¢ 4+ years' experience using Oracle database & PL/SQL (some... experience in Oracle 19c ideally)
‚Ä¢ Understanding of Data Warehouses or Data Lakes at an enterprise level
‚Ä¢ Nice to have Python experience
‚Ä¢ Fluent in English and B1 German speaking

Benefits:
‚Ä¢ Base Salary up to ‚Ç¨105,000 + 15% Annual Bonus
‚Ä¢ Fully remote working environment within Germany - modern offices in Munich
‚Ä¢ Flexible working times
‚Ä¢ Great progression opportunities both vertically and laterally within the company
‚Ä¢ Strong Upskilling culture with both internal and external training/courses.
‚Ä¢ 30 Vacation days
‚Ä¢ Company benefits - Healthcare plan, pension plan, etc.
‚Ä¢ 2 Stage Interview process

For more information, apply or contact Norman Cistovas","[{'items': [""Head office: Munich\n\nOne of the most cutting edge & established Investment Strategy and Data Management services in the world are looking for a Senior Data Warehouse Developer. They're part of a larger group which grossed +‚Ç¨150 Billion in 2022 allowing you access to a vast range of clients & projects, giving you the startup feel with the backing of a global superpower. You will be using your Data Warehousing skills to shape their Data landscape in the cloud & on premise.\n\nThe role‚Ä¶\n\nIn the short term, you will be designing and implementing data warehouses in their heterogeneous environment. You will create data models and use your programming skills in PL/SQL to develop data processes. Longer-term, you have the chance to choose from multiple progression options, whether that be upskilling and working with different tools, becoming a tech lead, taking responsibility of projects from a managerial perspective.\n\nYour experience:\n‚Ä¢ 4+ years' experience using Oracle database & PL/SQL (some... experience in Oracle 19c ideally)\n‚Ä¢ Understanding of Data Warehouses or Data Lakes at an enterprise level\n‚Ä¢ Nice to have Python experience\n‚Ä¢ Fluent in English and B1 German speaking\n\nBenefits:\n‚Ä¢ Base Salary up to ‚Ç¨105,000 + 15% Annual Bonus\n‚Ä¢ Fully remote working environment within Germany - modern offices in Munich\n‚Ä¢ Flexible working times\n‚Ä¢ Great progression opportunities both vertically and laterally within the company\n‚Ä¢ Strong Upskilling culture with both internal and external training/courses.\n‚Ä¢ 30 Vacation days\n‚Ä¢ Company benefits - Healthcare plan, pension plan, etc.\n‚Ä¢ 2 Stage Interview process\n\nFor more information, apply or contact Norman Cistovas""]}]","[{'link': 'http://www.xcede.com/', 'text': 'xcede.com'}, {'link': 'https://www.google.com/search?q=Xcede&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIImg0', 'text': 'See web results for Xcede'}]",,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBXYXJlaG91c2UgRGV2ZWxvcGVyIC0gT3JhY2xlIiwiaHRpZG9jaWQiOiJ1QVRUekRMMENDUUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVMXJNbXhzU2paVldHUnNkamgxZWpKclpGWnpPRzVTZG5Sb2VUYzNhMDVSTW5CZmRHZGpWRnBVUWpoc2NVWXpaelUxWTFGYVRrODFjazF0YVhCdU1WUm1NVlJzTTBZdGExbHdWMVk0WTJsT1lsbzJOMU40V1ZablIwdERlSG8wTmtRNU5FMWhjekprZWxoRlVVbHdja1o2TFhsWU9YTndkMHR6UlhSa1Z6UkhSa0ZrY1V4MExXRnJiMGxWTkZaNldEbEVla2cwVkUxU1ZXRXlNM2RwY1U1cFMyd3djR0ptYzBsWVEyeDBZME54YWxwa05HRXROVEkwU2xGa2FWWXpUSEJQVWpRMU9EQnJhRU53V0dGdFNsOVBTbVp3TUhKaU9VSTRNbGx4Y0c5Slp4SVhRbUpRU0ZwTlNFZE9VQzFwTlU1dlVHcG1Reko1UVUwYUlrRk1SVk01ZFU5SFpFMHdSbDluWVhwcmFXNVJRbTFTZDBKeU1GRXlNbGRvTkZFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTIiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gWGNlZGUiLCJsaW5rIjoiaHR0cHM6Ly93d3cueGNlZGUuY29tL2pvYi9zZW5pb3ItZGF0YS13YXJlaG91c2UtZGV2ZWxvcGVyLW9yYWNsZT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior/Staff Data Engineer,Kpler,  Austria   ,via Lever,"In a world where trades are happening faster than ever to answer our needs, where sustainability is not just an option anymore, clarity and trust in the information we trade with are a must.

So, say hello to Kpler! We exist to facilitate sustainable and efficient trade to meet the changing needs of our world. To do so we've built a Data-as-a-Service solution that does exactly that across the lifecycle of a trade.

Our solution aggregates data from hundreds of sources including radar and satellite imagery as well as logistics, governmental, shipping databases and more. Intelligently connecting the dots across fragmented information landscapes, we bring to our clients a unique, real-time understanding of the trades happening all over the world, by giving them access to live information about the movement of cargos, the availability of vessels as well as commodity storage.

To support this endeavor, we have teams in more than 9 countries and 11 key locations (Brussels, Paris, London... Athens, Vienna, Rostock, Hy√®res, Dubai, Singapore, Houston and New York). With individuals of various backgrounds, diverse skills, and international experiences, being global & inclusive is in our DNA!

We are looking for a Senior Data Engineer to join our software engineering team (over 100 engineers).

Some of the exciting projects you could work on include:

‚Ä¢ Building a new pipeline to feed a live database which is used by clients and research teams to produce useful insight on the commodity market

‚Ä¢ Building new features for our core platform including metrics & forecasting as well as scaling and stabilizing our data pipelines

As a Senior Data Engineer, you will:

‚Ä¢ Find efficient ways to tackle challenges using the relevant and up to date technologies

‚Ä¢ Work across the stack to deliver new features from start-to-finish

‚Ä¢ Improve performance and overcome scalability limits

‚Ä¢ Own meaningful parts of our service, have an impact, grow with the company

‚Ä¢ Actively share knowledge and document insights to support continuous team improvement and collaboration

‚Ä¢ Act as a mentor for our junior engineers; On some projects, you may also need to act as the Tech lead

Our Tech stack includes:

‚Ä¢ VueJs, D3js, RESTfulAPI and more on the frontend

‚Ä¢ Python, Java, Scala, Postgresql, ElasticSearch, Kafka, Spark, Snowflake and more on the backend

‚Ä¢ AWS, GCP, terraform and ansible for DevOps tools

You may be a fit if...

‚Ä¢ You have at least 10 years of experience in a similar role including significant experience in Python, Java, Scala or equivalent language

‚Ä¢ You have over 5 years experience working with AWS and cloud technologies

‚Ä¢ You have experience in radar image processing

‚Ä¢ You have used the Java libraries of the ESA SNAP toolboxes

‚Ä¢ You are familiar with orchestration and in particular Astronomer

‚Ä¢ You are familiar with building ETL and data pipelines, using asynchronous framework is a plus

‚Ä¢ You are comfortable with SQL and NoSQL databases for OLTP and OLAP usages

‚Ä¢ You value code simplicity, performance and details

‚Ä¢ You have demonstrated that you can learn and adapt quickly

‚Ä¢ You are fluent in English and have experience working in an international environment

What you will receive from Kpler:

‚Ä¢ You‚Äôll get to work in a truly global work environment, with offices in 7 countries (UK, France, Belgium, Austria, US, Dubai and Singapore), we come from more than 50 countries and speak more than 20 languages

‚Ä¢ We have truly embraced the new age of workplace flexibility where you can chose to work hybrid or onsite

‚Ä¢ We offer competitive compensation & benefits including work from home allowance, medical and life insurance, training and development allowance, paid volunteer work and more!

‚Ä¢ You will receive a company laptop and you can choose between Windows, Mac, or Linux

‚Ä¢ Global maternity (extended leave), parental, festival and compassionate leave policies aligned to the contemporary needs of the family, and individual choices

And you REALLY want to join our Engineering team because:

‚Ä¢ Interesting product & challenging technical problems to solve: our market is very specialized and quite complex! This means we build real algos and there‚Äôs some serious software engineering at work here!

‚Ä¢ Our growth is exponential: we build new features and products everyday! We frequently tackle brand-new business areas which means there‚Äôs always everything to build and always an interesting problem to sink your teeth into!

‚Ä¢ We are at the cross-road of Software Engineering, Commodity, Energy and Finance. This creates an interesting cultural mix: We value the flexibility, collaboration and employee-centric approach that the Tech culture brings but we also value the pragmatism, hard-working and intellectual excellence expectation that often runs in the Finance and Energy worlds

‚Ä¢ Team of 85+ talented Engineers working with the most modern tech stack

Recruitment Process:

Recruiter Screen: 30 minute video interview with a recruiter from hiring team

Hiring Manager Interview: 45 minute exchange with one of our Engineering Managers from the dedicated team

Take Home Technical Exercise

Meet the Team: An opportunity to see the fit and get to know your potential future team!

Our values

‚Ä¢ Be humble - We always place the interests of the collective before your own.

‚Ä¢ Respect and care for others - We make every person feel comfortable in their own beliefs, decisions, and perspectives.

‚Ä¢ Take responsibility - We take ownership of our actions.

‚Ä¢ Act with integrity -We are honest and transparent in all your dealings.

‚Ä¢ Be bold - We push the boundaries in order to improve and grow.

You‚Äôll get to work in a truly global environment, with more than 30 nationalities speaking more than 15 languages.

Our People Pledge

Don‚Äôt meet every single requirement? Research shows that women and people of color are less likely than others to apply if they feel like they don‚Äôt match 100% of the job requirements. Don‚Äôt let the confidence gap stand in your way, we‚Äôd love to hear from you! We understand that experience comes in many different forms and are dedicated to adding new perspectives to the team.

Kpler is committed to providing a fair, inclusive and diverse work-environment. We believe that different perspectives lead to better ideas, and better ideas allow us to better understand the needs and interests of our diverse, global community. We welcome people of different backgrounds, experiences, abilities and perspectives and are an equal opportunity employer.

By applying, I confirm that I have read and accept the Staff Privacy Notice","[{'items': [""In a world where trades are happening faster than ever to answer our needs, where sustainability is not just an option anymore, clarity and trust in the information we trade with are a must.\n\nSo, say hello to Kpler! We exist to facilitate sustainable and efficient trade to meet the changing needs of our world. To do so we've built a Data-as-a-Service solution that does exactly that across the lifecycle of a trade.\n\nOur solution aggregates data from hundreds of sources including radar and satellite imagery as well as logistics, governmental, shipping databases and more. Intelligently connecting the dots across fragmented information landscapes, we bring to our clients a unique, real-time understanding of the trades happening all over the world, by giving them access to live information about the movement of cargos, the availability of vessels as well as commodity storage.\n\nTo support this endeavor, we have teams in more than 9 countries and 11 key locations (Brussels, Paris, London... Athens, Vienna, Rostock, Hy√®res, Dubai, Singapore, Houston and New York). With individuals of various backgrounds, diverse skills, and international experiences, being global & inclusive is in our DNA!\n\nWe are looking for a Senior Data Engineer to join our software engineering team (over 100 engineers).\n\nSome of the exciting projects you could work on include:\n\n‚Ä¢ Building a new pipeline to feed a live database which is used by clients and research teams to produce useful insight on the commodity market\n\n‚Ä¢ Building new features for our core platform including metrics & forecasting as well as scaling and stabilizing our data pipelines\n\nAs a Senior Data Engineer, you will:\n\n‚Ä¢ Find efficient ways to tackle challenges using the relevant and up to date technologies\n\n‚Ä¢ Work across the stack to deliver new features from start-to-finish\n\n‚Ä¢ Improve performance and overcome scalability limits\n\n‚Ä¢ Own meaningful parts of our service, have an impact, grow with the company\n\n‚Ä¢ Actively share knowledge and document insights to support continuous team improvement and collaboration\n\n‚Ä¢ Act as a mentor for our junior engineers; On some projects, you may also need to act as the Tech lead\n\nOur Tech stack includes:\n\n‚Ä¢ VueJs, D3js, RESTfulAPI and more on the frontend\n\n‚Ä¢ Python, Java, Scala, Postgresql, ElasticSearch, Kafka, Spark, Snowflake and more on the backend\n\n‚Ä¢ AWS, GCP, terraform and ansible for DevOps tools\n\nYou may be a fit if...\n\n‚Ä¢ You have at least 10 years of experience in a similar role including significant experience in Python, Java, Scala or equivalent language\n\n‚Ä¢ You have over 5 years experience working with AWS and cloud technologies\n\n‚Ä¢ You have experience in radar image processing\n\n‚Ä¢ You have used the Java libraries of the ESA SNAP toolboxes\n\n‚Ä¢ You are familiar with orchestration and in particular Astronomer\n\n‚Ä¢ You are familiar with building ETL and data pipelines, using asynchronous framework is a plus\n\n‚Ä¢ You are comfortable with SQL and NoSQL databases for OLTP and OLAP usages\n\n‚Ä¢ You value code simplicity, performance and details\n\n‚Ä¢ You have demonstrated that you can learn and adapt quickly\n\n‚Ä¢ You are fluent in English and have experience working in an international environment\n\nWhat you will receive from Kpler:\n\n‚Ä¢ You‚Äôll get to work in a truly global work environment, with offices in 7 countries (UK, France, Belgium, Austria, US, Dubai and Singapore), we come from more than 50 countries and speak more than 20 languages\n\n‚Ä¢ We have truly embraced the new age of workplace flexibility where you can chose to work hybrid or onsite\n\n‚Ä¢ We offer competitive compensation & benefits including work from home allowance, medical and life insurance, training and development allowance, paid volunteer work and more!\n\n‚Ä¢ You will receive a company laptop and you can choose between Windows, Mac, or Linux\n\n‚Ä¢ Global maternity (extended leave), parental, festival and compassionate leave policies aligned to the contemporary needs of the family, and individual choices\n\nAnd you REALLY want to join our Engineering team because:\n\n‚Ä¢ Interesting product & challenging technical problems to solve: our market is very specialized and quite complex! This means we build real algos and there‚Äôs some serious software engineering at work here!\n\n‚Ä¢ Our growth is exponential: we build new features and products everyday! We frequently tackle brand-new business areas which means there‚Äôs always everything to build and always an interesting problem to sink your teeth into!\n\n‚Ä¢ We are at the cross-road of Software Engineering, Commodity, Energy and Finance. This creates an interesting cultural mix: We value the flexibility, collaboration and employee-centric approach that the Tech culture brings but we also value the pragmatism, hard-working and intellectual excellence expectation that often runs in the Finance and Energy worlds\n\n‚Ä¢ Team of 85+ talented Engineers working with the most modern tech stack\n\nRecruitment Process:\n\nRecruiter Screen: 30 minute video interview with a recruiter from hiring team\n\nHiring Manager Interview: 45 minute exchange with one of our Engineering Managers from the dedicated team\n\nTake Home Technical Exercise\n\nMeet the Team: An opportunity to see the fit and get to know your potential future team!\n\nOur values\n\n‚Ä¢ Be humble - We always place the interests of the collective before your own.\n\n‚Ä¢ Respect and care for others - We make every person feel comfortable in their own beliefs, decisions, and perspectives.\n\n‚Ä¢ Take responsibility - We take ownership of our actions.\n\n‚Ä¢ Act with integrity -We are honest and transparent in all your dealings.\n\n‚Ä¢ Be bold - We push the boundaries in order to improve and grow.\n\nYou‚Äôll get to work in a truly global environment, with more than 30 nationalities speaking more than 15 languages.\n\nOur People Pledge\n\nDon‚Äôt meet every single requirement? Research shows that women and people of color are less likely than others to apply if they feel like they don‚Äôt match 100% of the job requirements. Don‚Äôt let the confidence gap stand in your way, we‚Äôd love to hear from you! We understand that experience comes in many different forms and are dedicated to adding new perspectives to the team.\n\nKpler is committed to providing a fair, inclusive and diverse work-environment. We believe that different perspectives lead to better ideas, and better ideas allow us to better understand the needs and interests of our diverse, global community. We welcome people of different backgrounds, experiences, abilities and perspectives and are an equal opportunity employer.\n\nBy applying, I confirm that I have read and accept the Staff Privacy Notice""]}]","[{'link': 'https://www.google.com/search?q=Kpler&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIIyw0', 'text': 'See web results for Kpler'}]",,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IvU3RhZmYgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiYWxybTh3N3VweHdBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVTFyTW14c1NrWmFaaTFZTmpodWFETkZUekZMUlZveFJGbHBlVzFSVlU5VE9HNW5VM1pyWXkxTFNXWTVNMHRCUVZwNldrd3dOR0pzYWxjM1ZEUjNUVWR5UWtSM04wUjFkbFZxU25WbVJrNVRiekpvV0c5dWJFRmpjRzk2YlhCYVpFazBRbVJaVTJaRFVGZG5OV2xvWjJWQlMwcFpiRWxTWm1kemVYQkxURVJ5YzFSaVpIQlFhV2RSZUdsbWQyVkJVR1kzV2pGQ1RtaERhMmxPU0VOdk1IRkJFaGRDWWxCSVdrMUlSMDVRTFdrMVRtOVFhbVpETW5sQlRSb2lRVXhGVXpsMVRqRlNia3BwVDNOaWRDMXRjbTgzY1daQ00yNVZNMUp1VGs5cFFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gTGV2ZXIiLCJsaW5rIjoiaHR0cHM6Ly9qb2JzLmxldmVyLmNvL2twbGVyL2QwNWViYWY5LTM1MWItNDJkMi04NzY4LTkwM2U5MTYwMjEwMz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (f/m/d),1300 Swarovski International Holding AG, Anywhere ,via Workday,"At Swarovski, where innovation meets inspiration, our people desire to explore, experience and create. As a Data Engineer (f/m/d) you will get a chance to work in a rewarding role within a diverse team that is pushing boundaries. Be part of a truly iconic global brand, learn and grow with us. We‚Äôre bold and inventive, revealing astonishing things like no one else can. A world of wonder awaits you. About the job We are seeking a skilled and passionate Data Engineer (f/m/d) to join our dynamic Data Engineering team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure from the landing zone in Google Cloud Platform (GCP) to the consumption layer. You will collaborate closely with data scientists, analysts, and other stakeholders to ensure the availability, quality, and reliability of our data assets, enabling data-driven decision-making throughout the organization. Your responsibilities include, but are not limited to... Designing and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house Collaborating with cross-functional teams to understand data requirements and to translate them into technical solutions Optimizing and fine-tuning data pipelines for efficiency, performance, and scalability Implementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness Working closely with data scientists and analysts to provide them with the necessary data and tools for analysis and reporting Maintaining and enhancing data models and data dictionaries to facilitate data understanding and usage Staying up-to-date with the latest industry trends, best practices, and emerging technologies in data engineering and analytics About you We are looking for a unique and amazing talent, who brings along the following: Bachelor's or Master's degree in Computer Science, Engineering, or a related field 5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems Strong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub/Sub Solid programming skills in languages like Python, SQL Experience with data modeling, data warehousing, and ETL/ELT processes Familiarity with data governance, data privacy, and security practices Strong problem-solving and analytical skills, with the ability to handle complex data-related issues Excellent communication and collaboration skills to work effectively with cross-functional teams Self-motivated and able to work independently, as well as in a team-oriented environment Nice-to-have: SAP BW data engineering skills (SAP BW 3.x, 7.x, BW on Hana) What we offer You can expect a range of benefits: including: Swarovski products discounts Employee Assistance Program Volunteering leave Learning and development programs, training and further education offers Flexible working time models (flextime, home office, part-time, etc.) Travel allowance/public transport ticket/bike leasing Company subsidy for lunch in the canteens Company pension plan (from the 3rd year of employment) Childbirth grant, other personal allowances, if applicable Company cr√®che, summer holiday care for children Free sports and health programs Voluntary profit-sharing Subsidy for private health insurance Loyalty benefits such as bonuses, anniversary gifts, etc. Rent of company apartments for the employees Masters of Light Since 1895 Swarovski creates beautiful crystal-based products of impeccable quality and craftsmanship that bring joy and celebrate individuality. Founded in 1895 in Austria, the company designs, manufactures and sells the world's finest crystal, gemstones, Swarovski Created Diamonds and zirconia, jewelry, and accessories, as well as crystal objects and home accessories. Swarovski Crystal Business has a global reach with approximately 2,400 stores and 6,700 points of sales in around 140 countries and employs more than 18,000 people. Together with its sister companies Swarovski Optik (optical devices) and Tyrolit (abrasives), Swarovski Crystal Business forms the Swarovski Group. A responsible relationship with people and the planet is part of Swarovski‚Äôs heritage. Today this legacy is rooted in sustainability measures across the value chain, with an emphasis on circular innovation, championing diversity, inclusion and self-expression, and in the philanthropic work of the Swarovski Foundation, which supports charitable organizations bringing positive environmental and social impact. Swarovski is an equal opportunity employer. We give our people the guts to celebrate individuality and pride ourselves on creating a workplace where people feel involved, respected, valued, connected, and heard. A place where anyone/everyone belongs. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate based on race, color, religion, marital status, age, national origin, physical or mental disability, medical condition, pregnancy, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under the law of the countries we operate in. Due to legal reasons, we advise that the collectively agreed base monthly salary for this position is at least ‚Ç¨ 3.497,87 gross. Our actual salaries are market competitive and take individual qualifications and experience into consideration. Erschaffe eine Welt der Wunder Bei Swarovski zu arbeiten bedeutet ein Teil eines gr√∂√üeren Ziels zu sein. Du kannst einen positiven Einfluss aus√ºben und Wunder bewirken, indem du deine einzigartigen Ideen zum Leben erweckst. Gemeinsam inspirieren wir die Welt der Inneneinrichtung, der Mode, der Kultur, des Films und der Unterhaltung. Einstellungsprozess bei Swarovski Du bist nur ein paar Schritte davon entfernt, ein Teil unserer Welt der Wunder zu werden. W√§hle die Stelle aus, die dich am meisten reizt, schreibe deinen Lebenslauf und schicke deine Bewerbung ab. Sobald deine Bewerbung sorgf√§ltig gepr√ºft wurde, werden wir uns mit dir in Verbindung setzen, um dir weitere Fragen zu stellen, dich √ºber die Stelle zu informieren und dir die n√§chsten Schritte mitzuteilen. Wenn du erfolgreich bist, laden wir dich zu mindestens einem Vorstellungsgespr√§ch ein und k√∂nnen dich bitten, eine Fallstudie vorzubereiten oder einen Test zu machen. Du wirst auch Zeit haben, deine Fragen zu stellen. Lebenslauf-Tipps f√ºr deinen Traumjob Der erste Eindruck z√§hlt: Gestalte deinen zweiseitigen Lebenslauf professionell und √§sthetisch. F√ºge die wichtigsten Details hinzu, die zeigen, dass du f√ºr die Stelle gut geeignet bist, und konzentriere dich auf deine F√§higkeiten, Projekte, Erfolge, Ergebnisse und Ausbildung. Sag uns, wie gut du Fremdsprachen sprichst/schreibst. Wir lesen gerne die Zusammenfassungen von Bewerberprofilen mit Zielen und Leidenschaften - sie unterstreichen deine Pers√∂nlichkeit und Motivation. Wenn du noch am Anfang deiner beruflichen Laufbahn stehst, zeige deine Individualit√§t und hebe die Details hervor, die f√ºr die Stelle relevant sind (z.B. Praktika, Freiwilligen- oder Aushilfsjobs, Online-Kurse, Zertifikate, Austauschprogramme im Ausland","[{'items': [""At Swarovski, where innovation meets inspiration, our people desire to explore, experience and create. As a Data Engineer (f/m/d) you will get a chance to work in a rewarding role within a diverse team that is pushing boundaries. Be part of a truly iconic global brand, learn and grow with us. We‚Äôre bold and inventive, revealing astonishing things like no one else can. A world of wonder awaits you. About the job We are seeking a skilled and passionate Data Engineer (f/m/d) to join our dynamic Data Engineering team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure from the landing zone in Google Cloud Platform (GCP) to the consumption layer. You will collaborate closely with data scientists, analysts, and other stakeholders to ensure the availability, quality, and reliability of our data assets, enabling data-driven decision-making throughout the organization. Your responsibilities include, but are not limited to... Designing and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house Collaborating with cross-functional teams to understand data requirements and to translate them into technical solutions Optimizing and fine-tuning data pipelines for efficiency, performance, and scalability Implementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness Working closely with data scientists and analysts to provide them with the necessary data and tools for analysis and reporting Maintaining and enhancing data models and data dictionaries to facilitate data understanding and usage Staying up-to-date with the latest industry trends, best practices, and emerging technologies in data engineering and analytics About you We are looking for a unique and amazing talent, who brings along the following: Bachelor's or Master's degree in Computer Science, Engineering, or a related field 5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems Strong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub/Sub Solid programming skills in languages like Python, SQL Experience with data modeling, data warehousing, and ETL/ELT processes Familiarity with data governance, data privacy, and security practices Strong problem-solving and analytical skills, with the ability to handle complex data-related issues Excellent communication and collaboration skills to work effectively with cross-functional teams Self-motivated and able to work independently, as well as in a team-oriented environment Nice-to-have: SAP BW data engineering skills (SAP BW 3.x, 7.x, BW on Hana) What we offer You can expect a range of benefits: including: Swarovski products discounts Employee Assistance Program Volunteering leave Learning and development programs, training and further education offers Flexible working time models (flextime, home office, part-time, etc.) Travel allowance/public transport ticket/bike leasing Company subsidy for lunch in the canteens Company pension plan (from the 3rd year of employment) Childbirth grant, other personal allowances, if applicable Company cr√®che, summer holiday care for children Free sports and health programs Voluntary profit-sharing Subsidy for private health insurance Loyalty benefits such as bonuses, anniversary gifts, etc. Rent of company apartments for the employees Masters of Light Since 1895 Swarovski creates beautiful crystal-based products of impeccable quality and craftsmanship that bring joy and celebrate individuality. Founded in 1895 in Austria, the company designs, manufactures and sells the world's finest crystal, gemstones, Swarovski Created Diamonds and zirconia, jewelry, and accessories, as well as crystal objects and home accessories. Swarovski Crystal Business has a global reach with approximately 2,400 stores and 6,700 points of sales in around 140 countries and employs more than 18,000 people. Together with its sister companies Swarovski Optik (optical devices) and Tyrolit (abrasives), Swarovski Crystal Business forms the Swarovski Group. A responsible relationship with people and the planet is part of Swarovski‚Äôs heritage. Today this legacy is rooted in sustainability measures across the value chain, with an emphasis on circular innovation, championing diversity, inclusion and self-expression, and in the philanthropic work of the Swarovski Foundation, which supports charitable organizations bringing positive environmental and social impact. Swarovski is an equal opportunity employer. We give our people the guts to celebrate individuality and pride ourselves on creating a workplace where people feel involved, respected, valued, connected, and heard. A place where anyone/everyone belongs. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate based on race, color, religion, marital status, age, national origin, physical or mental disability, medical condition, pregnancy, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under the law of the countries we operate in. Due to legal reasons, we advise that the collectively agreed base monthly salary for this position is at least ‚Ç¨ 3.497,87 gross. Our actual salaries are market competitive and take individual qualifications and experience into consideration. Erschaffe eine Welt der Wunder Bei Swarovski zu arbeiten bedeutet ein Teil eines gr√∂√üeren Ziels zu sein. Du kannst einen positiven Einfluss aus√ºben und Wunder bewirken, indem du deine einzigartigen Ideen zum Leben erweckst. Gemeinsam inspirieren wir die Welt der Inneneinrichtung, der Mode, der Kultur, des Films und der Unterhaltung. Einstellungsprozess bei Swarovski Du bist nur ein paar Schritte davon entfernt, ein Teil unserer Welt der Wunder zu werden. W√§hle die Stelle aus, die dich am meisten reizt, schreibe deinen Lebenslauf und schicke deine Bewerbung ab. Sobald deine Bewerbung sorgf√§ltig gepr√ºft wurde, werden wir uns mit dir in Verbindung setzen, um dir weitere Fragen zu stellen, dich √ºber die Stelle zu informieren und dir die n√§chsten Schritte mitzuteilen. Wenn du erfolgreich bist, laden wir dich zu mindestens einem Vorstellungsgespr√§ch ein und k√∂nnen dich bitten, eine Fallstudie vorzubereiten oder einen Test zu machen. Du wirst auch Zeit haben, deine Fragen zu stellen. Lebenslauf-Tipps f√ºr deinen Traumjob Der erste Eindruck z√§hlt: Gestalte deinen zweiseitigen Lebenslauf professionell und √§sthetisch. F√ºge die wichtigsten Details hinzu, die zeigen, dass du f√ºr die Stelle gut geeignet bist, und konzentriere dich auf deine F√§higkeiten, Projekte, Erfolge, Ergebnisse und Ausbildung. Sag uns, wie gut du Fremdsprachen sprichst/schreibst. Wir lesen gerne die Zusammenfassungen von Bewerberprofilen mit Zielen und Leidenschaften - sie unterstreichen deine Pers√∂nlichkeit und Motivation. Wenn du noch am Anfang deiner beruflichen Laufbahn stehst, zeige deine Individualit√§t und hebe die Details hervor, die f√ºr die Stelle relevant sind (z.B. Praktika, Freiwilligen- oder Aushilfsjobs, Online-Kurse, Zertifikate, Austauschprogramme im Ausland""]}]","[{'link': 'https://www.google.com/search?q=1300+Swarovski+International+Holding+AG&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAII_Q0', 'text': 'See web results for 1300 Swarovski International Holding AG'}]",,"['Work from home', 'Part-time']","{'schedule_type': 'Part-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChmL20vZCkiLCJodGlkb2NpZCI6Im1VbHJyb3RYM2lnQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVUxck1teHNUSFkzY0ZsT1YyUnZhRWxQVTBVeVNXRXdTMVJXTTBWRVNtVnlVMjVDYWw5RFgxWTFkMWxtVHpoa1dWTkZiSGhUY2tvNFdVeElTMkZYUzBKb2RHRnBRMmgxVGt4cVRISTBOakZxUzFWT1UwdzJNbll5WVdKalkySldTRXhFTFVKTWEzTk1VWEU1WTB0dFNrWXdXbXBUUmxGTWFpMXhOa0pTUm0xSlkxTjJOVUkyYW5CVWFDMXBOME5CVDI5TE5UZGFUbDlKZWpkUWExTndXWGN3VVhaeFVFMHhSR2xaYTFkdVQyc3haa3hCZDFORVNuaGhZV0ppUVRCeGVFRkxlbTFyWm5ZelNrSlRNMHRoVDA1amRVRlRabFpQYm1oUWFqQXhUVkk1UVJJWFFtSlFTRnBOU0VkT1VDMXBOVTV2VUdwbVF6SjVRVTBhSWtGTVJWTTVkVTB3Y0RKNFUyaG9kaTFUTVVSb2F6UkNhV05sU0VZMlUxRXlhMUUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBXb3JrZGF5IiwibGluayI6Imh0dHBzOi8vc3dhcm92c2tpLndkMy5teXdvcmtkYXlqb2JzLmNvbS9kZS1ERS9zd2Fyb3Zza2kvam9iL0RhdGEtRW5naW5lZXJfUi04MjAzMS0xP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (f/m/d),Swarovski,"  Wattens, Austria   ",via Talent.com,"About the job

We are seeking a skilled and passionate Data Engineer (f / m / d) to join our dynamic Data Engineering team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure from the landing zone in Google Cloud Platform (GCP) to the consumption layer.

You will collaborate closely with data scientists, analysts, and other stakeholders to ensure the availability, quality, and reliability of our data assets, enabling data-driven decision-making throughout the organization.

Your responsibilities include, but are not limited to :
‚Ä¢ Designing and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house
‚Ä¢ Collaborating with cross-functional teams to understand data requirements and to translate them into technical solutions
‚Ä¢ Optimizing and fine-tuning data pipelines for efficiency, performance, and... scalability
‚Ä¢ Implementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness
‚Ä¢ Working closely with data scientists and analysts to provide them with the necessary data and tools for analysis and reporting
‚Ä¢ Maintaining and enhancing data models and data dictionaries to facilitate data understanding and usage
‚Ä¢ Staying up-to-date with the latest industry trends, best practices, and emerging technologies in data engineering and analytics

About you

We are looking for a unique and amazing talent, who brings along the following :
‚Ä¢ Bachelor's or Master's degree in Computer Science, Engineering, or a related field
‚Ä¢ 5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems
‚Ä¢ Strong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub / Sub
‚Ä¢ Solid programming skills in languages like Python, SQL
‚Ä¢ Experience with data modeling, data warehousing, and ETL / ELT processes
‚Ä¢ Familiarity with data governance, data privacy, and security practices
‚Ä¢ Strong problem-solving and analytical skills, with the ability to handle complex data-related issues
‚Ä¢ Excellent communication and collaboration skills to work effectively with cross-functional teams
‚Ä¢ Self-motivated and able to work independently, as well as in a team-oriented environment
‚Ä¢ Nice-to-have : SAP BW data engineering skills (SAP BW 3.x, 7.x, BW on Hana)

What we offer

You can expect a range of benefits : including :
‚Ä¢ Swarovski products discounts
‚Ä¢ Employee Assistance Program
‚Ä¢ Volunteering leave
‚Ä¢ Learning and development programs, training and further education offers
‚Ä¢ Flexible working time models (flextime, home office, part-time, etc.)
‚Ä¢ Travel allowance / public transport ticket / bike leasing
‚Ä¢ Company subsidy for lunch in the canteens
‚Ä¢ Company pension plan (from the 3rd year of employment)
‚Ä¢ Childbirth grant, other personal allowances, if applicable
‚Ä¢ Company cr√®che, summer holiday care for children
‚Ä¢ Free sports and health programs
‚Ä¢ Voluntary profit-sharing
‚Ä¢ Subsidy for private health insurance
‚Ä¢ Loyalty benefits such as bonuses, anniversary gifts, etc.
‚Ä¢ Rent of company apartments for the employees

Masters of Light Since 1895

Swarovski creates beautiful crystal-based products of impeccable quality and craftsmanship that bring joy and celebrate individuality.

Founded in 1895 in Austria, the company designs, manufactures and sells the world's finest crystal, gemstones, Swarovski Created Diamonds and zirconia, jewelry, and accessories, as well as crystal objects and home accessories.

Swarovski Crystal Business has a global reach with approximately 2,400 stores and 6,700 points of sales in around 140 countries and employs more than 18,000 people.

Together with its sister companies Swarovski Optik (optical devices) and Tyrolit (abrasives), Swarovski Crystal Business forms the Swarovski Group.

A responsible relationship with people and the planet is part of Swarovski‚Äôs heritage. Today this legacy is rooted in sustainability measures across the value chain, with an emphasis on circular innovation, championing diversity, inclusion and self-expression, and in the philanthropic work of the Swarovski Foundation, which supports charitable organizations bringing positive environmental and social impact.

Swarovski is an equal opportunity employer. We give our people the guts to celebrate individuality and pride ourselves on creating a workplace where people feel involved, respected, valued, connected, and heard.

A place where anyone / everyone belongs. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs.

We do not discriminate based on race, color, religion, marital status, age, national origin, physical or mental disability, medical condition, pregnancy, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under the law of the countries we operate in.

Due to legal reasons, we advise that the collectively agreed base monthly salary for this position is at least ‚Ç¨ 3.497,87 gross.

Our actual salaries are market competitive and take individual qualifications and experience into consideration","[{'items': [""About the job\n\nWe are seeking a skilled and passionate Data Engineer (f / m / d) to join our dynamic Data Engineering team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure from the landing zone in Google Cloud Platform (GCP) to the consumption layer.\n\nYou will collaborate closely with data scientists, analysts, and other stakeholders to ensure the availability, quality, and reliability of our data assets, enabling data-driven decision-making throughout the organization.\n\nYour responsibilities include, but are not limited to :\n‚Ä¢ Designing and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house\n‚Ä¢ Collaborating with cross-functional teams to understand data requirements and to translate them into technical solutions\n‚Ä¢ Optimizing and fine-tuning data pipelines for efficiency, performance, and... scalability\n‚Ä¢ Implementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness\n‚Ä¢ Working closely with data scientists and analysts to provide them with the necessary data and tools for analysis and reporting\n‚Ä¢ Maintaining and enhancing data models and data dictionaries to facilitate data understanding and usage\n‚Ä¢ Staying up-to-date with the latest industry trends, best practices, and emerging technologies in data engineering and analytics\n\nAbout you\n\nWe are looking for a unique and amazing talent, who brings along the following :\n‚Ä¢ Bachelor's or Master's degree in Computer Science, Engineering, or a related field\n‚Ä¢ 5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems\n‚Ä¢ Strong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub / Sub\n‚Ä¢ Solid programming skills in languages like Python, SQL\n‚Ä¢ Experience with data modeling, data warehousing, and ETL / ELT processes\n‚Ä¢ Familiarity with data governance, data privacy, and security practices\n‚Ä¢ Strong problem-solving and analytical skills, with the ability to handle complex data-related issues\n‚Ä¢ Excellent communication and collaboration skills to work effectively with cross-functional teams\n‚Ä¢ Self-motivated and able to work independently, as well as in a team-oriented environment\n‚Ä¢ Nice-to-have : SAP BW data engineering skills (SAP BW 3.x, 7.x, BW on Hana)\n\nWhat we offer\n\nYou can expect a range of benefits : including :\n‚Ä¢ Swarovski products discounts\n‚Ä¢ Employee Assistance Program\n‚Ä¢ Volunteering leave\n‚Ä¢ Learning and development programs, training and further education offers\n‚Ä¢ Flexible working time models (flextime, home office, part-time, etc.)\n‚Ä¢ Travel allowance / public transport ticket / bike leasing\n‚Ä¢ Company subsidy for lunch in the canteens\n‚Ä¢ Company pension plan (from the 3rd year of employment)\n‚Ä¢ Childbirth grant, other personal allowances, if applicable\n‚Ä¢ Company cr√®che, summer holiday care for children\n‚Ä¢ Free sports and health programs\n‚Ä¢ Voluntary profit-sharing\n‚Ä¢ Subsidy for private health insurance\n‚Ä¢ Loyalty benefits such as bonuses, anniversary gifts, etc.\n‚Ä¢ Rent of company apartments for the employees\n\nMasters of Light Since 1895\n\nSwarovski creates beautiful crystal-based products of impeccable quality and craftsmanship that bring joy and celebrate individuality.\n\nFounded in 1895 in Austria, the company designs, manufactures and sells the world's finest crystal, gemstones, Swarovski Created Diamonds and zirconia, jewelry, and accessories, as well as crystal objects and home accessories.\n\nSwarovski Crystal Business has a global reach with approximately 2,400 stores and 6,700 points of sales in around 140 countries and employs more than 18,000 people.\n\nTogether with its sister companies Swarovski Optik (optical devices) and Tyrolit (abrasives), Swarovski Crystal Business forms the Swarovski Group.\n\nA responsible relationship with people and the planet is part of Swarovski‚Äôs heritage. Today this legacy is rooted in sustainability measures across the value chain, with an emphasis on circular innovation, championing diversity, inclusion and self-expression, and in the philanthropic work of the Swarovski Foundation, which supports charitable organizations bringing positive environmental and social impact.\n\nSwarovski is an equal opportunity employer. We give our people the guts to celebrate individuality and pride ourselves on creating a workplace where people feel involved, respected, valued, connected, and heard.\n\nA place where anyone / everyone belongs. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs.\n\nWe do not discriminate based on race, color, religion, marital status, age, national origin, physical or mental disability, medical condition, pregnancy, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under the law of the countries we operate in.\n\nDue to legal reasons, we advise that the collectively agreed base monthly salary for this position is at least ‚Ç¨ 3.497,87 gross.\n\nOur actual salaries are market competitive and take individual qualifications and experience into consideration""]}]","[{'link': 'http://www.swarovski.com/', 'text': 'swarovski.com'}, {'link': 'https://www.google.com/search?q=Swarovski&sa=X&ved=0ahUKEwiB3bDbgrmAAxV_EVkFHQ24DTk4PBCYkAIIsA4', 'text': 'See web results for Swarovski'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQWWdtjKe_B_y13plqy_WtWWuamFRMT0six0e9GTDU&s,"['7 days ago', 'Full-time']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChmL20vZCkiLCJodGlkb2NpZCI6ImNRcG04UV84YnNvQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTMHcyYTIxTllXOW1aalp1ZWs5UlUya3dkMjFwVjNWU2NGWnRkalJJVWxCRk9HRXhibVU0Y1RkNlNVNWliRU5uYlRKeFVucGlURlJhVG1OdVkzZE5jVmR0U1MxVldVRm1VbE5YVHpKMFFVVmplR3RPUTFjNGQzazBRMEZFTUZCU1dYZzBTRVZxTlVSQmMxVnBhazVaY1ZSb1R6RmlOVFJLYjFad1kzbEJTVUZvWWtsdWRIUXRVa1pFU25sc2RUZHBhVEk0WkVwSGQyWklNRE14UmpCcVYwUm5VRnBZVUZGS2MzazBNbHBFTWxGWkVoZENZbEJJV2sxSVIwNVFMV2sxVG05UWFtWkRNbmxCVFJvaVFVeEZVemwxVUhGUlNtZzFaV1pWVG1oVVlVcEhibmh6ZVdGMldVcE9jbWRoWnciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBUYWxlbnQuY29tIiwibGluayI6Imh0dHBzOi8vYXQudGFsZW50LmNvbS92aWV3P2lkPWQ1ZTUyNjQ0ZTViNFx1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
TEAM LEADER (M/F/D) SYSTEM ENGINEER DATA CENTRE,Mediaprint,"  Vienna, Austria   ",via Jobs For Ukraine,"YOUR TASKS

¬∑ Lead a team of 8, managing and prioritising tasks

¬∑ Create the standby schedules and plan tasks together with your team

¬∑ Regularly plan and practise emergency scenarios

¬∑ Act as a link between in-house departments, customers and external partners

¬∑ Continue to develop and optimise the server landscape

YOUR PROFILE

¬∑ You have IT qualifications from a training course/study programme (from apprenticeship upward)

¬∑ You are skilled in working with the VMware product range

¬∑ You have knowledge of designing and managing storage and back-up solutions

¬∑ You have knowledge of implementing emergency plans

¬∑ You have extensive knowledge of running Windows and Linux system landscapes

OUR BENEFITS

¬∑ Interesting range of activities with great scope for organising your own work

¬∑ Hybrid working and performance-based pay

¬∑ Employee benefits of a large enterprise

¬∑ Opportunities for further training and education","[{'items': ['YOUR TASKS\n\n¬∑ Lead a team of 8, managing and prioritising tasks\n\n¬∑ Create the standby schedules and plan tasks together with your team\n\n¬∑ Regularly plan and practise emergency scenarios\n\n¬∑ Act as a link between in-house departments, customers and external partners\n\n¬∑ Continue to develop and optimise the server landscape\n\nYOUR PROFILE\n\n¬∑ You have IT qualifications from a training course/study programme (from apprenticeship upward)\n\n¬∑ You are skilled in working with the VMware product range\n\n¬∑ You have knowledge of designing and managing storage and back-up solutions\n\n¬∑ You have knowledge of implementing emergency plans\n\n¬∑ You have extensive knowledge of running Windows and Linux system landscapes\n\nOUR BENEFITS\n\n¬∑ Interesting range of activities with great scope for organising your own work\n\n¬∑ Hybrid working and performance-based pay\n\n¬∑ Employee benefits of a large enterprise\n\n¬∑ Opportunities for further training and education']}]","[{'link': 'https://www.mediaprint.at/', 'text': 'mediaprint.at'}, {'link': 'https://www.google.com/search?hl=en&q=Mediaprint&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAII4Ao', 'text': 'See web results for Mediaprint'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJAKfwHBos6weYNRg9VpAQrPfy35rQkUNdWj9nCas&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJURUFNIExFQURFUiAoTS9GL0QpIFNZU1RFTSBFTkdJTkVFUiBEQVRBIENFTlRSRSIsImh0aWRvY2lkIjoic2hsWmhpakxTQjhBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVTFyTW14c1NsbzVlbGRaTWs5cGVXWTJlREJNUjJWclkySmllRkJsUzA5elRuWTJOVGhPWkd4NFExUXdValZIUWkxRGFVWXpkVEZGZFZaQ1kzRTNRV2RNZFVKNUxWQTVlRmxqWTFsSFIyaFZSMmRXV2tKb1MzQm9iMUF3YURkd2FuTk9SV0ZxZDB4bWVYcFJZa3BCWVhwYVpqUnBja3ByY2tRemFITlFWMUY1UjJwMGVrOWxSRTluUkU5bVFXTXhSbFJwVmpkS2Qwb3hSa3htYURCamMzZDJTa2g2VldReGNVTkxXR0YxZDJ4bFF6aGxWSGMyYVdsSldISlRjMnBqWDFkSWVESkZaakpPT1Rka09FeG5YM0l3UW1OWVlWbFpUazVpUkVsaGRGZzBRUklYUkdKUVNGcE5ZVkZMTldKc05VNXZVR2hhYVhWeFFVVWFJa0ZNUlZNNWRVNTJhWFZhY1dwMU5HTkxhWEoyZDNOQk1GcDZRMU5tUVc5WFJVRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgb24gSm9icyBGb3IgVWtyYWluZSIsImxpbmsiOiJodHRwczovL3d3dy5qb2JzLWZvci11a3JhaW5lLmF0L2pvYi9tZWRpYXByaW50LXZpZW5uYS1mdWxsLXRpbWUtdGVhbS1sZWFkZXItbS1mLWQtc3lzdGVtLWVuZ2luZWVyLWRhdGEtY2VudHJlLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Sr. Research Engineer - Indoor Positioning and Location Analytics,Esri,"  Vienna, Austria   ",via Esri,"At the Esri R&D Center in Vienna, Austria, we drive innovation in Indoor Positioning System (IPS) technology to enhance the capabilities of indoor GIS for both casual and power users across all platforms and devices.‚ÄØ‚ÄØ‚ÄØ‚ÄØ As a talented","[{'items': ['At the Esri R&D Center in Vienna, Austria, we drive innovation in Indoor Positioning System (IPS) technology to enhance the capabilities of indoor GIS for both casual and power users across all platforms and devices.\u202f\u202f\u202f\u202f As a talented']}]","[{'link': 'http://www.esri.com/', 'text': 'esri.com'}, {'link': 'https://www.google.com/search?hl=en&q=Esri&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIkgs', 'text': 'See web results for Esri'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTOEqIMg2kLI4o1zWNhrd46b-mU6F4CLmNZbOH0rbM&s,"['8 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '8 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTci4gUmVzZWFyY2ggRW5naW5lZXIgLSBJbmRvb3IgUG9zaXRpb25pbmcgYW5kIExvY2F0aW9uIEFuYWx5dGljcyIsImh0aWRvY2lkIjoiMDN4SE1pMjRqVVlBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVTFyTW14c1REaEJWbEJ4VG14TmRsbHZYekJoYW5SclJWZEJPRkZxV1V0SVNrNXpaRTlTZDNobU5reFVibWR0VTNCek1DMVJia2MyTTNnemVsaG9kblY2YUdORmFrNW5MVkF0WTBZemJVUnFiRXBCVUZCa1VtYzVUMWsyT1VOUFMzbDRaRzh4TUdOM01YcERha1ZQYUd0dGFuQk1OMnBSVVc5WGRISkNXVmhxZEV0cUxWOTNZV1kwUVdsb2F6ZFlXR0pJUzB4VmJYUkVaVGxtVDBkaVdVZFlNbVZpYlZOcFRrSjRlbkp1WnpOTWNuaGthV1I2UlVGSlVYVXRia1F3VEZCM09XbFVibDlTZEZWME9HVXlVVlIxVW1aWExVRnVTVGN0Tm5Oa09FUlBRUklYUkdKUVNGcE5ZVkZMTldKc05VNXZVR2hhYVhWeFFVVWFJa0ZNUlZNNWRVMVJSMFIwWlhaVWRIRnRRa0ZqV0ZGWlNEZERVMVpXUXpadFEwRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gRXNyaSIsImxpbmsiOiJodHRwczovL3d3dy5lc3JpLmNvbS9jYXJlZXJzL3NyZG90LXJlc2VhcmNoLWVuZ2luZWVyLWluZG9vci1wb3NpdGlvbmluZy1hbmQtbG9jYXRpb24tYW5hbHl0aWNzLTE4OTMxP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
(Senior) Data Engineer (f/m/d) - Remote in EMEA,GraphCMS, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe, Africa

This offer from ""GraphCMS"" has been enriched by Jobgether and got a 82% flex score.

Purpose of your role as a (Senior) Data Engineer

Hygraph is looking for an experienced and passionate (Senior) Data Engineer to join our team! You will be the second data hire for Hygraph so there's a lot of overlap in this position with an Analytics Engineer. The overall goal of the data team is to empower the organization to make data-informed decisions. To realize this goal as a Data Engineer you will collaborate with our Data scientist and Product teams to further improve our data infrastructure. As one of the early members of the data team, you will have a lot of opportunities to shape the future of our data infrastructure.

Some of your tasks and responsibilities:
‚Ä¢ Design and build end-to-end data pipelines, including foundational datasets to support analytics, modeling, experimentation, and product needs
‚Ä¢ Work closely with... Data Scientist/Analyst, Product Managers and Engineering leaders
‚Ä¢ Help to define and improve our internal standards for style, maintainability, and best practices for a reliable data infrastructure
‚Ä¢ Act as a thought leader in the domain of Data Engineering and Infrastructure

Job requirements‚ÄçEssential requirements for this role: - 3+ years of experience in a Data Engineering role or similar, with architectural purview - Experience with designing and building custom data ingestion pipelines - Strong collaboration and communication skills, both verbal and written. Ability to take ownership, but also ask for help and advice when needed. - Openness to feedback and willingness to learn, reflect, and grow within the organization

Nice to have - Experience with building an Event-driven data ingestion - Experience with our data stack - Has Analytics Engineering experience

Our current data stack mainly includes: - Ingestion: Fivetran, Rudderstack - Warehouse: BigQuery - Transformation: dbt - BITools: Metabase, Hex - Activation: Hightouch

The process: - Intro call with Talent Acquisition Manager. - Technical interview - Assignment call - Team Fit call and Reference check. - Job Offer.

The response time after application, screening applications, and setting up the first intro call is usually within 1-2 weeks. You could expect some alterations when necessary.

About us

At Hygraph we're building the leading GraphQL Federated Content Platform. Our goal is to enable developers and content operators to create, enrich, unify, and deliver content across platforms seamlessly. We are trusted to manage content for teams from over 50,000 organizations like Dr. Oetker, Shure, Samsung, Ashley Furniture, Telenor, Philips, and Gamescom. With over $35M in funding led by One Peak, alongside OpenOcean, Peak, and SquareOne Venture Capital, you will be part of a remote-first and globally distributed team of about 70 team members, committed to working collaboratively, transparently, and passionately.

We believe in a remote-first approach where everyone is encouraged to do their best from wherever they are and work together with transparency, accountability, and ownership. We learn continuously through feedback and have a yearly learning budget to attend training and conferences","[{'items': ['This a Full Remote job, the offer is available from: Europe, Africa\n\nThis offer from ""GraphCMS"" has been enriched by Jobgether and got a 82% flex score.\n\nPurpose of your role as a (Senior) Data Engineer\n\nHygraph is looking for an experienced and passionate (Senior) Data Engineer to join our team! You will be the second data hire for Hygraph so there\'s a lot of overlap in this position with an Analytics Engineer. The overall goal of the data team is to empower the organization to make data-informed decisions. To realize this goal as a Data Engineer you will collaborate with our Data scientist and Product teams to further improve our data infrastructure. As one of the early members of the data team, you will have a lot of opportunities to shape the future of our data infrastructure.\n\nSome of your tasks and responsibilities:\n‚Ä¢ Design and build end-to-end data pipelines, including foundational datasets to support analytics, modeling, experimentation, and product needs\n‚Ä¢ Work closely with... Data Scientist/Analyst, Product Managers and Engineering leaders\n‚Ä¢ Help to define and improve our internal standards for style, maintainability, and best practices for a reliable data infrastructure\n‚Ä¢ Act as a thought leader in the domain of Data Engineering and Infrastructure\n\nJob requirements\u200dEssential requirements for this role: - 3+ years of experience in a Data Engineering role or similar, with architectural purview - Experience with designing and building custom data ingestion pipelines - Strong collaboration and communication skills, both verbal and written. Ability to take ownership, but also ask for help and advice when needed. - Openness to feedback and willingness to learn, reflect, and grow within the organization\n\nNice to have - Experience with building an Event-driven data ingestion - Experience with our data stack - Has Analytics Engineering experience\n\nOur current data stack mainly includes: - Ingestion: Fivetran, Rudderstack - Warehouse: BigQuery - Transformation: dbt - BITools: Metabase, Hex - Activation: Hightouch\n\nThe process: - Intro call with Talent Acquisition Manager. - Technical interview - Assignment call - Team Fit call and Reference check. - Job Offer.\n\nThe response time after application, screening applications, and setting up the first intro call is usually within 1-2 weeks. You could expect some alterations when necessary.\n\nAbout us\n\nAt Hygraph we\'re building the leading GraphQL Federated Content Platform. Our goal is to enable developers and content operators to create, enrich, unify, and deliver content across platforms seamlessly. We are trusted to manage content for teams from over 50,000 organizations like Dr. Oetker, Shure, Samsung, Ashley Furniture, Telenor, Philips, and Gamescom. With over $35M in funding led by One Peak, alongside OpenOcean, Peak, and SquareOne Venture Capital, you will be part of a remote-first and globally distributed team of about 70 team members, committed to working collaboratively, transparently, and passionately.\n\nWe believe in a remote-first approach where everyone is encouraged to do their best from wherever they are and work together with transparency, accountability, and ownership. We learn continuously through feedback and have a yearly learning budget to attend training and conferences']}]","[{'link': 'http://hygraph.com/', 'text': 'hygraph.com'}, {'link': 'https://www.google.com/search?hl=en&q=GraphCMS&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIyAs', 'text': 'See web results for GraphCMS'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQv0sNYLABy4DPPrmQJ0VuM-EaX7_ga1qKlM3S4MfU&s,"['12 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '12 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiIoU2VuaW9yKSBEYXRhIEVuZ2luZWVyIChmL20vZCkgLSBSZW1vdGUgaW4gRU1FQSIsImh0aWRvY2lkIjoiekdNU2Fyelc3OWNBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXJjQ0N2Y0JRVTFyTW14c1RIbE5VM1J0VDNoTllXVXpjMVZEVW1Kc1MwdG1XSEI1Y2xJelVGTlVjbEZ3VURaR1owTXlWVWR3ZDJsNWFIbExPSE5vUWt3MmNVNXVVSEkyVWpCcE9XOVBjUzFFV2xaa05XRTFja0Z2WTNkaUxXOWhSRFZDUlRaNmRUbERRMEphVkVKM2FqRm5ibUp1TlhwalEwVnZRVTVuTkVScVFsUkpWRWxWVTBwZlNqUlZhamxtVGtoQ2IySkdURTlHYVZodk5FTlpXbk4xVm5vMFQweElkMnhaWlhkbFEzQnFMVUY2TWxKa1VHUXdNWEJ2TFhOSFgyOXpVa1pPVnpKbVdGcElXRGx5V1ZWVlZXNTNaMVZaUlV4clNXVkpNWGs0VEdaaE1sRkphV0V4YUZZMU5XRk9OMjUxTlhWQ1pqbGtWa0pYTkJJWFJHSlFTRnBOWVZGTE5XSnNOVTV2VUdoYWFYVnhRVVVhSWtGTVJWTTVkVTFQTWxkeE5HbGlObk5yUlZOWFQwWkpaMDVpZWtkcFZrb3pMV2MiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYmdldGhlciIsImxpbmsiOiJodHRwczovL2pvYmdldGhlci5jb20vb2ZmZXIvNjRiN2FkY2JiZWZiOTIxNDM5NTEwN2QyLXNlbmlvci1kYXRhLWVuZ2luZWVyLWZtZC1yZW1vdGUtaW4tZW1lYT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer,solvistas GmbH,"  Vienna, Austria  (+1 other)    ",via DEVjobs.at,"Your role in the team
‚Ä¢ You are responsible for data preparation for harmonization and further processing (cleansing, ingestion, ...)
‚Ä¢ You work on data modeling (e.g. Data Vault 2.0, Kimball,...)
‚Ä¢ You develop and continuously optimize reliable data routes
‚Ä¢ You work independently on setting up, configuring and optimizing the infrastructure
‚Ä¢ Implementing a robust CI/CD workflow (Jenkins, Git, ...) is routine for you
‚Ä¢ You take care of the support of our customers and the implementation of their wishes and requirements
‚Ä¢ You assume responsibility for the analysis and optimization of the performance of ETL processes
‚Ä¢ You use data visualization (e.g. PowerBI, Cognos,...) to create that certain ""wow effect"" for our customers

Technologies and skills
‚Ä¢ SQL
‚Ä¢ Cognos
‚Ä¢ Jenkins
‚Ä¢ Power BI
‚Ä¢ PL/SQL
‚Ä¢ Python

Our expectations:

Qualifications
‚Ä¢ Knowledge of infrastructure (databases, cloud systems, virtual machines)
‚Ä¢ independent and committed way of working
‚Ä¢ Very good knowledge of German... (level at least B2, oral and written)
‚Ä¢ SQL/PL-SQL knowledge
‚Ä¢ Knowledge of data profiling

Experience
‚Ä¢ Professional experience as a data engineer or in a comparable function
‚Ä¢ Experience with Python or other programming/scripting languages

Education
‚Ä¢ Completed technical training (degree, FH, HTL ...) in which you discovered your interest in data science

Benefits
‚Ä¢ *
‚Ä¢ Fresh Fruit
‚Ä¢ Health Care Benefits
‚Ä¢ Meal Vouchers
‚Ä¢ Flexible Working Hours
‚Ä¢ Excellent Traffic Connections","[{'items': ['Your role in the team\n‚Ä¢ You are responsible for data preparation for harmonization and further processing (cleansing, ingestion, ...)\n‚Ä¢ You work on data modeling (e.g. Data Vault 2.0, Kimball,...)\n‚Ä¢ You develop and continuously optimize reliable data routes\n‚Ä¢ You work independently on setting up, configuring and optimizing the infrastructure\n‚Ä¢ Implementing a robust CI/CD workflow (Jenkins, Git, ...) is routine for you\n‚Ä¢ You take care of the support of our customers and the implementation of their wishes and requirements\n‚Ä¢ You assume responsibility for the analysis and optimization of the performance of ETL processes\n‚Ä¢ You use data visualization (e.g. PowerBI, Cognos,...) to create that certain ""wow effect"" for our customers\n\nTechnologies and skills\n‚Ä¢ SQL\n‚Ä¢ Cognos\n‚Ä¢ Jenkins\n‚Ä¢ Power BI\n‚Ä¢ PL/SQL\n‚Ä¢ Python\n\nOur expectations:\n\nQualifications\n‚Ä¢ Knowledge of infrastructure (databases, cloud systems, virtual machines)\n‚Ä¢ independent and committed way of working\n‚Ä¢ Very good knowledge of German... (level at least B2, oral and written)\n‚Ä¢ SQL/PL-SQL knowledge\n‚Ä¢ Knowledge of data profiling\n\nExperience\n‚Ä¢ Professional experience as a data engineer or in a comparable function\n‚Ä¢ Experience with Python or other programming/scripting languages\n\nEducation\n‚Ä¢ Completed technical training (degree, FH, HTL ...) in which you discovered your interest in data science\n\nBenefits\n‚Ä¢ *\n‚Ä¢ Fresh Fruit\n‚Ä¢ Health Care Benefits\n‚Ä¢ Meal Vouchers\n‚Ä¢ Flexible Working Hours\n‚Ä¢ Excellent Traffic Connections']}]","[{'link': 'http://www.solvistas.com/', 'text': 'solvistas.com'}, {'link': 'https://www.google.com/search?hl=en&q=solvistas+GmbH&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAII_ws', 'text': 'See web results for solvistas GmbH'}]",,"['21 days ago', '‚Ç¨56,448 a year', 'Full-time', 'No degree mentioned']","{'posted_at': '21 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiY2hnS0VkdjVwS1FBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1MwSkdhV3RSVlVsZlRucDBhVXRRU1VNd1FWOVlZMjVSYjA1NGVFeEZha0ZwUlVsT1VIUnJXRTVLVERoMmIwaEtlV1F6YW5WcGVrOUhlbXBJWkcwNWVtdHpkR3AwV2sxbE5YbFBVazFxZUZoUmNrZFVaa05hVFhWQlFXWTJkblF6WjFSUFFXWk9iM2t6Ukc5T01saExNV3hrY1djellqUlZjRVZaWkZGUFNWRnFNa1oxWWtKbmVWaGxUbkpKV0VKb1NrUTJPVXMzYzBFdGFGTm5iMHBUU0d4cFpVTmpNbHAyUWxKTGVXUktNRFZSRWhkRVlsQklXazFoVVVzMVltdzFUbTlRYUZwcGRYRkJSUm9pUVV4RlV6bDFUVlpDTUdGcU5rWlNZMDg0YVROT2RYcGtaRUpwUTFSak9HaHdadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzciLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gREVWam9icy5hdCIsImxpbmsiOiJodHRwczovL2VuLmRldmpvYnMuYXQvam9iL2UxMjI3NmEwNDZmNTU0MzY3MGRmMDE5MzQ4NzUyZmVmP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Azure Data Engineer,SO Digital Recruitment,"  Vienna, Austria   ",via LinkedIn,"We're working with an innovative and fast-growing AI and platform consultancy based in Vienna who are currently looking to increase their headcount of expert Azure Data Engineers.

Required experience:
‚Ä¢ Experience in Python, C#, Scala & SQL
‚Ä¢ Strong interest in Artificial Intelligence
‚Ä¢ Experience working with Data Scientists
‚Ä¢ Experience in Cloud Technology (preferably in Azure).
‚Ä¢ Experience with Hadoop and/or Spark
‚Ä¢ Experience in Datafactory, Databricks, and Synapse is a big advantage.
‚Ä¢ German speaking is preferred

The client will provide an opportunity to be part of a young and highly motivated team, being at the cutting-edge of AI Development. They have a big emphasis on learning and development whilst working on challenging and extremely interesting projects.

Please apply to the job advert or send your resume to reece@sodigitalrecruitment.com","[{'items': [""We're working with an innovative and fast-growing AI and platform consultancy based in Vienna who are currently looking to increase their headcount of expert Azure Data Engineers.\n\nRequired experience:\n‚Ä¢ Experience in Python, C#, Scala & SQL\n‚Ä¢ Strong interest in Artificial Intelligence\n‚Ä¢ Experience working with Data Scientists\n‚Ä¢ Experience in Cloud Technology (preferably in Azure).\n‚Ä¢ Experience with Hadoop and/or Spark\n‚Ä¢ Experience in Datafactory, Databricks, and Synapse is a big advantage.\n‚Ä¢ German speaking is preferred\n\nThe client will provide an opportunity to be part of a young and highly motivated team, being at the cutting-edge of AI Development. They have a big emphasis on learning and development whilst working on challenging and extremely interesting projects.\n\nPlease apply to the job advert or send your resume to reece@sodigitalrecruitment.com""]}]","[{'link': 'https://www.google.com/search?hl=en&q=SO+Digital+Recruitment&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIsQw', 'text': 'See web results for SO Digital Recruitment'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSixURB9NvpfObXJinr3mQATh7Y6NnO9STvtRdZ2jQ&s,"['7 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgQXp1cmUgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiSWtZdUZQWVloeFlBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1NrUnBaa0kwYlhaelduSlVWRzlZV0dsNGN5MHhWbEV6Y3pkcE5IVmlUbEpVTFcxU1RGcE1RWFppZUZOR01FTnBWWFk1TlUxNGIwdEJaMU5XVkRJeGFVSnhjbFZ5WkdGc01sRjJVM0IwWVdKSlNsaHVOMjFHT1RaVU9HTmlWVE41YW5walRrc3pUbDlLTVhvM2VXMTZOVmw0VDFacVZVZHRaeTB4TTBWNlJXRlpOWEJvTkZka1duVlpPVEpTWkdWTVNrUkVkMXBGTVVSSVdFTktVM3BZYlVoRlZrSlhOQzF4ZFdvelZteFlTbkpyRWhkRVlsQklXazFoVVVzMVltdzFUbTlRYUZwcGRYRkJSUm9pUVV4RlV6bDFUVlpXVWxOaE1UUlpVRVEyYVRabGVGQnJiRXhGYTBkamNYSm1adyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzkiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gTGlua2VkSW4iLCJsaW5rIjoiaHR0cHM6Ly9hdC5saW5rZWRpbi5jb20vam9icy92aWV3L3Nlbmlvci1henVyZS1kYXRhLWVuZ2luZWVyLWF0LXNvLWRpZ2l0YWwtcmVjcnVpdG1lbnQtMzY3NDE3NjA5OD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer*,KTM Innovation,  Austria   ,via Jooble,"with a passion for databases and interfaces
(Ref.Nr.:3135)

full time

asap

IT Data Integration
‚Ä¢ As a global player rooted in Austria, we thrive on diversity. No matter what gender you may be, where you come from or the color of your skin - here, you are YOU, and that‚Äôs what matters to us.

The opportunities are endless when you are fearless
Driven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion. To this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees. That‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience. With or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!

To ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE... we are also stepping on the gas in the area of IT and data integration. Are you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you? Then this is the right job for you. THE TASKS AWAITING YOU
‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).
‚Ä¢ provision of data using different technologies/paradigms (ETL, web services such as REST/SOAP/ODATA, Stream processing/Message Broker) in coordination with those responsible for source and target systems
‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)
‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)
‚Ä¢ coordination and cooperation with external service providers
‚Ä¢ orchestration and monitoring of automated process steps
HOW YOU CAN INSPIRE US
‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience
‚Ä¢ very good knowledge of relational database systems
‚Ä¢ mastery of at least one scripting or programming language
‚Ä¢ experience with web services (REST/SOAP/ODATA)
‚Ä¢ experience with data integration and/or orchestration tools would be an advantage
‚Ä¢ very good written and spoken English
‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation
‚Ä¢ independent and self-reliant working style as well as absolute reliability
WHAT YOU CAN LOOK FORWARD TO
‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer
‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu
‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit
Flexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation.

Professional
development You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System. From seminars to in-house training, we'll get you ready for the front row.

KTM MasterCard Gold Free Mastercard Gold in KTM Style. Travel insurance coverage for the whole family included.

Employee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together.

Special rates
for employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us.

Pension
scheme Each year, the company voluntarily pays additional life insurance for its employees.

If you have any questions, please contact Eva Reithofer on Telefonnummer auf click.appcast.io ansehen

Find similar jobs in IT here or check out jobs at Avocodo .

Application process:
Two-stage with personal interviews (department and HR), as well as a brief introduction to the team during the second interview
Are you interested in working in a dynamic and motivated team? If so, we look forward to your informative online application (curriculum vitae, cover letter as well as relevant references)! Apply now","[{'items': [""with a passion for databases and interfaces\n(Ref.Nr.:3135)\n\nfull time\n\nasap\n\nIT Data Integration\n‚Ä¢ As a global player rooted in Austria, we thrive on diversity. No matter what gender you may be, where you come from or the color of your skin - here, you are YOU, and that‚Äôs what matters to us.\n\nThe opportunities are endless when you are fearless\nDriven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion. To this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees. That‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience. With or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!\n\nTo ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE... we are also stepping on the gas in the area of IT and data integration. Are you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you? Then this is the right job for you. THE TASKS AWAITING YOU\n‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).\n‚Ä¢ provision of data using different technologies/paradigms (ETL, web services such as REST/SOAP/ODATA, Stream processing/Message Broker) in coordination with those responsible for source and target systems\n‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)\n‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)\n‚Ä¢ coordination and cooperation with external service providers\n‚Ä¢ orchestration and monitoring of automated process steps\nHOW YOU CAN INSPIRE US\n‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience\n‚Ä¢ very good knowledge of relational database systems\n‚Ä¢ mastery of at least one scripting or programming language\n‚Ä¢ experience with web services (REST/SOAP/ODATA)\n‚Ä¢ experience with data integration and/or orchestration tools would be an advantage\n‚Ä¢ very good written and spoken English\n‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation\n‚Ä¢ independent and self-reliant working style as well as absolute reliability\nWHAT YOU CAN LOOK FORWARD TO\n‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer\n‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu\n‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit\nFlexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation.\n\nProfessional\ndevelopment You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System. From seminars to in-house training, we'll get you ready for the front row.\n\nKTM MasterCard Gold Free Mastercard Gold in KTM Style. Travel insurance coverage for the whole family included.\n\nEmployee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together.\n\nSpecial rates\nfor employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us.\n\nPension\nscheme Each year, the company voluntarily pays additional life insurance for its employees.\n\nIf you have any questions, please contact Eva Reithofer on Telefonnummer auf click.appcast.io ansehen\n\nFind similar jobs in IT here or check out jobs at Avocodo .\n\nApplication process:\nTwo-stage with personal interviews (department and HR), as well as a brief introduction to the team during the second interview\nAre you interested in working in a dynamic and motivated team? If so, we look forward to your informative online application (curriculum vitae, cover letter as well as relevant references)! Apply now""]}]","[{'link': 'https://www.google.com/search?hl=en&q=KTM+Innovation&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAII5Aw', 'text': 'See web results for KTM Innovation'}]",,"['2 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyKiIsImh0aWRvY2lkIjoicFk5dGZVRDBYVG9BQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVTFyTW14c1NtbEROVE5mZVZRMmVUaElSVU4yTjFaSE9HdEVOWFJ4WWtwUlZqUmxVM1UxY25kM2Qyc3hSbVZRUVdvemJXaGpUM2MxWVV0Tk4xUkJSRFppWW1OWlpYWnpPRU5oV0V4cmVVWjNjRU5YUVdwTlZYZElWbEoxTVdkRlRIbHFNakZOVFRSd05FTkJkRTlXVWpsallXVlBXbFpsTUd4R1YxUk9WWE5RTFhWSVlYYzBZVlkzTFhrM1NYRXpPR3h1V1habFoycHBNa0pGWld3M09UWm5FaGRFWWxCSVdrMWhVVXMxWW13MVRtOVFhRnBwZFhGQlJSb2lRVXhGVXpsMVVIUXlOV1pxT1VacU1uTmFkRFZzU0dwU2NHcDNVRzVOWnpKc1FRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTAiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9vYmxlIiwibGluayI6Imh0dHBzOi8vYXQuam9vYmxlLm9yZy9qZHAvLTUzODQ5MjEzMDM4OTYxODkxNTkvRGF0YS1FbmdpbmVlciotJUMzJTk2c3RlcnJlaWNoP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Software & Data Engineer for Data Science Applications,√ñBB-Holding AG,"  Vienna, Austria   ",via M√ºnchner Jobanzeiger,"Wir m√∂chten neue Wege gehen. Und neue Wege schaffen. Heute. F√ºr morgen. F√ºr uns.

Werden auch Sie Teil des #Team √ñBB.

Wir sind die Zukunft der Mobilit√§t: Die Gesellschaften des √ñBB-Konzerns leisten zusammen alles, was eine moderne, zuverl√§ssige und umweltfreundliche Mobilit√§tskette braucht.

Ob Schienennetz, Bahnh√∂fe oder andere Anlagen, wir bauen und betreiben die Infrastruktur der √ñBB bedarfsgerecht und zuverl√§ssig. Auch den sicheren und p√ºnktlichen Betrieb aller Z√ºge managen wir. Wir, das sind die 18.000 KollegInnen der √ñBB-Infrastruktur AG.

Wir sorgen daf√ºr, dass die Bahnanlagen zuverl√§ssig f√ºr unsere BahnkundInnen zur Verf√ºgung stehen. Mit unserer technischen Expertise leisten wir einen zentralen Beitrag f√ºr den sicheren und p√ºnktlichen Eisenbahnverkehr. Wir, das sind die 6.000 KollegInnen aus dem Gesch√§ftsbereich Streckenmanagement und Anlagenentwicklung (SAE).

Ihr Job
‚Ä¢ Sie begleiten von der Planung bis zur Umsetzung datenzentrierter Softwareprojekte sowohl steuernd als auch... durch praktische Mitarbeit.
‚Ä¢ Sie entwickeln Tools zur Datenanalyse, u.a. auch auf einem K8s Cluster sowie allgemein Software zur Unterst√ºtzung unserer Data-Science-Projekte.
‚Ä¢ Sie arbeiten aktiv beim Aufbau einer nachhaltigen IT-Infrastruktur f√ºr flexible, innovative und effiziente Analysen,
Explorative Analyse, Auswertung und Darstellung gro√üer strukturierter und unstrukturierter Datenmengen aus verschiedenen Systemen und deren Zusammenh√§nge mit.
‚Ä¢ Die Bearbeitung von Fragestellungen in interdisziplin√§ren, agilen Teams geh√∂rt ebenfalls zu Ihrem Aufgaben sowie das Vorstellen und Pr√§sentieren der Ergebnisse vor Stakeholdern.

Ihr Profil
‚Ä¢ Abgeschlossenes FH- oder Universit√§tsstudium im Bereich Informatik, Wirtschaftsinformatik oder Computertechnik bzw. eine vergleichbare Qualifikation.
‚Ä¢ Berufserfahrung im Bereich Software Engineering, Data Engineering und Softwareprojektmanagement
Optionale Erfahrung im Bereich Data Science ist von Vorteil.
‚Ä¢ Sehr gute Kenntnisse in der Programmierung mit Python und in einer oder mehreren der folgenden Sprachen: Java, Kotlin, C#, C++, C sowie generelle Begeisterung am Lernen von Sprachen.
‚Ä¢ Sehr gute Kenntnisse in der Versionsverwaltung mit Git.
‚Ä¢ Optionale Kenntnisse betreffend IoT-Frameworks, Apache Camel, Docker/Podman (Containerisierung i. A.), Apache Kafka, Knime und R sind von Vorteil.
‚Ä¢ Sehr gute Kenntnisse in relationaler Datenmodellierung und relationalen DBMS, Grundverst√§ndnis f√ºr DWH und Reportinganwendungen.
‚Ä¢ Optionale Kenntnisse im Bereich GNU/Linux, Commandline, Shell Scripting sind von Vorteil.
‚Ä¢ Interesse an pers√∂nlicher Weiterentwicklung und Begeisterung Neues zu lernen.
‚Ä¢ Kommunikations- und Teamf√§higkeit.

Unser Angebot
‚Ä¢ F√ºr die Funktion ""Techn. Spez. Sen. Stab Leistungsmng.‚Äú ist ein Mindestentgelt von ‚Ç¨ 47.053,58 brutto/Jahr vorgesehen. Je nach Qualifikation und Berufserfahrung ist eine √úberzahlung m√∂glich.
‚Ä¢ Wir erm√∂glichen flexible Freizeitgestaltung durch ein attraktives Gleitzeitmodell.
‚Ä¢ Als gr√∂√ütes Klimaschutzunternehmen des Landes bieten wir Ihnen einen sicheren und nachhaltigen Arbeitsplatz mit spannenden Aufgaben sowie die Chance, Ihren pers√∂nlichen Beitrag zur klima- und umweltfreundlichen Mobilit√§t zu leisten.
‚Ä¢ Besondere Konditionen bei Bahnreisen & in unseren Reiseb√ºros, Ferienh√§user und Appartements in beliebten heimischen Urlaubsregionen.
‚Ä¢ Unser konzerninternes Wohnungsservice bietet bundesweit √ñBB-Mitarbeiter:innenwohnungen an.
‚Ä¢ Sie haben die Option, die Fahrbeg√ºnstigung in Anspruch zu nehmen und √ñsterreich mit der √ñBB zu entdecken.So arbeiten Sie nicht nur an klimafreundlicher Mobilit√§t, sondern k√∂nnen auch umweltfreundlich mit Ihrer Familie reisen.
‚Ä¢ Sie profitieren von hervorragenden Weiterbildungsangeboten sowie zahlreichen Weiterentwicklungsm√∂glichkeiten innerhalb des Konzerns.

Ihre Bewerbung

Bitte bewerben Sie sich online mit Motivationsschreiben und Lebenslauf. Als interne/r BewerberIn f√ºgen Sie idealerweise bitte auch Ihren SAP-Auszug hinzu

Frauen sind ein unverzichtbarer Teil unseres Erfolges und unserer Unternehmenskultur. Deshalb begr√º√üen wir besonders Bewerbungen von Frauen, die bei gleicher Qualifikation ‚Äì unter Ber√ºcksichtigung der relevanten Rahmenumst√§nde aller Bewerbungen ‚Äì bevorzugt aufgenommen werden.

Wir weisen darauf hin, dass im Zuge der Aufnahme die Beibringung einer Strafregisterbescheinigung erforderlich ist.
Ansprechpartner:innen

Fragen zu dieser Jobausschreibung wenden Sie sich bitte an Monika M√ºller , +43664/88331 664.
F√ºr allgemeine Fragen zum Bewerbungsprozess steht Ihnen unser √ñBB Recruiting Team unter 05 1778 97 77888 gerne zur Verf√ºgung","[{'items': ['Wir m√∂chten neue Wege gehen. Und neue Wege schaffen. Heute. F√ºr morgen. F√ºr uns.\n\nWerden auch Sie Teil des #Team √ñBB.\n\nWir sind die Zukunft der Mobilit√§t: Die Gesellschaften des √ñBB-Konzerns leisten zusammen alles, was eine moderne, zuverl√§ssige und umweltfreundliche Mobilit√§tskette braucht.\n\nOb Schienennetz, Bahnh√∂fe oder andere Anlagen, wir bauen und betreiben die Infrastruktur der √ñBB bedarfsgerecht und zuverl√§ssig. Auch den sicheren und p√ºnktlichen Betrieb aller Z√ºge managen wir. Wir, das sind die 18.000 KollegInnen der √ñBB-Infrastruktur AG.\n\nWir sorgen daf√ºr, dass die Bahnanlagen zuverl√§ssig f√ºr unsere BahnkundInnen zur Verf√ºgung stehen. Mit unserer technischen Expertise leisten wir einen zentralen Beitrag f√ºr den sicheren und p√ºnktlichen Eisenbahnverkehr. Wir, das sind die 6.000 KollegInnen aus dem Gesch√§ftsbereich Streckenmanagement und Anlagenentwicklung (SAE).\n\nIhr Job\n‚Ä¢ Sie begleiten von der Planung bis zur Umsetzung datenzentrierter Softwareprojekte sowohl steuernd als auch... durch praktische Mitarbeit.\n‚Ä¢ Sie entwickeln Tools zur Datenanalyse, u.a. auch auf einem K8s Cluster sowie allgemein Software zur Unterst√ºtzung unserer Data-Science-Projekte.\n‚Ä¢ Sie arbeiten aktiv beim Aufbau einer nachhaltigen IT-Infrastruktur f√ºr flexible, innovative und effiziente Analysen,\nExplorative Analyse, Auswertung und Darstellung gro√üer strukturierter und unstrukturierter Datenmengen aus verschiedenen Systemen und deren Zusammenh√§nge mit.\n‚Ä¢ Die Bearbeitung von Fragestellungen in interdisziplin√§ren, agilen Teams geh√∂rt ebenfalls zu Ihrem Aufgaben sowie das Vorstellen und Pr√§sentieren der Ergebnisse vor Stakeholdern.\n\nIhr Profil\n‚Ä¢ Abgeschlossenes FH- oder Universit√§tsstudium im Bereich Informatik, Wirtschaftsinformatik oder Computertechnik bzw. eine vergleichbare Qualifikation.\n‚Ä¢ Berufserfahrung im Bereich Software Engineering, Data Engineering und Softwareprojektmanagement\nOptionale Erfahrung im Bereich Data Science ist von Vorteil.\n‚Ä¢ Sehr gute Kenntnisse in der Programmierung mit Python und in einer oder mehreren der folgenden Sprachen: Java, Kotlin, C#, C++, C sowie generelle Begeisterung am Lernen von Sprachen.\n‚Ä¢ Sehr gute Kenntnisse in der Versionsverwaltung mit Git.\n‚Ä¢ Optionale Kenntnisse betreffend IoT-Frameworks, Apache Camel, Docker/Podman (Containerisierung i. A.), Apache Kafka, Knime und R sind von Vorteil.\n‚Ä¢ Sehr gute Kenntnisse in relationaler Datenmodellierung und relationalen DBMS, Grundverst√§ndnis f√ºr DWH und Reportinganwendungen.\n‚Ä¢ Optionale Kenntnisse im Bereich GNU/Linux, Commandline, Shell Scripting sind von Vorteil.\n‚Ä¢ Interesse an pers√∂nlicher Weiterentwicklung und Begeisterung Neues zu lernen.\n‚Ä¢ Kommunikations- und Teamf√§higkeit.\n\nUnser Angebot\n‚Ä¢ F√ºr die Funktion ""Techn. Spez. Sen. Stab Leistungsmng.‚Äú ist ein Mindestentgelt von ‚Ç¨ 47.053,58 brutto/Jahr vorgesehen. Je nach Qualifikation und Berufserfahrung ist eine √úberzahlung m√∂glich.\n‚Ä¢ Wir erm√∂glichen flexible Freizeitgestaltung durch ein attraktives Gleitzeitmodell.\n‚Ä¢ Als gr√∂√ütes Klimaschutzunternehmen des Landes bieten wir Ihnen einen sicheren und nachhaltigen Arbeitsplatz mit spannenden Aufgaben sowie die Chance, Ihren pers√∂nlichen Beitrag zur klima- und umweltfreundlichen Mobilit√§t zu leisten.\n‚Ä¢ Besondere Konditionen bei Bahnreisen & in unseren Reiseb√ºros, Ferienh√§user und Appartements in beliebten heimischen Urlaubsregionen.\n‚Ä¢ Unser konzerninternes Wohnungsservice bietet bundesweit √ñBB-Mitarbeiter:innenwohnungen an.\n‚Ä¢ Sie haben die Option, die Fahrbeg√ºnstigung in Anspruch zu nehmen und √ñsterreich mit der √ñBB zu entdecken.So arbeiten Sie nicht nur an klimafreundlicher Mobilit√§t, sondern k√∂nnen auch umweltfreundlich mit Ihrer Familie reisen.\n‚Ä¢ Sie profitieren von hervorragenden Weiterbildungsangeboten sowie zahlreichen Weiterentwicklungsm√∂glichkeiten innerhalb des Konzerns.\n\nIhre Bewerbung\n\nBitte bewerben Sie sich online mit Motivationsschreiben und Lebenslauf. Als interne/r BewerberIn f√ºgen Sie idealerweise bitte auch Ihren SAP-Auszug hinzu\n\nFrauen sind ein unverzichtbarer Teil unseres Erfolges und unserer Unternehmenskultur. Deshalb begr√º√üen wir besonders Bewerbungen von Frauen, die bei gleicher Qualifikation ‚Äì unter Ber√ºcksichtigung der relevanten Rahmenumst√§nde aller Bewerbungen ‚Äì bevorzugt aufgenommen werden.\n\nWir weisen darauf hin, dass im Zuge der Aufnahme die Beibringung einer Strafregisterbescheinigung erforderlich ist.\nAnsprechpartner:innen\n\nFragen zu dieser Jobausschreibung wenden Sie sich bitte an Monika M√ºller , +43664/88331 664.\nF√ºr allgemeine Fragen zum Bewerbungsprozess steht Ihnen unser √ñBB Recruiting Team unter 05 1778 97 77888 gerne zur Verf√ºgung']}]","[{'link': 'https://www.google.com/search?hl=en&q=%C3%96BB-Holding+AG&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIlg0', 'text': 'See web results for √ñBB-Holding AG'}]",,"['7 days ago', 'Full-time']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgU29mdHdhcmUgXHUwMDI2IERhdGEgRW5naW5lZXIgZm9yIERhdGEgU2NpZW5jZSBBcHBsaWNhdGlvbnMiLCJodGlkb2NpZCI6ImRZZ1U2TXR6ZDRnQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVUxck1teHNTMnBNZWtaVlZrRnNVM1ZoV2tKWWR6UndhV2RGY0ZGVFFtOUNiMGRKY0djNFQzbDNla2xIWWt0aWFuSmpOekJhU1ZsRU1uWk1ibU5HWW5SblJFcG5aRzVFV25aNVlYWm5lRnBsTFdOcmIzTkhWREZZZDJzd01EWnZiV05FZWxsdkxVdFFaMXBFVTNSQk5HVnBNbGxrWDBOQ2JVMXBlRnBOZGtSUmJHdHRURFl3Y1c1alpUQnJTMDFuZDBkM1ZXZE9SMlp0WmxKVFpGQmpkVzV2Y0V3dGNEVlFOV05DVGxoU2RFZEpXbFpTZVdKVGFrUXpPSGhQVDJKM1YyRkZPV1ExUkhFNVVWSjFTRlpETmxFeFZWcFFXVXBKY1ZoSWFrdHFSbUUyUVJJWFJHSlFTRnBOWVZGTE5XSnNOVTV2VUdoYWFYVnhRVVVhSWtGTVJWTTVkVTVQVFdaWllWOUdTak4yVDBkVWJHSTJiWGhWTms1elNuazJXVkUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBNw7xuY2huZXIgSm9iYW56ZWlnZXIiLCJsaW5rIjoiaHR0cHM6Ly93d3cubXVlbmNobmVyLWpvYmFuemVpZ2VyLmRlL2pvYi8wYmZhdC9zZW5pb3Itc29mdHdhcmUtZGF0YS1lbmdpbmVlci1mb3ItZGF0YS1zY2llbmNlLWFwcGxpY2F0aW9ucy13aWVuLS0tMTkzMDg5MDQvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Machine Learning/Computer Vision Engineer - Photo Editing...,Canva,"  Vienna, Austria   ",via Ai-Jobs.net,"Join the team redefining how the world experiences design.Hey, g'day, mabuhay, kia ora,‰Ω†Â•Ω, hallo, v√≠tejte!Thanks for stopping by. We know job hunting can be a little time consuming and you're probably keen to find out what's on offer, so we'll get straight to the point. Where and how you can workOur flagship campus is in Sydney, Australia but Austria is home to part of our European operations. And with that you will have choice in how you work. That means if you want to do your thing in the office (if you're nearby), at home or a bit of both, it's up to you. Fun fact - our Austrian team actually started out as Kaleido before being acquired by us in 2021. Kaleido's product team develops visual AI products, that make complex things simple for users. Now, together we deliver visual AI features within Canva to help reimagine how artificial intelligence can be used in design. We think it's a perfect match. What you‚Äôd be doing in this roleAs Canva scales change continues to be part of our... DNA. But we like to think that's all part of the fun. So this will give you the flavour of the type of things you'll be working on when you start, but this will likely evolve. In this role, you'll be in a key position to make our ambitious goals in the AI-based photo editing space happen. By using innovative deep-learning techniques, you'll help deliver magical photo editing tools to our users, allowing them to edit the whole image or just a part of it. Talking about users: With us, you work on a huge scale. Our global design community has created more than 15 billion designs in Canva, and your work will impact the lives of more than 135 Million monthly Canva users. Tasks Work collaboratively as part of a team of machine learning engineers, frontend engineers, backend developers, designers, and quality assurance engineers to develop, implement, and improve Canva AI features such as Auto-Adjust, Smart Crop, Magic Eraser, and Magic Edit that will be used by more than 135 million users every month and make a global impact.Take ownership of the ML projects you are working on (refer to above‚Äôs list of established AI features): We have many novel products in our pipeline that we can‚Äôt write about publicly right now :-). You will be driving the planning of the project and iterating on the AI features to achieve the best and most magical solution possible in order to foster innovation at Canva.Staying updated on machine learning trends is crucial for your role. It ensures that the features we release in Canva empower users to design and edit photos using the latest technology and gives Canva an enthusiastic edge in a constantly evolving technological landscape.Study best practices, develop untried approaches, work on prototypes, e.g. for latent diffusion-based photo editing or for object detection and instance segmentation, and evaluate the performance.Experiment on large-scale cloud infrastructure (GCP and AWS) with high-end hardware, being mostly NVIDIA A10 and A100 Tensor Core GPUs.Analyze internal and external data sources, and generate, collect, and prepare data with commercial licensing in mind. Collaborate with our internal data generation team as well as with external partners.Set up data augmentation pipelines and perform hyper-parameter searches to build production-ready AI solutions that meet the quality requirements of photo editing effects in Canva.Implement automated testing and suitable metrics to monitor the performance of our AI features in production. Requirements You have a Master's (ideally Ph.D.) degree in Computer Science (or similar), focusing on machine learning. Published papers in peer-reviewed journals and conferences would be a valuable addition.You have a solid understanding of computer vision, especially the concepts of convolutional neural networks (CNNs), transformers, generative adversarial networks, and diffusion models.Proficiency with the following technologies is required to be set up for success in this position: Deep learning frameworks (Pytorch gives bonus points, other frameworks like Tensorflow or JAX), Python 3, Numpy, OpenCV, Docker & Kubernetes.You substantially understand modern software engineering principles, Python 3 classes and inheritance, multithreading, testing, and QA to write clean code.You are familiar with convolutional neural networks for tasks such as image classification and segmentation: As a visual AI company, we primarily work with images and videos.Nice to have: Experience with JavaScript, node.js, react, typescript, or (WebGL) shaders to prototype new AI features in our internal, flexible, and easy-to-use testing environment.Our projects require picking up knowledge of the state-of-the-art of a specific ML topic quickly (Example 1, Example 2) since most projects start with a phase of literature research and communicating the context to the team (across timezones).You have a proven sense of ownership and are eager to find and develop novel solutions to challenging problems, such as developing ML models for processing large images (having up to 24 megapixels) in a memory-efficient and runtime-efficient manner proactively.You are an excellent communicator and teammate, keen to work with your colleagues and brainstorm ideas together. Job Postings ‚Äì Lever Hire Work in one of the fastest-growing visual AI companies in Austria, surrounded by like-minded people. Our visual AI products are industry-leading solutions that are easing the life of more than 135 Million monthly users worldwide. We are a part of the Canva family. Our collaboration with teams around the globe supercharges our work to empower the world to design. Canva‚Äôs success story is unique - and you benefit from it by participating in the company stock option program.Join an international team in Vienna (more than 70 people from more than 25 nationalities) and collaborate with lots of smart, like-minded people who love to ship quickly, and you get to know the space of visual AI. Watch this video to learn more about our engineering organization. You will have a flexible work schedule of 38.5h/week and a no-all-in contract. Work remotely, from our office located in Vienna's 3rd district, or mix-and-match. We can easily find an option that works best for you and Kaleido.We care about our employees and we believe mental health should be a priority, just like taking care of our bodies and staying in shape. We provide mental health support through an online platform specialized in professional counseling.Your lunch and your commute with Wiener Linien are on us. You can also find unlimited snacks, coffee, and beverages in our office.You receive a yearly allowance for professional education & personal well-being as well as additional leave days for volunteering.We organize regular (international) events at the company & team levels to foster team bonding.We are required by law to state the minimum salary for this position, which is at least EUR 60,000 gross per year. We pay competitive salaries - depending on your qualifications and experience - and you also get to participate in the company‚Äôs stock option program.What's in it for you?Achieving our crazy big goals motivates us to work hard - and we do - but you'll experience lots of moments of magic, connectivity and fun woven throughout life at Canva, too. We also offer a stack of benefits to set you up for every success in and outside of work.Here's a taste of what's on offer: ‚Ä¢ Equity packages - we want our success to be yours too ‚Ä¢ Inclusive parental leave policy that supports all parents & carers ‚Ä¢ An annual Vibe & Thrive allowance to support your wellbeing, social connection, office setup & more ‚Ä¢ Flexible leave options that empower you to be a force for good, take time to recharge and supports you personally Check out lifeatcanva.com for more info. Other stuff to knowWe make hiring decisions based on your experience, skills and passion, as well as how you can enhance Canva and our culture. When you apply, please tell us the pronouns you use and any reasonable adjustments you may need during the interview process. Please note that interviews are conducted virtually","[{'items': [""Join the team redefining how the world experiences design.Hey, g'day, mabuhay, kia ora,‰Ω†Â•Ω, hallo, v√≠tejte!Thanks for stopping by. We know job hunting can be a little time consuming and you're probably keen to find out what's on offer, so we'll get straight to the point. Where and how you can workOur flagship campus is in Sydney, Australia but Austria is home to part of our European operations. And with that you will have choice in how you work. That means if you want to do your thing in the office (if you're nearby), at home or a bit of both, it's up to you. Fun fact - our Austrian team actually started out as Kaleido before being acquired by us in 2021. Kaleido's product team develops visual AI products, that make complex things simple for users. Now, together we deliver visual AI features within Canva to help reimagine how artificial intelligence can be used in design. We think it's a perfect match. What you‚Äôd be doing in this roleAs Canva scales change continues to be part of our... DNA. But we like to think that's all part of the fun. So this will give you the flavour of the type of things you'll be working on when you start, but this will likely evolve. In this role, you'll be in a key position to make our ambitious goals in the AI-based photo editing space happen. By using innovative deep-learning techniques, you'll help deliver magical photo editing tools to our users, allowing them to edit the whole image or just a part of it. Talking about users: With us, you work on a huge scale. Our global design community has created more than 15 billion designs in Canva, and your work will impact the lives of more than 135 Million monthly Canva users. Tasks Work collaboratively as part of a team of machine learning engineers, frontend engineers, backend developers, designers, and quality assurance engineers to develop, implement, and improve Canva AI features such as Auto-Adjust, Smart Crop, Magic Eraser, and Magic Edit that will be used by more than 135 million users every month and make a global impact.Take ownership of the ML projects you are working on (refer to above‚Äôs list of established AI features): We have many novel products in our pipeline that we can‚Äôt write about publicly right now :-). You will be driving the planning of the project and iterating on the AI features to achieve the best and most magical solution possible in order to foster innovation at Canva.Staying updated on machine learning trends is crucial for your role. It ensures that the features we release in Canva empower users to design and edit photos using the latest technology and gives Canva an enthusiastic edge in a constantly evolving technological landscape.Study best practices, develop untried approaches, work on prototypes, e.g. for latent diffusion-based photo editing or for object detection and instance segmentation, and evaluate the performance.Experiment on large-scale cloud infrastructure (GCP and AWS) with high-end hardware, being mostly NVIDIA A10 and A100 Tensor Core GPUs.Analyze internal and external data sources, and generate, collect, and prepare data with commercial licensing in mind. Collaborate with our internal data generation team as well as with external partners.Set up data augmentation pipelines and perform hyper-parameter searches to build production-ready AI solutions that meet the quality requirements of photo editing effects in Canva.Implement automated testing and suitable metrics to monitor the performance of our AI features in production. Requirements You have a Master's (ideally Ph.D.) degree in Computer Science (or similar), focusing on machine learning. Published papers in peer-reviewed journals and conferences would be a valuable addition.You have a solid understanding of computer vision, especially the concepts of convolutional neural networks (CNNs), transformers, generative adversarial networks, and diffusion models.Proficiency with the following technologies is required to be set up for success in this position: Deep learning frameworks (Pytorch gives bonus points, other frameworks like Tensorflow or JAX), Python 3, Numpy, OpenCV, Docker & Kubernetes.You substantially understand modern software engineering principles, Python 3 classes and inheritance, multithreading, testing, and QA to write clean code.You are familiar with convolutional neural networks for tasks such as image classification and segmentation: As a visual AI company, we primarily work with images and videos.Nice to have: Experience with JavaScript, node.js, react, typescript, or (WebGL) shaders to prototype new AI features in our internal, flexible, and easy-to-use testing environment.Our projects require picking up knowledge of the state-of-the-art of a specific ML topic quickly (Example 1, Example 2) since most projects start with a phase of literature research and communicating the context to the team (across timezones).You have a proven sense of ownership and are eager to find and develop novel solutions to challenging problems, such as developing ML models for processing large images (having up to 24 megapixels) in a memory-efficient and runtime-efficient manner proactively.You are an excellent communicator and teammate, keen to work with your colleagues and brainstorm ideas together. Job Postings ‚Äì Lever Hire Work in one of the fastest-growing visual AI companies in Austria, surrounded by like-minded people. Our visual AI products are industry-leading solutions that are easing the life of more than 135 Million monthly users worldwide. We are a part of the Canva family. Our collaboration with teams around the globe supercharges our work to empower the world to design. Canva‚Äôs success story is unique - and you benefit from it by participating in the company stock option program.Join an international team in Vienna (more than 70 people from more than 25 nationalities) and collaborate with lots of smart, like-minded people who love to ship quickly, and you get to know the space of visual AI. Watch this video to learn more about our engineering organization. You will have a flexible work schedule of 38.5h/week and a no-all-in contract. Work remotely, from our office located in Vienna's 3rd district, or mix-and-match. We can easily find an option that works best for you and Kaleido.We care about our employees and we believe mental health should be a priority, just like taking care of our bodies and staying in shape. We provide mental health support through an online platform specialized in professional counseling.Your lunch and your commute with Wiener Linien are on us. You can also find unlimited snacks, coffee, and beverages in our office.You receive a yearly allowance for professional education & personal well-being as well as additional leave days for volunteering.We organize regular (international) events at the company & team levels to foster team bonding.We are required by law to state the minimum salary for this position, which is at least EUR 60,000 gross per year. We pay competitive salaries - depending on your qualifications and experience - and you also get to participate in the company‚Äôs stock option program.What's in it for you?Achieving our crazy big goals motivates us to work hard - and we do - but you'll experience lots of moments of magic, connectivity and fun woven throughout life at Canva, too. We also offer a stack of benefits to set you up for every success in and outside of work.Here's a taste of what's on offer: ‚Ä¢ Equity packages - we want our success to be yours too ‚Ä¢ Inclusive parental leave policy that supports all parents & carers ‚Ä¢ An annual Vibe & Thrive allowance to support your wellbeing, social connection, office setup & more ‚Ä¢ Flexible leave options that empower you to be a force for good, take time to recharge and supports you personally Check out lifeatcanva.com for more info. Other stuff to knowWe make hiring decisions based on your experience, skills and passion, as well as how you can enhance Canva and our culture. When you apply, please tell us the pronouns you use and any reasonable adjustments you may need during the interview process. Please note that interviews are conducted virtually""]}]","[{'link': 'http://www.canva.com/', 'text': 'canva.com'}, {'link': 'https://www.google.com/search?hl=en&q=Canva&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIyA0', 'text': 'See web results for Canva'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsZBLXC9j0_AhFeeNliyir32E0kNsoTcbNRJ7Q&s=0,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IgTWFjaGluZSBMZWFybmluZy9Db21wdXRlciBWaXNpb24gRW5naW5lZXIgLSBQaG90byBFZGl0aW5nIChtL2YveCkiLCJodGlkb2NpZCI6Im00NW9zR1Z5WWRRQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVyY0NDdmNCUVUxck1teHNTVFJJY0VGeFdGRTRTbmRoWld0UGJFNDNSRGxCUW1Oek9XRk5lVVZoUjNOT1V5MHlSR2hZZWpSeVNIWkRZVWM0WDNoTlowSTRSbk5hWVVwT1NsZ3plblJtTVdoZmJsWTNORVpFTFd4QldqbHJlRU5hVlVSQ2RWSXdVREk1ZEhwdGQySk1UR0p5YkdRMGExUkZOMlV5U25oVGVuZFJkRVZqYWxGNmFWTldhSFp2Um5VemNHcHpaRjgzYzNONFpURnhOMUpuT1ZoUk1HUnlabVpuTUcxNVYzWkNVbmxmVkc1eGNXOHRjVEJ0TTBwVVZTMHlNRkpzZURKWFkzYzFYMmRaTm5GNGFTMVJMWFpTT1Vod2FrUkVPVGhZTkU5NVpXYzJkR1I1VDIxaWNtNWhPRmhEUzFWeWRFbHNNV05zWWsxVE9CSVhSR0pRU0ZwTllWRkxOV0pzTlU1dlVHaGFhWFZ4UVVVYUlrRk1SVk01ZFUxaFoyVjZNRVp3WjNKTk4ybGZSVTFYU0RGb1QwY3llbE5SVGtFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTIiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQWktSm9icy5uZXQiLCJsaW5rIjoiaHR0cHM6Ly9haS1qb2JzLm5ldC9qb2IvNTU1MTQtc2VuaW9yLW1hY2hpbmUtbGVhcm5pbmdjb21wdXRlci12aXNpb24tZW5naW5lZXItcGhvdG8tZWRpdGluZy1tZngvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Centre Engineer (On Demand model),DeRisk Technologies,"  Vienna, Austria   ",via Recruit.net,"Description A DC engineer is needed to work on-demand for one of our clients. The following duties should be able to be carried out by the engineer: Deployment / In-Scope Configuration Items ‚Ä¢ Servers (Virtual & Physical) ‚Ä¢ Storage & Backup Devices ‚Ä¢ Server Appliances ‚Ä¢ Hyper Converged Infrastructure (E.g. Nutanix, Cisco UCS) ‚Ä¢ Tape Storage Units ‚Ä¢ Power Distribution Units rated 3KVA and below ‚Ä¢ SAN Fabric Switches ‚Ä¢ Network Switches ‚Ä¢ KVM Units ‚Ä¢ WAN Optimization Devices ‚Ä¢ Firewalls ‚Ä¢ Access Points ‚Ä¢ Routers ‚Ä¢ Physical Cabling ‚Ä¢ Cable Management ‚Ä¢ Cables which connect the device to itself, a peripheral, or a power/network port Break-fix / Technical Tasks List ‚Ä¢ Power Cycling ‚Ä¢ Running Diagnostics Commands ‚Ä¢ Conducting whole unit replacement ‚Ä¢ Inserting/Removing Media ‚Ä¢ Replacing Defective Components ‚Ä¢ Assist with fault diagnosis and investigation ‚Ä¢ Configuring Remote Access ‚Ä¢ Basic Storage Array Configuration ‚Ä¢ Replacing faulty cables ‚Ä¢ Tape Management and Maintenance ‚Ä¢ Rebooting... routers, servers, storage devices or other equipment ‚Ä¢ Providing loop-back cables in order to test circuits remotely ‚Ä¢ Re-seating or replacing components or cables ‚Ä¢ Cleaning fibers ‚Ä¢ Identify/Analyze fiber issues by using OTDR/LSPM/VFL ‚Ä¢ Installing loop backs ‚Ä¢ Racking, de-racking, and upgrade of any device installed Operations Tasks List ‚Ä¢ Updating and Recording of activities in relevant IT Ticket Management System ‚Ä¢ Coordinating and agreeing attendance time and date with key stakeholders ‚Ä¢ Provide support either through phone, remote tools, or in person at onsite ‚Ä¢ Perform installation as needed either through physical or network medium ‚Ä¢ Coordinate the actual activity date and timing, including arrival and departure times. ‚Ä¢ Carry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment ‚Ä¢ Labeling, Patching and Asset Tagging activities ‚Ä¢ Following specific task instructions and providing necessary reporting as necessary Job Requirements: Technical Skills ‚Ä¢ Good general understanding of IT principles such as Networks, Hardware and Domains ‚Ä¢ Knowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support ‚Ä¢ Knowledge of server/client operations in a domain environment including Active Directory ‚Ä¢ Understanding of current and legacy hardware Infrastructure platforms ‚Ä¢ Hands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment/cable ‚Ä¢ Good Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment ‚Ä¢ Ability to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations ‚Ä¢ Knowledge of TCP/I P standards and networking ‚Ä¢ Experience with Tape Management activities ‚Ä¢ Excellent knowledge of best practices around management, control, and monitoring of server infrastructure ‚Ä¢ Familiarity with backup and recovery software and methodologies Language skills needed ‚Ä¢ English Soft Skills ‚Ä¢ Exceptional customer facing skills ‚Ä¢ Able to communicate clearly and effectively both with Client and the Customer ‚Ä¢ Logical and analytical approach to work ‚Ä¢ Accurate record keeping ‚Ä¢ Able to work unsupervised ‚Ä¢ Good timekeeper ‚Ä¢ Intense focus on quality work ‚Ä¢ Productive and Efficient Academic Background ‚Ä¢ Bachelor of Engineering / Technology / Science or Equivalent Work Experience Overall Experience (in yrs.) ‚Ä¢ 5 ‚Äì 7 years (min Job Summary ID: E168586573 Department: Hiring & Recruitment - APAC","[{'items': [""Description A DC engineer is needed to work on-demand for one of our clients. The following duties should be able to be carried out by the engineer: Deployment / In-Scope Configuration Items ‚Ä¢ Servers (Virtual & Physical) ‚Ä¢ Storage & Backup Devices ‚Ä¢ Server Appliances ‚Ä¢ Hyper Converged Infrastructure (E.g. Nutanix, Cisco UCS) ‚Ä¢ Tape Storage Units ‚Ä¢ Power Distribution Units rated 3KVA and below ‚Ä¢ SAN Fabric Switches ‚Ä¢ Network Switches ‚Ä¢ KVM Units ‚Ä¢ WAN Optimization Devices ‚Ä¢ Firewalls ‚Ä¢ Access Points ‚Ä¢ Routers ‚Ä¢ Physical Cabling ‚Ä¢ Cable Management ‚Ä¢ Cables which connect the device to itself, a peripheral, or a power/network port Break-fix / Technical Tasks List ‚Ä¢ Power Cycling ‚Ä¢ Running Diagnostics Commands ‚Ä¢ Conducting whole unit replacement ‚Ä¢ Inserting/Removing Media ‚Ä¢ Replacing Defective Components ‚Ä¢ Assist with fault diagnosis and investigation ‚Ä¢ Configuring Remote Access ‚Ä¢ Basic Storage Array Configuration ‚Ä¢ Replacing faulty cables ‚Ä¢ Tape Management and Maintenance ‚Ä¢ Rebooting... routers, servers, storage devices or other equipment ‚Ä¢ Providing loop-back cables in order to test circuits remotely ‚Ä¢ Re-seating or replacing components or cables ‚Ä¢ Cleaning fibers ‚Ä¢ Identify/Analyze fiber issues by using OTDR/LSPM/VFL ‚Ä¢ Installing loop backs ‚Ä¢ Racking, de-racking, and upgrade of any device installed Operations Tasks List ‚Ä¢ Updating and Recording of activities in relevant IT Ticket Management System ‚Ä¢ Coordinating and agreeing attendance time and date with key stakeholders ‚Ä¢ Provide support either through phone, remote tools, or in person at onsite ‚Ä¢ Perform installation as needed either through physical or network medium ‚Ä¢ Coordinate the actual activity date and timing, including arrival and departure times. ‚Ä¢ Carry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment ‚Ä¢ Labeling, Patching and Asset Tagging activities ‚Ä¢ Following specific task instructions and providing necessary reporting as necessary Job Requirements: Technical Skills ‚Ä¢ Good general understanding of IT principles such as Networks, Hardware and Domains ‚Ä¢ Knowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support ‚Ä¢ Knowledge of server/client operations in a domain environment including Active Directory ‚Ä¢ Understanding of current and legacy hardware Infrastructure platforms ‚Ä¢ Hands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment/cable ‚Ä¢ Good Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment ‚Ä¢ Ability to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations ‚Ä¢ Knowledge of TCP/I P standards and networking ‚Ä¢ Experience with Tape Management activities ‚Ä¢ Excellent knowledge of best practices around management, control, and monitoring of server infrastructure ‚Ä¢ Familiarity with backup and recovery software and methodologies Language skills needed ‚Ä¢ English Soft Skills ‚Ä¢ Exceptional customer facing skills ‚Ä¢ Able to communicate clearly and effectively both with Client and the Customer ‚Ä¢ Logical and analytical approach to work ‚Ä¢ Accurate record keeping ‚Ä¢ Able to work unsupervised ‚Ä¢ Good timekeeper ‚Ä¢ Intense focus on quality work ‚Ä¢ Productive and Efficient Academic Background ‚Ä¢ Bachelor of Engineering / Technology / Science or Equivalent Work Experience Overall Experience (in yrs.) ‚Ä¢ 5 ‚Äì 7 years (min Job Summary ID: E168586573 Department: Hiring & Recruitment - APAC""]}]","[{'link': 'https://www.google.com/search?hl=en&q=DeRisk+Technologies&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAII-A0', 'text': 'See web results for DeRisk Technologies'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJMMSM3JVIY8PKn3JqstTUcODytm3gCiug77YSW8Y&s,"['2 days ago', 'Full-time']","{'posted_at': '2 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIENlbnRyZSBFbmdpbmVlciAoT24gRGVtYW5kIG1vZGVsKSIsImh0aWRvY2lkIjoiVkJRcDJIc2hPVDhBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1RGaHVhWEpNVm14a1FVeDRaVzFaY0ZJMlRtcHhNM0pTY0dJdFkxcHBXRVpMY1ZkME5XOTVhRmxNWld0cU4wUXhWREV6UlVJNWFsZHROMU0zWmpoc1p6bGFZWFphU25ocVltbzFTVkUyTm10aU9GOXpibGd5WkZGSk9Fd3daVXBoYWxKd1YxQkRMVE5UWmpOTWVEWmZlRzgzZDBZeWJEa3pOSFJSVFROaFJXRXhZbVUyYW1Vd1ZHZEJaMWRsUTNoaldtazJNRE55WWsxRGFsRlNTMlJZZUVVeGNXcGlia05tYTFsblFWTnhWRWw2Y1dOWFZWRlpRamhRYW5wamVEaFFPVTlUUnpSakVoZEVZbEJJV2sxaFVVczFZbXcxVG05UWFGcHBkWEZCUlJvaVFVeEZVemwxVDNKclNuRk5NM3B1T0dnelNUQlRTRGw2VVd4alNuRlVVWFJTVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBSZWNydWl0Lm5ldCIsImxpbmsiOiJodHRwczovL3d3dy5yZWNydWl0Lm5ldC9qb2IvZW5naW5lZXItam9icy83OTA0M0Q5MUUxNDRBRjEyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Security Data Engineer,GitLab, Anywhere ,via Remote Workers,"Title:Senior Security Data Engineer
Location: Remote, Global

The GitLab DevSecOps platform empowers 100,000+ organizations to deliver software faster and more efficiently. We are one of the world‚Äôs largest all- remote companies with 2,000+ team members and values that foster a culture where people embrace the belief that everyone can contribute. Learn more about Life at GitLab.
Senior Security Data Engineer
This position is 100% remote.
What we are looking for

Driven by incredible growth in our customer base and product, we now need to evolve our existing modern cloud Data Platform into a modern cloud Big Data Platform with capabilities to store, transform, and model data outside of the confines of a traditional Data Warehouse. We are searching for a Senior Data Security Engineer that dedicates their time and expertise to keep the Data Platform secure from an internal- and external perspective. This role requires a strong background in Data Engineering and Data Security.

This role... requires an analytical and business-oriented mindset with the ability to implement rigorous database solutions and best practices in order to produce and influence the adoption of strong quality data insights to drive business decisions in all areas of GitLab. The Senior Data Security Engineer will be dedicated to keep data safe and will be the extra set of eyes in the team. You will be responsible building new pipelines and infrastructure, ensuring the pipelines are encrypted and safe.

Don‚Äôt have a ton of knowledge about GitLab yet? Don‚Äôt worry. We have an extensive onboarding and training program at GitLab and you will be provided with necessary DevOps and GitLab knowledge to fulfil your role.

The Senior Data Security Engineer role extends the Data Engineer role.
Job responsibilities in scope:
‚Ä¢ Works together with the GitLab security department to keep our Data Platform secure from an internal- and external perspective.
‚Ä¢ Establish policy and data security controls to protect data in our Data Platform.
‚Ä¢ Ensures the compliance of policy, processes and procedures.
‚Ä¢ Assess security effectiveness of our Data Platform.
We‚Äôre looking for:
‚Ä¢ 3-5 years minimum, hands-on experience deploying production quality code
‚Ä¢ Professional experience using Python, Java, or Scala for data processing (Python preferred)
‚Ä¢ Knowledge of and experience with data-related Python packages
‚Ä¢ Demonstrably deep understanding of SQL and analytical data warehouses (Snowflake preferred)
‚Ä¢ Hands-on experience implementing ETL (or ELT) best practices at scale.
‚Ä¢ Hands-on experience with data pipeline tools (Airflow, Luigi, Azkaban, dbt)
‚Ä¢ Experience with Salesforce, Zuora, Zendesk and Marketo as data sources and consuming data from SaaS application APIs.
‚Ä¢ Share and work in accordance with our values
‚Ä¢ Constantly improve product quality, security, and performance
‚Ä¢ Desire to continually keep up with advancements in data engineering practices
‚Ä¢ Catch bugs and style issues in code reviews
‚Ä¢ Ship large features independently
‚Ä¢ Successful completion of a background check
‚Ä¢ Ability to use GitLab
‚Ä¢ A shared interest in our values, and working in accordance with those values
What we are looking for in your Security Experience:
‚Ä¢ Strong knowledge of data security principles, best practices, and industry standards.
‚Ä¢ Experience with data protection technologies, such as encryption, tokenization, data loss prevention (DLP), and secure data storage.
‚Ä¢ Familiarity with security frameworks (e.g., NIST Cybersecurity Framework) and regulatory requirements (e.g., GDPR, HIPAA).
‚Ä¢ Proficiency in security assessment tools and techniques.
‚Ä¢ Knowledge of network protocols, firewall technologies, and intrusion detection/prevention systems (IDS/IPS).
‚Ä¢ Experience with security incident response and forensic investigation.
‚Ä¢ Ideally tertiary educated in Information Security or hold certifications preferred but not essential

Also, we know it‚Äôs tough, but please try to avoid the confidence gap . You don‚Äôt have to match all the listed requirements exactly to be considered for this role.
Hiring Process

To view the full job description and hiring process, please view our handbook . Additional details about our process can also be found on our hiring page .
LI-YP1

Remote-Global

Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.

Privacy Policy: Please review our Recruitment Privacy Policy. Your privacy is important to us.

GitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab‚Äôs policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab‚Äôs EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know during the recruiting process","[{'items': ['Title:Senior Security Data Engineer\nLocation: Remote, Global\n\nThe GitLab DevSecOps platform empowers 100,000+ organizations to deliver software faster and more efficiently. We are one of the world‚Äôs largest all- remote companies with 2,000+ team members and values that foster a culture where people embrace the belief that everyone can contribute. Learn more about Life at GitLab.\nSenior Security Data Engineer\nThis position is 100% remote.\nWhat we are looking for\n\nDriven by incredible growth in our customer base and product, we now need to evolve our existing modern cloud Data Platform into a modern cloud Big Data Platform with capabilities to store, transform, and model data outside of the confines of a traditional Data Warehouse. We are searching for a Senior Data Security Engineer that dedicates their time and expertise to keep the Data Platform secure from an internal- and external perspective. This role requires a strong background in Data Engineering and Data Security.\n\nThis role... requires an analytical and business-oriented mindset with the ability to implement rigorous database solutions and best practices in order to produce and influence the adoption of strong quality data insights to drive business decisions in all areas of GitLab. The Senior Data Security Engineer will be dedicated to keep data safe and will be the extra set of eyes in the team. You will be responsible building new pipelines and infrastructure, ensuring the pipelines are encrypted and safe.\n\nDon‚Äôt have a ton of knowledge about GitLab yet? Don‚Äôt worry. We have an extensive onboarding and training program at GitLab and you will be provided with necessary DevOps and GitLab knowledge to fulfil your role.\n\nThe Senior Data Security Engineer role extends the Data Engineer role.\nJob responsibilities in scope:\n‚Ä¢ Works together with the GitLab security department to keep our Data Platform secure from an internal- and external perspective.\n‚Ä¢ Establish policy and data security controls to protect data in our Data Platform.\n‚Ä¢ Ensures the compliance of policy, processes and procedures.\n‚Ä¢ Assess security effectiveness of our Data Platform.\nWe‚Äôre looking for:\n‚Ä¢ 3-5 years minimum, hands-on experience deploying production quality code\n‚Ä¢ Professional experience using Python, Java, or Scala for data processing (Python preferred)\n‚Ä¢ Knowledge of and experience with data-related Python packages\n‚Ä¢ Demonstrably deep understanding of SQL and analytical data warehouses (Snowflake preferred)\n‚Ä¢ Hands-on experience implementing ETL (or ELT) best practices at scale.\n‚Ä¢ Hands-on experience with data pipeline tools (Airflow, Luigi, Azkaban, dbt)\n‚Ä¢ Experience with Salesforce, Zuora, Zendesk and Marketo as data sources and consuming data from SaaS application APIs.\n‚Ä¢ Share and work in accordance with our values\n‚Ä¢ Constantly improve product quality, security, and performance\n‚Ä¢ Desire to continually keep up with advancements in data engineering practices\n‚Ä¢ Catch bugs and style issues in code reviews\n‚Ä¢ Ship large features independently\n‚Ä¢ Successful completion of a background check\n‚Ä¢ Ability to use GitLab\n‚Ä¢ A shared interest in our values, and working in accordance with those values\nWhat we are looking for in your Security Experience:\n‚Ä¢ Strong knowledge of data security principles, best practices, and industry standards.\n‚Ä¢ Experience with data protection technologies, such as encryption, tokenization, data loss prevention (DLP), and secure data storage.\n‚Ä¢ Familiarity with security frameworks (e.g., NIST Cybersecurity Framework) and regulatory requirements (e.g., GDPR, HIPAA).\n‚Ä¢ Proficiency in security assessment tools and techniques.\n‚Ä¢ Knowledge of network protocols, firewall technologies, and intrusion detection/prevention systems (IDS/IPS).\n‚Ä¢ Experience with security incident response and forensic investigation.\n‚Ä¢ Ideally tertiary educated in Information Security or hold certifications preferred but not essential\n\nAlso, we know it‚Äôs tough, but please try to avoid the confidence gap . You don‚Äôt have to match all the listed requirements exactly to be considered for this role.\nHiring Process\n\nTo view the full job description and hiring process, please view our handbook . Additional details about our process can also be found on our hiring page .\nLI-YP1\n\nRemote-Global\n\nCountry Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process.\n\nPrivacy Policy: Please review our Recruitment Privacy Policy. Your privacy is important to us.\n\nGitLab is proud to be an equal opportunity workplace and is an affirmative action employer. GitLab‚Äôs policies and practices relating to recruitment, employment, career development and advancement, promotion, and retirement are based solely on merit, regardless of race, color, religion, ancestry, sex (including pregnancy, lactation, sexual orientation, gender identity, or gender expression), national origin, age, citizenship, marital status, mental or physical disability, genetic information (including family medical history), discharge status from the military, protected veteran status (which includes disabled veterans, recently separated veterans, active duty wartime or campaign badge veterans, and Armed Forces service medal veterans), or any other basis protected by law. GitLab will not tolerate discrimination or harassment based on any of these characteristics. See also GitLab‚Äôs EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know during the recruiting process']}]","[{'link': 'https://www.google.com/search?hl=en&q=GitLab&sa=X&ved=0ahUKEwiGy4_fgrmAAxWWMlkFHQWMCxU4RhCYkAIIqg4', 'text': 'See web results for GitLab'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQZYvErjUbYQ4r-32wIoaGKwY7dnQVOCv4pj5F16JI&s,"['22 days ago', 'Work from home', 'Full-time']","{'posted_at': '22 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgU2VjdXJpdHkgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoia2s2MGJqR3hWaU1BQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVTFyTW14c1RIWnNaVEJ5T0ZNMlpGcGZaMjlqZEVwMmNUUXdjVFZNU1dGTFFXbFlhMnBTWmxCcWRVRTBXVGhxVUMwdFYycGxlbkpGYWpoMVpHRnRXRWxvYmtkb05qTlBjR0pHZURsdlNUTndNVXRFTFRaSmVGUkRNMTluYVdsVWNFMXJkVE5mUkdsbWRrOUVPVFpuYlRFMGJrNVJObTF1TjJSUFpHbE9lbUZCUmxKTFRUaGxWMDVEVFVoTk5UVlhXbXBMWlRkcVFqSjNXREZ6VmxabWQxbEJFaGRFWWxCSVdrMWhVVXMxWW13MVRtOVFhRnBwZFhGQlJSb2lRVXhGVXpsMVRqTnpURlpLYkUwNU9ERlZORk5PU0RrdFpHOVVkbEkwUVZkUFFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gUmVtb3RlIFdvcmtlcnMiLCJsaW5rIjoiaHR0cHM6Ly9yZW1vdGV3b3JrZXJzLm5ldC9yZW1vdGUtam9icy9kYXRhLXNjaWVuY2Uvc2VuaW9yLXNlY3VyaXR5LWRhdGEtZW5naW5lZXItYXQtZ2l0bGFiP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
SQL Developer - Vienna,Technojobs,"  Vienna, Austria   ",via Recruit.net,"SQL Developer- Vienna, Austria

(Tech stack: SQL Server Database Developer, Microsoft SQL Server, T-SQL, SSMS, Database Design and Modeling Tools, Query Optimization and Performance Tuning, Indexing and Query Optimization, Data Integration Services (SSIS), Database Backup and Recovery, Database Security and Permissions, Version Control Systems (e.g., Git, SVN), Monitoring and Performance Tools (e.g., SQL Server Profiler, SQL Server Extended Events, Performance Monitor), Reporting and Analysis Services (SSRS, SSAS), Data Migration and Synchronization)

We have several exciting new opportunities for SQL Server Database Developers (Microsoft SQL Server, T-SQL, SSMS, Database Design and Modeling Tools, Query Optimization and Performance Tuning, Indexing and Query Optimization, Data Integration Services (SSIS), Database Backup and Recovery, Database Security and Permissions, Version Control Systems (e.g., Git, SVN), Monitoring and Performance Tools, Reporting and Analysis Services, Data... Migration and Synchronization) to join a dynamic gaming company. This is your chance to collaborate with some of the brightest minds in the gaming industry and contribute to cutting-edge game development. Our client's latest releases have revolutionized the gaming experience, offering players immersive gameplay and ground-breaking virtual worlds.

All SQL Database Developer positions come with the following benefits:
‚Ä¢ Shares in the company.
‚Ä¢ Pension scheme (8%).
‚Ä¢ 3 hours 'free time' each week to investigate new technologies.
‚Ä¢ An annual training allowance of EUR4,500.
‚Ä¢ 27 days holiday (excluding Public Holidays) plus your birthday off.
‚Ä¢ Flexible working hours.
‚Ä¢ Pizza and beer delivered to your home on Fridays.
‚Ä¢ Access to free online yoga classes which take place over lunch or after work.

Location: Vienna, Austria/ Hybrid Working

Salary: EUR50,000 - EUR80,000 + Bonus + Pension + Benefits

To apply for this position please send your CV to Charlie Skipper at Noir.

NC/CS/SQL5080

NOIRAUSTRIAREC

NOIREUROPERECRUITMENT","[{'items': [""SQL Developer- Vienna, Austria\n\n(Tech stack: SQL Server Database Developer, Microsoft SQL Server, T-SQL, SSMS, Database Design and Modeling Tools, Query Optimization and Performance Tuning, Indexing and Query Optimization, Data Integration Services (SSIS), Database Backup and Recovery, Database Security and Permissions, Version Control Systems (e.g., Git, SVN), Monitoring and Performance Tools (e.g., SQL Server Profiler, SQL Server Extended Events, Performance Monitor), Reporting and Analysis Services (SSRS, SSAS), Data Migration and Synchronization)\n\nWe have several exciting new opportunities for SQL Server Database Developers (Microsoft SQL Server, T-SQL, SSMS, Database Design and Modeling Tools, Query Optimization and Performance Tuning, Indexing and Query Optimization, Data Integration Services (SSIS), Database Backup and Recovery, Database Security and Permissions, Version Control Systems (e.g., Git, SVN), Monitoring and Performance Tools, Reporting and Analysis Services, Data... Migration and Synchronization) to join a dynamic gaming company. This is your chance to collaborate with some of the brightest minds in the gaming industry and contribute to cutting-edge game development. Our client's latest releases have revolutionized the gaming experience, offering players immersive gameplay and ground-breaking virtual worlds.\n\nAll SQL Database Developer positions come with the following benefits:\n‚Ä¢ Shares in the company.\n‚Ä¢ Pension scheme (8%).\n‚Ä¢ 3 hours 'free time' each week to investigate new technologies.\n‚Ä¢ An annual training allowance of EUR4,500.\n‚Ä¢ 27 days holiday (excluding Public Holidays) plus your birthday off.\n‚Ä¢ Flexible working hours.\n‚Ä¢ Pizza and beer delivered to your home on Fridays.\n‚Ä¢ Access to free online yoga classes which take place over lunch or after work.\n\nLocation: Vienna, Austria/ Hybrid Working\n\nSalary: EUR50,000 - EUR80,000 + Bonus + Pension + Benefits\n\nTo apply for this position please send your CV to Charlie Skipper at Noir.\n\nNC/CS/SQL5080\n\nNOIRAUSTRIAREC\n\nNOIREUROPERECRUITMENT""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Technojobs&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAII4Qo', 'text': 'See web results for Technojobs'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSI6O-T7ecfm6wpOrtmpMEmF_UsfUTiH7qUN1oaiDg&s,"['7 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJTUUwgRGV2ZWxvcGVyIC0gVmllbm5hIiwiaHRpZG9jaWQiOiJaUE1sWFRFOHpKMEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVMXJNbXhzVERab2QxRnBRVzB5Y25aMk9VSnNYMjlaWjFkWlpVRmZZVmRNTkRrdGNreExTR0l6TWtreFJtdzBjMmhWVnpOSFJVWjFPRkJXV25SV00ybDRlVUV3WTBWVVpEbDNha2RhWjBkNFh6UkdNMUZZY0hBeVRtRTFVR1l3V1VSVGFVbENPVkJITTFwNk9XRkdhRlJYZG1kdmFqRlRibWgwVjFVd1NsOXVPVFJDVm1WSGRrUm9jR2QzTXpKR2QydGZSRU40ZWtJMlpFVmtSRmt5YXpGUkVoZEZURkJJV2s1dFUwVmZUMGgzWW10UUxYSkRjVEpCZHhvaVFVeEZVemwxVFdOdFRVOTRaRzFRU0VOTlVITnFlV1J2UlMwM1oyTXdMVWx3ZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIFJlY3J1aXQubmV0IiwibGluayI6Imh0dHBzOi8vd3d3LnJlY3J1aXQubmV0L2pvYi9zcWwtZGV2ZWxvcGVyLWpvYnMvNzEwODVDMzA1RTFDMTAzRj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer,CoinsPaid, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe

This offer from ""CoinsPaid"" has been enriched by Jobgether and got a 76.5% flex score.
Data Engineer
Remote - European Region /
Engineering ‚Äì Data Office /
Full-time
/ Hybrid

Apply for this job

CoinsPaid is an ecosystem of multiple innovative solutions for the smooth integration of crypto into business and everyday life. It claimed absolute leadership in terms of transaction volume and marked a tremendous growth since 2014. Our team designs products that help people get ready for the new era of digital assets that will transform the way we work with money.

Headquartered in Estonia and having 3 international hubs, we are still a remote-first company with employees working from 20+ countries around the world. At CoinsPaid, we are passionate about crypto, fintech and are putting great effort into building a team that will get the world ready for every-day crypto use.

At CoinsPaid we are passionate about crypto, tech, and... product development quality. If these feel close to you - give us a shout!

In this role, you will:
‚Ä¢ Create and maintain optimal data pipeline architecture
‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Vertica
‚Ä¢ Create data tools for analytics and other team members that assist them in building and optimizing our product and business processes into an innovative industry leader

About you:
‚Ä¢ Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
‚Ä¢ Experience building and optimizing data pipelines, architectures and data sets
‚Ä¢ Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
‚Ä¢ Strong analytic skills related to working with unstructured datasets
‚Ä¢ 3+ years of experience in a Data Engineer role
‚Ä¢ Experience using the following software/tools:- Relational Databases, including MySQL, Vertica
- Data pipeline and workflow management tools as Airflow
- Python

Why should you choose us?
Become a part of a rapidly developing international company and a crypto payments leader in terms of monthly transaction volume. Become a part of this solid team, passionate about their jobs and the crypto industry as a whole. Feel a great team spirit and meet people supporting each other's growth and development.

Key facts about CoinsPaid:
A solid and profitable private company, registered and licensed in Estonia;
#1 crypto payment gateway by monthly transaction volume;
Over 19 billion euros processed in crypto (as of Jan 2023);
Over 34 million transactions processed (as of Jan 2023)
Over 9 years of experience in the blockchain sector;
Over 800 merchants accounts serviced (as of Jan 2023);
Over 220 team members across 20+ countries;
Secure, with 2 independent security audits passed;
Awarded with ‚ÄúExcellence in Cryptocurrencies‚Äù at Finnovex Qatar 2022, ‚ÄúPayment Provider of the Year‚Äù at AIBC 2021 and nominated 6 more times throughout 2020-2022.

In addition, we‚Äôre proud of the fact that in 2022, while select industry leaders laid-off 15-50% of their staff, we‚Äôve almost doubled the size of our company.

By joining CoinsPaid now, you‚Äôll participate in building the world's best crypto payments ecosystem, conquering new markets, and popularizing cryptocurrencies.

Sounds good? Well then, we can‚Äôt wait to see your resume!

Apply for this job","[{'items': ['This a Full Remote job, the offer is available from: Europe\n\nThis offer from ""CoinsPaid"" has been enriched by Jobgether and got a 76.5% flex score.\nData Engineer\nRemote - European Region /\nEngineering ‚Äì Data Office /\nFull-time\n/ Hybrid\n\nApply for this job\n\nCoinsPaid is an ecosystem of multiple innovative solutions for the smooth integration of crypto into business and everyday life. It claimed absolute leadership in terms of transaction volume and marked a tremendous growth since 2014. Our team designs products that help people get ready for the new era of digital assets that will transform the way we work with money.\n\nHeadquartered in Estonia and having 3 international hubs, we are still a remote-first company with employees working from 20+ countries around the world. At CoinsPaid, we are passionate about crypto, fintech and are putting great effort into building a team that will get the world ready for every-day crypto use.\n\nAt CoinsPaid we are passionate about crypto, tech, and... product development quality. If these feel close to you - give us a shout!\n\nIn this role, you will:\n‚Ä¢ Create and maintain optimal data pipeline architecture\n‚Ä¢ Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Vertica\n‚Ä¢ Create data tools for analytics and other team members that assist them in building and optimizing our product and business processes into an innovative industry leader\n\nAbout you:\n‚Ä¢ Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases\n‚Ä¢ Experience building and optimizing data pipelines, architectures and data sets\n‚Ä¢ Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement\n‚Ä¢ Strong analytic skills related to working with unstructured datasets\n‚Ä¢ 3+ years of experience in a Data Engineer role\n‚Ä¢ Experience using the following software/tools:- Relational Databases, including MySQL, Vertica\n- Data pipeline and workflow management tools as Airflow\n- Python\n\nWhy should you choose us?\nBecome a part of a rapidly developing international company and a crypto payments leader in terms of monthly transaction volume. Become a part of this solid team, passionate about their jobs and the crypto industry as a whole. Feel a great team spirit and meet people supporting each other\'s growth and development.\n\nKey facts about CoinsPaid:\nA solid and profitable private company, registered and licensed in Estonia;\n#1 crypto payment gateway by monthly transaction volume;\nOver 19 billion euros processed in crypto (as of Jan 2023);\nOver 34 million transactions processed (as of Jan 2023)\nOver 9 years of experience in the blockchain sector;\nOver 800 merchants accounts serviced (as of Jan 2023);\nOver 220 team members across 20+ countries;\nSecure, with 2 independent security audits passed;\nAwarded with ‚ÄúExcellence in Cryptocurrencies‚Äù at Finnovex Qatar 2022, ‚ÄúPayment Provider of the Year‚Äù at AIBC 2021 and nominated 6 more times throughout 2020-2022.\n\nIn addition, we‚Äôre proud of the fact that in 2022, while select industry leaders laid-off 15-50% of their staff, we‚Äôve almost doubled the size of our company.\n\nBy joining CoinsPaid now, you‚Äôll participate in building the world\'s best crypto payments ecosystem, conquering new markets, and popularizing cryptocurrencies.\n\nSounds good? Well then, we can‚Äôt wait to see your resume!\n\nApply for this job']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=CoinsPaid&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIlAs', 'text': 'See web results for CoinsPaid'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRs0k59OtxlTtt81fRluyEOcEMM3ogMdAwnFfE9sfw&s,"['Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJQSUVIMUhqbmhvd0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVEc1NVNYWnRWVlZ2T1hOSGMzaFZVVGRNTFVwM04yOWpYMEZJYlVnNFdYVnZaVnBvVlRCVVExQlhTek5RVUdaelVVd3RhVFpUVVZad1Z6QXpVRGRCVDFSc1JrZzJOVEZpWDFST1JGcG9SRk5mV2tOclRrSmFOSFl3TlVWUlIzSkVkM0JWWjJKMlNWQktlVGRSV1hGUmJWUXdTME5QU0ZSM2RXeDZNa1JTVDFwSmJEbFBjamh5TmkwNWNXcG5URVV3Y3pORFVXcEROV2g2YlMxbFdGVjZibEIwTTFoR1lVTnFWbGRZYmtwVVFsWnpFaGRGVEZCSVdrNXRVMFZmVDBoM1ltdFFMWEpEY1RKQmR4b2lRVXhGVXpsMVVIQlZRM3AyY0ZVNFJFbEtPRmR5Ukdkb1kyRm9UVVo2Y0dKd1VRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JnZXRoZXIiLCJsaW5rIjoiaHR0cHM6Ly9qb2JnZXRoZXIuY29tL29mZmVyLzY0NTRmMjkxMDkyZTk1MzIwODFmMGFmZi1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer/Cloud Developer (m/f/d),waterdrop¬Æ Microdrink,  Austria   ,via Wellfound,"Drop in!

All the great people here at waterdrop¬Æ (www.waterdrop.com) have been shaking up the market with our innovative microdrinks that help people to drink more water in a fun, healthy and more sustainable way. We‚Äôre proud of the fact we save a ton on plastic bottles, carbon emissions and sugar content. Following our rapid growth to well over 500K satisfied customers, including 18 stores, many loyal corporate customers and listed in over 3,500 retail markets, we are now conquering Europe! We need YOU to join us to conquer more markets! We need a detail-oriented and passionate Data Engineer/Cloud Developer (m/f/d)

If you want to be part of our success story, then drop in! We are a highly dynamic and international team who always have a good reason to drink (!).
‚Ä¢ Your responsibilities: *
‚Ä¢ As an Data Engineer/Cloud Developer (m/f/d) you take over full ownership and responsibility for building data integration from various sources (e.g. ERP, eCommerce stores, loyalty program, CRM... etc.)
‚Ä¢ You extend and improve our existing data warehouse running on Google BigQuery
‚Ä¢ Through your expertise, you gain insights into and create large datasets and ensure their quality
‚Ä¢ You prepare datasets ready for BI tools, used by our finance, operations & data science teams
‚Ä¢ You support the evaluation and integration of new BI tools

Your strengths and qualifications:
‚Ä¢ You have gained a minimum of one year experience in working with Google Cloud Platform (BigQuery, etc.), ELT tools (ideally Stitch), REST API/Webhooks as well as SQL Traits
‚Ä¢ You graduated in Computer Science, MIS, or Information Management focusing on information technology or informatics
‚Ä¢ You have a great Interested in eCommerce and all related processes
‚Ä¢ You are a self-starter, driven and hungry to deepen your knowledge and expand your skills
‚Ä¢ A fast-paced and vibrant working environment spurs you on to your highest performance

What we offer you:
‚Ä¢ A high level of responsibility from day one onwards, within a young, dynamic and international working environment
‚Ä¢ A high learning curve and attractive career opportunities in one of Europe's most successful e-commerce companies
‚Ä¢ Flat hierarchies as well as collegial and respectful interaction in a very positive atmosphere.
‚Ä¢ A modern and well-equipped office in the heart of Vienna
‚Ä¢ Fresh fruits, supporting your fitness club membership, regular team lunches and breakfasts as well as an employee discount
‚Ä¢ Legendary summer and Christmas parties

Wanna Drop in? Just send your application documents in English or German through the application button.

Austrian law requires us to post a minimum salary for this position, which is ‚Ç¨ 3.500 - gross per month (for a full-time job). However, our attractive salary packages are based on current market salaries and are therefore well above the stated minimum salary.

waterdrop¬Æ Microdrink focuses on Healthcare, Cloud Computing, Food and Beverages, CRM, and Health Care Information Technology. Their company has offices in Austria and Vienna. They have a mid-size team that's between 51-200 employees.

You can view their website at https://www.waterdrop.de","[{'items': [""Drop in!\n\nAll the great people here at waterdrop¬Æ (www.waterdrop.com) have been shaking up the market with our innovative microdrinks that help people to drink more water in a fun, healthy and more sustainable way. We‚Äôre proud of the fact we save a ton on plastic bottles, carbon emissions and sugar content. Following our rapid growth to well over 500K satisfied customers, including 18 stores, many loyal corporate customers and listed in over 3,500 retail markets, we are now conquering Europe! We need YOU to join us to conquer more markets! We need a detail-oriented and passionate Data Engineer/Cloud Developer (m/f/d)\n\nIf you want to be part of our success story, then drop in! We are a highly dynamic and international team who always have a good reason to drink (!).\n‚Ä¢ Your responsibilities: *\n‚Ä¢ As an Data Engineer/Cloud Developer (m/f/d) you take over full ownership and responsibility for building data integration from various sources (e.g. ERP, eCommerce stores, loyalty program, CRM... etc.)\n‚Ä¢ You extend and improve our existing data warehouse running on Google BigQuery\n‚Ä¢ Through your expertise, you gain insights into and create large datasets and ensure their quality\n‚Ä¢ You prepare datasets ready for BI tools, used by our finance, operations & data science teams\n‚Ä¢ You support the evaluation and integration of new BI tools\n\nYour strengths and qualifications:\n‚Ä¢ You have gained a minimum of one year experience in working with Google Cloud Platform (BigQuery, etc.), ELT tools (ideally Stitch), REST API/Webhooks as well as SQL Traits\n‚Ä¢ You graduated in Computer Science, MIS, or Information Management focusing on information technology or informatics\n‚Ä¢ You have a great Interested in eCommerce and all related processes\n‚Ä¢ You are a self-starter, driven and hungry to deepen your knowledge and expand your skills\n‚Ä¢ A fast-paced and vibrant working environment spurs you on to your highest performance\n\nWhat we offer you:\n‚Ä¢ A high level of responsibility from day one onwards, within a young, dynamic and international working environment\n‚Ä¢ A high learning curve and attractive career opportunities in one of Europe's most successful e-commerce companies\n‚Ä¢ Flat hierarchies as well as collegial and respectful interaction in a very positive atmosphere.\n‚Ä¢ A modern and well-equipped office in the heart of Vienna\n‚Ä¢ Fresh fruits, supporting your fitness club membership, regular team lunches and breakfasts as well as an employee discount\n‚Ä¢ Legendary summer and Christmas parties\n\nWanna Drop in? Just send your application documents in English or German through the application button.\n\nAustrian law requires us to post a minimum salary for this position, which is ‚Ç¨ 3.500 - gross per month (for a full-time job). However, our attractive salary packages are based on current market salaries and are therefore well above the stated minimum salary.\n\nwaterdrop¬Æ Microdrink focuses on Healthcare, Cloud Computing, Food and Beverages, CRM, and Health Care Information Technology. Their company has offices in Austria and Vienna. They have a mid-size team that's between 51-200 employees.\n\nYou can view their website at https://www.waterdrop.de""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=waterdrop%C2%AE+Microdrink&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIxgs', 'text': 'See web results for waterdrop¬Æ Microdrink'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRdsJWpYWMGvmx6QO7LSIP1oVBrNyicbl1xHJDuJf4&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyL0Nsb3VkIERldmVsb3BlciAobS9mL2QpIiwiaHRpZG9jaWQiOiJqMUJmYV9tNU9nb0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzVEc1WlFrcFpTR1ZqU21WclVtUnVkV3BDZHpjMGQzWjBha3MyV2tkb1VtSmZZMnRuTWpoVVEwbDJka0pPWDBzMlkzbEhjMWM1VFRsWVNXWXlaMVJvUkZwNlEwRk5WRlpOZGpkeU5VTkNWa2h1VUZadmNsUklkRkJmT0VKSVRVRXdWWHBOYkdOU05saFFTQzB0Tm1KWFQwaEJVR1owT1VRME5URm9iWE5STUhKa1prMDRkbmQwZFhGUlNIcFBXVFJLVEZSVlZ6VTJRVUpmVGtGWGFraHRSbTFhZHpKdFNERm5ORnBUWlVoaVNsSklMVk5KYTIxdUxXMUhUVVJzUWsxa05EWlJTME14RWhkRlRGQklXazV0VTBWZlQwaDNZbXRRTFhKRGNUSkJkeG9pUVV4RlV6bDFUekl6WDIxTVNGVm1OVzR5YVVsVlQwUTNVVmxWWDFGQ1JVRnNRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gV2VsbGZvdW5kIiwibGluayI6Imh0dHBzOi8vd2VsbGZvdW5kLmNvbS9jb21wYW55L3dhdGVyZHJvcC1taWNyb2RyaW5rL2pvYnMvMTA1NDgyMC1kYXRhLWVuZ2luZWVyLWNsb3VkLWRldmVsb3Blci1tLWYtZD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (m/f/d),Sclable,"  Vienna, Austria   ",via Jooble,"We are looking for a Data Engineer (m/f/d) with a strong technical background and the ability to build reliable and efficient data platforms. Data is the core essence for all AI based business models, products and services. However, getting the most out of data is not an easy task. And it all begins with knowing how to efficiently work with data ‚Äì from collection via transformation to storage. A performant yet reliable setup requires talent and know-how in state-of-the-art data technologies and tools. Team players with the ability to work closely with related data & AI experts as well as domain experts from various backgrounds to a common goal can excel. If this is you and you are keen to shape the future with bringing AI-based products and services into a variety of industries, then what are you still waiting for?
What you will be doing
‚Ä¢ Design and implement reliable (big) data storage solutions (on-premises or Cloud-based)
‚Ä¢ Design and set up efficient data (transformation... pipelines.
‚Ä¢ Monitor health of data storage and transformation and optimize accordingly.
‚Ä¢ Advise on and implement best practices for data security and data privacy.
‚Ä¢ Keeping up to date with state-of-the-art data technologies, tools and relevant trends
‚Ä¢ Researching the feasibility of data-enabled use cases.
‚Ä¢ Identifying data sources and data gaps and supporting in establishing a data strategy
‚Ä¢ Collaborating with data scientists, machine learning engineers and other stakeholders in continuously optimizing the product delivery method.
What you should have
‚Ä¢ At least 3 years of data engineering experience concepting, designing and implementing data storage and transformation, ideally in the context of data science and machine learning.
‚Ä¢ Excellent know-how on data storage solutions (structured and unstructured, on-premises and Cloud-based) and track record in their setup with strong consideration of data security
‚Ä¢ Excellent understanding of data processing in stream and batch (e.g., PySpark, Kafka)
‚Ä¢ Hands on experience with data engineering in Cloud environment
‚Ä¢ Profound technical skills acquired through academic studies (e.g., computer science) or comparable work experience.
‚Ä¢ Experience and interest in data analytics and data visualization (e.g., Tableau, Power BI) is a plus
‚Ä¢ Strong analytical & problem-solving skills
‚Ä¢ Team player with hands-on mentality focusing on customer satisfaction.
‚Ä¢ Demonstrated commitment to continuously learn about data engineering.
What we offer
‚Ä¢ A new way of thinking and working that rapidly brings success to innovative ideas.
‚Ä¢ Work in an agile team of experts who enjoy sharing ideas and expertise.
‚Ä¢ Open communication, flat hierarchy, plenty of individual responsibility.
‚Ä¢ The opportunity of evolving rapidly by pushing transformative DS/ML products into industries.
‚Ä¢ The gross monthly salary starts at 3.300 Euro (according to the collective agreement for data processing and information technology) and, depending on qualifications and experience, usually ranges around 3.900 Euro, in the case of special qualifications, we are also prepared to negotiate beyond that.

Not exactly what you are looking for?
Check out our other open positions ","[{'items': ['We are looking for a Data Engineer (m/f/d) with a strong technical background and the ability to build reliable and efficient data platforms. Data is the core essence for all AI based business models, products and services. However, getting the most out of data is not an easy task. And it all begins with knowing how to efficiently work with data ‚Äì from collection via transformation to storage. A performant yet reliable setup requires talent and know-how in state-of-the-art data technologies and tools. Team players with the ability to work closely with related data & AI experts as well as domain experts from various backgrounds to a common goal can excel. If this is you and you are keen to shape the future with bringing AI-based products and services into a variety of industries, then what are you still waiting for?\nWhat you will be doing\n‚Ä¢ Design and implement reliable (big) data storage solutions (on-premises or Cloud-based)\n‚Ä¢ Design and set up efficient data (transformation... pipelines.\n‚Ä¢ Monitor health of data storage and transformation and optimize accordingly.\n‚Ä¢ Advise on and implement best practices for data security and data privacy.\n‚Ä¢ Keeping up to date with state-of-the-art data technologies, tools and relevant trends\n‚Ä¢ Researching the feasibility of data-enabled use cases.\n‚Ä¢ Identifying data sources and data gaps and supporting in establishing a data strategy\n‚Ä¢ Collaborating with data scientists, machine learning engineers and other stakeholders in continuously optimizing the product delivery method.\nWhat you should have\n‚Ä¢ At least 3 years of data engineering experience concepting, designing and implementing data storage and transformation, ideally in the context of data science and machine learning.\n‚Ä¢ Excellent know-how on data storage solutions (structured and unstructured, on-premises and Cloud-based) and track record in their setup with strong consideration of data security\n‚Ä¢ Excellent understanding of data processing in stream and batch (e.g., PySpark, Kafka)\n‚Ä¢ Hands on experience with data engineering in Cloud environment\n‚Ä¢ Profound technical skills acquired through academic studies (e.g., computer science) or comparable work experience.\n‚Ä¢ Experience and interest in data analytics and data visualization (e.g., Tableau, Power BI) is a plus\n‚Ä¢ Strong analytical & problem-solving skills\n‚Ä¢ Team player with hands-on mentality focusing on customer satisfaction.\n‚Ä¢ Demonstrated commitment to continuously learn about data engineering.\nWhat we offer\n‚Ä¢ A new way of thinking and working that rapidly brings success to innovative ideas.\n‚Ä¢ Work in an agile team of experts who enjoy sharing ideas and expertise.\n‚Ä¢ Open communication, flat hierarchy, plenty of individual responsibility.\n‚Ä¢ The opportunity of evolving rapidly by pushing transformative DS/ML products into industries.\n‚Ä¢ The gross monthly salary starts at 3.300 Euro (according to the collective agreement for data processing and information technology) and, depending on qualifications and experience, usually ranges around 3.900 Euro, in the case of special qualifications, we are also prepared to negotiate beyond that.\n\nNot exactly what you are looking for?\nCheck out our other open positions ']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Sclable&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAII-As', 'text': 'See web results for Sclable'}]",,"['5 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '5 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6IktpaV92YXE1WUprQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV1SUJDcUlCUVUxck1teHNTMWxrYkROSVVteHNVMmRNWm1SVFNETndhV1l0TkhSTU1sQlFhMGgzWW1OYWRGZEhZbDl5WjFZNFdWRkVZVWxyTFVkUFUxQnNRbkl6ZHpOaWJVUTFZM0p3UnpRelFsaFNPVkpNV0hvdGRUSnlWbXhUTVVNek9HbHFSak01ZW1GelNEaHhWREpJVDB4TFNpMTZYM1pqTUZjNVJHdHdSWGcxWVVWRmVsUmZjVWN5TkdKRloyaFJOVWhLZDNkNU5tNDRibVYzYld0S1VrNHRSSGRSRWhkRlRGQklXazV0VTBWZlQwaDNZbXRRTFhKRGNUSkJkeG9pUVV4RlV6bDFUbHBvY2tNeU1qbHBTM2xCU1RSQk4wZGFObFkyZHpoNGJGQkJkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9vYmxlIiwibGluayI6Imh0dHBzOi8vYXQuam9vYmxlLm9yZy9qZHAvLTIyMDY3ODE3MjgwNjExNjMwMTgvRGF0YS1FbmdpbmVlci0obSUyRmYlMkZkKS1XaWVuP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer (m/w/d),ALDI | HOFER,"  Eberstalzell, Austria   ",via Jobs.aldi-Hofer.com,"Aufgaben, die mich erwarten
‚Ä¢ aktives Mitgestalten von BI Projekten im internationalen Umfeld
‚Ä¢ Entwickeln und Umsetzen von ETL Prozessen in Abstimmung mit dem Frontend Development
‚Ä¢ Weiterentwickeln der Berichtslandschaft mit Fokus auf das Backend
‚Ä¢ eigenst√§ndiges Betreuen des Data Warehouse und Data Lake
‚Ä¢ Extrahieren und Aufbereiten von Daten im Bereich Process Mining
‚Ä¢ Konzipieren und Erstellen von Datenexporten aus unseren Systemen (z.B. f√ºr den Einkauf, die Logistik, unsere Zweigniederlassungen)

Qualifikationen, die ich mitbringe
‚Ä¢ abgeschlossenes IT Studium
‚Ä¢ einschl√§gige Berufserfahrung
‚Ä¢ Know-how in der Analyse, Validierung sowie Darstellung von Daten
‚Ä¢ fundierte Fachkenntnisse im SQL Bereich und Erfahrungen in Reporting L√∂sungen wie Tableau, QlikView oder SAP BusinessObjects
‚Ä¢ Erfahrung in der Konzeption und Erstellung von Datenmodellen und ETL Prozessen
‚Ä¢ Kenntnisse von Datenstrukturen in ERP-Systemen wie SAP S/4 HANA von Vorteil
‚Ä¢ gute Englischkenntnisse
‚Ä¢ analytische und... l√∂sungsorientierte Pers√∂nlichkeit mit ausgepr√§gten Kommunikations- und Teamf√§higkeiten

Angebote, die mich √ºberzeugen
‚Ä¢ vielseitiges T√§tigkeitsfeld in einer innovativen Arbeitsumgebung
‚Ä¢ Arbeiten mit den neuesten Technologien
‚Ä¢ abwechslungsreiche internationale Projekte
‚Ä¢ umfangreiche fachliche Einarbeitung inkl. Anwendungstrainings
‚Ä¢ top ausgestatteter ergonomischer Arbeitsplatz in einem modernen B√ºrogeb√§ude mit Co-Working Space
‚Ä¢ M√∂glichkeit im Home-Office zu arbeiten (bis zu 50 %)
‚Ä¢ zahlreiche Weiterbildungsm√∂glichkeiten zur Unterst√ºtzung der pers√∂nlichen und fachlichen Entwicklung
‚Ä¢ kostenlose Verpflegung in Form von t√§glich frischem Obst und Gem√ºse, Kaffee sowie Tee
‚Ä¢ M√∂glichkeit eines mehrmonatigen Sabbaticals
‚Ä¢ sicherer und verl√§sslicher Arbeitgeber

Entgelt

attraktives Brutto-Monatseinstiegsgehalt ab ‚Ç¨ 3.922,- f√ºr 38,5 Stunden/Woche, abh√§ngig von Qualifikation und Berufserfahrung bis ‚Ç¨ 4.966,- in der Endstufe

Arbeitsort

‚Äã4653 Eberstalzell, Solarstra√üe 7‚Äã

Arbeitsbeginn

‚Äãab sofort‚Äã

Online bewerben

Jetzt online bewerben und Lebenslauf inklusive Foto sowie s√§mtliche relevante Zeugnisse beif√ºgen","[{'items': ['Aufgaben, die mich erwarten\n‚Ä¢ aktives Mitgestalten von BI Projekten im internationalen Umfeld\n‚Ä¢ Entwickeln und Umsetzen von ETL Prozessen in Abstimmung mit dem Frontend Development\n‚Ä¢ Weiterentwickeln der Berichtslandschaft mit Fokus auf das Backend\n‚Ä¢ eigenst√§ndiges Betreuen des Data Warehouse und Data Lake\n‚Ä¢ Extrahieren und Aufbereiten von Daten im Bereich Process Mining\n‚Ä¢ Konzipieren und Erstellen von Datenexporten aus unseren Systemen (z.B. f√ºr den Einkauf, die Logistik, unsere Zweigniederlassungen)\n\nQualifikationen, die ich mitbringe\n‚Ä¢ abgeschlossenes IT Studium\n‚Ä¢ einschl√§gige Berufserfahrung\n‚Ä¢ Know-how in der Analyse, Validierung sowie Darstellung von Daten\n‚Ä¢ fundierte Fachkenntnisse im SQL Bereich und Erfahrungen in Reporting L√∂sungen wie Tableau, QlikView oder SAP BusinessObjects\n‚Ä¢ Erfahrung in der Konzeption und Erstellung von Datenmodellen und ETL Prozessen\n‚Ä¢ Kenntnisse von Datenstrukturen in ERP-Systemen wie SAP S/4 HANA von Vorteil\n‚Ä¢ gute Englischkenntnisse\n‚Ä¢ analytische und... l√∂sungsorientierte Pers√∂nlichkeit mit ausgepr√§gten Kommunikations- und Teamf√§higkeiten\n\nAngebote, die mich √ºberzeugen\n‚Ä¢ vielseitiges T√§tigkeitsfeld in einer innovativen Arbeitsumgebung\n‚Ä¢ Arbeiten mit den neuesten Technologien\n‚Ä¢ abwechslungsreiche internationale Projekte\n‚Ä¢ umfangreiche fachliche Einarbeitung inkl. Anwendungstrainings\n‚Ä¢ top ausgestatteter ergonomischer Arbeitsplatz in einem modernen B√ºrogeb√§ude mit Co-Working Space\n‚Ä¢ M√∂glichkeit im Home-Office zu arbeiten (bis zu 50 %)\n‚Ä¢ zahlreiche Weiterbildungsm√∂glichkeiten zur Unterst√ºtzung der pers√∂nlichen und fachlichen Entwicklung\n‚Ä¢ kostenlose Verpflegung in Form von t√§glich frischem Obst und Gem√ºse, Kaffee sowie Tee\n‚Ä¢ M√∂glichkeit eines mehrmonatigen Sabbaticals\n‚Ä¢ sicherer und verl√§sslicher Arbeitgeber\n\nEntgelt\n\nattraktives Brutto-Monatseinstiegsgehalt ab ‚Ç¨ 3.922,- f√ºr 38,5 Stunden/Woche, abh√§ngig von Qualifikation und Berufserfahrung bis ‚Ç¨ 4.966,- in der Endstufe\n\nArbeitsort\n\n\u200b4653 Eberstalzell, Solarstra√üe 7\u200b\n\nArbeitsbeginn\n\n\u200bab sofort\u200b\n\nOnline bewerben\n\nJetzt online bewerben und Lebenslauf inklusive Foto sowie s√§mtliche relevante Zeugnisse beif√ºgen']}]","[{'link': 'http://www.hofer.at/', 'text': 'hofer.at'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=ALDI+%7C+HOFER&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIrQw', 'text': 'See web results for ALDI | HOFER'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQFKMkavSVFqgrzUtZDLJ1ghHGwQ4J4wf37gSZs&s=0,"['15 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '15 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL3cvZCkiLCJodGlkb2NpZCI6Inc1ZHhsaVNET0JzQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTVTVoYlhWMFQwNVZXV3BvUkRoUU9YbGlUVXRSU21ablltWTNRa3RNY0dodGNXRlBRamw2WWpSd00ybDZXSE16V0VFMFFuRndPVTUwWjNGdFZWSllkSGhQYzBOSWQxazVUMXBSVTNORk5EVXhiRlJzYTJGeldYQnpORmc1TW13eVVHMXBlVGRoTmkxeFMyeHZVSEZvUjB0elF6STBTelJzTVVWRVdEQXplVVI0ZWxWMlVHbFVVWE5QYTNWd2VVdHZOelpMV1RjM1EwRnZUR2x3ZGxkc09FcHNYMFpRZWtoS0xUWnhlamQzVEhSeU4wVlRNV2xCVTI5clpuQm5XbWd6VnpSTldERlhFaGRGVEZCSVdrNXRVMFZmVDBoM1ltdFFMWEpEY1RKQmR4b2lRVXhGVXpsMVRtVm5Ua3BOY1VkbFdTMHljMlIzYmxkVGFrUklNRGhRZURoU1FRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JzLmFsZGktSG9mZXIuY29tIiwibGluayI6Imh0dHBzOi8vam9icy5hbGRpLWhvZmVyLmNvbS9ob2Zlci1rYXJyaWVyZS1hdC9qb2IvRGF0YS1FbmdpbmVlci0lMjhtd2QlMjkvODM0OTY5OTAxLz9mZWVkSWQ9MjQ1MTAxXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,StudentFinance, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe

This offer from ""StudentFinance"" has been enriched by Jobgether and got a 72% flex score.
Data Engineer
Job description

You'll enjoy this role the most if:
‚Ä¢ You want to be fully remote - forever!
‚Ä¢ You ask good questions and don't shy away from figuring out the answer if we don't have them (yet)
‚Ä¢ You are passionate about building superior data infrastructures and have a hint of data science expertise
‚Ä¢ You have been through transforming teams from no data to being data driven
‚Ä¢ You don't shy away from building a data team from scratch with us

About StudentFinance

The World Economic Forum predicts that we will need to retrain one billion people by 2030. StudentFinance‚Äôs Career Mobility Platform is here to scale upskilling globally.

We are proud to empower economic mobility and change people's lives through revolutionary education financing. Our startup is backed by VCs like Iberis Capital, Mustard Seed MAZE, Armilar VP... Seedcamp and many more. And the news are out - we just raised our Series A funding round and 2023 is a year of acceleration! üìà

üí•2023 in a nutshell:
‚Ä¢ We‚Äôre upgrading our labor market data intelligence with AI models, technology and machine learning
‚Ä¢ We‚Äôre serving the UK and ES markets + opening up our operation in Germany
‚Ä¢ We‚Äôre expanding to new and exciting fields of study, such as green skills/net zero transition and healthcare

We are building the infrastructure to offer outcomes-based financing. Through Income Share Agreements (ISA for short), people defer the tuition payment and only start making payments after securing a job. ISAs are all about aligned incentives, and so are we at StudentFinance. Our end game is supporting our customer's transition to employment and financial health.

We are building a world-class team of purpose-driven and entrepreneurial people, working in a remote setting from cities across Europe.

About the role

Our ambition is to reach 100 million users by the end of 2030. Our next chapter is about upping our game in data. We are looking to add a Data Engineer to join our team as an expert and our first dedicated Data hire alongside a Data Analyst who is shortly joining the team, as well.

One of our engineering principles is that Data is an asset. The quality of our decisions depend on the data and we have a lot to do on this front. In this role, you will work with teams across the organisation to understand how data could be retrieved, used and fed back to the business to improve our overall strategy. You‚Äôll be an essential part of creating our data strategy, sharing insights and driving high decision making standards. You‚Äôll be our first hire in the Data team, this is a unique role with the potential to have a great impact and oversight about the entire business.

Your responsibilities:
‚Ä¢ Data is a native pillar in our strategy and you will driving the data-driven approach across the team
‚Ä¢ Manage data in the backend, take insights to the business to make decisions
‚Ä¢ You‚Äôll take ownership of the integrity and security of the data
‚Ä¢ Have ownership of capturing data in the right format, moving, transforming and finding ways to leverage it
‚Ä¢ Operate the data warehouse
‚Ä¢ Transfer data from one format / place to another
‚Ä¢ Periodically review the set of tools we use
‚Ä¢ Educate the wider team on utilising data, develop data driven mindset and coach team members where beneficial

Job requirements
About you
‚Ä¢ You know and understand the data, how is it derived and how we can use it
‚Ä¢ Understanding data mindset and tools tools
‚Ä¢ Thorough understanding and working experience with Python, Postgres and data warehouses
‚Ä¢ At this point we won‚Äôt have a Data Scientist in the team, so you‚Äôll be building models, hence we‚Äôd like you to have familiarity with data science or better yet, experience in similar, hybrid roles

Benefits

At StudentFinance, we believe our team is our biggest asset. We are very ambitious and hard-working and expect that this benefits package motivates and generates well-being in the team. Please find below a summary of the current benefits package:
‚Ä¢ Equity üìà
‚Ä¢ You can freely chose your location, we are remote first! ‚úàÔ∏è
‚Ä¢ Unlimited vacation days and flexible working hours - be your own boss! üèù
‚Ä¢ Yearly home office allowance üë©‚Äçüíª
‚Ä¢ Newest MacBook/PC of your choice üíª
‚Ä¢ Personal development budget ü§ì and 1on1 mentoring with world-class data experts from our network
‚Ä¢ Annual retreats üß≥üõ•üèî‚úàÔ∏èüèùü´∂

Apply for this job","[{'items': ['This a Full Remote job, the offer is available from: Europe\n\nThis offer from ""StudentFinance"" has been enriched by Jobgether and got a 72% flex score.\nData Engineer\nJob description\n\nYou\'ll enjoy this role the most if:\n‚Ä¢ You want to be fully remote - forever!\n‚Ä¢ You ask good questions and don\'t shy away from figuring out the answer if we don\'t have them (yet)\n‚Ä¢ You are passionate about building superior data infrastructures and have a hint of data science expertise\n‚Ä¢ You have been through transforming teams from no data to being data driven\n‚Ä¢ You don\'t shy away from building a data team from scratch with us\n\nAbout StudentFinance\n\nThe World Economic Forum predicts that we will need to retrain one billion people by 2030. StudentFinance‚Äôs Career Mobility Platform is here to scale upskilling globally.\n\nWe are proud to empower economic mobility and change people\'s lives through revolutionary education financing. Our startup is backed by VCs like Iberis Capital, Mustard Seed MAZE, Armilar VP... Seedcamp and many more. And the news are out - we just raised our Series A funding round and 2023 is a year of acceleration! üìà\n\nüí•2023 in a nutshell:\n‚Ä¢ We‚Äôre upgrading our labor market data intelligence with AI models, technology and machine learning\n‚Ä¢ We‚Äôre serving the UK and ES markets + opening up our operation in Germany\n‚Ä¢ We‚Äôre expanding to new and exciting fields of study, such as green skills/net zero transition and healthcare\n\nWe are building the infrastructure to offer outcomes-based financing. Through Income Share Agreements (ISA for short), people defer the tuition payment and only start making payments after securing a job. ISAs are all about aligned incentives, and so are we at StudentFinance. Our end game is supporting our customer\'s transition to employment and financial health.\n\nWe are building a world-class team of purpose-driven and entrepreneurial people, working in a remote setting from cities across Europe.\n\nAbout the role\n\nOur ambition is to reach 100 million users by the end of 2030. Our next chapter is about upping our game in data. We are looking to add a Data Engineer to join our team as an expert and our first dedicated Data hire alongside a Data Analyst who is shortly joining the team, as well.\n\nOne of our engineering principles is that Data is an asset. The quality of our decisions depend on the data and we have a lot to do on this front. In this role, you will work with teams across the organisation to understand how data could be retrieved, used and fed back to the business to improve our overall strategy. You‚Äôll be an essential part of creating our data strategy, sharing insights and driving high decision making standards. You‚Äôll be our first hire in the Data team, this is a unique role with the potential to have a great impact and oversight about the entire business.\n\nYour responsibilities:\n‚Ä¢ Data is a native pillar in our strategy and you will driving the data-driven approach across the team\n‚Ä¢ Manage data in the backend, take insights to the business to make decisions\n‚Ä¢ You‚Äôll take ownership of the integrity and security of the data\n‚Ä¢ Have ownership of capturing data in the right format, moving, transforming and finding ways to leverage it\n‚Ä¢ Operate the data warehouse\n‚Ä¢ Transfer data from one format / place to another\n‚Ä¢ Periodically review the set of tools we use\n‚Ä¢ Educate the wider team on utilising data, develop data driven mindset and coach team members where beneficial\n\nJob requirements\nAbout you\n‚Ä¢ You know and understand the data, how is it derived and how we can use it\n‚Ä¢ Understanding data mindset and tools tools\n‚Ä¢ Thorough understanding and working experience with Python, Postgres and data warehouses\n‚Ä¢ At this point we won‚Äôt have a Data Scientist in the team, so you‚Äôll be building models, hence we‚Äôd like you to have familiarity with data science or better yet, experience in similar, hybrid roles\n\nBenefits\n\nAt StudentFinance, we believe our team is our biggest asset. We are very ambitious and hard-working and expect that this benefits package motivates and generates well-being in the team. Please find below a summary of the current benefits package:\n‚Ä¢ Equity üìà\n‚Ä¢ You can freely chose your location, we are remote first! ‚úàÔ∏è\n‚Ä¢ Unlimited vacation days and flexible working hours - be your own boss! üèù\n‚Ä¢ Yearly home office allowance üë©\u200düíª\n‚Ä¢ Newest MacBook/PC of your choice üíª\n‚Ä¢ Personal development budget ü§ì and 1on1 mentoring with world-class data experts from our network\n‚Ä¢ Annual retreats üß≥üõ•üèî‚úàÔ∏èüèù\U0001faf6\n\nApply for this job']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=StudentFinance&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAII4Aw', 'text': 'See web results for StudentFinance'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRSO27oVsfoBuuvfGiv70wIvHEmBRSa9R-3pgLMMwI&s,"['Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiIzVUVERE0yQWhQVUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVMXJNbXhzVERocFVqbDRNWEpXTVhWbVJFMUJNVFpRUzA5ME1YQkhYMVYxVUc1bFZrTmpORVF0UVhaS2VraDJRa0ZNVkRKdE9WZDBhM1ZNYTJRMmNqRjVVWGxOUnpod1N6VnBZWGR5UVZFMk9FUlVPSEJaWjBOaFZVZzVkak5zUmxGMlJ6aGhhR2swWmxJNU1rdFRPR1UxU2xKallXbzRjelpQZVVkd1pISkVlV1pOUjBwTVRYWm5VbVJIZUhOVVNsWk5Na1J2ZURNelNqTkNhamxuV1dGamQzQXhWVkU1VUhjNVJXRkVWMDF4UzFJeldtWTBFaGRGVEZCSVdrNXRVMFZmVDBoM1ltdFFMWEpEY1RKQmR4b2lRVXhGVXpsMVRWUlFka1pWZGpOQk1ITkxOWEphUjBKMFJHTktWMXBsTlRaVWR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JnZXRoZXIiLCJsaW5rIjoiaHR0cHM6Ly9qb2JnZXRoZXIuY29tL29mZmVyLzY0NGY3OGYxZWY2MTk3ZDhiNDQ0NjljMS1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
International logistics,FH Ober√∂sterreich,"  Steyr, Austria   ",via FH Ober√∂sterreich,"We are looking for a Data Engineer to join our team. Within our fully funded research project, we are building a new and innovative solution in the logistics sector to help companies visualize and monitor real-time information about their supply chains.

YOUR TASKS
‚Ä¢ Developing scripts for the extraction of structured and non-structured information (e.g. SQL databases, csv, xlsx, xml, txt, web pages and others).
‚Ä¢ Design data models considering best practices regarding efficiency and information security.
‚Ä¢ Create dedicated scripts to perform data transformation and store in redundant repositories.
‚Ä¢ Evaluate and collaborate in the implementation of solutions for handling big data environments.
‚Ä¢ Optimize legacy ETL processes and perform new developments.
‚Ä¢ Document the data processing pipelines and manage the code versioning.
‚Ä¢ Collaborate with the engineering team in the development or modification of the core existing platforms.
‚Ä¢ Contribute to publications
‚Ä¢ Take operational... responsibility for the components that you develop.

YOUR PROFILE
‚Ä¢ MSC - Degree in computer science / software engineering
‚Ä¢ Experience using Python as programing language focus on data field (e.g. Anaconda, Jupyter Notebook, Pandas, Dask, PySpark, Numpy, Scikit, others).
‚Ä¢ Deep understanding of the web scrapping approach, web pages structures and techniques to extract information.
‚Ä¢ Experience with the RDBMS and of SQL query language, database optimizations, indexing, replications.
‚Ä¢ Experience with NOSQL resources, like ElasticSearch, MongoDB, Apache Cassandra,etc.
‚Ä¢ Using of parallelism in the execution of ETL process, execution based on events.
‚Ä¢ Data lake principles and practical experience with big data solutions (e.g. Hadoop, Apache Spark)
‚Ä¢ Good to have experience in:
‚Ä¢ Using of Amazon cloud computing resources like EMR and S3 storage.
‚Ä¢ Experience with deployment ETL process in Docker containers.
‚Ä¢ Use of Graph Database Neo4j and Cypher query language.
‚Ä¢ Experience with secure data at transit and rest (encryption) and techniques for clustering and replication implementation.
‚Ä¢ Working in an environment where you constantly experiment and iterate quickly

ABOUT US

As the most research-intensive university of applied sciences in Austria, with nearly 6000 students in over 70 degree programs, we teach and research with a strong practical orientation and the highest quality.Thus, we have been providing top education for the next generation for more than 25 years and invest in the future of Upper Austria with great pleasure. Steyr: At the Steyr Campus, we train the managers of tomorrow and score points with what is probably Austria's most beautiful campus, right on the water.

R&D: Our university offers the ideal environment for forward-looking and innovative research projects. With an excellent order volume of about 40 million Euros, more than 500 projects are being carried out with a total of 630 partners from business and society.

The Upper Austrian University of Applied Sciences is a place for people with curiosity and spirit of discovery. Shape the future together with us! #AllAboutYourCareer

The FH Upper Austria stands for equal opportunities and diversity. With this in mind, we specifically invite women/men to apply. For this position, we offer a gross monthly salary (on a full-time basis, 14x per year) starting at EUR 3.200 (depending on eligible prior service","[{'items': [""We are looking for a Data Engineer to join our team. Within our fully funded research project, we are building a new and innovative solution in the logistics sector to help companies visualize and monitor real-time information about their supply chains.\n\nYOUR TASKS\n‚Ä¢ Developing scripts for the extraction of structured and non-structured information (e.g. SQL databases, csv, xlsx, xml, txt, web pages and others).\n‚Ä¢ Design data models considering best practices regarding efficiency and information security.\n‚Ä¢ Create dedicated scripts to perform data transformation and store in redundant repositories.\n‚Ä¢ Evaluate and collaborate in the implementation of solutions for handling big data environments.\n‚Ä¢ Optimize legacy ETL processes and perform new developments.\n‚Ä¢ Document the data processing pipelines and manage the code versioning.\n‚Ä¢ Collaborate with the engineering team in the development or modification of the core existing platforms.\n‚Ä¢ Contribute to publications\n‚Ä¢ Take operational... responsibility for the components that you develop.\n\nYOUR PROFILE\n‚Ä¢ MSC - Degree in computer science / software engineering\n‚Ä¢ Experience using Python as programing language focus on data field (e.g. Anaconda, Jupyter Notebook, Pandas, Dask, PySpark, Numpy, Scikit, others).\n‚Ä¢ Deep understanding of the web scrapping approach, web pages structures and techniques to extract information.\n‚Ä¢ Experience with the RDBMS and of SQL query language, database optimizations, indexing, replications.\n‚Ä¢ Experience with NOSQL resources, like ElasticSearch, MongoDB, Apache Cassandra,etc.\n‚Ä¢ Using of parallelism in the execution of ETL process, execution based on events.\n‚Ä¢ Data lake principles and practical experience with big data solutions (e.g. Hadoop, Apache Spark)\n‚Ä¢ Good to have experience in:\n‚Ä¢ Using of Amazon cloud computing resources like EMR and S3 storage.\n‚Ä¢ Experience with deployment ETL process in Docker containers.\n‚Ä¢ Use of Graph Database Neo4j and Cypher query language.\n‚Ä¢ Experience with secure data at transit and rest (encryption) and techniques for clustering and replication implementation.\n‚Ä¢ Working in an environment where you constantly experiment and iterate quickly\n\nABOUT US\n\nAs the most research-intensive university of applied sciences in Austria, with nearly 6000 students in over 70 degree programs, we teach and research with a strong practical orientation and the highest quality.Thus, we have been providing top education for the next generation for more than 25 years and invest in the future of Upper Austria with great pleasure. Steyr: At the Steyr Campus, we train the managers of tomorrow and score points with what is probably Austria's most beautiful campus, right on the water.\n\nR&D: Our university offers the ideal environment for forward-looking and innovative research projects. With an excellent order volume of about 40 million Euros, more than 500 projects are being carried out with a total of 630 partners from business and society.\n\nThe Upper Austrian University of Applied Sciences is a place for people with curiosity and spirit of discovery. Shape the future together with us! #AllAboutYourCareer\n\nThe FH Upper Austria stands for equal opportunities and diversity. With this in mind, we specifically invite women/men to apply. For this position, we offer a gross monthly salary (on a full-time basis, 14x per year) starting at EUR 3.200 (depending on eligible prior service""]}]","[{'link': 'https://www.fh-ooe.at/', 'text': 'fh-ooe.at'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=FH+Ober%C3%B6sterreich&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIkw0', 'text': 'See web results for FH Ober√∂sterreich'}]",,['Full-time'],{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJJbnRlcm5hdGlvbmFsIGxvZ2lzdGljcyIsImh0aWRvY2lkIjoiT2pkWExib1BEZ29BQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1MwTkVZbXB0VlVoclZtOW1kMEV4VWpWT2FYQmtVRk5tWlVOR01VdHlaakpKYjNwcU5WRktlRTlpVVhSTFprRmthWGRFVFVnMVFYbzJPRXRMYldaTWMyeFFXVjlTZFVoc1RGRlNPVkE1ZFRKdmMwMVZkSFpIU2xGaFdFSmthVkpDZVcxRFprWTVSRXRRY25SNlRHTnVMVmROWjJGWlRrUkdObEpmYkdoblJ6WkNkelV6TFdkaFZqRlhOSGhIYjNOZk1qTkVUM05rUzJ4TGVETnVOR2RJVjNGbGNWbDNVM0JIV1V4NlVGbEpSMEkxZFdwRk1VdHJiMTh6ZDFGWVgxZDNibFZOYUZsZkVoZEZURkJJV2s1dFUwVmZUMGgzWW10UUxYSkRjVEpCZHhvaVFVeEZVemwxVUZZeWNWZzVSV053UTNWUU0xWlFTVGQwZG5WUE1FcHJWV1l3UVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY184IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEZIIE9iZXLDtnN0ZXJyZWljaCIsImxpbmsiOiJodHRwczovL3d3dy5maC1vb2UuYXQvdWViZXItdW5zL2pvYnMta2FycmllcmUtYW4tZGVyLWZoLW9vZS9qb2Jib2Vyc2UvZGV0YWlsL2RhdGEtZW5naW5lZXItbS1mLXgvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer | Europe | Remote,Unite, Anywhere ,via Indeed,"We can offer you a permanent employment contract in the following countries: Austria, Estonia, France, Germany, Hungary, Italy, Netherlands, Poland, Slovakia, Spain, Switzerland and the UK.

Hello, my name is Jeremias and as Chapter Lead, I am looking for an experienced Data Engineer to join our international Analytics Team.
In the Analytics and IT department, we have been developing our software products for more than 20 years. During this time, we have developed new products, features and ideas and implemented them with passion and interest.
Our Analytics Team takes care of Business Intelligence systems, customer journey tracking and modelling data. We are open-minded, work according to Scrum and stand for good teamwork. It gives Unitees access to our data and thus provides the basic framework for good decisions. We want to become better and see current challenges in getting rid of ""old habits"" in the infrastructure and using new approaches (e.g., renewal of DWH). In order to be... modern, we are looking for someone who has a lot of experience in data engineering and at the same time, also would bring good knowledge and expertise in the area of DataOps. Are you ready for new challenges?

Your role
‚Ä¢ You‚Äôll develop a data stack on cloud technologies and modernize the data tooling landscape
‚Ä¢ You‚Äôll design and develop database models and work on the expansion of our data warehouse
‚Ä¢ You‚Äôll develop and maintain our infrastructure in the cloud
‚Ä¢ You‚Äôll work within a Scrum team with responsibility across a broad range of analytics applications

Your qualifications
‚Ä¢ You love working with a modern data and tech stack (engineering, testing, versioning, microservices, DomainDrivenDesign)
‚Ä¢ You have good experience with Python, data lake architectures, cloud infrastructure, data warehouse, orchestration, Tableau, SQL, AWS concepts
‚Ä¢ You are passionate about DevOps: we build it, we run it!
‚Ä¢ You have experience with ‚ÄúInfrastructure as Code‚Äù (e.g. Docker, AWS Cloudformation, AWS CDK, Terraform)
‚Ä¢ You like best practices and enforce high-quality data
‚Ä¢ You love teamwork and agile software development

What you can expect from us
‚Ä¢ An exciting, fast-paced job at Europe‚Äôs trusted B2B platform, where we connect the economy for sustainable business
‚Ä¢ An agile technology company with flat hierarchies and open communication, where you can learn from others and contribute your expertise
‚Ä¢ A fair and open corporate culture, with experienced, engaged managers and friendly, helpful colleagues
‚Ä¢ A flexible and forward-thinking approach, including remote working and personal autonomy
‚Ä¢ Opportunities to develop your skills, build a career and grow within the company ‚Äì we encourage you to spend 10% of your working time on professional development, e.g. by providing unlimited access to online learning platforms such as Udemy
‚Ä¢ An organisation that supports your personal goals, commitments and responsibilities

We are Unite.
Unite connects the economy for sustainable business. The trusted e-procurement platform, with its integrated Mercateo Marketplace and Procurement Portal, enables effortless sourcing and purchasing for B2B and public sector organisations. Bringing buyers and suppliers together for mutual benefit, Unite has established a solid foundation of fair competition and trustworthy partnerships. The platform‚Äôs scalable infrastructure supports connections, business stability and a robust supply chain. Unite revolutionises e-commerce for B2B and the public sector by adding and sharing value for markets and communities.

Would you like to become a part of Unite?

Our headquarters are located in Leipzig, Germany. We are active in 15 European countries. More than 700 people work for Unite ‚Äì both at its physical Unite offices and remotely. In 2022, Unite achieved a turnover of ‚Ç¨447m.

Contact us

Anna Fussa
Tech Recruiter | Human Resources

anna.fussa@unite.eu
+49 341 355 865 68","[{'items': ['We can offer you a permanent employment contract in the following countries: Austria, Estonia, France, Germany, Hungary, Italy, Netherlands, Poland, Slovakia, Spain, Switzerland and the UK.\n\nHello, my name is Jeremias and as Chapter Lead, I am looking for an experienced Data Engineer to join our international Analytics Team.\nIn the Analytics and IT department, we have been developing our software products for more than 20 years. During this time, we have developed new products, features and ideas and implemented them with passion and interest.\nOur Analytics Team takes care of Business Intelligence systems, customer journey tracking and modelling data. We are open-minded, work according to Scrum and stand for good teamwork. It gives Unitees access to our data and thus provides the basic framework for good decisions. We want to become better and see current challenges in getting rid of ""old habits"" in the infrastructure and using new approaches (e.g., renewal of DWH). In order to be... modern, we are looking for someone who has a lot of experience in data engineering and at the same time, also would bring good knowledge and expertise in the area of DataOps. Are you ready for new challenges?\n\nYour role\n‚Ä¢ You‚Äôll develop a data stack on cloud technologies and modernize the data tooling landscape\n‚Ä¢ You‚Äôll design and develop database models and work on the expansion of our data warehouse\n‚Ä¢ You‚Äôll develop and maintain our infrastructure in the cloud\n‚Ä¢ You‚Äôll work within a Scrum team with responsibility across a broad range of analytics applications\n\nYour qualifications\n‚Ä¢ You love working with a modern data and tech stack (engineering, testing, versioning, microservices, DomainDrivenDesign)\n‚Ä¢ You have good experience with Python, data lake architectures, cloud infrastructure, data warehouse, orchestration, Tableau, SQL, AWS concepts\n‚Ä¢ You are passionate about DevOps: we build it, we run it!\n‚Ä¢ You have experience with ‚ÄúInfrastructure as Code‚Äù (e.g. Docker, AWS Cloudformation, AWS CDK, Terraform)\n‚Ä¢ You like best practices and enforce high-quality data\n‚Ä¢ You love teamwork and agile software development\n\nWhat you can expect from us\n‚Ä¢ An exciting, fast-paced job at Europe‚Äôs trusted B2B platform, where we connect the economy for sustainable business\n‚Ä¢ An agile technology company with flat hierarchies and open communication, where you can learn from others and contribute your expertise\n‚Ä¢ A fair and open corporate culture, with experienced, engaged managers and friendly, helpful colleagues\n‚Ä¢ A flexible and forward-thinking approach, including remote working and personal autonomy\n‚Ä¢ Opportunities to develop your skills, build a career and grow within the company ‚Äì we encourage you to spend 10% of your working time on professional development, e.g. by providing unlimited access to online learning platforms such as Udemy\n‚Ä¢ An organisation that supports your personal goals, commitments and responsibilities\n\nWe are Unite.\nUnite connects the economy for sustainable business. The trusted e-procurement platform, with its integrated Mercateo Marketplace and Procurement Portal, enables effortless sourcing and purchasing for B2B and public sector organisations. Bringing buyers and suppliers together for mutual benefit, Unite has established a solid foundation of fair competition and trustworthy partnerships. The platform‚Äôs scalable infrastructure supports connections, business stability and a robust supply chain. Unite revolutionises e-commerce for B2B and the public sector by adding and sharing value for markets and communities.\n\nWould you like to become a part of Unite?\n\nOur headquarters are located in Leipzig, Germany. We are active in 15 European countries. More than 700 people work for Unite ‚Äì both at its physical Unite offices and remotely. In 2022, Unite achieved a turnover of ‚Ç¨447m.\n\nContact us\n\nAnna Fussa\nTech Recruiter | Human Resources\n\nanna.fussa@unite.eu\n+49 341 355 865 68']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Unite&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIxA0', 'text': 'See web results for Unite'}]",,"['Work from home', 'Full-time', 'No degree mentioned']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciB8IEV1cm9wZSB8IFJlbW90ZSIsImh0aWRvY2lkIjoiUWRhUHhQYWZEOGdBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1NYQlFXV2xsTkZoR05WaHdkMkZ3TFhwWlRXaEdTMGhIYWxoNWEzRm9MVU5yWVROa2JYcGxTRkZGWlRCaVdsQXRjMWRKVDI1VGVIaGtTRTFFV1RGc2JGWlRhWE5zVjJseGQzTXRWakpzYlZsMmNFNUVOVTgwV2xRMmIxRjJUMDluTjA1Vk1GZGxlWEI0WVVsT2RtRmtPRUZRVkRaSFZHeFlkRkZqZERKa1V6QkRRVzVRYTJsT1FtRkJRa0kzY2pGYU5URmpRV3RWZUMxVFUxRjRTRzVUZFZwMVUwUlpURUZ2VkU1NVFtSTBkbEZ2RWhkRlRGQklXazV0VTBWZlQwaDNZbXRRTFhKRGNUSkJkeG9pUVV4RlV6bDFUVnB0V1hkU09GQlZlVGxqUXpoQ01VOVZPRnBrTjNnd01XOTZkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEwIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEluZGVlZCIsImxpbmsiOiJodHRwczovL2F0LmluZGVlZC5jb20vdmlld2pvYj9qaz1lODQ0ODE2YjE1ZTZlNTdiXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (m/f/d),softwareXperts GmbH,"  Linz, Austria   ",via SimplyHired,"Motherboard

We, softwareXperts, are looking for qualified IT experts with broad know-how for our customers from different industries.

Infrastruktur

Our client is an Austrian IT company and world market leader in its field.

Deine Upgrades

Home office possibility

Good public transport connections

Flexitime arrangement

Assumption of costs for commuters (climate ticket)

Modern office equipment

Vouchers for massages, sports activities etc.

Relocation bonus

Deine Hard- und Software

IT education (HTL, technical college, university).

Experience in designing and deploying data solutions, including data pipelines, modelling and/or processing.

Good knowledge of the latest data engineering tools and technologies, including ETL/ELT, SQL/NoSQL databases, data lake storage and DWH

Hands-on experience with stream and batch processing technologies such as Apache Spark

Know-how in dealing with complex data structures

Experience with Python and Pyspark

PLUS: Experience with Apache... Airflow

PLUS: experience with AWS cloud solutions such as Amazon Glue, DMS, Athena, Redshift Spectrum

Very good English skills

Deine Tasks

Design and build secure, scalable and resilient end-to-end data architectures and solutions.

Developing state-of-the-art data pipelines and streamlining data transfers between platforms and databases

Build and develop solutions to monitor the health of data workflows and optimise performance and stability

Ensure that data in our environment is stored in a clean, structured, secure and cost-effective manner

Ensuring the accuracy and availability of application and business data

Implement data quality strategies

Gain access to external data and make it available for internal use

The minimum salary for this position is ‚Ç¨ 70,000 gross per year, with the willingness to pay more depending on qualifications and experience. If you want to be part of a motivated team and contribute to the long-term success of the company, please apply with your application documents, quoting reference number 8482.

Gew√ºnschte Technologien

Apache Spark

DWH (Data-Warehouse)

ETL - Extract Transform Load

NoSQL

Python

SQL

Amazon Glue

Athena

Redshift Spectrum

Gesuchter Bereich

DWH / BI - Developer

Job - Overview

Company softwareXperts GmbH

Location Linz

Language deutsch, englisch

Contract Type full time

Remote Anteil 60 %

Kontakt Kerstin Thron

+43 (0)50 22 88-440

kerstin.thron@sw-xperts.com","[{'items': ['Motherboard\n\nWe, softwareXperts, are looking for qualified IT experts with broad know-how for our customers from different industries.\n\nInfrastruktur\n\nOur client is an Austrian IT company and world market leader in its field.\n\nDeine Upgrades\n\nHome office possibility\n\nGood public transport connections\n\nFlexitime arrangement\n\nAssumption of costs for commuters (climate ticket)\n\nModern office equipment\n\nVouchers for massages, sports activities etc.\n\nRelocation bonus\n\nDeine Hard- und Software\n\nIT education (HTL, technical college, university).\n\nExperience in designing and deploying data solutions, including data pipelines, modelling and/or processing.\n\nGood knowledge of the latest data engineering tools and technologies, including ETL/ELT, SQL/NoSQL databases, data lake storage and DWH\n\nHands-on experience with stream and batch processing technologies such as Apache Spark\n\nKnow-how in dealing with complex data structures\n\nExperience with Python and Pyspark\n\nPLUS: Experience with Apache... Airflow\n\nPLUS: experience with AWS cloud solutions such as Amazon Glue, DMS, Athena, Redshift Spectrum\n\nVery good English skills\n\nDeine Tasks\n\nDesign and build secure, scalable and resilient end-to-end data architectures and solutions.\n\nDeveloping state-of-the-art data pipelines and streamlining data transfers between platforms and databases\n\nBuild and develop solutions to monitor the health of data workflows and optimise performance and stability\n\nEnsure that data in our environment is stored in a clean, structured, secure and cost-effective manner\n\nEnsuring the accuracy and availability of application and business data\n\nImplement data quality strategies\n\nGain access to external data and make it available for internal use\n\nThe minimum salary for this position is ‚Ç¨ 70,000 gross per year, with the willingness to pay more depending on qualifications and experience. If you want to be part of a motivated team and contribute to the long-term success of the company, please apply with your application documents, quoting reference number 8482.\n\nGew√ºnschte Technologien\n\nApache Spark\n\nDWH (Data-Warehouse)\n\nETL - Extract Transform Load\n\nNoSQL\n\nPython\n\nSQL\n\nAmazon Glue\n\nAthena\n\nRedshift Spectrum\n\nGesuchter Bereich\n\nDWH / BI - Developer\n\nJob - Overview\n\nCompany softwareXperts GmbH\n\nLocation Linz\n\nLanguage deutsch, englisch\n\nContract Type full time\n\nRemote Anteil 60 %\n\nKontakt Kerstin Thron\n\n+43 (0)50 22 88-440\n\nkerstin.thron@sw-xperts.com']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=softwareXperts+GmbH&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAII9w0', 'text': 'See web results for softwareXperts GmbH'}]",,"['5 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '5 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6ImdjTEMzZ2p3eV84QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTV280ZUVkclNsQlJiMk5XV0dKRmFWWkZaR1JHZVdSZlZXVlVXV05wWWxGWVJsbHNUVzFHVUVwdGJsVnROa3g1ZVV0MmExRnhYMUUyTURkQlRIRTRWelZvWWxsSlVtcHhVemhmUmtkSlIydHdkUzFTUkdvMUxVeGlNVlppU2pCMGNFb3labGh6V1ZSSWFtUlVWMmh5T0hkT1dHbHZObko1WWpaTVh5MTZWMGxJV25sck1HMUhPSGczTlhKNVozcG1WRlZtZEd4VGFYRkxNM0JKYm5CbVFrTlBSV2c0VEhOWFFYaEpaalp2Vm5OekVoZEZURkJJV2s1dFUwVmZUMGgzWW10UUxYSkRjVEpCZHhvaVFVeEZVemwxVDFFeGIwTTVUVGRrTTI4NGVGOUpMVXBKV0RWbFRIQlpWRk5hVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTaW1wbHlIaXJlZCIsImxpbmsiOiJodHRwczovL3d3dy5zaW1wbHloaXJlZC5hdC9qb2IvRVBGbE1DMDllNVR6ZlBvYU84Z3FLLTZ2dnlJN245WVdGeEpJUzVlZEJhTnZZR0NNWUcyWDV3P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior Data Engineer,Polar Analytics, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe

This offer from ""Polar Analytics"" has been enriched by Jobgether and got a 75.25% flex score.

Polar Analytics is a Full-Stack Business Intelligence Solution for Consumer Brands. A powerful, yet simple solution for business users to get the insights they need to succeed and make the right decisions.

Our mission is to empower indie DTC brands worldwide to grow faster and more profitably!

What's Unique About Polar Analytics? üíé
‚Ä¢ Traction - We've grown to over 2,000 + active merchants as of June 2023, and we're on track to reach 5,000 this year.
‚Ä¢ Tech & Product - We leverage the latest advancements of the modern data stack and make it user-friendly to non-technical users.
‚Ä¢ Funding Strategy - We're backed by Point9, an exceptional B2B SaaS investor that's renowned for finding Unicorns at an early stage.
‚Ä¢ Team - We're a collective of experienced individuals from leading eCommerce SaaS platforms and are on a mission to... become the next unicorn.

What we‚Äôre looking for üéØ

We're looking for individuals who love to create products and have ownership from inception to shipping.

We live in a moment where growing with data has never been more essential: your mission at Polar will be critical. We‚Äôre looking for people who love to grow and empower brands to grow with data.

Finally, we're looking for humble innovators, people who have crazy ideas and who value impact more than anything else.

Why this role üôã
‚Ä¢ You will work on the core product. You will help empower thousands of entrepreneurs to grow their brand, with a product they use daily
‚Ä¢ Have an impact on the future of the Modern Data Stack for eCommerce, working on core technologies like dbt, Snowflake, Postgres, Airbyte, Fivetran, Airflow, Kubernetes, etc‚Ä¶
‚Ä¢ Have strong ownership as a Senior Data Engineer on the team, and grow a product that is already used by 1,500+ brands
‚Ä¢ Join us at one of the most exciting moments of our history: we are building the core features of the app with $9M raised and a growth rate of 30% month-over-month

What‚Äôs the scope üîé
‚Ä¢ You will help us add new capabilities and features to delight users even more
‚Ä¢ Own the data-connectors experience end-to-end
‚Ä¢ Build new integrations from scratch (our roadmap of integrations is big)
‚Ä¢ Build new capabilities to integrate any kind of data into Polar using airbyte, meltano/singer or custom scripts
‚Ä¢ Help provide full observability on the health of the connectors and lifecycle
‚Ä¢ Data activation capabilities to send data back to our users' platforms
‚Ä¢ ‚Ä¶ our backlog is huge. You will work closely with Product to gather and translate requirements into technical solutions to achieve the maximum impact
‚Ä¢ You will support us as we build a world-class data platform (scalable, performant, reliable):
‚Ä¢ Unlock new infrastructure capabilities. Today data is collected using Airbyte & Fivetran, and transformed on Snowflake using dbt. We want to set up a data lake to perform only bulk operations on Snowflake and scale our computing power to support our growth (+ 1000 brands / year).
‚Ä¢ Help scale our multi-tenant architecture. For ex: better isolation of data storage and compute

The job is made for you if...
‚Ä¢ üíÉ You are passionate about data products: you are creative and curious when it comes to data, with an active technological watch
‚Ä¢ üöÄ You have previous experience working as a software engineer and have engineered robust APIs in a production environment with multiple users
‚Ä¢ üïê You have spent a meaningful time (5+ years) as a hands-on data-engineer / software engineer
‚Ä¢ ü¶æ You are fluent in Python and have a good knowledge of SQL
‚Ä¢ üëÄ You are very rigorous
‚Ä¢ üéñ You have a sense of ownership, responsibility and strong communication skills

Being an Engineer at Polar Analytics üë©‚Äçüíªüßë‚Äçüíª

Getting Stuff Done, Ownership, Excellence, and Agility.

At Polar, engineers have a lot of ownership, as they both build features and make crucial product decisions.

You should join us if you want to ship fast without sacrificing quality, and be a part of a growing team that thrives for excellence.

Our stack üìö

We like to try new things out but most of our data stack is built around Python & SQL. Here are the things we use - and love:
‚Ä¢ dbt
‚Ä¢ Airflow
‚Ä¢ Airbyte & Fivetran
‚Ä¢ Snowflake
‚Ä¢ Kubernetes
‚Ä¢ Docker
‚Ä¢ Micro-services architecture on AWS

Hiring process ü§ù

We like to move fast but want to give you a chance to meet as many team members as possible:
‚Ä¢ Introduction chat with Head of Talent: vision, progress, milestones, past experience, what you like working on, etc. remote - 30 mins
‚Ä¢ Technical fit (Ways of working, business / product discussion) with CTO and/or Lead Data Engineer - 45 mins
‚Ä¢ Technical test (Coding & Knowledge questions) with CTO and/or Lead Data Engineer. Similar to problems we‚Äôve worked on. Live test - 1 hour
‚Ä¢ Culture Fit with CEO & meet with the team - 1 hour

Our Hiring Process üìù

We follow a structured hiring process to ensure fairness and transparency. Our process may vary depending on the role, but this is what you can expect after you apply:

1. Recruiter Screen (30 mins): A call with our Head of Talent to talk through your current/past experience, your motivations and Tell you more about Polar Analytics.

2. Technical Fit (45 mins): Here, you'll meet either the Hiring Manager or a team member of a similar level to discuss your ways of working and understand your skillset and ability for the role.

3. Technical Deep Dive (1 hour): This interview usually consists of a practical element (case study, Presentation, Technical Problem Solving etc) designed to give you a broader understanding of how we drive impact at Polar. This will be with the hiring manager and one other team member.

4. Culture Interview (45 mins): A conversation with one of our Culture Champions. We assess your team fit based on our values (see below).

We value your time and effort in the application process, and we aim to provide feedback as quickly as possible.

Our Values üåü
‚Ä¢ No Ego ü§ù - We're all about teamwork and valuing everyone's input.
‚Ä¢ Transparency ü™û - Honesty, feedback, and open communication are cornerstones of our growth.
‚Ä¢ Growth Mindset üöÄ - We're always learning, improving, and striving for excellence.
‚Ä¢ Care for others üíú - We're empathetic, customer-centric, and proactive in helping others.
‚Ä¢ Act Like the Owner üîë - We take responsibility and ownership to drive the success of our business.
‚Ä¢ Driven by Impact üéØ - We focus on delivering value to our customers and stakeholders.

Company Perks & Benefits:
‚Ä¢ üåé Choice-first organisation with a culture built around impact rather than hours
‚Ä¢ üèñ 5 weeks of vacation
‚Ä¢ üí∞ Competitive salary & equity (our compensation philosophy targets 60th - 80th percentile in the top 3 European tech markets)
‚Ä¢ üíª Latest MacBook Pro or equivalent
‚Ä¢ üè° Remote Office Upgrade budget to spend in your first year to ensure you have the best environment possible to work in
‚Ä¢ ü©∫ Complimentary private health insurance (we use Alan)
‚Ä¢ üòç Every 6 months we organize a company-wide offsite to discuss where we're going and strengthen the social bonds","[{'items': ['This a Full Remote job, the offer is available from: Europe\n\nThis offer from ""Polar Analytics"" has been enriched by Jobgether and got a 75.25% flex score.\n\nPolar Analytics is a Full-Stack Business Intelligence Solution for Consumer Brands. A powerful, yet simple solution for business users to get the insights they need to succeed and make the right decisions.\n\nOur mission is to empower indie DTC brands worldwide to grow faster and more profitably!\n\nWhat\'s Unique About Polar Analytics? üíé\n‚Ä¢ Traction - We\'ve grown to over 2,000 + active merchants as of June 2023, and we\'re on track to reach 5,000 this year.\n‚Ä¢ Tech & Product - We leverage the latest advancements of the modern data stack and make it user-friendly to non-technical users.\n‚Ä¢ Funding Strategy - We\'re backed by Point9, an exceptional B2B SaaS investor that\'s renowned for finding Unicorns at an early stage.\n‚Ä¢ Team - We\'re a collective of experienced individuals from leading eCommerce SaaS platforms and are on a mission to... become the next unicorn.\n\nWhat we‚Äôre looking for üéØ\n\nWe\'re looking for individuals who love to create products and have ownership from inception to shipping.\n\nWe live in a moment where growing with data has never been more essential: your mission at Polar will be critical. We‚Äôre looking for people who love to grow and empower brands to grow with data.\n\nFinally, we\'re looking for humble innovators, people who have crazy ideas and who value impact more than anything else.\n\nWhy this role üôã\n‚Ä¢ You will work on the core product. You will help empower thousands of entrepreneurs to grow their brand, with a product they use daily\n‚Ä¢ Have an impact on the future of the Modern Data Stack for eCommerce, working on core technologies like dbt, Snowflake, Postgres, Airbyte, Fivetran, Airflow, Kubernetes, etc‚Ä¶\n‚Ä¢ Have strong ownership as a Senior Data Engineer on the team, and grow a product that is already used by 1,500+ brands\n‚Ä¢ Join us at one of the most exciting moments of our history: we are building the core features of the app with $9M raised and a growth rate of 30% month-over-month\n\nWhat‚Äôs the scope üîé\n‚Ä¢ You will help us add new capabilities and features to delight users even more\n‚Ä¢ Own the data-connectors experience end-to-end\n‚Ä¢ Build new integrations from scratch (our roadmap of integrations is big)\n‚Ä¢ Build new capabilities to integrate any kind of data into Polar using airbyte, meltano/singer or custom scripts\n‚Ä¢ Help provide full observability on the health of the connectors and lifecycle\n‚Ä¢ Data activation capabilities to send data back to our users\' platforms\n‚Ä¢ ‚Ä¶ our backlog is huge. You will work closely with Product to gather and translate requirements into technical solutions to achieve the maximum impact\n‚Ä¢ You will support us as we build a world-class data platform (scalable, performant, reliable):\n‚Ä¢ Unlock new infrastructure capabilities. Today data is collected using Airbyte & Fivetran, and transformed on Snowflake using dbt. We want to set up a data lake to perform only bulk operations on Snowflake and scale our computing power to support our growth (+ 1000 brands / year).\n‚Ä¢ Help scale our multi-tenant architecture. For ex: better isolation of data storage and compute\n\nThe job is made for you if...\n‚Ä¢ üíÉ You are passionate about data products: you are creative and curious when it comes to data, with an active technological watch\n‚Ä¢ üöÄ You have previous experience working as a software engineer and have engineered robust APIs in a production environment with multiple users\n‚Ä¢ üïê You have spent a meaningful time (5+ years) as a hands-on data-engineer / software engineer\n‚Ä¢ ü¶æ You are fluent in Python and have a good knowledge of SQL\n‚Ä¢ üëÄ You are very rigorous\n‚Ä¢ üéñ You have a sense of ownership, responsibility and strong communication skills\n\nBeing an Engineer at Polar Analytics üë©\u200düíªüßë\u200düíª\n\nGetting Stuff Done, Ownership, Excellence, and Agility.\n\nAt Polar, engineers have a lot of ownership, as they both build features and make crucial product decisions.\n\nYou should join us if you want to ship fast without sacrificing quality, and be a part of a growing team that thrives for excellence.\n\nOur stack üìö\n\nWe like to try new things out but most of our data stack is built around Python & SQL. Here are the things we use - and love:\n‚Ä¢ dbt\n‚Ä¢ Airflow\n‚Ä¢ Airbyte & Fivetran\n‚Ä¢ Snowflake\n‚Ä¢ Kubernetes\n‚Ä¢ Docker\n‚Ä¢ Micro-services architecture on AWS\n\nHiring process ü§ù\n\nWe like to move fast but want to give you a chance to meet as many team members as possible:\n‚Ä¢ Introduction chat with Head of Talent: vision, progress, milestones, past experience, what you like working on, etc. remote - 30 mins\n‚Ä¢ Technical fit (Ways of working, business / product discussion) with CTO and/or Lead Data Engineer - 45 mins\n‚Ä¢ Technical test (Coding & Knowledge questions) with CTO and/or Lead Data Engineer. Similar to problems we‚Äôve worked on. Live test - 1 hour\n‚Ä¢ Culture Fit with CEO & meet with the team - 1 hour\n\nOur Hiring Process üìù\n\nWe follow a structured hiring process to ensure fairness and transparency. Our process may vary depending on the role, but this is what you can expect after you apply:\n\n1. Recruiter Screen (30 mins): A call with our Head of Talent to talk through your current/past experience, your motivations and Tell you more about Polar Analytics.\n\n2. Technical Fit (45 mins): Here, you\'ll meet either the Hiring Manager or a team member of a similar level to discuss your ways of working and understand your skillset and ability for the role.\n\n3. Technical Deep Dive (1 hour): This interview usually consists of a practical element (case study, Presentation, Technical Problem Solving etc) designed to give you a broader understanding of how we drive impact at Polar. This will be with the hiring manager and one other team member.\n\n4. Culture Interview (45 mins): A conversation with one of our Culture Champions. We assess your team fit based on our values (see below).\n\nWe value your time and effort in the application process, and we aim to provide feedback as quickly as possible.\n\nOur Values üåü\n‚Ä¢ No Ego ü§ù - We\'re all about teamwork and valuing everyone\'s input.\n‚Ä¢ Transparency ü™û - Honesty, feedback, and open communication are cornerstones of our growth.\n‚Ä¢ Growth Mindset üöÄ - We\'re always learning, improving, and striving for excellence.\n‚Ä¢ Care for others üíú - We\'re empathetic, customer-centric, and proactive in helping others.\n‚Ä¢ Act Like the Owner üîë - We take responsibility and ownership to drive the success of our business.\n‚Ä¢ Driven by Impact üéØ - We focus on delivering value to our customers and stakeholders.\n\nCompany Perks & Benefits:\n‚Ä¢ üåé Choice-first organisation with a culture built around impact rather than hours\n‚Ä¢ üèñ 5 weeks of vacation\n‚Ä¢ üí∞ Competitive salary & equity (our compensation philosophy targets 60th - 80th percentile in the top 3 European tech markets)\n‚Ä¢ üíª Latest MacBook Pro or equivalent\n‚Ä¢ üè° Remote Office Upgrade budget to spend in your first year to ensure you have the best environment possible to work in\n‚Ä¢ ü©∫ Complimentary private health insurance (we use Alan)\n‚Ä¢ üòç Every 6 months we organize a company-wide offsite to discuss where we\'re going and strengthen the social bonds']}]","[{'link': 'http://www.polaranalytics.co/', 'text': 'polaranalytics.co'}, {'link': 'https://www.google.com/search?sca_esv=552448117&hl=en&q=Polar+Analytics&sa=X&ved=0ahUKEwjZ2q7ggrmAAxXzQzABHXqYCss4UBCYkAIIrQ4', 'text': 'See web results for Polar Analytics'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRfIRJwn7AJGGRjGAGK30foSccMesd0fqgmHLBzIBk&s,"['12 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '12 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiRmdLbTJHSlphdlVBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1MyUnZVR3BNVGpacE5WUnpTbEJuY2tSbWNFTkVjbkp4V2pGeGFHTjVWblF5YkZWd2JYVXRUMGRXU0Uxa09VdE1VRXBZTkdkZlVuSTRkV1ZXYW1wSGFEa3RkRFpCVkVZd2FYUllkbVJMVGtacVRWVjBlVWRWUTJ4RVVIVnRVSHBpVlVObE1EWndOM04zYm5CUFZ6TkJVV0p3WjNBd1dFSnpUR0ZCV1ZKNFpXVTVVRk0yTlZrMlEyUlVkMkZLY1V0Q1NGTkJXRjluUlVWaU9WQnJjRjlzUlZoWWRHd3RjVTh0UW1ocVRrUjBWbTE1YjNOaWQyZ3lVSFY1Y1RJMlNtMVhUVlJKVWxwVUVoZEZURkJJV2s1dFUwVmZUMGgzWW10UUxYSkRjVEpCZHhvaVFVeEZVemwxVGtONlN6WktVMHN5UlhKc1VHSk1URXRLWDNoMmN6Y3RNSFpFWnciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xMiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBKb2JnZXRoZXIiLCJsaW5rIjoiaHR0cHM6Ly9qb2JnZXRoZXIuY29tL29mZmVyLzY0Yjg4ZTU2YzgyNjZjNDQwM2QxZmJkYi1zZW5pb3ItZGF0YS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Senior Data Engineer,Polar Analytics, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: Europe

This offer from ""Polar Analytics"" has been enriched by Jobgether and got a 75.25% flex score.

Polar Analytics is a Full-Stack Business Intelligence Solution for Consumer Brands. A powerful, yet simple solution for business users to get the insights they need to succeed and make the right decisions.

Our mission is to empower indie DTC brands worldwide to grow faster and more profitably!

What's Unique About Polar Analytics? üíé
‚Ä¢ Traction - We've grown to over 2,000 + active merchants as of June 2023, and we're on track to reach 5,000 this year.
‚Ä¢ Tech & Product - We leverage the latest advancements of the modern data stack and make it user-friendly to non-technical users.
‚Ä¢ Funding Strategy - We're backed by Point9, an exceptional B2B SaaS investor that's renowned for finding Unicorns at an early stage.
‚Ä¢ Team - We're a collective of experienced individuals from leading eCommerce SaaS platforms and are on a mission to... become the next unicorn.

What we‚Äôre looking for üéØ

We're looking for individuals who love to create products and have ownership from inception to shipping.

We live in a moment where growing with data has never been more essential: your mission at Polar will be critical. We‚Äôre looking for people who love to grow and empower brands to grow with data.

Finally, we're looking for humble innovators, people who have crazy ideas and who value impact more than anything else.

Why this role üôã
‚Ä¢ You will work on the core product. You will help empower thousands of entrepreneurs to grow their brand, with a product they use daily
‚Ä¢ Have an impact on the future of the Modern Data Stack for eCommerce, working on core technologies like dbt, Snowflake, Postgres, Airbyte, Fivetran, Airflow, Kubernetes, etc‚Ä¶
‚Ä¢ Have strong ownership as a Senior Data Engineer on the team, and grow a product that is already used by 1,500+ brands
‚Ä¢ Join us at one of the most exciting moments of our history: we are building the core features of the app with $9M raised and a growth rate of 30% month-over-month

What‚Äôs the scope üîé
‚Ä¢ You will help us add new capabilities and features to delight users even more
‚Ä¢ Own the data-connectors experience end-to-end
‚Ä¢ Build new integrations from scratch (our roadmap of integrations is big)
‚Ä¢ Build new capabilities to integrate any kind of data into Polar using airbyte, meltano/singer or custom scripts
‚Ä¢ Help provide full observability on the health of the connectors and lifecycle
‚Ä¢ Data activation capabilities to send data back to our users' platforms
‚Ä¢ ‚Ä¶ our backlog is huge. You will work closely with Product to gather and translate requirements into technical solutions to achieve the maximum impact
‚Ä¢ You will support us as we build a world-class data platform (scalable, performant, reliable):
‚Ä¢ Unlock new infrastructure capabilities. Today data is collected using Airbyte & Fivetran, and transformed on Snowflake using dbt. We want to set up a data lake to perform only bulk operations on Snowflake and scale our computing power to support our growth (+ 1000 brands / year).
‚Ä¢ Help scale our multi-tenant architecture. For ex: better isolation of data storage and compute

The job is made for you if...
‚Ä¢ üíÉ You are passionate about data products: you are creative and curious when it comes to data, with an active technological watch
‚Ä¢ üöÄ You have previous experience working as a software engineer and have engineered robust APIs in a production environment with multiple users
‚Ä¢ üïê You have spent a meaningful time (5+ years) as a hands-on data-engineer / software engineer
‚Ä¢ ü¶æ You are fluent in Python and have a good knowledge of SQL
‚Ä¢ üëÄ You are very rigorous
‚Ä¢ üéñ You have a sense of ownership, responsibility and strong communication skills

Being an Engineer at Polar Analytics üë©‚Äçüíªüßë‚Äçüíª

Getting Stuff Done, Ownership, Excellence, and Agility.

At Polar, engineers have a lot of ownership, as they both build features and make crucial product decisions.

You should join us if you want to ship fast without sacrificing quality, and be a part of a growing team that thrives for excellence.

Our stack üìö

We like to try new things out but most of our data stack is built around Python & SQL. Here are the things we use - and love:
‚Ä¢ dbt
‚Ä¢ Airflow
‚Ä¢ Airbyte & Fivetran
‚Ä¢ Snowflake
‚Ä¢ Kubernetes
‚Ä¢ Docker
‚Ä¢ Micro-services architecture on AWS

Hiring process ü§ù

We like to move fast but want to give you a chance to meet as many team members as possible:
‚Ä¢ Introduction chat with Head of Talent: vision, progress, milestones, past experience, what you like working on, etc. remote - 30 mins
‚Ä¢ Technical fit (Ways of working, business / product discussion) with CTO and/or Lead Data Engineer - 45 mins
‚Ä¢ Technical test (Coding & Knowledge questions) with CTO and/or Lead Data Engineer. Similar to problems we‚Äôve worked on. Live test - 1 hour
‚Ä¢ Culture Fit with CEO & meet with the team - 1 hour

Our Hiring Process üìù

We follow a structured hiring process to ensure fairness and transparency. Our process may vary depending on the role, but this is what you can expect after you apply:

1. Recruiter Screen (30 mins): A call with our Head of Talent to talk through your current/past experience, your motivations and Tell you more about Polar Analytics.

2. Technical Fit (45 mins): Here, you'll meet either the Hiring Manager or a team member of a similar level to discuss your ways of working and understand your skillset and ability for the role.

3. Technical Deep Dive (1 hour): This interview usually consists of a practical element (case study, Presentation, Technical Problem Solving etc) designed to give you a broader understanding of how we drive impact at Polar. This will be with the hiring manager and one other team member.

4. Culture Interview (45 mins): A conversation with one of our Culture Champions. We assess your team fit based on our values (see below).

We value your time and effort in the application process, and we aim to provide feedback as quickly as possible.

Our Values üåü
‚Ä¢ No Ego ü§ù - We're all about teamwork and valuing everyone's input.
‚Ä¢ Transparency ü™û - Honesty, feedback, and open communication are cornerstones of our growth.
‚Ä¢ Growth Mindset üöÄ - We're always learning, improving, and striving for excellence.
‚Ä¢ Care for others üíú - We're empathetic, customer-centric, and proactive in helping others.
‚Ä¢ Act Like the Owner üîë - We take responsibility and ownership to drive the success of our business.
‚Ä¢ Driven by Impact üéØ - We focus on delivering value to our customers and stakeholders.

Company Perks & Benefits:
‚Ä¢ üåé Choice-first organisation with a culture built around impact rather than hours
‚Ä¢ üèñ 5 weeks of vacation
‚Ä¢ üí∞ Competitive salary & equity (our compensation philosophy targets 60th - 80th percentile in the top 3 European tech markets)
‚Ä¢ üíª Latest MacBook Pro or equivalent
‚Ä¢ üè° Remote Office Upgrade budget to spend in your first year to ensure you have the best environment possible to work in
‚Ä¢ ü©∫ Complimentary private health insurance (we use Alan)
‚Ä¢ üòç Every 6 months we organize a company-wide offsite to discuss where we're going and strengthen the social bonds","[{'items': ['This a Full Remote job, the offer is available from: Europe\n\nThis offer from ""Polar Analytics"" has been enriched by Jobgether and got a 75.25% flex score.\n\nPolar Analytics is a Full-Stack Business Intelligence Solution for Consumer Brands. A powerful, yet simple solution for business users to get the insights they need to succeed and make the right decisions.\n\nOur mission is to empower indie DTC brands worldwide to grow faster and more profitably!\n\nWhat\'s Unique About Polar Analytics? üíé\n‚Ä¢ Traction - We\'ve grown to over 2,000 + active merchants as of June 2023, and we\'re on track to reach 5,000 this year.\n‚Ä¢ Tech & Product - We leverage the latest advancements of the modern data stack and make it user-friendly to non-technical users.\n‚Ä¢ Funding Strategy - We\'re backed by Point9, an exceptional B2B SaaS investor that\'s renowned for finding Unicorns at an early stage.\n‚Ä¢ Team - We\'re a collective of experienced individuals from leading eCommerce SaaS platforms and are on a mission to... become the next unicorn.\n\nWhat we‚Äôre looking for üéØ\n\nWe\'re looking for individuals who love to create products and have ownership from inception to shipping.\n\nWe live in a moment where growing with data has never been more essential: your mission at Polar will be critical. We‚Äôre looking for people who love to grow and empower brands to grow with data.\n\nFinally, we\'re looking for humble innovators, people who have crazy ideas and who value impact more than anything else.\n\nWhy this role üôã\n‚Ä¢ You will work on the core product. You will help empower thousands of entrepreneurs to grow their brand, with a product they use daily\n‚Ä¢ Have an impact on the future of the Modern Data Stack for eCommerce, working on core technologies like dbt, Snowflake, Postgres, Airbyte, Fivetran, Airflow, Kubernetes, etc‚Ä¶\n‚Ä¢ Have strong ownership as a Senior Data Engineer on the team, and grow a product that is already used by 1,500+ brands\n‚Ä¢ Join us at one of the most exciting moments of our history: we are building the core features of the app with $9M raised and a growth rate of 30% month-over-month\n\nWhat‚Äôs the scope üîé\n‚Ä¢ You will help us add new capabilities and features to delight users even more\n‚Ä¢ Own the data-connectors experience end-to-end\n‚Ä¢ Build new integrations from scratch (our roadmap of integrations is big)\n‚Ä¢ Build new capabilities to integrate any kind of data into Polar using airbyte, meltano/singer or custom scripts\n‚Ä¢ Help provide full observability on the health of the connectors and lifecycle\n‚Ä¢ Data activation capabilities to send data back to our users\' platforms\n‚Ä¢ ‚Ä¶ our backlog is huge. You will work closely with Product to gather and translate requirements into technical solutions to achieve the maximum impact\n‚Ä¢ You will support us as we build a world-class data platform (scalable, performant, reliable):\n‚Ä¢ Unlock new infrastructure capabilities. Today data is collected using Airbyte & Fivetran, and transformed on Snowflake using dbt. We want to set up a data lake to perform only bulk operations on Snowflake and scale our computing power to support our growth (+ 1000 brands / year).\n‚Ä¢ Help scale our multi-tenant architecture. For ex: better isolation of data storage and compute\n\nThe job is made for you if...\n‚Ä¢ üíÉ You are passionate about data products: you are creative and curious when it comes to data, with an active technological watch\n‚Ä¢ üöÄ You have previous experience working as a software engineer and have engineered robust APIs in a production environment with multiple users\n‚Ä¢ üïê You have spent a meaningful time (5+ years) as a hands-on data-engineer / software engineer\n‚Ä¢ ü¶æ You are fluent in Python and have a good knowledge of SQL\n‚Ä¢ üëÄ You are very rigorous\n‚Ä¢ üéñ You have a sense of ownership, responsibility and strong communication skills\n\nBeing an Engineer at Polar Analytics üë©\u200düíªüßë\u200düíª\n\nGetting Stuff Done, Ownership, Excellence, and Agility.\n\nAt Polar, engineers have a lot of ownership, as they both build features and make crucial product decisions.\n\nYou should join us if you want to ship fast without sacrificing quality, and be a part of a growing team that thrives for excellence.\n\nOur stack üìö\n\nWe like to try new things out but most of our data stack is built around Python & SQL. Here are the things we use - and love:\n‚Ä¢ dbt\n‚Ä¢ Airflow\n‚Ä¢ Airbyte & Fivetran\n‚Ä¢ Snowflake\n‚Ä¢ Kubernetes\n‚Ä¢ Docker\n‚Ä¢ Micro-services architecture on AWS\n\nHiring process ü§ù\n\nWe like to move fast but want to give you a chance to meet as many team members as possible:\n‚Ä¢ Introduction chat with Head of Talent: vision, progress, milestones, past experience, what you like working on, etc. remote - 30 mins\n‚Ä¢ Technical fit (Ways of working, business / product discussion) with CTO and/or Lead Data Engineer - 45 mins\n‚Ä¢ Technical test (Coding & Knowledge questions) with CTO and/or Lead Data Engineer. Similar to problems we‚Äôve worked on. Live test - 1 hour\n‚Ä¢ Culture Fit with CEO & meet with the team - 1 hour\n\nOur Hiring Process üìù\n\nWe follow a structured hiring process to ensure fairness and transparency. Our process may vary depending on the role, but this is what you can expect after you apply:\n\n1. Recruiter Screen (30 mins): A call with our Head of Talent to talk through your current/past experience, your motivations and Tell you more about Polar Analytics.\n\n2. Technical Fit (45 mins): Here, you\'ll meet either the Hiring Manager or a team member of a similar level to discuss your ways of working and understand your skillset and ability for the role.\n\n3. Technical Deep Dive (1 hour): This interview usually consists of a practical element (case study, Presentation, Technical Problem Solving etc) designed to give you a broader understanding of how we drive impact at Polar. This will be with the hiring manager and one other team member.\n\n4. Culture Interview (45 mins): A conversation with one of our Culture Champions. We assess your team fit based on our values (see below).\n\nWe value your time and effort in the application process, and we aim to provide feedback as quickly as possible.\n\nOur Values üåü\n‚Ä¢ No Ego ü§ù - We\'re all about teamwork and valuing everyone\'s input.\n‚Ä¢ Transparency ü™û - Honesty, feedback, and open communication are cornerstones of our growth.\n‚Ä¢ Growth Mindset üöÄ - We\'re always learning, improving, and striving for excellence.\n‚Ä¢ Care for others üíú - We\'re empathetic, customer-centric, and proactive in helping others.\n‚Ä¢ Act Like the Owner üîë - We take responsibility and ownership to drive the success of our business.\n‚Ä¢ Driven by Impact üéØ - We focus on delivering value to our customers and stakeholders.\n\nCompany Perks & Benefits:\n‚Ä¢ üåé Choice-first organisation with a culture built around impact rather than hours\n‚Ä¢ üèñ 5 weeks of vacation\n‚Ä¢ üí∞ Competitive salary & equity (our compensation philosophy targets 60th - 80th percentile in the top 3 European tech markets)\n‚Ä¢ üíª Latest MacBook Pro or equivalent\n‚Ä¢ üè° Remote Office Upgrade budget to spend in your first year to ensure you have the best environment possible to work in\n‚Ä¢ ü©∫ Complimentary private health insurance (we use Alan)\n‚Ä¢ üòç Every 6 months we organize a company-wide offsite to discuss where we\'re going and strengthen the social bonds']}]","[{'link': 'http://www.polaranalytics.co/', 'text': 'polaranalytics.co'}, {'link': 'https://www.google.com/search?sca_esv=552448117&q=Polar+Analytics&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAII5Ao', 'text': 'See web results for Polar Analytics'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRfIRJwn7AJGGRjGAGK30foSccMesd0fqgmHLBzIBk&s,"['12 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '12 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiRmdLbTJHSlphdlVBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1NVdHhjMVIxY0VGdVlVbERlRjl4Vm5WVFprWXlkVXBhZFVNdGNUVnBYemRQY3pkbk1rTmpka0l5Wm5ONVNWZE5OblUwYjFoemJGQnhWWHA0ZVhWcU5WcHhkbE40WmxRM2NHMUpWamhCWlhGVWQyaFdiRlppTVVac1NESkdXakpZUjFOQlEzZEVTa04yVG5aWVdrcFVPRXhLU0hOQlpFVlVkVE5uU0MxdVRrbFJSbnBKWm1WblJpMWZYMlZoVWxRdE0zbEZkMDk1Wm1wbFkwUTVkbWxwYlVWYWFGZzVNRTVoUkdwVlpuSlRNRGh0WldGcE56TnhMWHBZTWxWYU1sZ3pTbGsyZFZwcUVoZEdjbEJJV2t4bWFVYzRjVmwzWW10UU1qWmhhV3RCY3hvaVFVeEZVemwxVDJ0dlZtYzJhVlF4TTJGVVlXVXhTRXBJWm5ac01XVnBOekZvUVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIEpvYmdldGhlciIsImxpbmsiOiJodHRwczovL2pvYmdldGhlci5jb20vb2ZmZXIvNjRiODhlNTZjODI2NmM0NDAzZDFmYmRiLXNlbmlvci1kYXRhLWVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Senior/Staff Data Engineer @ Kpler in Austria,Kpler,  Austria   ,via Startupcareers,"In a world where trades are happening faster than ever to answer our needs, where sustainability is not just an option anymore, clarity and trust in the information we trade with are a must.

So, say hello to Kpler! We exist to facilitate sustainable and efficient trade to meet the changing needs of our world. To do so we‚Äôve built a Data-as-a-Service solution that does exactly that across the lifecycle of a trade.

Our solution aggregates data from hundreds of sources including radar and satellite imagery as well as logistics, governmental, shipping databases and more. Intelligently connecting the dots across fragmented information landscapes, we bring to our clients a unique, real-time understanding of the trades happening all over the world, by giving them access to live information about the movement of cargos, the availability of vessels as well as commodity storage.

To support this endeavor, we have teams in more than 9 countries and 11 key locations (Brussels, Paris, London... Athens, Vienna, Rostock, Hy√®res, Dubai, Singapore, Houston and New York). With individuals of various backgrounds, diverse skills, and international experiences, being global & inclusive is in our DNA!

We are looking for a Senior Data Engineer to join our software engineering team (over 100 engineers).

Some of the exciting projects you could work on include:

‚Ä¢ Building a new pipeline to feed a live database which is used by clients and research teams to produce useful insight on the commodity market

‚Ä¢ Building new features for our core platform including metrics & forecasting as well as scaling and stabilizing our data pipelines

As a Senior Data Engineer, you will:

‚Ä¢ Find efficient ways to tackle challenges using the relevant and up to date technologies

‚Ä¢ Work across the stack to deliver new features from start-to-finish

‚Ä¢ Improve performance and overcome scalability limits

‚Ä¢ Own meaningful parts of our service, have an impact, grow with the company

‚Ä¢ Actively share knowledge and document insights to support continuous team improvement and collaboration

‚Ä¢ Act as a mentor for our junior engineers; On some projects, you may also need to act as the Tech lead

Our Tech stack includes:

‚Ä¢ VueJs, D3js, RESTfulAPI and more on the frontend

‚Ä¢ Python, Java, Scala, Postgresql, ElasticSearch, Kafka, Spark, Snowflake and more on the backend

‚Ä¢ AWS, GCP, terraform and ansible for DevOps tools

You may be a fit if‚Ä¶

‚Ä¢ You have at least 10 years of experience in a similar role including significant experience in Python, Java, Scala or equivalent language

‚Ä¢ You have over 5 years experience working with AWS and cloud technologies

‚Ä¢ You have experience in radar image processing

‚Ä¢ You have used the Java libraries of the ESA SNAP toolboxes

‚Ä¢ You are familiar with orchestration and in particular Astronomer

‚Ä¢ You are familiar with building ETL and data pipelines, using asynchronous framework is a plus

‚Ä¢ You are comfortable with SQL and NoSQL databases for OLTP and OLAP usages

‚Ä¢ You value code simplicity, performance and details

‚Ä¢ You have demonstrated that you can learn and adapt quickly

‚Ä¢ You are fluent in English and have experience working in an international environment

What you will receive from Kpler:

‚Ä¢ You‚Äôll get to work in a truly global work environment, with offices in 7 countries (UK, France, Belgium, Austria, US, Dubai and Singapore), we come from more than 50 countries and speak more than 20 languages

‚Ä¢ We have truly embraced the new age of workplace flexibility where you can chose to work hybrid or onsite

‚Ä¢ We offer competitive compensation & benefits including work from home allowance, medical and life insurance, training and development allowance, paid volunteer work and more!

‚Ä¢ You will receive a company laptop and you can choose between Windows, Mac, or Linux

‚Ä¢ Global maternity (extended leave), parental, festival and compassionate leave policies aligned to the contemporary needs of the family, and individual choices

And you REALLY want to join our Engineering team because:

‚Ä¢ Interesting product & challenging technical problems to solve: our market is very specialized and quite complex! This means we build real algos and there‚Äôs some serious software engineering at work here!

‚Ä¢ Our growth is exponential: we build new features and products everyday! We frequently tackle brand-new business areas which means there‚Äôs always everything to build and always an interesting problem to sink your teeth into!

‚Ä¢ We are at the cross-road of Software Engineering, Commodity, Energy and Finance. This creates an interesting cultural mix: We value the flexibility, collaboration and employee-centric approach that the Tech culture brings but we also value the pragmatism, hard-working and intellectual excellence expectation that often runs in the Finance and Energy worlds

‚Ä¢ Team of 85+ talented Engineers working with the most modern tech stack

Recruitment Process:

Recruiter Screen: 30 minute video interview with a recruiter from hiring team

Hiring Manager Interview: 45 minute exchange with one of our Engineering Managers from the dedicated team

Take Home Technical Exercise

Meet the Team: An opportunity to see the fit and get to know your potential future team!

Our values

‚Ä¢ Be humble ‚Äì We always place the interests of the collective before your own.

‚Ä¢ Respect and care for others ‚Äì We make every person feel comfortable in their own beliefs, decisions, and perspectives.

‚Ä¢ Take responsibility ‚Äì We take ownership of our actions.

‚Ä¢ Act with integrity -We are honest and transparent in all your dealings.

‚Ä¢ Be bold ‚Äì We push the boundaries in order to improve and grow.

You‚Äôll get to work in a truly global environment, with more than 30 nationalities speaking more than 15 languages.

Our People Pledge

Don‚Äôt meet every single requirement? Research shows that women and people of color are less likely than others to apply if they feel like they don‚Äôt match 100% of the job requirements. Don‚Äôt let the confidence gap stand in your way, we‚Äôd love to hear from you! We understand that experience comes in many different forms and are dedicated to adding new perspectives to the team.

Kpler is committed to providing a fair, inclusive and diverse work-environment. We believe that different perspectives lead to better ideas, and better ideas allow us to better understand the needs and interests of our diverse, global community. We welcome people of different backgrounds, experiences, abilities and perspectives and are an equal opportunity employer.

By applying, I confirm that I have read and accept the Staff Privacy Notice","[{'items': ['In a world where trades are happening faster than ever to answer our needs, where sustainability is not just an option anymore, clarity and trust in the information we trade with are a must.\n\nSo, say hello to Kpler! We exist to facilitate sustainable and efficient trade to meet the changing needs of our world. To do so we‚Äôve built a Data-as-a-Service solution that does exactly that across the lifecycle of a trade.\n\nOur solution aggregates data from hundreds of sources including radar and satellite imagery as well as logistics, governmental, shipping databases and more. Intelligently connecting the dots across fragmented information landscapes, we bring to our clients a unique, real-time understanding of the trades happening all over the world, by giving them access to live information about the movement of cargos, the availability of vessels as well as commodity storage.\n\nTo support this endeavor, we have teams in more than 9 countries and 11 key locations (Brussels, Paris, London... Athens, Vienna, Rostock, Hy√®res, Dubai, Singapore, Houston and New York). With individuals of various backgrounds, diverse skills, and international experiences, being global & inclusive is in our DNA!\n\nWe are looking for a Senior Data Engineer to join our software engineering team (over 100 engineers).\n\nSome of the exciting projects you could work on include:\n\n‚Ä¢ Building a new pipeline to feed a live database which is used by clients and research teams to produce useful insight on the commodity market\n\n‚Ä¢ Building new features for our core platform including metrics & forecasting as well as scaling and stabilizing our data pipelines\n\nAs a Senior Data Engineer, you will:\n\n‚Ä¢ Find efficient ways to tackle challenges using the relevant and up to date technologies\n\n‚Ä¢ Work across the stack to deliver new features from start-to-finish\n\n‚Ä¢ Improve performance and overcome scalability limits\n\n‚Ä¢ Own meaningful parts of our service, have an impact, grow with the company\n\n‚Ä¢ Actively share knowledge and document insights to support continuous team improvement and collaboration\n\n‚Ä¢ Act as a mentor for our junior engineers; On some projects, you may also need to act as the Tech lead\n\nOur Tech stack includes:\n\n‚Ä¢ VueJs, D3js, RESTfulAPI and more on the frontend\n\n‚Ä¢ Python, Java, Scala, Postgresql, ElasticSearch, Kafka, Spark, Snowflake and more on the backend\n\n‚Ä¢ AWS, GCP, terraform and ansible for DevOps tools\n\nYou may be a fit if‚Ä¶\n\n‚Ä¢ You have at least 10 years of experience in a similar role including significant experience in Python, Java, Scala or equivalent language\n\n‚Ä¢ You have over 5 years experience working with AWS and cloud technologies\n\n‚Ä¢ You have experience in radar image processing\n\n‚Ä¢ You have used the Java libraries of the ESA SNAP toolboxes\n\n‚Ä¢ You are familiar with orchestration and in particular Astronomer\n\n‚Ä¢ You are familiar with building ETL and data pipelines, using asynchronous framework is a plus\n\n‚Ä¢ You are comfortable with SQL and NoSQL databases for OLTP and OLAP usages\n\n‚Ä¢ You value code simplicity, performance and details\n\n‚Ä¢ You have demonstrated that you can learn and adapt quickly\n\n‚Ä¢ You are fluent in English and have experience working in an international environment\n\nWhat you will receive from Kpler:\n\n‚Ä¢ You‚Äôll get to work in a truly global work environment, with offices in 7 countries (UK, France, Belgium, Austria, US, Dubai and Singapore), we come from more than 50 countries and speak more than 20 languages\n\n‚Ä¢ We have truly embraced the new age of workplace flexibility where you can chose to work hybrid or onsite\n\n‚Ä¢ We offer competitive compensation & benefits including work from home allowance, medical and life insurance, training and development allowance, paid volunteer work and more!\n\n‚Ä¢ You will receive a company laptop and you can choose between Windows, Mac, or Linux\n\n‚Ä¢ Global maternity (extended leave), parental, festival and compassionate leave policies aligned to the contemporary needs of the family, and individual choices\n\nAnd you REALLY want to join our Engineering team because:\n\n‚Ä¢ Interesting product & challenging technical problems to solve: our market is very specialized and quite complex! This means we build real algos and there‚Äôs some serious software engineering at work here!\n\n‚Ä¢ Our growth is exponential: we build new features and products everyday! We frequently tackle brand-new business areas which means there‚Äôs always everything to build and always an interesting problem to sink your teeth into!\n\n‚Ä¢ We are at the cross-road of Software Engineering, Commodity, Energy and Finance. This creates an interesting cultural mix: We value the flexibility, collaboration and employee-centric approach that the Tech culture brings but we also value the pragmatism, hard-working and intellectual excellence expectation that often runs in the Finance and Energy worlds\n\n‚Ä¢ Team of 85+ talented Engineers working with the most modern tech stack\n\nRecruitment Process:\n\nRecruiter Screen: 30 minute video interview with a recruiter from hiring team\n\nHiring Manager Interview: 45 minute exchange with one of our Engineering Managers from the dedicated team\n\nTake Home Technical Exercise\n\nMeet the Team: An opportunity to see the fit and get to know your potential future team!\n\nOur values\n\n‚Ä¢ Be humble ‚Äì We always place the interests of the collective before your own.\n\n‚Ä¢ Respect and care for others ‚Äì We make every person feel comfortable in their own beliefs, decisions, and perspectives.\n\n‚Ä¢ Take responsibility ‚Äì We take ownership of our actions.\n\n‚Ä¢ Act with integrity -We are honest and transparent in all your dealings.\n\n‚Ä¢ Be bold ‚Äì We push the boundaries in order to improve and grow.\n\nYou‚Äôll get to work in a truly global environment, with more than 30 nationalities speaking more than 15 languages.\n\nOur People Pledge\n\nDon‚Äôt meet every single requirement? Research shows that women and people of color are less likely than others to apply if they feel like they don‚Äôt match 100% of the job requirements. Don‚Äôt let the confidence gap stand in your way, we‚Äôd love to hear from you! We understand that experience comes in many different forms and are dedicated to adding new perspectives to the team.\n\nKpler is committed to providing a fair, inclusive and diverse work-environment. We believe that different perspectives lead to better ideas, and better ideas allow us to better understand the needs and interests of our diverse, global community. We welcome people of different backgrounds, experiences, abilities and perspectives and are an equal opportunity employer.\n\nBy applying, I confirm that I have read and accept the Staff Privacy Notice']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&q=Kpler&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIlws', 'text': 'See web results for Kpler'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjd_kassA7cFtXgJ351grmcGvSmihTHHciYyolctc&s,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJTZW5pb3IvU3RhZmYgRGF0YSBFbmdpbmVlciBAIEtwbGVyIGluIEF1c3RyaWEiLCJodGlkb2NpZCI6IkI2QnU1QzNkZWd3QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNTMlJ4UVc5RVJsUkRMVWhwVURFMk1rUjBaV3hrYm5KU01qVjBMVUppUW1SZlJWaEtRVTVRV1ROaGFuZDFPVVJWUTJ0clVUZHhXSEUyTmtSWlpuWmxjRTUxZFZCeGFUWklRV2xxVjJselpsVmZNM3BJTUhWVllWOUhjbWRMZEZRelZVMHlhSE5QYmxSTFkxcGlhREZ5ZWt4aFpFTlhMV0V6UjNaaFZFa3hURlI2WWtscFJFSTBRWFUyUkRoRWRIcERibWxNYVc5RWJGcHhWVXRNZEhCdVNVeFBOWGhUVTE5RE5rMUZRelpCZDNCekVoZEdjbEJJV2t4bWFVYzRjVmwzWW10UU1qWmhhV3RCY3hvaVFVeEZVemwxVFhCQ1ZXZEtWSEUzWm5aclgxVXRZVEZJVVZkeFlrUjFYME5zZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18zIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFN0YXJ0dXBjYXJlZXJzIiwibGluayI6Imh0dHBzOi8vc3RhcnR1cGNhcmVlcnMuZXUvam9iL3Nlbmlvci1zdGFmZi1kYXRhLWVuZ2luZWVyLWtwbGVyLWluLWF1c3RyaWEvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer*,KTM Group North America,"  Munderfing, Austria   ",via Talent.com,"The opportunities are endless when you are fearless

Driven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion.

To this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees.

That‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience.

With or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!

To ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE, we are also stepping on the gas in the area of IT and data integration.

Are you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you?

Then this is the right job for you.

THE TASKS... AWAITING YOU
‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).
‚Ä¢ provision of data using different technologies / paradigms (ETL, web services such as REST / SOAP / ODATA, Stream processing / Message Broker) in coordination with those responsible for source and target systems
‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)
‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)
‚Ä¢ coordination and cooperation with external service providers
‚Ä¢ orchestration and monitoring of automated process steps

HOW YOU CAN INSPIRE US
‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience
‚Ä¢ very good knowledge of relational database systems
‚Ä¢ mastery of at least one scripting or programming language
‚Ä¢ experience with web services (REST / SOAP / ODATA)
‚Ä¢ experience with data integration and / or orchestration tools would be an advantage
‚Ä¢ very good written and spoken English
‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation
‚Ä¢ independent and self-reliant working style as well as absolute reliability

WHAT YOU CAN LOOK FORWARD TO
‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer
‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu
‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit

Benefits

Flexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation. Professional

development You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System.

From seminars to in-house training, we'll get you ready for the front row. KTM MasterCard Gold Free Mastercard Gold in KTM Style.

Travel insurance coverage for the whole family included. Employee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together. Special rates

for employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us. Pension

scheme Each year, the company voluntarily pays additional life insurance for its employees","[{'items': [""The opportunities are endless when you are fearless\n\nDriven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion.\n\nTo this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees.\n\nThat‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience.\n\nWith or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!\n\nTo ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE, we are also stepping on the gas in the area of IT and data integration.\n\nAre you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you?\n\nThen this is the right job for you.\n\nTHE TASKS... AWAITING YOU\n‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).\n‚Ä¢ provision of data using different technologies / paradigms (ETL, web services such as REST / SOAP / ODATA, Stream processing / Message Broker) in coordination with those responsible for source and target systems\n‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)\n‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)\n‚Ä¢ coordination and cooperation with external service providers\n‚Ä¢ orchestration and monitoring of automated process steps\n\nHOW YOU CAN INSPIRE US\n‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience\n‚Ä¢ very good knowledge of relational database systems\n‚Ä¢ mastery of at least one scripting or programming language\n‚Ä¢ experience with web services (REST / SOAP / ODATA)\n‚Ä¢ experience with data integration and / or orchestration tools would be an advantage\n‚Ä¢ very good written and spoken English\n‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation\n‚Ä¢ independent and self-reliant working style as well as absolute reliability\n\nWHAT YOU CAN LOOK FORWARD TO\n‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer\n‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu\n‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit\n\nBenefits\n\nFlexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation. Professional\n\ndevelopment You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System.\n\nFrom seminars to in-house training, we'll get you ready for the front row. KTM MasterCard Gold Free Mastercard Gold in KTM Style.\n\nTravel insurance coverage for the whole family included. Employee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together. Special rates\n\nfor employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us. Pension\n\nscheme Each year, the company voluntarily pays additional life insurance for its employees""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&q=KTM+Group+North+America&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIyAs', 'text': 'See web results for KTM Group North America'}]",,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyKiIsImh0aWRvY2lkIjoiU19QdExad0xpdmdBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1NrMDBNM05UUVZkTmNtVmZWekp4YVVSWFRsUmZhRE5MYjNSbVoxaDFRVzgyVjBVd1RrOTJka1ZpUzFkWGFtOXJSVTFWUVVsS2FtOVZVVVYwTFZNeVgwSlRaamxZWDBaUWMxTlpVMXA1WVV4WFQyczBORWxuZVMwM2RYRndkR2wwZFRWaWFHOVRTVkJSVEZkd1N6ZDNZM0JmTW1wNFJqQnNWakpRV1RVeFh6WkdlVGgxTVV4TlRXTlplV3BLTXpWQlUyMWpTVTl0V1ZWR1NqSTFUVU5oTXpONlpuazRWM0I2ZFZkVFVqVmFkMFpuRWhkR2NsQklXa3htYVVjNGNWbDNZbXRRTWpaaGFXdEJjeG9pUVV4RlV6bDFUMmROZWpkTlFYazNXbWhGUm5ORWVtaFVVbk5zTTNsMWNHMHRadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gVGFsZW50LmNvbSIsImxpbmsiOiJodHRwczovL2F0LnRhbGVudC5jb20vdmlldz9pZD01NjJjNmMxOWM3OTZcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19
Data Engineer (f/m/d),SWAROVSKI KG,"  Wattens, Austria   ",via HTL Jenbach,"DataEngineer(f/m/d)

Wattens, Austria

At Swarovski, where innovation meets inspiration, our people desire to explore, experience and create. As a DataEngineer(F/m/d)you will get a chance to work in a rewarding role within a diverse team that is pushing boundaries. Be part of a truly iconicglobal brand, learn and grow with us. We‚Äôre bold and inventive, revealing astonishing things like no one lse can. A world ofwonder awaits you.

About the job

Designing and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house

Collaborating with cross-functional teams to understand data requirements and to translate them into technical Solutions

Optimizing and fine-tuning data pipelines for efficiency, performance, and scalability

Implementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness

Working closely with data... scientists and analysts to provide them with the necessary data and tools for analysis and reporting

About you

We are looking for a unique and amazing talent, who brings along the following:

Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Engineering, or a related field

5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems

Strong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub/Sub

Solid programming skills in languages like Python, SQL

Whatwe offer

Voluntary Leave

Product discounts etc.

Ready to create a world of wonder? Find out more and apply at swarovski.com/careers

Masters of Light Since 1895

Swarovskicreatesbeautifulcrystal-basedproductsofimpeccablequalityandcraftsmanshipthatbringjoyandcelebrateindividuality.

Foundedin1895inAustria,thecompanydesigns,manufacturesandsellstheworld‚Äôsfinestcrystal,gemstones,SwarovskiCreatedDiamondsandzirconia,jewelry,andaccessories,aswellascrystalobjectsandhomeaccessories.TogetherwithitssistercompaniesSwarovskiOptik(opticaldevices)andTyrolit(abrasives),SwarovskiCrystalBusinessformstheSwarovskiGroup.

Swarovskiisanequalopportunityemployer.Wegiveourpeoplethegutstocelebrateindividualityandprideourselvesoncreatingaworkplacewherepeoplefeelinvolved,respected,valued,connected,andheard","[{'items': ['DataEngineer(f/m/d)\n\nWattens, Austria\n\nAt Swarovski, where innovation meets inspiration, our people desire to explore, experience and create. As a DataEngineer(F/m/d)you will get a chance to work in a rewarding role within a diverse team that is pushing boundaries. Be part of a truly iconicglobal brand, learn and grow with us. We‚Äôre bold and inventive, revealing astonishing things like no one lse can. A world ofwonder awaits you.\n\nAbout the job\n\nDesigning and building scalable and robust data pipelines, spanning from the landing zone in GCP to the consumption layer, to transform and load data from the landing zone into our data lake house\n\nCollaborating with cross-functional teams to understand data requirements and to translate them into technical Solutions\n\nOptimizing and fine-tuning data pipelines for efficiency, performance, and scalability\n\nImplementing data quality checks and monitoring processes to ensure data accuracy, consistency, and completeness\n\nWorking closely with data... scientists and analysts to provide them with the necessary data and tools for analysis and reporting\n\nAbout you\n\nWe are looking for a unique and amazing talent, who brings along the following:\n\nBachelor‚Äôs or Master‚Äôs degree in Computer Science, Engineering, or a related field\n\n5 years of hands-on experience in data engineering, building and maintaining data pipelines and systems\n\nStrong proficiency in GCP (Google Cloud Platform), including services such as BigQuery, Dataflow, Cloud Storage, and Pub/Sub\n\nSolid programming skills in languages like Python, SQL\n\nWhatwe offer\n\nVoluntary Leave\n\nProduct discounts etc.\n\nReady to create a world of wonder? Find out more and apply at swarovski.com/careers\n\nMasters of Light Since 1895\n\nSwarovskicreatesbeautifulcrystal-basedproductsofimpeccablequalityandcraftsmanshipthatbringjoyandcelebrateindividuality.\n\nFoundedin1895inAustria,thecompanydesigns,manufacturesandsellstheworld‚Äôsfinestcrystal,gemstones,SwarovskiCreatedDiamondsandzirconia,jewelry,andaccessories,aswellascrystalobjectsandhomeaccessories.TogetherwithitssistercompaniesSwarovskiOptik(opticaldevices)andTyrolit(abrasives),SwarovskiCrystalBusinessformstheSwarovskiGroup.\n\nSwarovskiisanequalopportunityemployer.Wegiveourpeoplethegutstocelebrateindividualityandprideourselvesoncreatingaworkplacewherepeoplefeelinvolved,respected,valued,connected,andheard']}]","[{'link': 'http://www.swarovski.com/', 'text': 'swarovski.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&q=SWAROVSKI+KG&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAII-ws', 'text': 'See web results for SWAROVSKI KG'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSloOhF5A4ufd_REbovjD2o7WWjjynjkNlW6wTZf-mJot8Rgowc-RTS-4g&s,"['10 days ago', 'Full-time']","{'posted_at': '10 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChmL20vZCkiLCJodGlkb2NpZCI6Ii14THVTWFNhckJVQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVUxck1teHNURFJCVEc1SVltOXBTMGN6UnpGaVMzVXdhbmhQY1RZNFNrc3lWSG80WDNaclRsaFpNMnBpUkVkQ1ZETnVTMHBrWDA1SVlrTjVjekZVUmxWSWNFNWpkVWRTZVhaUWNVaDFURTF0ZDNoVVpWVlhjMWczTTJkRGNqSmlkMlp4ZFY5QlYxVTRVSHBKVFVSblEyVm5iRkpFTjE5UE16SmpWblEzVlZSbGVFcEVkMFowUnpKRE5sSnpja3h4YzI5M2VGVlNTVGxTTjB4U2JEVnZORmRNWVMxQ2MzTndjbGRMTmpaMVFXbzFTaTFGWkdaTkVoZEdjbEJJV2t4bWFVYzRjVmwzWW10UU1qWmhhV3RCY3hvaVFVeEZVemwxVG5kV2JHZGZPRlJKUVRGUVRVVmxZM0V0YTFoclFqbG5OSE55VVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEhUTCBKZW5iYWNoIiwibGluayI6Imh0dHBzOi8vaHRsLWplbmJhY2guYXQvam9iL2RhdGEtZW5naW5lZXItZi1tLWQvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
Data Engineer  (gn*),T√úV AUSTRIA,"  Klagenfurt am W√∂rthersee, Austria   ",via Jobrapido.com,"3.000 People. 30 Countries. #LivingTheFuture.

The independent T√úV AUSTRIA Group operates worldwide with over 3,000 employees in more than 30 countries. We, the leading testing, inspection and certification company, offer sustainable and flexible solutions through technical safety. For the T√úV AUSTRIA Group we are looking for a

T√úV AUSTRIA Data Intelligence is a data science consulting company of the T√úV Austria Group. We develop customized data-driven
AI solutions and support our customers in digitization projects.
Our focus is on the process industry and energy industry.

You are interested in data-driven automation and want to further expand your technology stack in practical use cases?
We are looking for a motivated Data Engineer (gn*) to start as soon as possible. With us you can gain practical experience and actively participate in the development of AI solutions.
If you want to use your IT affinity to drive the digital transformation in European industry together with us... apply as Data Engieer:

Data Engineer (gn*) (Jn. 215489)

Vienna or Klagenfurt

Job Description:
‚Ä¢ In your future job you will strengthen the T√úV AUSTRIA Data Intelligence Team and work together with experienced Data Scientists and Data Engineers.
‚Ä¢ You provide technical consulting services to customers, designing and implementing data engineering solutions with a special focus on ETL processes, AI operations and monitoring.
‚Ä¢ You support TUV teams in their TIC business by automatically processing technical documentation to extract relevant data for the inspection business.
‚Ä¢ You build cloud and on premise platforms for data streaming and online asset condition, data and ML model performance monitoring.
‚Ä¢ You quickly adapt to changing requirements and new technologies in accordance with customer requirements.

Your qualifications:
‚Ä¢ We recruit from all levels of experience (Junior to Senior).
‚Ä¢ You bring relevant work experience or have completed training at university, technical college (or comparable in the relevant departments)
‚Ä¢ You have experience working with data storage solutions (SQL, NoSQL, Blob storages, etc.)
‚Ä¢ You have profound knowledge of Python and an understanding of programming paradigms and design patterns; experience with third party libraries/applications integration.
‚Ä¢ You have an agile, solution oriented mindset and are eager to adapt to new technologies.

Nice to have:
‚Ä¢ Ideally, you have worked with containerization (Docker) and cloud (Azure or AWS) solutions, DevOps solutions and Infrastructure as code.
‚Ä¢ Monitoring and resilient logging designs are part of our daily business.
‚Ä¢ Experience with data warehouse or data lake solutions.
‚Ä¢ Familiarity with the principles of secure software development, Continuous Integration/Continuous Deployment (CI/CD), comprehensive testing strategies, and version control systems (GIT).
‚Ä¢ You will work with Data Scientists and AI solution development teams. AI know-how is a welcome addition to your technical foundation.
‚Ä¢ We rely on JavaScript/TypeScript for frontend implementation and appreciate experience with those programming languages.
‚Ä¢ Experience with processing sensor data and experience with connection of hardware devices and sensors is a valuable bonus.
‚Ä¢ Experience with SAP and the ability to build interfaces for data ingestion is frequently necessary.

We offer:

Training & Development
Company doctor
Laptop
Benefits
Work Life Balance
Home office
‚Ä¢ The collective bargain for this position is between EUR 2.854,- and EUR 4.761,- depending on your qualification and experience. We offer a fair overpayment in line with the market.
‚Ä¢ Flexible working environment with free time management and home office
‚Ä¢ A strong focus on your individual further training
‚Ä¢ Challenging and, above all, varied activities in a young and dynamic team with a family environment

You are interested? We're looking forward to your online application to Karin Schumeth.
online application
Back to career portal
‚Ä¢ The sign ""gn"" stands for gender neutral. We are open to all people and address all genders equally","[{'items': ['3.000 People. 30 Countries. #LivingTheFuture.\n\nThe independent T√úV AUSTRIA Group operates worldwide with over 3,000 employees in more than 30 countries. We, the leading testing, inspection and certification company, offer sustainable and flexible solutions through technical safety. For the T√úV AUSTRIA Group we are looking for a\n\nT√úV AUSTRIA Data Intelligence is a data science consulting company of the T√úV Austria Group. We develop customized data-driven\nAI solutions and support our customers in digitization projects.\nOur focus is on the process industry and energy industry.\n\nYou are interested in data-driven automation and want to further expand your technology stack in practical use cases?\nWe are looking for a motivated Data Engineer (gn*) to start as soon as possible. With us you can gain practical experience and actively participate in the development of AI solutions.\nIf you want to use your IT affinity to drive the digital transformation in European industry together with us... apply as Data Engieer:\n\nData Engineer (gn*) (Jn. 215489)\n\nVienna or Klagenfurt\n\nJob Description:\n‚Ä¢ In your future job you will strengthen the T√úV AUSTRIA Data Intelligence Team and work together with experienced Data Scientists and Data Engineers.\n‚Ä¢ You provide technical consulting services to customers, designing and implementing data engineering solutions with a special focus on ETL processes, AI operations and monitoring.\n‚Ä¢ You support TUV teams in their TIC business by automatically processing technical documentation to extract relevant data for the inspection business.\n‚Ä¢ You build cloud and on premise platforms for data streaming and online asset condition, data and ML model performance monitoring.\n‚Ä¢ You quickly adapt to changing requirements and new technologies in accordance with customer requirements.\n\nYour qualifications:\n‚Ä¢ We recruit from all levels of experience (Junior to Senior).\n‚Ä¢ You bring relevant work experience or have completed training at university, technical college (or comparable in the relevant departments)\n‚Ä¢ You have experience working with data storage solutions (SQL, NoSQL, Blob storages, etc.)\n‚Ä¢ You have profound knowledge of Python and an understanding of programming paradigms and design patterns; experience with third party libraries/applications integration.\n‚Ä¢ You have an agile, solution oriented mindset and are eager to adapt to new technologies.\n\nNice to have:\n‚Ä¢ Ideally, you have worked with containerization (Docker) and cloud (Azure or AWS) solutions, DevOps solutions and Infrastructure as code.\n‚Ä¢ Monitoring and resilient logging designs are part of our daily business.\n‚Ä¢ Experience with data warehouse or data lake solutions.\n‚Ä¢ Familiarity with the principles of secure software development, Continuous Integration/Continuous Deployment (CI/CD), comprehensive testing strategies, and version control systems (GIT).\n‚Ä¢ You will work with Data Scientists and AI solution development teams. AI know-how is a welcome addition to your technical foundation.\n‚Ä¢ We rely on JavaScript/TypeScript for frontend implementation and appreciate experience with those programming languages.\n‚Ä¢ Experience with processing sensor data and experience with connection of hardware devices and sensors is a valuable bonus.\n‚Ä¢ Experience with SAP and the ability to build interfaces for data ingestion is frequently necessary.\n\nWe offer:\n\nTraining & Development\nCompany doctor\nLaptop\nBenefits\nWork Life Balance\nHome office\n‚Ä¢ The collective bargain for this position is between EUR 2.854,- and EUR 4.761,- depending on your qualification and experience. We offer a fair overpayment in line with the market.\n‚Ä¢ Flexible working environment with free time management and home office\n‚Ä¢ A strong focus on your individual further training\n‚Ä¢ Challenging and, above all, varied activities in a young and dynamic team with a family environment\n\nYou are interested? We\'re looking forward to your online application to Karin Schumeth.\nonline application\nBack to career portal\n‚Ä¢ The sign ""gn"" stands for gender neutral. We are open to all people and address all genders equally']}]","[{'link': 'http://www.tuv.at/', 'text': 'tuv.at'}, {'link': 'https://www.google.com/search?sca_esv=552448117&q=T%C3%9CV+AUSTRIA&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIrww', 'text': 'See web results for T√úV AUSTRIA'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQewRVCKInOl9aQUV8aJTIXRmEcR4ZZI7veqa2d&s=0,"['7 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '7 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyICAoZ24qKSIsImh0aWRvY2lkIjoiQ1c4a3NSek9xNThBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTFyTW14c1MwRjJjWGRYTlZWS1JEZ3lhWE5UVFhjM2IweHdhbEpGY0RkV2NrNHlOWGcwTms1MlRWZzFhVXBVTWxaYU5HcEZMVlpsYlRsWFEyczJZelJKUkdOdmIzUnFObWRxTlcwMlVVTjVZMFJRY0ZCdFFrNWFlWEZsVkc4ME1VcDZSMDVhUWtwWVVGUkpMV1J3ZFZCTWVEWllkVXhoUkdoR1EydHJTVFE0ZEhJd09XNUhaemhKT1dGT2RtVlZWR3hQYjBrMFpXUTNZMmRqUTBab2JHTkplSGd3V0Y5UVRFdzJaSEoxU3poSmJqVmhia1ZZWDFRNFgyeFJhMU0yTVV0WmJESjVZWGc0WkdOd0VoZEdjbEJJV2t4bWFVYzRjVmwzWW10UU1qWmhhV3RCY3hvaVFVeEZVemwxVUdodWRXdEZhekppZGkwNWREQlBhelJ1ZUhSblNFdHlTVzlDVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY183IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYnJhcGlkby5jb20iLCJsaW5rIjoiaHR0cHM6Ly9hdC5qb2JyYXBpZG8uY29tL2pvYnByZXZpZXcvMzkzNzE3MDg/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Machine Learning Engineer (m/f/d),Machine Learning Reply GmbH,"  Graz, Austria   ",via DataYoshi,"Job Description

At

Machine Learning Reply Austria we strive to work on leading-edge data science projects with our clients for which we are seeking Cloud Engineer consultants with a strong technical background.

Machine Learning Reply, with its sister companies in Italy and Germany and over 8500 employees at Reply globally, is a fast-growing consultancy focused on solving problems with Data Science, Cloud technologies and the right organizational frameworks as their backbone. We are a tight knit, laid back, but seriously motivated unit that aims to be involved at conferences and in community of practice with our tech partners.

We offer tailor-made end-to-end cloud-based solutions in the Data Science area that cover the entire project life cycle - from initial strategy consulting to data architecture and infrastructure issues to data processing and deployment of production-ready algorithms.

We have a vast expertise in every step of the Data Science implementation spectrum in all... key industries of the German HDAX-companies. With focus on open source and cloud technologies we enable our customers to successfully introduce and implement new data-driven solutions and to optimize already existing processes and products while simultaneously adapting to cloud technologies.

Tasks

Use your cloud know-how and work closely with our customers to find out what the perfect (cloud) technology is for them!
‚Ä¢ Through your knowledge you are able to design innovative, technical approaches for cloud solution architectures
‚Ä¢ Your designed cloud architectures (based on AWS, Microsoft Azure or Google Cloud) will be implemented by you also always considering DevOps / MLOps
‚Ä¢ You will not be alone and will work closely with colleagues from Data Science or Data Engineering to jointly develop data-intensive applicationssuch as data warehouses, data lakes and/or data platforms
‚Ä¢ You enjoy brainstorming, conceptualization and final implementation. You therefore like to accompany the complete LifeCycle by creating specifications, code and presentations for your solutions.
‚Ä¢ As part of the Reply network, you join communities of practice, participate in hackathons and use all available learning resources

What we offer you:
‚Ä¢ We offer you for this position according to the collective agreement for employees in data processing and information technology a gross monthly salary of at least EUR 3215 (Consultant) or EUR 4286 (Senior Consultant) depending on your previous experience.
‚Ä¢ Access to work on projects across industries (large and mid-market companies in Banking, Insurance, Automotive, Retail, etc.)
‚Ä¢ Very active group social program - including conference funding, team building, group events, Reply Exchange
‚Ä¢ Recognition for Innovation to foster your personal development
‚Ä¢ Work in an open, flat environment, within a broad Reply knowledge sharing network (more than 90 autonomous Reply groups across 8 countries)
‚Ä¢ Office space in downtown Vienna with access to Stammstrecke
‚Ä¢ Training and certification encouraged
‚Ä¢ Home-office contracts
‚Ä¢ State of the art work equipment
‚Ä¢ Award winning office spaces for an excellent work experience
‚Ä¢ Public transport ticket within Vienna
‚Ä¢ Gym-membership subsidy for a gym of your choice
‚Ä¢ Flexible work environment between client, Reply office and remote work

Requirements

A university degree in (business) informatics, mathematics, statistics (or comparable) and at least 3 years of professional experience in industry or consulting
‚Ä¢ Experience in the development of data-intensive applications such as data warehouses, data lakes and / or data platforms
‚Ä¢ You have knowledge in code development using Java/Scala or Python
‚Ä¢ You are familiar with relational databases as well as ideally NoSQL databases (e.g. Oracle, Aurora, Mongodb, Cassandra)
‚Ä¢ Deep understanding in the development of Machine Learning applications as well as solutions based on Big Data technologies such as Hadoop or Spark or their cloud-based equivalents
‚Ä¢ Very good English and good German skills as well as willingness to travel nationally","[{'items': ['Job Description\n\nAt\n\nMachine Learning Reply Austria we strive to work on leading-edge data science projects with our clients for which we are seeking Cloud Engineer consultants with a strong technical background.\n\nMachine Learning Reply, with its sister companies in Italy and Germany and over 8500 employees at Reply globally, is a fast-growing consultancy focused on solving problems with Data Science, Cloud technologies and the right organizational frameworks as their backbone. We are a tight knit, laid back, but seriously motivated unit that aims to be involved at conferences and in community of practice with our tech partners.\n\nWe offer tailor-made end-to-end cloud-based solutions in the Data Science area that cover the entire project life cycle - from initial strategy consulting to data architecture and infrastructure issues to data processing and deployment of production-ready algorithms.\n\nWe have a vast expertise in every step of the Data Science implementation spectrum in all... key industries of the German HDAX-companies. With focus on open source and cloud technologies we enable our customers to successfully introduce and implement new data-driven solutions and to optimize already existing processes and products while simultaneously adapting to cloud technologies.\n\nTasks\n\nUse your cloud know-how and work closely with our customers to find out what the perfect (cloud) technology is for them!\n‚Ä¢ Through your knowledge you are able to design innovative, technical approaches for cloud solution architectures\n‚Ä¢ Your designed cloud architectures (based on AWS, Microsoft Azure or Google Cloud) will be implemented by you also always considering DevOps / MLOps\n‚Ä¢ You will not be alone and will work closely with colleagues from Data Science or Data Engineering to jointly develop data-intensive applicationssuch as data warehouses, data lakes and/or data platforms\n‚Ä¢ You enjoy brainstorming, conceptualization and final implementation. You therefore like to accompany the complete LifeCycle by creating specifications, code and presentations for your solutions.\n‚Ä¢ As part of the Reply network, you join communities of practice, participate in hackathons and use all available learning resources\n\nWhat we offer you:\n‚Ä¢ We offer you for this position according to the collective agreement for employees in data processing and information technology a gross monthly salary of at least EUR 3215 (Consultant) or EUR 4286 (Senior Consultant) depending on your previous experience.\n‚Ä¢ Access to work on projects across industries (large and mid-market companies in Banking, Insurance, Automotive, Retail, etc.)\n‚Ä¢ Very active group social program - including conference funding, team building, group events, Reply Exchange\n‚Ä¢ Recognition for Innovation to foster your personal development\n‚Ä¢ Work in an open, flat environment, within a broad Reply knowledge sharing network (more than 90 autonomous Reply groups across 8 countries)\n‚Ä¢ Office space in downtown Vienna with access to Stammstrecke\n‚Ä¢ Training and certification encouraged\n‚Ä¢ Home-office contracts\n‚Ä¢ State of the art work equipment\n‚Ä¢ Award winning office spaces for an excellent work experience\n‚Ä¢ Public transport ticket within Vienna\n‚Ä¢ Gym-membership subsidy for a gym of your choice\n‚Ä¢ Flexible work environment between client, Reply office and remote work\n\nRequirements\n\nA university degree in (business) informatics, mathematics, statistics (or comparable) and at least 3 years of professional experience in industry or consulting\n‚Ä¢ Experience in the development of data-intensive applications such as data warehouses, data lakes and / or data platforms\n‚Ä¢ You have knowledge in code development using Java/Scala or Python\n‚Ä¢ You are familiar with relational databases as well as ideally NoSQL databases (e.g. Oracle, Aurora, Mongodb, Cassandra)\n‚Ä¢ Deep understanding in the development of Machine Learning applications as well as solutions based on Big Data technologies such as Hadoop or Spark or their cloud-based equivalents\n‚Ä¢ Very good English and good German skills as well as willingness to travel nationally']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&q=Machine+Learning+Reply+GmbH&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAII4Qw', 'text': 'See web results for Machine Learning Reply GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQwiwqpYYLEoB60tYzup9YBRHSlk_31XbyFz23kAik&s,"['25 days ago', 'Full-time']","{'posted_at': '25 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6IjRhWF8zdlA4aExNQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTWFZaZFMxMFFVaHNSakppZEVKaU9XNVJOeTB0VUVaWkxXUTFaMkp3UlRoeU1WbDRWVTVpYlhobFJrNWpXbXMwTkV4eVQyTTBjRVJPTUZkeVpUSk9XR1J4UW1kWGQwMUpSRU50VDJ0RGJtUkZORGRtV2s5dGVHSnpObkZVZDNOVE5qVlZPSE5wU21OcGNtOHRUSEoyZGxVMWJXSnhVazlSY0RSQ2QxVk1PRTE0T1cxYU9XOUZSblEyU1VWamMzbFROMWxmUTNGUlZGa3RTREp6VjB3MFFuZ3RaSHA1ZEhKTmNXWjVTMDl1T1c1cE5ISkdXa00zYVdaTmRHVk9SbGxsWWpKT1ZITkJFaGRHY2xCSVdreG1hVWM0Y1ZsM1ltdFFNalpoYVd0QmN4b2lRVXhGVXpsMVQwdEJaekZUTFdoVlkzazFiMjl0WVdseVUzRlZlRlJ0UmpsQlFRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBEYXRhWW9zaGkiLCJsaW5rIjoiaHR0cHM6Ly93d3cuZGF0YXlvc2hpLmNvbS9vZmZlci80NzU0MDQvbWFjaGluZS1sZWFybmluZy1lbmdpbmVlci1tLWY/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (m/f/x),Ubiq, Anywhere ,via Indeed,"Full-time in Vienna, Austria or remote within a similar timezone (+/- 2 hours!!)

With urbanization and climate change the defining features of our time, mobility is in a significant state of flux, with innovative solutions needed to address this new reality. At Ubiq we believe it is only through a data-driven approach that these solutions can be both sustainable and profitable. We are confident that, with our product and services, we can play a vital role in shaping the future of mobility.

With a growing number of customers around the world, and an exciting data-driven product that is developing continuously, we are looking for a Data Engineer to join our team.

Tasks
‚Ä¢ Work in a great team of data scientists, developers, GIS experts and product owners to bring our data workflows to the next level.
‚Ä¢ Identify data sources and incorporate them into the data pipelines.
‚Ä¢ Come up with new approaches for improving our service and measuring its impact.
‚Ä¢ Drive automation, data source... integration in close cooperation with data scientists and GIS experts.
‚Ä¢ Recognize inefficiencies, propose and implement solutions.

Requirements

You enjoy working in a team but are not afraid to work independently. You love to come up with new ideas, try them & see them develop. You think further than the status quo. The more skills you can cover from this list, the better:
‚Ä¢ You have experience using ETL tools, building data pipelines based on cloud solutions.
‚Ä¢ You have worked with PostgreSQL, R or MongoDB
‚Ä¢ You‚Äôre motivated to evaluate and implement new approaches, and, hence, whatever tools and knowledge that you bring with you like Python, ML frameworks or general understanding of ML are appreciated
‚Ä¢ Knowledge of GIS, Data mining, even model building and validation is a plus
‚Ä¢ You are based in Vienna, Austria or in a country in a timezone +/- 2 hours of CET

Benefits
‚Ä¢ The opportunity to a shape a fast-growing start-up & take a leading role in it
‚Ä¢ Working with international clients in the mobility field
‚Ä¢ A fantastic team with lots of start-up spirit and English as the working language
‚Ä¢ Flexible working hours - healthy balance between office & remote work
‚Ä¢ Continuous training & learning support (events, training, courses, etc.)
‚Ä¢ Top equipment, incl. individual equipment budget for special requests, company phone, company e-scooters, etc.
‚Ä¢ Free fruits, snacks and drinks
‚Ä¢ Regular team events
‚Ä¢ Competitive salary in line with your experience & qualifications

Please send your documents in English, CV & description of why you are the right person for the role, incl. your earliest start date & salary expectation. We look forward to hearing from you","[{'items': ['Full-time in Vienna, Austria or remote within a similar timezone (+/- 2 hours!!)\n\nWith urbanization and climate change the defining features of our time, mobility is in a significant state of flux, with innovative solutions needed to address this new reality. At Ubiq we believe it is only through a data-driven approach that these solutions can be both sustainable and profitable. We are confident that, with our product and services, we can play a vital role in shaping the future of mobility.\n\nWith a growing number of customers around the world, and an exciting data-driven product that is developing continuously, we are looking for a Data Engineer to join our team.\n\nTasks\n‚Ä¢ Work in a great team of data scientists, developers, GIS experts and product owners to bring our data workflows to the next level.\n‚Ä¢ Identify data sources and incorporate them into the data pipelines.\n‚Ä¢ Come up with new approaches for improving our service and measuring its impact.\n‚Ä¢ Drive automation, data source... integration in close cooperation with data scientists and GIS experts.\n‚Ä¢ Recognize inefficiencies, propose and implement solutions.\n\nRequirements\n\nYou enjoy working in a team but are not afraid to work independently. You love to come up with new ideas, try them & see them develop. You think further than the status quo. The more skills you can cover from this list, the better:\n‚Ä¢ You have experience using ETL tools, building data pipelines based on cloud solutions.\n‚Ä¢ You have worked with PostgreSQL, R or MongoDB\n‚Ä¢ You‚Äôre motivated to evaluate and implement new approaches, and, hence, whatever tools and knowledge that you bring with you like Python, ML frameworks or general understanding of ML are appreciated\n‚Ä¢ Knowledge of GIS, Data mining, even model building and validation is a plus\n‚Ä¢ You are based in Vienna, Austria or in a country in a timezone +/- 2 hours of CET\n\nBenefits\n‚Ä¢ The opportunity to a shape a fast-growing start-up & take a leading role in it\n‚Ä¢ Working with international clients in the mobility field\n‚Ä¢ A fantastic team with lots of start-up spirit and English as the working language\n‚Ä¢ Flexible working hours - healthy balance between office & remote work\n‚Ä¢ Continuous training & learning support (events, training, courses, etc.)\n‚Ä¢ Top equipment, incl. individual equipment budget for special requests, company phone, company e-scooters, etc.\n‚Ä¢ Free fruits, snacks and drinks\n‚Ä¢ Regular team events\n‚Ä¢ Competitive salary in line with your experience & qualifications\n\nPlease send your documents in English, CV & description of why you are the right person for the role, incl. your earliest start date & salary expectation. We look forward to hearing from you']}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&q=Ubiq&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIlA0', 'text': 'See web results for Ubiq'}]",,"['21 days ago', 'Work from home', 'Full-time', 'No degree mentioned']","{'posted_at': '21 days ago', 'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YveCkiLCJodGlkb2NpZCI6IjBiVzIxR1BmTmhNQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkV1SUJDcUlCUVUxck1teHNTMWczWTJoMVFuZzBkbkpHUzFWellVcDRVRzFCWVUxemRESmZPRzlvTldoelRVcENjMnQ2TFRoemVIbEhRMVkzYURKNVozbEZkbEZ4WVRSelpHOXhUV2xYY0U1YWVFeEZNMko2YUdwcUxXbGtXVkpQTURoTVRHNTBPWEJYY2xoS1VsTlpVV2wyTURSVk1GOWxkVXhNTjNGMVVGZFVaWFZzU1VWRFJrZ3lTSEp0ZEdzMFR6ZE9NVlZKU0hkbmNWZHROM1pSWmpCdk9XRjZkRWxuRWhkR2NsQklXa3htYVVjNGNWbDNZbXRRTWpaaGFXdEJjeG9pUVV4RlV6bDFVREpZV1hwSE56TkJTVEptZVRSM2REaHhPRlZKZEdSNWVtNUpkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEwIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIEluZGVlZCIsImxpbmsiOiJodHRwczovL2F0LmluZGVlZC5jb20vdmlld2pvYj9qaz04NzU4NWM5ZDY4ZDhmYTUyXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer,Amplemarket, Anywhere ,via Jobgether,"This a Full Remote job, the offer is available from: South America, Europe, Africa

This offer from ""Amplemarket"" has been enriched by Jobgether and got a 75.75% flex score.
What is Amplemarket all about?
Amplemarket's premise is that a lot of the playbooks used by B2B sales teams that worked 5 years ago don't cut it anymore.
In today's environment, sales teams need to have a tremendous amount of information about their prospects to decide when is the best moment and channel to reach out in the most relevant way. You can't do this with 5 different data/sales enablement point solutions that don't share the same data schema and barely communicate with each other. Amplemarket is the all-in-one compound solution that enables this.
Our AI-powered sales platform helps B2B companies generate more opportunities thanks to our advanced lead generation engine, hyper-personalized sequencing, omnichannel outreach, and AI-powered smart actions. We are backed by Y Combinator, and we are powering the... sales teams at some of the fastest-growing companies in the world like Deel, Moveworks, H1 and Vanta.

About the Engineering Team

The three co-founders have an engineering background (Jo√£o, Lu√≠s and Mica studied Physics & Computer Science in university) and deeply value the work that engineers are responsible for.

Our main goal is to build a sales platform that helps companies grow. Our product requires us to solve a myriad of difficult engineering problems very diverse in nature: from working on NLP models that can extract information from a thread of emails to scaling an Elasticsearch cluster holding terabytes of data.

We are deeply aware of the importance of our tool to our customers and look for people that share that vision.

We are seeking a highly motivated and experienced Data Engineer to join our growing startup as we build out our data stack.

In this role, you will be responsible for designing, building, and maintaining the infrastructure and processes necessary for the collection, storage, and analysis of large datasets. You will work closely with our development, product, and data teams to ensure that our data is accurate, reliable, and accessible to support business decision-making and drive product innovation.

You will:
‚Ä¢ Design and implement data pipelines for the collection, storage, and transformation of data from a variety of sources
‚Ä¢ Develop and maintain data models and schema to support data analysis and reporting
‚Ä¢ Write and maintain ETL jobs to extract, transform, and load data into our data warehouse
‚Ä¢ Collaborate with data scientists, data analysts, and other stakeholders to understand data requirements and develop solutions to support data-driven decision-making
‚Ä¢ Monitor and optimize data pipelines and processes to ensure data quality and performance

About you:
‚Ä¢ Bachelor's or Master's degree in Computer Science, Data Science, or a related field
‚Ä¢ 3+ years of experience as a Data Engineer or similar role
‚Ä¢ Strong programming skills in Python, Ruby, or a similar language
‚Ä¢ Experience with SQL and data modeling concepts
‚Ä¢ Experience with cloud-based data warehousing solutions such as Redshift, Snowflake, or BigQuery
‚Ä¢ Experience with ETL tools such as Airflow
‚Ä¢ Excellent problem-solving and communication skills

Some more about Amplemarket:
‚Ä¢ We are profitable and we just raised $12M in back-to-back seed and Series A funding
‚Ä¢ Backed by YCombinator
‚Ä¢ Strong technical founding team from MIT and IST (also founders of https://fermatslibrary.com/)
‚Ä¢ Fast growing startup with product market fit
‚Ä¢ Great team spirit

We offer:
‚Ä¢ Nice work environment
‚Ä¢ Competitive Salary
‚Ä¢ Health Insurance
‚Ä¢ Stock Options
‚Ä¢ Annual Company Trip in a secret location
‚Ä¢ and more

Amplemarket is committed to creating an inclusive employee experience for all.
Regardless of race, gender, religion, sexual orientation, age, disability, or if you're parenting the next generation of innovators, we firmly believe that what truly matters is how your skills, knowledge and personality fit our company. So bring your best professional version of yourself, and apply - we'd like to hear from you","[{'items': ['This a Full Remote job, the offer is available from: South America, Europe, Africa\n\nThis offer from ""Amplemarket"" has been enriched by Jobgether and got a 75.75% flex score.\nWhat is Amplemarket all about?\nAmplemarket\'s premise is that a lot of the playbooks used by B2B sales teams that worked 5 years ago don\'t cut it anymore.\nIn today\'s environment, sales teams need to have a tremendous amount of information about their prospects to decide when is the best moment and channel to reach out in the most relevant way. You can\'t do this with 5 different data/sales enablement point solutions that don\'t share the same data schema and barely communicate with each other. Amplemarket is the all-in-one compound solution that enables this.\nOur AI-powered sales platform helps B2B companies generate more opportunities thanks to our advanced lead generation engine, hyper-personalized sequencing, omnichannel outreach, and AI-powered smart actions. We are backed by Y Combinator, and we are powering the... sales teams at some of the fastest-growing companies in the world like Deel, Moveworks, H1 and Vanta.\n\nAbout the Engineering Team\n\nThe three co-founders have an engineering background (Jo√£o, Lu√≠s and Mica studied Physics & Computer Science in university) and deeply value the work that engineers are responsible for.\n\nOur main goal is to build a sales platform that helps companies grow. Our product requires us to solve a myriad of difficult engineering problems very diverse in nature: from working on NLP models that can extract information from a thread of emails to scaling an Elasticsearch cluster holding terabytes of data.\n\nWe are deeply aware of the importance of our tool to our customers and look for people that share that vision.\n\nWe are seeking a highly motivated and experienced Data Engineer to join our growing startup as we build out our data stack.\n\nIn this role, you will be responsible for designing, building, and maintaining the infrastructure and processes necessary for the collection, storage, and analysis of large datasets. You will work closely with our development, product, and data teams to ensure that our data is accurate, reliable, and accessible to support business decision-making and drive product innovation.\n\nYou will:\n‚Ä¢ Design and implement data pipelines for the collection, storage, and transformation of data from a variety of sources\n‚Ä¢ Develop and maintain data models and schema to support data analysis and reporting\n‚Ä¢ Write and maintain ETL jobs to extract, transform, and load data into our data warehouse\n‚Ä¢ Collaborate with data scientists, data analysts, and other stakeholders to understand data requirements and develop solutions to support data-driven decision-making\n‚Ä¢ Monitor and optimize data pipelines and processes to ensure data quality and performance\n\nAbout you:\n‚Ä¢ Bachelor\'s or Master\'s degree in Computer Science, Data Science, or a related field\n‚Ä¢ 3+ years of experience as a Data Engineer or similar role\n‚Ä¢ Strong programming skills in Python, Ruby, or a similar language\n‚Ä¢ Experience with SQL and data modeling concepts\n‚Ä¢ Experience with cloud-based data warehousing solutions such as Redshift, Snowflake, or BigQuery\n‚Ä¢ Experience with ETL tools such as Airflow\n‚Ä¢ Excellent problem-solving and communication skills\n\nSome more about Amplemarket:\n‚Ä¢ We are profitable and we just raised $12M in back-to-back seed and Series A funding\n‚Ä¢ Backed by YCombinator\n‚Ä¢ Strong technical founding team from MIT and IST (also founders of https://fermatslibrary.com/)\n‚Ä¢ Fast growing startup with product market fit\n‚Ä¢ Great team spirit\n\nWe offer:\n‚Ä¢ Nice work environment\n‚Ä¢ Competitive Salary\n‚Ä¢ Health Insurance\n‚Ä¢ Stock Options\n‚Ä¢ Annual Company Trip in a secret location\n‚Ä¢ and more\n\nAmplemarket is committed to creating an inclusive employee experience for all.\nRegardless of race, gender, religion, sexual orientation, age, disability, or if you\'re parenting the next generation of innovators, we firmly believe that what truly matters is how your skills, knowledge and personality fit our company. So bring your best professional version of yourself, and apply - we\'d like to hear from you']}]","[{'link': 'http://amplemarket.com/', 'text': 'amplemarket.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&q=Amplemarket&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIyg0', 'text': 'See web results for Amplemarket'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPvqbZsO-ZbtcIeCGfp3sSVQ71wcLJFx2KiCDKz8s&s,"['Work from home', 'Full-time', 'Health insurance']","{'schedule_type': 'Full-time', 'work_from_home': True}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJoUUNUcmlOQ0dhUUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJT1ZtbGxibTVoTEVGMWMzUnlhV0UiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVMXJNbXhzU1VOUlRrNWxNbFZJV1ZwdGVIRm9hREJSVnpoaFUwZzNRa290U1haMVpYcFpkekptYzFvelpFSnNkVlZMWldKU2JtWndTMll0YUc1RWRtNWtOelZzVG1GUVYzcEZkR3REVFVaaGFWcGZUWFJNWkRsMVJWbFRjR3RVUjJGT2VWWkRPVk5NV0hSVGEwUXRYMmRCTTNoRVVuUjVOWE5zUm1NNVRFSlNkRFZ4YVVVNE5GRlFZVk5ZTmt4dExVZzFUVkZ3TTNGMVJFcEpjMDlRY0U1d1UxaEhjR0ZDWVZWRlV6WklVRnBaUlRScUxUVjZPWFZ5YzFKUVYxVTNOVE5MV2tka1dVeEZNMXBWRWhkR2NsQklXa3htYVVjNGNWbDNZbXRRTWpaaGFXdEJjeG9pUVV4RlV6bDFUMXBKY2tWblUwdDVhV05WUWpoaVpVaHlaSFoyTjA5V1NHOVhkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzExIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYmdldGhlciIsImxpbmsiOiJodHRwczovL2pvYmdldGhlci5jb20vb2ZmZXIvNjNjZjlhZWNiZjlkZjVkNmFiYjljNzU0LWRhdGEtZW5naW5lZXI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer*,KTM Group North America,"  Mattighofen, Austria   ",via Talent.com,"The opportunities are endless when you are fearless

Driven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion.

To this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees.

That‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience.

With or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!

To ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE, we are also stepping on the gas in the area of IT and data integration.

Are you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you?

Then this is the right job for you.

THE TASKS... AWAITING YOU
‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).
‚Ä¢ provision of data using different technologies / paradigms (ETL, web services such as REST / SOAP / ODATA, Stream processing / Message Broker) in coordination with those responsible for source and target systems
‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)
‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)
‚Ä¢ coordination and cooperation with external service providers
‚Ä¢ orchestration and monitoring of automated process steps

HOW YOU CAN INSPIRE US
‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience
‚Ä¢ very good knowledge of relational database systems
‚Ä¢ mastery of at least one scripting or programming language
‚Ä¢ experience with web services (REST / SOAP / ODATA)
‚Ä¢ experience with data integration and / or orchestration tools would be an advantage
‚Ä¢ very good written and spoken English
‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation
‚Ä¢ independent and self-reliant working style as well as absolute reliability

WHAT YOU CAN LOOK FORWARD TO
‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer
‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu
‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit

Benefits

Flexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation. Professional

development You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System.

From seminars to in-house training, we'll get you ready for the front row. KTM MasterCard Gold Free Mastercard Gold in KTM Style.

Travel insurance coverage for the whole family included. Employee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together. Special rates

for employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us. Pension

scheme Each year, the company voluntarily pays additional life insurance for its employees","[{'items': [""The opportunities are endless when you are fearless\n\nDriven by the passion of over 6000 employees, KTM is the largest European motorcycle manufacturer with a revenue of over ‚Ç¨2 billion.\n\nTo this end, we consistently pursue a long-term strategy based on the four pillars of brand, globalization, innovation and employees.\n\nThat‚Äôs why we are looking for new, proactive colleagues to work with us and share this journey. With or without career experience.\n\nWith or without a university education. With one or two X chromosomes. Because, no matter who you are, in the end, all that matters to us, is what you can do!\n\nTo ensure that not only our motorbikes, but also our business processes are 100% READY TO RACE, we are also stepping on the gas in the area of IT and data integration.\n\nAre you a data engineer with a wide range of know-how in the area of databases and do you bring a lot of commitment, team spirit and service orientation with you?\n\nThen this is the right job for you.\n\nTHE TASKS... AWAITING YOU\n‚Ä¢ develop, test and monitor interfaces (on premise and cloud) using a data integration platform (Informatica IDMC).\n‚Ä¢ provision of data using different technologies / paradigms (ETL, web services such as REST / SOAP / ODATA, Stream processing / Message Broker) in coordination with those responsible for source and target systems\n‚Ä¢ transformation, mapping and preparation of data from different systems (e.g. SAP, Servicenow, ...)\n‚Ä¢ collaboration in the conception and technical implementation of data management architectures (databases, data warehouse, data lake)\n‚Ä¢ coordination and cooperation with external service providers\n‚Ä¢ orchestration and monitoring of automated process steps\n\nHOW YOU CAN INSPIRE US\n‚Ä¢ finished degree (university, FH) with focus on data engineering or equivalent education with relevant work experience\n‚Ä¢ very good knowledge of relational database systems\n‚Ä¢ mastery of at least one scripting or programming language\n‚Ä¢ experience with web services (REST / SOAP / ODATA)\n‚Ä¢ experience with data integration and / or orchestration tools would be an advantage\n‚Ä¢ very good written and spoken English\n‚Ä¢ communicative, committed personality with a structured, precise way of working and a high level of solution orientation\n‚Ä¢ independent and self-reliant working style as well as absolute reliability\n\nWHAT YOU CAN LOOK FORWARD TO\n‚Ä¢ the opportunity to help shape the future of Europe‚Äôs most successful motorcycle manufacturer\n‚Ä¢ flexitime model with the possibility of using up to 3 Fridays per month as time-off in lieu\n‚Ä¢ attractive social benefits, flexible working hours, and interesting training and development opportunities, as well as a unique corporate culture characterized by collegiality and team spirit\n\nBenefits\n\nFlexible working hours Depending on your area of responsibility, location and department, we offer you various working time models to suit your private and professional situation. Professional\n\ndevelopment You'll have access to continuing education and training opportunities through our state-of-the-art Learning Management System.\n\nFrom seminars to in-house training, we'll get you ready for the front row. KTM MasterCard Gold Free Mastercard Gold in KTM Style.\n\nTravel insurance coverage for the whole family included. Employee events Work hard, play hard. At the end of the year or summer party, our successes are duly celebrated together. Special rates\n\nfor employees Special conditions for our employees when purchasing our products - from clothing to riding gear to motorcycles - are a matter of course for us. Pension\n\nscheme Each year, the company voluntarily pays additional life insurance for its employees""]}]","[{'link': 'https://www.google.com/search?sca_esv=552448117&q=KTM+Group+North+America&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAII_A0', 'text': 'See web results for KTM Group North America'}]",,"['Full-time', 'No degree mentioned']",{'schedule_type': 'Full-time'},eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyKiIsImh0aWRvY2lkIjoiWkxnYWhRRXdOYUlBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU9WbWxsYm01aExFRjFjM1J5YVdFIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVTFyTW14c1RIZGhaRk5KVTIwNFZqUnFVVlpYZDBGS2FUSXlSbXROU0dWd1lVTnBURFYxY21sMlZIWXpNVFZTUTFaUE1tTk9hV3RPYW5aT1JTMXJSVzFMZWtkdVgzSlhjMjh6VUROTlIydGpkRTlsWVZWMmR6TlJTbHBSUjJOc1NEQjZhbFUwWXpGT0xUWnZUMHMyYVRSeVJVUlBXRGhZZG5kMVNVSnlXRjlYVEVSa2MwWm9YMDgzUWpKaGJEZHNkREY0VGxKalRFTmZRekpOVlZSYWEyNDFUamt6YjNSUVVWUlpNMnBWTVdOSVJVeHBWa1ZaRWhkR2NsQklXa3htYVVjNGNWbDNZbXRRTWpaaGFXdEJjeG9pUVV4RlV6bDFVR0U1U1hCMVFtUjBVMjFXU2xSMlRXNW5kVlJ6UlVSMGNXbG1RUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEzIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFRhbGVudC5jb20iLCJsaW5rIjoiaHR0cHM6Ly9hdC50YWxlbnQuY29tL3ZpZXc/aWQ9NDcwZTViMjRhNmU4XHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ==
Data Engineer (m/f/d),Berger Logistik GmbH,"  W√∂rgl, Austria   ",via UNTERLAND.jobs,"Berger Logistik GmbH is part of a group of companies in the field of logistics and vehicle technology. As an established medium-sized company based in Tyrol and several locations in Austria, we focus on high-quality, tailor-made logistics products and industry solutions with a European and global orientation for all modes of transport (road, ocean, rail, and air): with excellent service, excellent know-how and our own, highly modern, and ecologically payload-optimized truck fleet.

Your Tasks and Priorities
‚Ä¢ Supporting Datawarehouse operations
‚Ä¢ Building data processing pipelines
‚Ä¢ Supporting the creation of data models
‚Ä¢ Working with an agile team and contributing to the continuous improvement of the teams‚Äô skills and practices

Your Profile
‚Ä¢ Experience working with databases
‚Ä¢ Experience in programming and a demonstrable ability to learn new programming languages. There is no strict requirement on the knowledge of any particular languages. Commonly used languages include Python... C#, PowerShell and various dialects and procedural extensions of SQL
‚Ä¢ Understanding of modern cloud-based data architecture and cloud services, preferably with Microsoft Azure
‚Ä¢ Willingness to take on technical challenges
‚Ä¢ Committed to self-learning, knowledge sharing and teamwork
‚Ä¢ Strong focus on stakeholders and quality
‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand different technical ecosystems and data
‚Ä¢ English and German proficiency (German less important for candidates with excellent technical skills)

Nice to Have
‚Ä¢ Knowledge of a reporting frontend
‚Ä¢ Knowledge of a web frontend programming language (JavaScript, React, Angular‚Ä¶)
‚Ä¢ Working with APIs

Our Offer
‚Ä¢ Supportive, motivated, and dynamic team
‚Ä¢ Flexible working time and location arrangements (within EU)
‚Ä¢ Exciting tasks, technical challenges, and development opportunities
‚Ä¢ Flat hierarchies, direct and uncomplicated communication
‚Ä¢ Current Microsoft Cloud Technology Stack, constantly improved by the team
‚Ä¢ State-of-the-art IT and communications equipment
‚Ä¢ Mobility package (‚ÄúKlimaTicket Tyrol‚Äù for public transport, bike leasing)
‚Ä¢ Additional company benefits such as childcare facilities at company headquarters, training and further education opportunities, electric cars & e-bikes for personal errands, company events

We will determine classification and salary based on your professional and personal competence in line with the market. For this position the salary consists of EUR 45,000.00/year. With appropriate qualifications and professional experience, there is willingness to overpay.

Have we piqued your interest, and would you like to become part of our team?
Then please send your application to:

Berger Logistik GmbH
Bahnhofplatz 1
6300 W√∂rgl

jobs@berger-logistik.com

Please send us your CV in PDF format, your LinkedIn or Git Hub profile.

Statement on equal opportunities

We promote an inclusive and open working environment where everyone can show themselves as they are. At Berger Logistik GmbH, every applicant is welcome: regardless of origin, nationality, faith, disability, age, marital status, partnership status, sexual orientation, gender and other legally protected grounds","[{'items': ['Berger Logistik GmbH is part of a group of companies in the field of logistics and vehicle technology. As an established medium-sized company based in Tyrol and several locations in Austria, we focus on high-quality, tailor-made logistics products and industry solutions with a European and global orientation for all modes of transport (road, ocean, rail, and air): with excellent service, excellent know-how and our own, highly modern, and ecologically payload-optimized truck fleet.\n\nYour Tasks and Priorities\n‚Ä¢ Supporting Datawarehouse operations\n‚Ä¢ Building data processing pipelines\n‚Ä¢ Supporting the creation of data models\n‚Ä¢ Working with an agile team and contributing to the continuous improvement of the teams‚Äô skills and practices\n\nYour Profile\n‚Ä¢ Experience working with databases\n‚Ä¢ Experience in programming and a demonstrable ability to learn new programming languages. There is no strict requirement on the knowledge of any particular languages. Commonly used languages include Python... C#, PowerShell and various dialects and procedural extensions of SQL\n‚Ä¢ Understanding of modern cloud-based data architecture and cloud services, preferably with Microsoft Azure\n‚Ä¢ Willingness to take on technical challenges\n‚Ä¢ Committed to self-learning, knowledge sharing and teamwork\n‚Ä¢ Strong focus on stakeholders and quality\n‚Ä¢ Good analytical and problem-solving skills, critical thinking, and an ability to explore and understand different technical ecosystems and data\n‚Ä¢ English and German proficiency (German less important for candidates with excellent technical skills)\n\nNice to Have\n‚Ä¢ Knowledge of a reporting frontend\n‚Ä¢ Knowledge of a web frontend programming language (JavaScript, React, Angular‚Ä¶)\n‚Ä¢ Working with APIs\n\nOur Offer\n‚Ä¢ Supportive, motivated, and dynamic team\n‚Ä¢ Flexible working time and location arrangements (within EU)\n‚Ä¢ Exciting tasks, technical challenges, and development opportunities\n‚Ä¢ Flat hierarchies, direct and uncomplicated communication\n‚Ä¢ Current Microsoft Cloud Technology Stack, constantly improved by the team\n‚Ä¢ State-of-the-art IT and communications equipment\n‚Ä¢ Mobility package (‚ÄúKlimaTicket Tyrol‚Äù for public transport, bike leasing)\n‚Ä¢ Additional company benefits such as childcare facilities at company headquarters, training and further education opportunities, electric cars & e-bikes for personal errands, company events\n\nWe will determine classification and salary based on your professional and personal competence in line with the market. For this position the salary consists of EUR 45,000.00/year. With appropriate qualifications and professional experience, there is willingness to overpay.\n\nHave we piqued your interest, and would you like to become part of our team?\nThen please send your application to:\n\nBerger Logistik GmbH\nBahnhofplatz 1\n6300 W√∂rgl\n\njobs@berger-logistik.com\n\nPlease send us your CV in PDF format, your LinkedIn or Git Hub profile.\n\nStatement on equal opportunities\n\nWe promote an inclusive and open working environment where everyone can show themselves as they are. At Berger Logistik GmbH, every applicant is welcome: regardless of origin, nationality, faith, disability, age, marital status, partnership status, sexual orientation, gender and other legally protected grounds']}]","[{'link': 'http://www.berger-logistik.com/', 'text': 'berger-logistik.com'}, {'link': 'https://www.google.com/search?sca_esv=552448117&q=Berger+Logistik+GmbH&sa=X&ved=0ahUKEwi3xaXjgrmAAxVKTDABHVuTCLI4WhCYkAIIsA4', 'text': 'See web results for Berger Logistik GmbH'}]",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRu4Dl82SlfeE2eqle8nKlhWNYdZ4LPyc3wB0OFVxQ&s,"['10 days ago', 'Full-time', 'No degree mentioned']","{'posted_at': '10 days ago', 'schedule_type': 'Full-time'}",eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIChtL2YvZCkiLCJodGlkb2NpZCI6InF2Tl9FQ3pWZHMwQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lPVm1sbGJtNWhMRUYxYzNSeWFXRSIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVUxck1teHNTVkY0YVZGM1FtMHRka0YxUVVSdGIwOXJaM0JqVkhoeE5ucHViMlU0VWs1RVRUaGhWbFp0ZG5aWFIwWklhMWhJWVV4bFRubHhhMlJVVEdsWWNXNHllamR2VjB0U01XdGhNelJaU1c5ek5uZEVSV0ZGY0cxaVNERnNhekpyVkdoc1IyRkxTRGR6WkU5T01rSmhiVUYwYkdaVU4wdHNOMjFIVTFGUVdXZHpaekZqVXpjM1dFUlVNamRYVWxkYWRURmtSMjV5TXpGTlZ6SnJja1IyYVRsWVVrMUlaR1J1ZDJaWVpuTmpZbmhhZUV0RFRtSnhWblZUTFU4d1RsVkVlbXhPYkMxSFZrUlRFaGRHY2xCSVdreG1hVWM0Y1ZsM1ltdFFNalpoYVd0QmN4b2lRVXhGVXpsMVRVZFViMlJEVVdwdFJrNXpMVGcyY1RWSmEwaGlia0Z4TkRSZlVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gVU5URVJMQU5ELmpvYnMiLCJsaW5rIjoiaHR0cHM6Ly93d3cudW50ZXJsYW5kLmpvYnMvam9iLzE3NjY2L2RhdGEtZW5naW5lZXItbS1mLWQvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0=
